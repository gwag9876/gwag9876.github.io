{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "W = 1\n",
    "ZASXDDC\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y) \n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w_list = []\n",
    "mse_list = []\n",
    "\n",
    "for w in np.arange(0.0, 4.1, 0.1):\n",
    "    print(\"w=\" , w)\n",
    "    l_sum = 0\n",
    "    for x_val, y_val in zip(x_data, y_data): #3번반복.\n",
    "        y_pred_val = forward(x_val)\n",
    "        l =  loss(x_val, y_val) \n",
    "        l_sum += l\n",
    "        \n",
    "    print(\"MSE = \", l_sum / 3)\n",
    "    w_list.append(w)\n",
    "    mse_list.append(l_sum / 3)\n",
    "\n",
    "plt.plot(w_list, mse_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-1cdbf7a455d2>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1cdbf7a455d2>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    W = 1 ZASXDDC def forward(x): return w*x\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "W = 1 ZASXDDC \n",
    "def forward(x): return w*x\n",
    "\n",
    "def loss(x,y): y_pred = forward(x) return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0] y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w_list = [] mse_list = []\n",
    "\n",
    "for w in np.arange(0.0, 4.1, 0.1): print(\"w=\" , w) l_sum = 0 for x_val, y_val in zip(x_data, y_data): #3번반복. y_pred_val = forward(x_val) l = loss(x_val, y_val) l_sum += l\n",
    "\n",
    "print(\"MSE = \", l_sum / 3)\n",
    "w_list.append(w)\n",
    "mse_list.append(l_sum / 3)\n",
    "plt.plot(w_list, mse_list) plt.ylabel('loss') plt.xlabel('w') plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0 \n",
      "\n",
      "\tgrad: 1.0 2.0 -2.0\n",
      "\tgrad: 2.0 4.0 -7.84\n",
      "\tgrad: 3.0 6.0 -16.2288\n",
      "progress: 0 w= 1.260688 loss= 4.919240100095999 \n",
      "\n",
      "\tgrad: 1.0 2.0 -1.478624\n",
      "\tgrad: 2.0 4.0 -5.796206079999999\n",
      "\tgrad: 3.0 6.0 -11.998146585599997\n",
      "progress: 1 w= 1.453417766656 loss= 2.688769240265834 \n",
      "\n",
      "\tgrad: 1.0 2.0 -1.093164466688\n",
      "\tgrad: 2.0 4.0 -4.285204709416961\n",
      "\tgrad: 3.0 6.0 -8.87037374849311\n",
      "progress: 2 w= 1.5959051959019805 loss= 1.4696334962911515 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.8081896081960389\n",
      "\tgrad: 2.0 4.0 -3.1681032641284723\n",
      "\tgrad: 3.0 6.0 -6.557973756745939\n",
      "progress: 3 w= 1.701247862192685 loss= 0.8032755585999681 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.59750427561463\n",
      "\tgrad: 2.0 4.0 -2.3422167604093502\n",
      "\tgrad: 3.0 6.0 -4.848388694047353\n",
      "progress: 4 w= 1.7791289594933983 loss= 0.43905614881022015 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.44174208101320334\n",
      "\tgrad: 2.0 4.0 -1.7316289575717576\n",
      "\tgrad: 3.0 6.0 -3.584471942173538\n",
      "progress: 5 w= 1.836707389300983 loss= 0.2399802903801062 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.3265852213980338\n",
      "\tgrad: 2.0 4.0 -1.2802140678802925\n",
      "\tgrad: 3.0 6.0 -2.650043120512205\n",
      "progress: 6 w= 1.8792758133988885 loss= 0.1311689630744999 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.241448373202223\n",
      "\tgrad: 2.0 4.0 -0.946477622952715\n",
      "\tgrad: 3.0 6.0 -1.9592086795121197\n",
      "progress: 7 w= 1.910747160155559 loss= 0.07169462478267678 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.17850567968888198\n",
      "\tgrad: 2.0 4.0 -0.6997422643804168\n",
      "\tgrad: 3.0 6.0 -1.4484664872674653\n",
      "progress: 8 w= 1.9340143044689266 loss= 0.03918700813247573 \n",
      "\n",
      "\tgrad: 1.0 2.0 -0.13197139106214673\n",
      "\tgrad: 2.0 4.0 -0.5173278529636143\n",
      "\tgrad: 3.0 6.0 -1.0708686556346834\n",
      "progress: 9 w= 1.9512159834655312 loss= 0.021418922423117836 \n",
      "\n",
      "predict (after training) 4 hours 7.804863933862125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]    # y = 2x\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w_list = []\n",
    "l_list = []\n",
    "\n",
    "w = 1.0\n",
    "\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)*(y_pred - y)\n",
    "\n",
    "def gradient(x,y):\n",
    "    return 2*x*(x*w-y)\n",
    "\n",
    "print(\"predict (before training)\", 4, forward(4),\"\\n\")\n",
    "\n",
    "for epoch in range (10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient(x_val, y_val)\n",
    "        w = w - 0.01*grad\n",
    "        print(\"\\tgrad:\", x_val, y_val, grad)\n",
    "        l = loss(x_val, y_val)\n",
    "        \n",
    "    print(\"progress:\", epoch, \"w=\", w, \"loss=\", l,\"\\n\")\n",
    "    w_list.append(w)\n",
    "    l_list.append(l)\n",
    "    \n",
    "print(\"predict (after training)\", \"4 hours\", forward(4))\n",
    "\n",
    "plt.plot(w_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad1 =  -2.0 1.0 3.0\n",
      "\tgrad2 =  -1.96 1.0 3.0\n",
      "\tgrad1 =  -15.046399999999998 2.0 8.0\n",
      "\tgrad2 =  -5.115776 2.0 8.0\n",
      "\tgrad1 =  -22.563912960000028 3.0 15.0\n",
      "\tgrad2 =  4.663208678400007 3.0 15.0\n",
      "progress: 0 w1= 1.3961031296000002 w2= 1.024125673216 loss= 0.40615790016367775 \n",
      "\n",
      "\tgrad1 =  -1.1595423943679997 1.0 3.0\n",
      "\tgrad2 =  -1.1363515464806397 1.0 3.0\n",
      "\tgrad1 =  -2.385819267709337 2.0 8.0\n",
      "\tgrad2 =  -0.8111785510211718 2.0 8.0\n",
      "\tgrad1 =  18.26664549408025 3.0 15.0\n",
      "\tgrad2 =  -3.775106735443245 3.0 15.0\n",
      "progress: 1 w1= 1.2488902912799709 w2= 1.0813520415454505 loss= 0.2661850586929505 \n",
      "\n",
      "\tgrad1 =  -1.3395153343491568 1.0 3.0\n",
      "\tgrad2 =  -1.3127250276621742 1.0 3.0\n",
      "\tgrad1 =  -6.095197102896051 2.0 8.0\n",
      "\tgrad2 =  -2.072367014984657 2.0 8.0\n",
      "\tgrad1 =  4.585421282176149 3.0 15.0\n",
      "\tgrad2 =  -0.9476537316497371 3.0 15.0\n",
      "progress: 2 w1= 1.2773832028306615 w2= 1.1246794992884162 loss= 0.016773533415326464 \n",
      "\n",
      "\tgrad1 =  -1.195874595761845 1.0 3.0\n",
      "\tgrad2 =  -1.1719571038466077 1.0 3.0\n",
      "\tgrad1 =  -4.55867251354492 2.0 8.0\n",
      "\tgrad2 =  -1.5499486546052736 2.0 8.0\n",
      "\tgrad1 =  8.460967246782616 3.0 15.0\n",
      "\tgrad2 =  -1.74859989766842 3.0 15.0\n",
      "progress: 3 w1= 1.250319001455903 w2= 1.1693845558496192 loss= 0.05710920325748728 \n",
      "\n",
      "\tgrad1 =  -1.1605928853889562 1.0 3.0\n",
      "\tgrad2 =  -1.137381027681176 1.0 3.0\n",
      "\tgrad1 =  -4.726268372063743 2.0 8.0\n",
      "\tgrad2 =  -1.6069312465016736 2.0 8.0\n",
      "\tgrad1 =  6.71708811686781 3.0 15.0\n",
      "\tgrad2 =  -1.388198210819354 3.0 15.0\n",
      "progress: 4 w1= 1.2420167328617517 w2= 1.210709660699641 loss= 0.035993838578995366 \n",
      "\n",
      "\tgrad1 =  -1.094547212877215 1.0 3.0\n",
      "\tgrad2 =  -1.0726562686196708 1.0 3.0\n",
      "\tgrad1 =  -4.362229866129837 2.0 8.0\n",
      "\tgrad2 =  -1.4831581544841441 2.0 8.0\n",
      "\tgrad1 =  6.805151057851852 3.0 15.0\n",
      "\tgrad2 =  -1.4063978852893797 3.0 15.0\n",
      "progress: 5 w1= 1.2285329930733038 w2= 1.250331783783573 loss= 0.03694380416384158 \n",
      "\n",
      "\tgrad1 =  -1.0422704462862464 1.0 3.0\n",
      "\tgrad2 =  -1.0214250373605216 1.0 3.0\n",
      "\tgrad1 =  -4.184681132327832 2.0 8.0\n",
      "\tgrad2 =  -1.4227915849914616 2.0 8.0\n",
      "\tgrad1 =  6.327799735612992 3.0 15.0\n",
      "\tgrad2 =  -1.3077452786933392 3.0 15.0\n",
      "progress: 6 w1= 1.2175245115033146 w2= 1.287851402794026 loss= 0.03194269285712283 \n",
      "\n",
      "\tgrad1 =  -0.9892481714053183 1.0 3.0\n",
      "\tgrad2 =  -0.9694632079772125 1.0 3.0\n",
      "\tgrad1 =  -3.9619196590634616 2.0 8.0\n",
      "\tgrad2 =  -1.3470526840815786 2.0 8.0\n",
      "\tgrad1 =  6.054757081485548 3.0 15.0\n",
      "\tgrad2 =  -1.251316463507031 3.0 15.0\n",
      "progress: 7 w1= 1.2064886189931467 w2= 1.3235297263496841 loss= 0.02924553167988154 \n",
      "\n",
      "\tgrad1 =  -0.9399633093143382 1.0 3.0\n",
      "\tgrad2 =  -0.9211640431280514 1.0 3.0\n",
      "\tgrad1 =  -3.7677140647432807 2.0 8.0\n",
      "\tgrad2 =  -1.281022782012716 2.0 8.0\n",
      "\tgrad1 =  5.737379731322065 3.0 15.0\n",
      "\tgrad2 =  -1.1857251444732242 3.0 15.0\n",
      "progress: 8 w1= 1.1961915954205022 w2= 1.357408846045824 loss= 0.026259911808386868 \n",
      "\n",
      "\tgrad1 =  -0.8927991170673479 1.0 3.0\n",
      "\tgrad2 =  -0.874943134726001 1.0 3.0\n",
      "\tgrad1 =  -3.5776407907930334 2.0 8.0\n",
      "\tgrad2 =  -1.216397868869631 2.0 8.0\n",
      "\tgrad1 =  5.454552937271281 3.0 15.0\n",
      "\tgrad2 =  -1.1272742737027173 3.0 15.0\n",
      "progress: 9 w1= 1.1863504651263932 w2= 1.3895949988188074 loss= 0.02373473545981694 \n",
      "\n",
      "\tgrad1 =  -0.8481090721095992 1.0 3.0\n",
      "\tgrad2 =  -0.8311468906674069 1.0 3.0\n",
      "\tgrad1 =  -3.398886729272647 2.0 8.0\n",
      "\tgrad2 =  -1.1556214879527005 2.0 8.0\n",
      "\tgrad1 =  5.179893409385372 3.0 15.0\n",
      "\tgrad2 =  -1.070511304606299 3.0 15.0\n",
      "progress: 10 w1= 1.177021489046362 w2= 1.4201677956510714 loss= 0.021404629733114383 \n",
      "\n",
      "\tgrad1 =  -0.8056214306051332 1.0 3.0\n",
      "\tgrad2 =  -0.7895090019930304 1.0 3.0\n",
      "\tgrad1 =  -3.22850732198674 2.0 8.0\n",
      "\tgrad2 =  -1.0976924894754916 2.0 8.0\n",
      "\tgrad1 =  4.920919575260324 3.0 15.0\n",
      "\tgrad2 =  -1.0169900455538006 3.0 15.0\n",
      "progress: 11 w1= 1.1681535808196775 w2= 1.4492097110212947 loss= 0.019317841926467263 \n",
      "\n",
      "\tgrad1 =  -0.7652734163180561 1.0 3.0\n",
      "\tgrad2 =  -0.7499679479916947 1.0 3.0\n",
      "\tgrad1 =  -3.066847672529164 2.0 8.0\n",
      "\tgrad2 =  -1.0427282086599163 2.0 8.0\n",
      "\tgrad1 =  4.67429657646197 3.0 15.0\n",
      "\tgrad2 =  -0.966021292468799 3.0 15.0\n",
      "progress: 12 w1= 1.1597318259435299 w2= 1.4767968855124987 loss= 0.01743004875714111 \n",
      "\n",
      "\tgrad1 =  -0.726942577087943 1.0 3.0\n",
      "\tgrad2 =  -0.7124037255461841 1.0 3.0\n",
      "\tgrad1 =  -2.9132251808515406 2.0 8.0\n",
      "\tgrad2 =  -0.9904965614895218 2.0 8.0\n",
      "\tgrad1 =  4.440225543387989 3.0 15.0\n",
      "\tgrad2 =  -0.9176466123001852 3.0 15.0\n",
      "progress: 13 w1= 1.1517312480890447 w2= 1.5030023545058575 loss= 0.015728095420177484 \n",
      "\n",
      "\tgrad1 =  -0.6905327948101956 1.0 3.0\n",
      "\tgrad2 =  -0.6767221389139912 1.0 3.0\n",
      "\tgrad1 =  -2.767316352491349 2.0 8.0\n",
      "\tgrad2 =  -0.9408875598470594 2.0 8.0\n",
      "\tgrad1 =  4.217814189700988 3.0 15.0\n",
      "\tgrad2 =  -0.871681599204873 3.0 15.0\n",
      "progress: 14 w1= 1.1441315976650501 w2= 1.5278952674855169 loss= 0.01419191366966181 \n",
      "\n",
      "\tgrad1 =  -0.655946269698866 1.0 3.0\n",
      "\tgrad2 =  -0.6428273443048891 1.0 3.0\n",
      "\tgrad1 =  -2.6287094135577007 2.0 8.0\n",
      "\tgrad2 =  -0.8937612006096174 2.0 8.0\n",
      "\tgrad1 =  4.0065632870855445 3.0 15.0\n",
      "\tgrad2 =  -0.8280230793310217 3.0 15.0\n",
      "progress: 15 w1= 1.1369125216267604 w2= 1.5515413837279723 loss= 0.012805899462889096 \n",
      "\n",
      "\tgrad1 =  -0.623092189290535 1.0 3.0\n",
      "\tgrad2 =  -0.610630345504724 1.0 3.0\n",
      "\tgrad1 =  -2.4970468124423846 2.0 8.0\n",
      "\tgrad2 =  -0.848995916230411 2.0 8.0\n",
      "\tgrad1 =  3.8058865889900027 3.0 15.0\n",
      "\tgrad2 =  -0.7865498950579273 3.0 15.0\n",
      "progress: 16 w1= 1.1300550457541896 w2= 1.5740031452959031 loss= 0.011555207773285364 \n",
      "\n",
      "\tgrad1 =  -0.5918836178998141 1.0 3.0\n",
      "\tgrad2 =  -0.5800459455418183 1.0 3.0\n",
      "\tgrad1 =  -2.371978102116856 2.0 8.0\n",
      "\tgrad2 =  -0.8064725547197327 2.0 8.0\n",
      "\tgrad1 =  3.6152632347257025 3.0 15.0\n",
      "\tgrad2 =  -0.7471544018433178 3.0 15.0\n",
      "progress: 17 w1= 1.1235410306070992 w2= 1.5953398743169518 loss= 0.010426677066953846 \n",
      "\n",
      "\tgrad1 =  -0.5622381901518985 1.0 3.0\n",
      "\tgrad2 =  -0.5509934263488603 1.0 3.0\n",
      "\tgrad1 =  -2.2531738624371656 2.0 8.0\n",
      "\tgrad2 =  -0.7660791132286349 2.0 8.0\n",
      "\tgrad1 =  3.4341868680316594 3.0 15.0\n",
      "\tgrad2 =  -0.7097319527265498 3.0 15.0\n",
      "progress: 18 w1= 1.1173532824526735 w2= 1.6156079192399921 loss= 0.009408359850845175 \n",
      "\n",
      "\tgrad1 =  -0.5340775966146687 1.0 3.0\n",
      "\tgrad2 =  -0.5233960446823751 1.0 3.0\n",
      "\tgrad1 =  -2.140320055608697 2.0 8.0\n",
      "\tgrad2 =  -0.727708818906958 2.0 8.0\n",
      "\tgrad1 =  3.262180219232796 3.0 15.0\n",
      "\tgrad2 =  -0.674183911974783 3.0 15.0\n",
      "progress: 19 w1= 1.1114754567825793 w2= 1.6348608069956332 loss= 0.008489497279837914 \n",
      "\n",
      "\tgrad1 =  -0.507327472443575 1.0 3.0\n",
      "\tgrad2 =  -0.49718092299470307 1.0 3.0\n",
      "\tgrad1 =  -2.03311873216623 2.0 8.0\n",
      "\tgrad2 =  -0.6912603689365184 2.0 8.0\n",
      "\tgrad1 =  3.0987887256527813 3.0 15.0\n",
      "\tgrad2 =  -0.6404163366349103 3.0 15.0\n",
      "progress: 20 w1= 1.1058920315721494 w2= 1.6531493832812947 loss= 0.007660374606541332 \n",
      "\n",
      "\tgrad1 =  -0.4819171702931122 1.0 3.0\n",
      "\tgrad2 =  -0.47227882688724954 1.0 3.0\n",
      "\tgrad1 =  -1.9312867503947473 2.0 8.0\n",
      "\tgrad2 =  -0.6566374951342127 2.0 8.0\n",
      "\tgrad1 =  2.943580977284057 3.0 15.0\n",
      "\tgrad2 =  -0.6083400686387179 3.0 15.0\n",
      "progress: 21 w1= 1.1005882610061875 w2= 1.6705219471878965 loss= 0.006912227903846483 \n",
      "\n",
      "\tgrad1 =  -0.45777958361183213 1.0 3.0\n",
      "\tgrad2 =  -0.4486239919395949 1.0 3.0\n",
      "\tgrad1 =  -1.834555187329535 2.0 8.0\n",
      "\tgrad2 =  -0.623748763692042 2.0 8.0\n",
      "\tgrad1 =  2.7961470481148964 3.0 15.0\n",
      "\tgrad2 =  -0.5778703899437474 3.0 15.0\n",
      "progress: 22 w1= 1.0955501382344521 w2= 1.6870243786436503 loss= 0.006237148547905232 \n",
      "\n",
      "\tgrad1 =  -0.43485096624379516 1.0 3.0\n",
      "\tgrad2 =  -0.4261539469189195 1.0 3.0\n",
      "\tgrad1 =  -1.7426685774940864 2.0 8.0\n",
      "\tgrad2 =  -0.5925073163479908 2.0 8.0\n",
      "\tgrad1 =  2.656097583757848 3.0 15.0\n",
      "\tgrad2 =  -0.5489268339766156 3.0 15.0\n",
      "progress: 23 w1= 1.0907643578342525 w2= 1.7027002596160856 loss= 0.005628000496546177 \n",
      "\n",
      "\tgrad1 =  -0.4130707650993237 1.0 3.0\n",
      "\tgrad2 =  -0.40480934979733707 1.0 3.0\n",
      "\tgrad1 =  -1.6553842546471884 2.0 8.0\n",
      "\tgrad2 =  -0.5628306465800428 2.0 8.0\n",
      "\tgrad1 =  2.523062718450703 3.0 15.0\n",
      "\tgrad2 =  -0.5214329618131508 3.0 15.0\n",
      "progress: 24 w1= 1.0862182808472107 w2= 1.717590989197991 loss= 0.0050783445876805364 \n",
      "\n",
      "\tgrad1 =  -0.39238145990959694 1.0 3.0\n",
      "\tgrad2 =  -0.3845338307114048 1.0 3.0\n",
      "\tgrad1 =  -1.5724717056365023 2.0 8.0\n",
      "\tgrad2 =  -0.5346403799164108 2.0 8.0\n",
      "\tgrad1 =  2.3966911158633515 3.0 15.0\n",
      "\tgrad2 =  -0.49531616394509115 3.0 15.0\n",
      "progress: 25 w1= 1.0818999013440382 w2= 1.73173589294372 loss= 0.004582370554532713 \n",
      "\n",
      "\tgrad1 =  -0.3727284114244833 1.0 3.0\n",
      "\tgrad2 =  -0.3652738431959932 1.0 3.0\n",
      "\tgrad1 =  -1.4937119633240599 2.0 8.0\n",
      "\tgrad2 =  -0.5078620675301799 2.0 8.0\n",
      "\tgrad1 =  2.276649035579851 3.0 15.0\n",
      "\tgrad2 =  -0.4705074673531726 3.0 15.0\n",
      "progress: 26 w1= 1.0777978147357252 w2= 1.7451723267245136 loss= 0.004134835581775402 \n",
      "\n",
      "\tgrad1 =  -0.35405971707952233 1.0 3.0\n",
      "\tgrad2 =  -0.34697852273793206 1.0 3.0\n",
      "\tgrad1 =  -1.4188970277610622 2.0 8.0\n",
      "\tgrad2 =  -0.482424989438762 2.0 8.0\n",
      "\tgrad1 =  2.162619453528343 3.0 15.0\n",
      "\tgrad2 =  -0.4469413537291871 3.0 15.0\n",
      "progress: 27 w1= 1.0739011876488476 w2= 1.7579357753835723 loss= 0.0037310088927198135 \n",
      "\n",
      "\tgrad1 =  -0.3363260739351599 1.0 3.0\n",
      "\tgrad2 =  -0.32959955245645745 1.0 3.0\n",
      "\tgrad1 =  -1.3478293170474345 2.0 8.0\n",
      "\tgrad2 =  -0.45826196779612616 2.0 8.0\n",
      "\tgrad1 =  2.0543012241544467 3.0 15.0\n",
      "\tgrad2 =  -0.42455558632525126 3.0 15.0\n",
      "progress: 28 w1= 1.0701997293171293 w2= 1.7700599464493507 loss= 0.0033666217391581997 \n",
      "\n",
      "\tgrad1 =  -0.3194806484670405 1.0 3.0\n",
      "\tgrad2 =  -0.313091035497699 1.0 3.0\n",
      "\tgrad1 =  -1.2803211454731667 2.0 8.0\n",
      "\tgrad2 =  -0.43530918946088093 2.0 8.0\n",
      "\tgrad1 =  1.9514082853006158 3.0 15.0\n",
      "\tgrad2 =  -0.40329104562879436 3.0 15.0\n",
      "progress: 29 w1= 1.066683664403525 w2= 1.7815768591552246 loss= 0.0030378222782357477 \n",
      "\n",
      "\tgrad1 =  -0.30347895288250104 1.0 3.0\n",
      "\tgrad2 =  -0.2974093738248511 1.0 3.0\n",
      "\tgrad1 =  -1.216194227869238 2.0 8.0\n",
      "\tgrad2 =  -0.4135060374755426 2.0 8.0\n",
      "\tgrad1 =  1.853668902673192 3.0 15.0\n",
      "\tgrad2 =  -0.38309157321914 3.0 15.0\n",
      "progress: 30 w1= 1.0633437071843101 w2= 1.79251692900042 loss= 0.0027411348553956355 \n",
      "\n",
      "\tgrad1 =  -0.28827872763053985 1.0 3.0\n",
      "\tgrad2 =  -0.2825131530779288 1.0 3.0\n",
      "\tgrad1 =  -1.1552792087611152 2.0 8.0\n",
      "\tgrad2 =  -0.3927949309787806 2.0 8.0\n",
      "\tgrad1 =  1.760824952226006 3.0 15.0\n",
      "\tgrad2 =  -0.3639038234600491 3.0 15.0\n",
      "progress: 31 w1= 1.0601710370259665 w2= 1.8029090480755876 loss= 0.002473423264190966 \n",
      "\n",
      "\tgrad1 =  -0.27383982979689137 1.0 3.0\n",
      "\tgrad2 =  -0.2683630332009539 1.0 3.0\n",
      "\tgrad1 =  -1.0974152151125125 2.0 8.0\n",
      "\tgrad2 =  -0.3731211731382551 2.0 8.0\n",
      "\tgrad1 =  1.6726312384647173 3.0 15.0\n",
      "\tgrad2 =  -0.34567712261605266 3.0 15.0\n",
      "progress: 32 w1= 1.0571572750904132 w2= 1.8127806613651403 loss= 0.002231857594236497 \n",
      "\n",
      "\tgrad1 =  -0.26012412708889343 1.0 3.0\n",
      "\tgrad2 =  -0.25492164454711563 1.0 3.0\n",
      "\tgrad1 =  -1.0424494314685475 2.0 8.0\n",
      "\tgrad2 =  -0.35443280669930743 2.0 8.0\n",
      "\tgrad1 =  1.588854846900638 3.0 15.0\n",
      "\tgrad2 =  -0.3283633350261361 3.0 15.0\n",
      "progress: 33 w1= 1.0542944622069812 w2= 1.822157839227866 loss= 0.002013884316956949 \n",
      "\n",
      "\tgrad1 =  -0.24709539713030537 1.0 3.0\n",
      "\tgrad2 =  -0.2421534891877002 1.0 3.0\n",
      "\tgrad1 =  -0.9902366963790143 2.0 8.0\n",
      "\tgrad2 =  -0.33668047676886914 2.0 8.0\n",
      "\tgrad1 =  1.5092745289373326 3.0 15.0\n",
      "\tgrad2 =  -0.3119167359803825 3.0 15.0\n",
      "progress: 34 w1= 1.051575037852701 w2= 1.8310653462472355 loss= 0.0018171992928934803 \n",
      "\n",
      "\tgrad1 =  -0.23471923180012766 1.0 3.0\n",
      "\tgrad2 =  -0.23002484716412486 1.0 3.0\n",
      "\tgrad1 =  -0.9406391190355095 2.0 8.0\n",
      "\tgrad2 =  -0.31981730047207435 2.0 8.0\n",
      "\tgrad1 =  1.4336801175655012 3.0 15.0\n",
      "\tgrad2 =  -0.29629389096353265 3.0 15.0\n",
      "progress: 35 w1= 1.048991820185402 w2= 1.8395267066332328 loss= 0.0016397234152367257 \n",
      "\n",
      "\tgrad1 =  -0.22296294636273029 1.0 3.0\n",
      "\tgrad2 =  -0.21850368743547577 1.0 3.0\n",
      "\tgrad1 =  -0.8935257151096607 2.0 8.0\n",
      "\tgrad2 =  -0.3037987431372855 2.0 8.0\n",
      "\tgrad1 =  1.361871972324245 3.0 15.0\n",
      "\tgrad2 =  -0.2814535409470089 3.0 15.0\n",
      "progress: 36 w1= 1.0465379870768834 w2= 1.8475642663484306 loss= 0.0014795806321246825 \n",
      "\n",
      "\tgrad1 =  -0.2117954931493724 1.0 3.0\n",
      "\tgrad2 =  -0.20755958328638435 1.0 3.0\n",
      "\tgrad1 =  -0.848772060831223 2.0 8.0\n",
      "\tgrad2 =  -0.28858250068261526 2.0 8.0\n",
      "\tgrad1 =  1.2936604520622055 3.0 15.0\n",
      "\tgrad2 =  -0.26735649342619894 3.0 15.0\n",
      "progress: 37 w1= 1.0442070580960674 w2= 1.8551992521223826 loss= 0.0013350781153797981 \n",
      "\n",
      "\tgrad1 =  -0.20118737956310007 1.0 3.0\n",
      "\tgrad2 =  -0.19716363197183817 1.0 3.0\n",
      "\tgrad1 =  -0.8062599643920407 2.0 8.0\n",
      "\tgrad2 =  -0.27412838789329186 2.0 8.0\n",
      "\tgrad1 =  1.2288654141060604 3.0 15.0\n",
      "\tgrad2 =  -0.2539655189152512 3.0 15.0\n",
      "progress: 38 w1= 1.0419928773945581 w2= 1.8624518275101865 loss= 0.001204688366058519 \n",
      "\n",
      "\tgrad1 =  -0.1911105901905108 1.0 3.0\n",
      "\tgrad2 =  -0.18728837838670032 1.0 3.0\n",
      "\tgrad1 =  -0.7658771538083187 2.0 8.0\n",
      "\tgrad2 =  -0.2603982322948326 2.0 8.0\n",
      "\tgrad1 =  1.167315738514585 3.0 15.0\n",
      "\tgrad2 =  -0.24124525262634222 3.0 15.0\n",
      "progress: 39 w1= 1.0398895974494005 w2= 1.8693411461432652 loss= 0.0010870330676520455 \n",
      "\n",
      "\tgrad1 =  -0.1815385128146687 1.0 3.0\n",
      "\tgrad2 =  -0.17790774255837505 1.0 3.0\n",
      "\tgrad1 =  -0.7275169804169082 2.0 8.0\n",
      "\tgrad2 =  -0.24735577334175218 2.0 8.0\n",
      "\tgrad1 =  1.1088488761603728 3.0 15.0\n",
      "\tgrad2 =  -0.22916210107313262 3.0 15.0\n",
      "progress: 40 w1= 1.0378916636201125 w2= 1.8758854023129978 loss= 0.0009808685162580855 \n",
      "\n",
      "\tgrad1 =  -0.1724458681337797 1.0 3.0\n",
      "\tgrad2 =  -0.16899695077110355 1.0 3.0\n",
      "\tgrad1 =  -0.6910781372222488 2.0 8.0\n",
      "\tgrad2 =  -0.23496656665556515 2.0 8.0\n",
      "\tgrad1 =  1.0533104194472749 3.0 15.0\n",
      "\tgrad2 =  -0.21768415335243319 3.0 15.0\n",
      "progress: 41 w1= 1.0359937994792001 w2= 1.8821018790207888 loss= 0.0008850724737056656 \n",
      "\n",
      "\tgrad1 =  -0.1638086430000225 1.0 3.0\n",
      "\tgrad2 =  -0.16053247014002103 1.0 3.0\n",
      "\tgrad1 =  -0.6564643913505606 2.0 8.0\n",
      "\tgrad2 =  -0.22319789305919002 2.0 8.0\n",
      "\tgrad1 =  1.0005536945285591 3.0 15.0\n",
      "\tgrad2 =  -0.20678109686923918 3.0 15.0\n",
      "progress: 42 w1= 1.0341909928774204 w2= 1.8880069936214734 loss= 0.0007986323046637179 \n",
      "\n",
      "\tgrad1 =  -0.15560402700221232 1.0 3.0\n",
      "\tgrad2 =  -0.15249194646216857 1.0 3.0\n",
      "\tgrad1 =  -0.6235843299043182 2.0 8.0\n",
      "\tgrad2 =  -0.21201867216746706 2.0 8.0\n",
      "\tgrad1 =  0.9504393739502355 3.0 15.0\n",
      "\tgrad2 =  -0.19642413728303865 3.0 15.0\n",
      "progress: 43 w1= 1.0324784827069835 w2= 1.8936163411806002 loss= 0.0007206342723345485 \n",
      "\n",
      "\tgrad1 =  -0.1478103522248322 1.0 3.0\n",
      "\tgrad2 =  -0.1448541451803358 1.0 3.0\n",
      "\tgrad1 =  -0.5923511185461194 2.0 8.0\n",
      "\tgrad2 =  -0.2013993803056806 2.0 8.0\n",
      "\tgrad1 =  0.9028351086951503 3.0 15.0\n",
      "\tgrad2 =  -0.18658592246367078 3.0 15.0\n",
      "progress: 44 w1= 1.0308517463277416 w2= 1.898944735660097 loss= 0.0006502538795775611 \n",
      "\n",
      "\tgrad1 =  -0.1404070360243228 1.0 3.0\n",
      "\tgrad2 =  -0.13759889530383695 1.0 3.0\n",
      "\tgrad1 =  -0.562682272174321 2.0 8.0\n",
      "\tgrad2 =  -0.19131197253926757 2.0 8.0\n",
      "\tgrad1 =  0.8576151786564665 3.0 15.0\n",
      "\tgrad2 =  -0.1772404702556578 3.0 15.0\n",
      "progress: 45 w1= 1.0293064876231635 w2= 1.904006249041085 loss= 0.0005867471533591727 \n",
      "\n",
      "\tgrad1 =  -0.13337452667150274 1.0 3.0\n",
      "\tgrad2 =  -0.1307070361380731 1.0 3.0\n",
      "\tgrad1 =  -0.5344994370844347 2.0 8.0\n",
      "\tgrad2 =  -0.1817298086087078 2.0 8.0\n",
      "\tgrad1 =  0.8146601606189314 3.0 15.0\n",
      "\tgrad2 =  -0.1683630998612422 3.0 15.0\n",
      "progress: 46 w1= 1.0278386256545335 w2= 1.908814248487165 loss= 0.0005294427804089067 \n",
      "\n",
      "\tgrad1 =  -0.12669425171660276 1.0 3.0\n",
      "\tgrad2 =  -0.12416036668227015 1.0 3.0\n",
      "\tgrad1 =  -0.5077281840418095 2.0 8.0\n",
      "\tgrad2 =  -0.17262758257421496 2.0 8.0\n",
      "\tgrad1 =  0.7738566128684745 3.0 15.0\n",
      "\tgrad2 =  -0.15993036665949134 3.0 15.0\n",
      "progress: 47 w1= 1.026444283883433 w2= 1.913381431646325 loss= 0.00047773501093673195 \n",
      "\n",
      "\tgrad1 =  -0.12034856894048396 1.0 3.0\n",
      "\tgrad2 =  -0.11794159756167488 1.0 3.0\n",
      "\tgrad1 =  -0.48229781171812647 2.0 8.0\n",
      "\tgrad2 =  -0.16398125598416158 2.0 8.0\n",
      "\tgrad1 =  0.7350967755993452 3.0 15.0\n",
      "\tgrad2 =  -0.15192000029052366 3.0 15.0\n",
      "progress: 48 w1= 1.0251197799340255 w2= 1.9177198601846883 loss= 0.00043107725540877343 \n",
      "\n",
      "\tgrad1 =  -0.11432071976257241 1.0 3.0\n",
      "\tgrad2 =  -0.11203430536732117 1.0 3.0\n",
      "\tgrad1 =  -0.4581411599733798 2.0 8.0\n",
      "\tgrad2 =  -0.15576799439094913 2.0 8.0\n",
      "\tgrad1 =  0.6982782863270067 3.0 15.0\n",
      "\tgrad2 =  -0.14431084584092346 3.0 15.0\n",
      "progress: 49 w1= 1.0238616158681149 w2= 1.9218409916406802 loss= 0.00038897630669033857 \n",
      "\n",
      "\tgrad1 =  -0.10859478498240982 1.0 3.0\n",
      "\tgrad2 =  -0.10642288928276145 1.0 3.0\n",
      "\tgrad1 =  -0.4351944324898227 2.0 8.0\n",
      "\tgrad2 =  -0.14796610704654256 2.0 8.0\n",
      "\tgrad1 =  0.6633039095542053 3.0 15.0\n",
      "\tgrad2 =  -0.13708280797453298 3.0 15.0\n",
      "progress: 50 w1= 1.0226664689472953 w2= 1.9257557096837186 loss= 0.0003509871264789753 \n",
      "\n",
      "\tgrad1 =  -0.10315564273797229 1.0 3.0\n",
      "\tgrad2 =  -0.10109252988321238 1.0 3.0\n",
      "\tgrad1 =  -0.41339702828958735 2.0 8.0\n",
      "\tgrad2 =  -0.14055498961845814 2.0 8.0\n",
      "\tgrad1 =  0.6300812799782065 3.0 15.0\n",
      "\tgrad2 =  -0.13021679786216822 3.0 15.0\n",
      "progress: 51 w1= 1.0215311828577889 w2= 1.929474352857357 loss= 0.0003167081409204783 \n",
      "\n",
      "\tgrad1 =  -0.0979889285697082 1.0 3.0\n",
      "\tgrad2 =  -0.09602914999831391 1.0 3.0\n",
      "\tgrad1 =  -0.3926913816910087 2.0 8.0\n",
      "\tgrad2 =  -0.1335150697749441 2.0 8.0\n",
      "\tgrad1 =  0.5985226585589771 3.0 15.0\n",
      "\tgrad2 =  -0.12369468276885698 3.0 15.0\n",
      "progress: 52 w1= 1.0204527593748063 w2= 1.933006741882778 loss= 0.0002857769956736456 \n",
      "\n",
      "\tgrad1 =  -0.09308099748483123 1.0 3.0\n",
      "\tgrad2 =  -0.09121937753513443 1.0 3.0\n",
      "\tgrad1 =  -0.37302281028097894 2.0 8.0\n",
      "\tgrad2 =  -0.12682775549553327 2.0 8.0\n",
      "\tgrad1 =  0.5685447008058162 3.0 15.0\n",
      "\tgrad2 =  -0.11749923816652341 3.0 15.0\n",
      "progress: 53 w1= 1.0194283504444064 w2= 1.93636220559475 loss= 0.00025786672555656534 \n",
      "\n",
      "\tgrad1 =  -0.08841888792168717 1.0 3.0\n",
      "\tgrad2 =  -0.08665051016325354 1.0 3.0\n",
      "\tgrad1 =  -0.35433937050193265 2.0 8.0\n",
      "\tgrad2 =  -0.1204753859706571 2.0 8.0\n",
      "\tgrad1 =  0.5400682366688798 3.0 15.0\n",
      "\tgrad2 =  -0.11161410224489288 3.0 15.0\n",
      "progress: 54 w1= 1.0184552506619537 w2= 1.9395496055785382 loss= 0.00023268229828118535 \n",
      "\n",
      "\tgrad1 =  -0.0839902875190166 1.0 3.0\n",
      "\tgrad2 =  -0.08231048176863531 1.0 3.0\n",
      "\tgrad1 =  -0.33659172047180164 2.0 8.0\n",
      "\tgrad2 =  -0.11444118496041256 2.0 8.0\n",
      "\tgrad1 =  0.513018061456382 3.0 15.0\n",
      "\tgrad2 =  -0.10602373270097942 3.0 15.0\n",
      "progress: 55 w1= 1.0175308901272981 w2= 1.9425773595728386 loss= 0.00020995749574357982 \n",
      "\n",
      "\tgrad1 =  -0.07978350059972605 1.0 3.0\n",
      "\tgrad2 =  -0.07818783058773171 1.0 3.0\n",
      "\tgrad1 =  -0.3197329896750958 2.0 8.0\n",
      "\tgrad2 =  -0.10870921648953313 2.0 8.0\n",
      "\tgrad1 =  0.48732273722249175 3.0 15.0\n",
      "\tgrad2 =  -0.10071336569264489 3.0 15.0\n",
      "progress: 56 w1= 1.0166528276578213 w2= 1.9454534637005376 loss= 0.00018945209989985046 \n",
      "\n",
      "\tgrad1 =  -0.07578741728328175 1.0 3.0\n",
      "\tgrad2 =  -0.07427166893761594 1.0 3.0\n",
      "\tgrad1 =  -0.3037186551804467 2.0 8.0\n",
      "\tgrad2 =  -0.10326434276135288 2.0 8.0\n",
      "\tgrad1 =  0.46291440410474394 3.0 15.0\n",
      "\tgrad2 =  -0.09566897684831588 3.0 15.0\n",
      "progress: 57 w1= 1.015818744341411 w2= 1.9481855135860104 loss= 0.000170949353483912 \n",
      "\n",
      "\tgrad1 =  -0.07199148414515655 1.0 3.0\n",
      "\tgrad2 =  -0.07055165446225331 1.0 3.0\n",
      "\tgrad1 =  -0.2885064240582693 2.0 8.0\n",
      "\tgrad2 =  -0.09809218417981214 2.0 8.0\n",
      "\tgrad1 =  0.4397286011094437 3.0 15.0\n",
      "\tgrad2 =  -0.0908772442292829 3.0 15.0\n",
      "progress: 58 w1= 1.015026437412351 w2= 1.9507807244147242 loss= 0.00015425366872165797 \n",
      "\n",
      "\tgrad1 =  -0.06838567634584969 1.0 3.0\n",
      "\tgrad2 =  -0.06701796281893291 1.0 3.0\n",
      "\tgrad1 =  -0.2740561216874795 2.0 8.0\n",
      "\tgrad2 =  -0.09317908137374786 2.0 8.0\n",
      "\tgrad1 =  0.4177040958739866 3.0 15.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad2 =  -0.08632551314729398 3.0 15.0\n",
      "progress: 59 w1= 1.0142738144339443 w2= 1.9532459499881238 loss= 0.0001391885598229132 \n",
      "\n",
      "\tgrad1 =  -0.06496047115586379 1.0 3.0\n",
      "\tgrad2 =  -0.06366126173274633 1.0 3.0\n",
      "\tgrad1 =  -0.2603295856566845 2.0 8.0\n",
      "\tgrad2 =  -0.08851205912327131 2.0 8.0\n",
      "\tgrad1 =  0.39678272295624595 3.0 15.0\n",
      "\tgrad2 =  -0.08200176274429083 3.0 15.0\n",
      "progress: 60 w1= 1.0135588877725075 w2= 1.955587700824127 loss= 0.00012559477739581873 \n",
      "\n",
      "\tgrad1 =  -0.06170682280673123 1.0 3.0\n",
      "\tgrad2 =  -0.06047268635059666 1.0 3.0\n",
      "\tgrad1 =  -0.24729056497947965 2.0 8.0\n",
      "\tgrad2 =  -0.08407879209302394 2.0 8.0\n",
      "\tgrad1 =  0.37690923022224965 3.0 15.0\n",
      "\tgrad2 =  -0.07789457424592072 3.0 15.0\n",
      "progress: 61 w1= 1.012879769348147 w2= 1.9578121613510222 loss= 0.00011332862506199836 \n",
      "\n",
      "\tgrad1 =  -0.05861613860166148 1.0 3.0\n",
      "\tgrad2 =  -0.057443815829628875 1.0 3.0\n",
      "\tgrad1 =  -0.234904624357668 2.0 8.0\n",
      "\tgrad2 =  -0.07986757228160712 2.0 8.0\n",
      "\tgrad1 =  0.35803113292920585 3.0 15.0\n",
      "\tgrad2 =  -0.07399310080538157 3.0 15.0\n",
      "progress: 62 w1= 1.0122346656484482 w2= 1.9599252062401884 loss= 0.00010226044047979817 \n",
      "\n",
      "\tgrad1 =  -0.05568025622272721 1.0 3.0\n",
      "\tgrad2 =  -0.054566651098271635 1.0 3.0\n",
      "\tgrad1 =  -0.2231390532396489 2.0 8.0\n",
      "\tgrad2 =  -0.07586727810147664 2.0 8.0\n",
      "\tgrad1 =  0.3400985751156753 3.0 15.0\n",
      "\tgrad2 =  -0.07028703885723786 3.0 15.0\n",
      "progress: 63 w1= 1.0116218729919153 w2= 1.961932415920758 loss= 9.227322471608201e-05 \n",
      "\n",
      "\tgrad1 =  -0.05289142217465326 1.0 3.0\n",
      "\tgrad2 =  -0.05183359373116048 1.0 3.0\n",
      "\tgrad1 =  -0.2119627794337049 2.0 8.0\n",
      "\tgrad2 =  -0.07206734500746137 2.0 8.0\n",
      "\tgrad1 =  0.32306419793562924 3.0 15.0\n",
      "\tgrad2 =  -0.06676660090669628 3.0 15.0\n",
      "progress: 64 w1= 1.0110397730286427 w2= 1.9638390913172112 loss= 8.326140548159944e-05 \n",
      "\n",
      "\tgrad1 =  -0.050242271308292175 1.0 3.0\n",
      "\tgrad2 =  -0.04923742588212576 1.0 3.0\n",
      "\tgrad1 =  -0.20134628704825985 2.0 8.0\n",
      "\tgrad2 =  -0.0684577375964075 2.0 8.0\n",
      "\tgrad1 =  0.30688301458553724 3.0 15.0\n",
      "\tgrad2 =  -0.0634224896810025 3.0 15.0\n",
      "progress: 65 w1= 1.0104868284663528 w2= 1.9656502678488066 loss= 7.512972115246608e-05 \n",
      "\n",
      "\tgrad1 =  -0.04772580736968113 1.0 3.0\n",
      "\tgrad2 =  -0.04677129122228685 1.0 3.0\n",
      "\tgrad1 =  -0.19126153854193717 2.0 8.0\n",
      "\tgrad2 =  -0.06502892310425779 2.0 8.0\n",
      "\tgrad1 =  0.2915122914978987 3.0 15.0\n",
      "\tgrad2 =  -0.06024587357622835 3.0 15.0\n",
      "progress: 66 w1= 1.00996157901049 w2= 1.9673707287278341 loss= 6.779221378514488e-05 \n",
      "\n",
      "\tgrad1 =  -0.04533538452335151 1.0 3.0\n",
      "\tgrad2 =  -0.04442867683288476 1.0 3.0\n",
      "\tgrad1 =  -0.1816819006782353 2.0 8.0\n",
      "\tgrad2 =  -0.061771846230598726 2.0 8.0\n",
      "\tgrad1 =  0.27691143548332775 3.0 15.0\n",
      "\tgrad2 =  -0.05722836333323045 3.0 15.0\n",
      "progress: 67 w1= 1.009462637507673 w2= 1.9690050175918012 loss= 6.117132047589661e-05 \n",
      "\n",
      "\tgrad1 =  -0.04306468980105116 1.0 3.0\n",
      "\tgrad2 =  -0.042203396005030314 1.0 3.0\n",
      "\tgrad1 =  -0.17258207418851157 2.0 8.0\n",
      "\tgrad2 =  -0.05867790522409422 2.0 8.0\n",
      "\tgrad1 =  0.26304188652709115 3.0 15.0\n",
      "\tgrad2 =  -0.05436198988226337 3.0 15.0\n",
      "progress: 68 w1= 1.0089886862822977 w2= 1.970557450502915 loss= 5.519705346440339e-05 \n",
      "\n",
      "\tgrad1 =  -0.040907726429574964 1.0 3.0\n",
      "\tgrad2 =  -0.0400895719009835 1.0 3.0\n",
      "\tgrad1 =  -0.16393802695821336 2.0 8.0\n",
      "\tgrad2 =  -0.05573892916579126 2.0 8.0\n",
      "\tgrad1 =  0.24986701595389604 3.0 15.0\n",
      "\tgrad2 =  -0.05163918329712658 3.0 15.0\n",
      "progress: 69 w1= 1.0085384736566367 w2= 1.9720321273465542 loss= 4.980626031030628e-05 \n",
      "\n",
      "\tgrad1 =  -0.03885879799361813 1.0 3.0\n",
      "\tgrad2 =  -0.03808162203374543 1.0 3.0\n",
      "\tgrad1 =  -0.15572693055940334 2.0 8.0\n",
      "\tgrad2 =  -0.052947156390196426 2.0 8.0\n",
      "\tgrad1 =  0.23735202969387714 3.0 15.0\n",
      "\tgrad2 =  -0.04905275280340149 3.0 15.0\n",
      "progress: 70 w1= 1.0081108106452281 w2= 1.9734329426588275 loss= 4.494195632568001e-05 \n",
      "\n",
      "\tgrad1 =  -0.03691249339188829 1.0 3.0\n",
      "\tgrad2 =  -0.03617424352405152 1.0 3.0\n",
      "\tgrad1 =  -0.1479270999622102 2.0 8.0\n",
      "\tgrad2 =  -0.050295213987151755 2.0 8.0\n",
      "\tgrad1 =  0.22546387639331655 3.0 15.0\n",
      "\tgrad2 =  -0.04659586778794633 3.0 15.0\n",
      "progress: 71 w1= 1.007704567814836 w2= 1.974763595911819 loss= 4.055272220386346e-05 \n",
      "\n",
      "\tgrad1 =  -0.03506367254668952 1.0 3.0\n",
      "\tgrad2 =  -0.034362399095756224 1.0 3.0\n",
      "\tgrad1 =  -0.14051793626587994 2.0 8.0\n",
      "\tgrad2 =  -0.047776098330402306 2.0 8.0\n",
      "\tgrad1 =  0.21417116012814574 3.0 15.0\n",
      "\tgrad2 =  -0.044262039759811245 3.0 15.0\n",
      "progress: 72 w1= 1.0073186723016803 w2= 1.9760276012836786 loss= 3.659216047976945e-05 \n",
      "\n",
      "\tgrad1 =  -0.03330745282928227 1.0 3.0\n",
      "\tgrad2 =  -0.032641303772696695 1.0 3.0\n",
      "\tgrad1 =  -0.13347987229837344 2.0 8.0\n",
      "\tgrad2 =  -0.04538315658144754 2.0 8.0\n",
      "\tgrad1 =  0.20344405748889471 3.0 15.0\n",
      "\tgrad2 =  -0.04204510521437754 3.0 15.0\n",
      "progress: 73 w1= 1.0069521049780679 w2= 1.9772282969393637 loss= 3.3018405073933355e-05 \n",
      "\n",
      "\tgrad1 =  -0.031639196165136774 1.0 3.0\n",
      "\tgrad2 =  -0.03100641224183409 1.0 3.0\n",
      "\tgrad1 =  -0.12679432094047627 2.0 8.0\n",
      "\tgrad2 =  -0.043110069119762784 2.0 8.0\n",
      "\tgrad1 =  0.19325423881895887 3.0 15.0\n",
      "\tgrad2 =  -0.03993920935591433 3.0 15.0\n",
      "progress: 74 w1= 1.0066038977609344 w2= 1.978368853846539 loss= 2.9793678736918866e-05 \n",
      "\n",
      "\tgrad1 =  -0.030054496785053786 1.0 3.0\n",
      "\tgrad2 =  -0.029453406849352604 1.0 3.0\n",
      "\tgrad1 =  -0.12044362603836589 2.0 8.0\n",
      "\tgrad2 =  -0.04095083285304213 2.0 8.0\n",
      "\tgrad1 =  0.18357479339771032 3.0 15.0\n",
      "\tgrad2 =  -0.03793879063553618 3.0 15.0\n",
      "progress: 75 w1= 1.0062731310551916 w2= 1.9794522841499183 loss= 2.688389371605844e-05 \n",
      "\n",
      "\tgrad1 =  -0.028549169589780377 1.0 3.0\n",
      "\tgrad2 =  -0.0279781861979842 1.0 3.0\n",
      "\tgrad1 =  -0.11441101577477042 2.0 8.0\n",
      "\tgrad2 =  -0.03889974536342322 2.0 8.0\n",
      "\tgrad1 =  0.17438015837034015 3.0 15.0\n",
      "\tgrad2 =  -0.03603856606319766 3.0 15.0\n",
      "progress: 76 w1= 1.0059589313251336 w2= 1.9804814491261642 loss= 2.4258291422024903e-05 \n",
      "\n",
      "\tgrad1 =  -0.02711923909740399 1.0 3.0\n",
      "\tgrad2 =  -0.02657685431545609 1.0 3.0\n",
      "\tgrad1 =  -0.10868055837545398 2.0 8.0\n",
      "\tgrad2 =  -0.036951389847658334 2.0 8.0\n",
      "\tgrad1 =  0.16564605123859621 3.0 15.0\n",
      "\tgrad2 =  -0.03423351725597357 3.0 15.0\n",
      "progress: 77 w1= 1.0056604687874762 w2= 1.981459066740355 loss= 2.188911728827658e-05 \n",
      "\n",
      "\tgrad1 =  -0.025760928944337458 1.0 3.0\n",
      "\tgrad2 =  -0.02524571036545087 1.0 3.0\n",
      "\tgrad1 =  -0.10323712003442154 2.0 8.0\n",
      "\tgrad2 =  -0.035100620811704175 2.0 8.0\n",
      "\tgrad1 =  0.15734940573153722 3.0 15.0\n",
      "\tgrad2 =  -0.032518877184521955 3.0 15.0\n",
      "progress: 78 w1= 1.0053769552199483 w2= 1.9823877188239718 loss= 1.9751327384313602e-05 \n",
      "\n",
      "\tgrad1 =  -0.024470651912159802 1.0 3.0\n",
      "\tgrad2 =  -0.02398123887391712 1.0 3.0\n",
      "\tgrad1 =  -0.09806632494638734 2.0 8.0\n",
      "\tgrad2 =  -0.03334255048177326 2.0 8.0\n",
      "\tgrad1 =  0.1494683108890129 3.0 15.0\n",
      "\tgrad2 =  -0.030890117583730614 3.0 15.0\n",
      "progress: 79 w1= 1.0051076418796434 w2= 1.983269857893366 loss= 1.7822323682780757e-05 \n",
      "\n",
      "\tgrad1 =  -0.023245000453981035 1.0 3.0\n",
      "\tgrad2 =  -0.022780100444901308 1.0 3.0\n",
      "\tgrad1 =  -0.09315451734109104 2.0 8.0\n",
      "\tgrad2 =  -0.03167253589597152 2.0 8.0\n",
      "\tgrad1 =  0.14198195319607976 3.0 15.0\n",
      "\tgrad2 =  -0.029342936993856483 3.0 15.0\n",
      "progress: 80 w1= 1.0048518175256334 w2= 1.9841078136267134 loss= 1.608171518162503e-05 \n",
      "\n",
      "\tgrad1 =  -0.022080737695306496 1.0 3.0\n",
      "\tgrad2 =  -0.02163912294140058 1.0 3.0\n",
      "\tgrad1 =  -0.08848872541919661 2.0 8.0\n",
      "\tgrad2 =  -0.03008616664252628 2.0 8.0\n",
      "\tgrad1 =  0.13487056161593003 3.0 15.0\n",
      "\tgrad2 =  -0.027873249400631295 3.0 15.0\n",
      "progress: 81 w1= 1.004608806540619 w2= 1.984903799016559 loss= 1.451110235605009e-05 \n",
      "\n",
      "\tgrad1 =  -0.020974788885643747 1.0 3.0\n",
      "\tgrad2 =  -0.020555293107930694 1.0 3.0\n",
      "\tgrad1 =  -0.08405662709456863 2.0 8.0\n",
      "\tgrad2 =  -0.028579253212157596 2.0 8.0\n",
      "\tgrad1 =  0.1281153553752432 3.0 15.0\n",
      "\tgrad2 =  -0.02647717344421352 3.0 15.0\n",
      "progress: 82 w1= 1.0043779671466686 w2= 1.9856599162142021 loss= 1.309388266170718e-05 \n",
      "\n",
      "\tgrad1 =  -0.01992423327825854 1.0 3.0\n",
      "\tgrad2 =  -0.019525748612693405 1.0 3.0\n",
      "\tgrad1 =  -0.07984651745229598 2.0 8.0\n",
      "\tgrad2 =  -0.02714781593378035 2.0 8.0\n",
      "\tgrad1 =  0.12169849436584457 3.0 15.0\n",
      "\tgrad2 =  -0.025151022168955706 3.0 15.0\n",
      "progress: 83 w1= 1.0041586897103156 w2= 1.9863781620813565 loss= 1.1815075033747613e-05 \n",
      "\n",
      "\tgrad1 =  -0.01892629641665522 1.0 3.0\n",
      "\tgrad2 =  -0.018547770488321902 1.0 3.0\n",
      "\tgrad1 =  -0.07584727783672918 2.0 8.0\n",
      "\tgrad2 =  -0.0257880744644865 2.0 8.0\n",
      "\tgrad1 =  0.11560303202943345 3.0 15.0\n",
      "\tgrad2 =  -0.023891293286084192 3.0 15.0\n",
      "progress: 84 w1= 1.0039503951325552 w2= 1.9870604334637456 loss= 1.0661161525515733e-05 \n",
      "\n",
      "\tgrad1 =  -0.01797834280739785 1.0 3.0\n",
      "\tgrad2 =  -0.017618775951250498 1.0 3.0\n",
      "\tgrad1 =  -0.07204834648773328 2.0 8.0\n",
      "\tgrad2 =  -0.024496437805829885 2.0 8.0\n",
      "\tgrad1 =  0.10981287060311118 3.0 15.0\n",
      "\tgrad2 =  -0.022694659924649585 3.0 15.0\n",
      "progress: 85 w1= 1.0037525333194752 w2= 1.987708532200563 loss= 9.61994441410389e-06 \n",
      "\n",
      "\tgrad1 =  -0.017077868959923137 1.0 3.0\n",
      "\tgrad2 =  -0.016736311580725527 1.0 3.0\n",
      "\tgrad1 =  -0.0684396906476934 2.0 8.0\n",
      "\tgrad2 =  -0.023269494820215897 2.0 8.0\n",
      "\tgrad1 =  0.10431271860625202 3.0 15.0\n",
      "\tgrad2 =  -0.021557961845296347 3.0 15.0\n",
      "progress: 86 w1= 1.003564581729489 w2= 1.9883241698830252 loss= 8.680417261222512e-06 \n",
      "\n",
      "\tgrad1 =  -0.016222496774972228 1.0 3.0\n",
      "\tgrad2 =  -0.015898046839472713 1.0 3.0\n",
      "\tgrad1 =  -0.06501178006564601 2.0 8.0\n",
      "\tgrad2 =  -0.02210400522231737 2.0 8.0\n",
      "\tgrad1 =  0.09908805045571967 3.0 15.0\n",
      "\tgrad2 =  -0.02047819709417098 3.0 15.0\n",
      "progress: 87 w1= 1.003386043993338 w2= 1.9889089723745847 loss= 7.83264856687022e-06 \n",
      "\n",
      "\tgrad1 =  -0.015409967264155 1.0 3.0\n",
      "\tgrad2 =  -0.01510176791887119 1.0 3.0\n",
      "\tgrad1 =  -0.061755561828277905 2.0 8.0\n",
      "\tgrad2 =  -0.020996891021617614 2.0 8.0\n",
      "\tgrad1 =  0.09412506810592802 3.0 15.0\n",
      "\tgrad2 =  -0.01945251407522619 3.0 15.0\n",
      "progress: 88 w1= 1.003216448603203 w2= 1.989464484104742 loss= 7.067676786298129e-06 \n",
      "\n",
      "\tgrad1 =  -0.014638134584110674 1.0 3.0\n",
      "\tgrad2 =  -0.01434537189242846 1.0 3.0\n",
      "\tgrad1 =  -0.058662436451932365 2.0 8.0\n",
      "\tgrad2 =  -0.019945228393655867 2.0 8.0\n",
      "\tgrad1 =  0.08941066460784697 3.0 15.0\n",
      "\tgrad2 =  -0.018478204018954614 3.0 15.0\n",
      "progress: 89 w1= 1.003055347667485 w2= 1.9899921721477922 loss= 6.377415599448302e-06 \n",
      "\n",
      "\tgrad1 =  -0.01390496036944544 1.0 3.0\n",
      "\tgrad2 =  -0.013626861162056692 1.0 3.0\n",
      "\tgrad1 =  -0.05572423517165248 2.0 8.0\n",
      "\tgrad2 =  -0.018946239958360422 2.0 8.0\n",
      "\tgrad1 =  0.08493238949496273 3.0 15.0\n",
      "\tgrad2 =  -0.017552693828964294 3.0 15.0\n",
      "progress: 90 w1= 1.0029023157279464 w2= 1.990493430097286 loss= 5.754568432870173e-06 \n",
      "\n",
      "\tgrad1 =  -0.013208508349535464 1.0 3.0\n",
      "\tgrad2 =  -0.012944338182544257 1.0 3.0\n",
      "\tgrad1 =  -0.052933198368080525 2.0 8.0\n",
      "\tgrad2 =  -0.017997287445147947 2.0 8.0\n",
      "\tgrad1 =  0.080678415902252 3.0 15.0\n",
      "\tgrad2 =  -0.016673539286454542 3.0 15.0\n",
      "progress: 91 w1= 1.0027569486361 w2= 1.9909695817464275 loss= 5.192551329318322e-06 \n",
      "\n",
      "\tgrad1 =  -0.012546939234944432 1.0 3.0\n",
      "\tgrad2 =  -0.012296000450246147 1.0 3.0\n",
      "\tgrad1 =  -0.05028195507473754 2.0 8.0\n",
      "\tgrad2 =  -0.01709586472541247 2.0 8.0\n",
      "\tgrad1 =  0.0766375093318068 3.0 15.0\n",
      "\tgrad2 =  -0.01583841859524071 3.0 15.0\n",
      "progress: 92 w1= 1.0026188624858787 w2= 1.9914218845841365 loss= 4.685423350535225e-06 \n",
      "\n",
      "\tgrad1 =  -0.011918505859969564 1.0 3.0\n",
      "\tgrad2 =  -0.011680135742770048 1.0 3.0\n",
      "\tgrad1 =  -0.04776350351166059 2.0 8.0\n",
      "\tgrad2 =  -0.016239591193965452 2.0 8.0\n",
      "\tgrad1 =  0.07279899798360745 3.0 15.0\n",
      "\tgrad2 =  -0.015045126249944474 3.0 15.0\n",
      "progress: 93 w1= 1.002487692599759 w2= 1.9918515331160034 loss= 4.227823777074037e-06 \n",
      "\n",
      "\tgrad1 =  -0.011321548568474782 1.0 3.0\n",
      "\tgrad2 =  -0.011095117597106352 1.0 3.0\n",
      "\tgrad1 =  -0.045371192594210186 2.0 8.0\n",
      "\tgrad2 =  -0.015426205482032884 2.0 8.0\n",
      "\tgrad1 =  0.06915274457137954 3.0 15.0\n",
      "\tgrad2 =  -0.014291567211415668 3.0 15.0\n",
      "progress: 94 w1= 1.002363092565672 w2= 1.992259662018909 loss= 3.8149154415021085e-06 \n",
      "\n",
      "\tgrad1 =  -0.010754490830837682 1.0 3.0\n",
      "\tgrad2 =  -0.010539401014221461 1.0 3.0\n",
      "\tgrad1 =  -0.04309870436780727 2.0 8.0\n",
      "\tgrad2 =  -0.014653559485054757 2.0 8.0\n",
      "\tgrad1 =  0.06568911955130474 3.0 15.0\n",
      "\tgrad2 =  -0.01357575137393141 3.0 15.0\n",
      "progress: 95 w1= 1.0022447333221451 w2= 1.992647349137641 loss= 3.4423335960138633e-06 \n",
      "\n",
      "\tgrad1 =  -0.01021583508042756 1.0 3.0\n",
      "\tgrad2 =  -0.010011518378819417 1.0 3.0\n",
      "\tgrad1 =  -0.040940037322748424 2.0 8.0\n",
      "\tgrad2 =  -0.013919612689733185 2.0 8.0\n",
      "\tgrad1 =  0.06239897569030006 3.0 15.0\n",
      "\tgrad2 =  -0.012895788309315037 3.0 15.0\n",
      "progress: 96 w1= 1.002132302289274 w2= 1.9930156183314198 loss= 3.1061397737262833e-06 \n",
      "\n",
      "\tgrad1 =  -0.009704158758612635 1.0 3.0\n",
      "\tgrad2 =  -0.009510075583440525 1.0 3.0\n",
      "\tgrad1 =  -0.03888949054440616 2.0 8.0\n",
      "\tgrad2 =  -0.013222426785098662 2.0 8.0\n",
      "\tgrad1 =  0.05927362390895752 3.0 15.0\n",
      "\tgrad2 =  -0.012249882274524282 3.0 15.0\n",
      "progress: 97 w1= 1.0020255025432145 w2= 1.9933654421778504 loss= 2.8027801562037297e-06 \n",
      "\n",
      "\tgrad1 =  -0.00921811055787014 1.0 3.0\n",
      "\tgrad2 =  -0.00903374834671311 1.0 3.0\n",
      "\tgrad1 =  -0.0369416486575318 2.0 8.0\n",
      "\tgrad2 =  -0.012560160543564791 2.0 8.0\n",
      "\tgrad1 =  0.05630481033433199 3.0 15.0\n",
      "\tgrad2 =  -0.011636327469076946 3.0 15.0\n",
      "progress: 98 w1= 1.0019240520320252 w2= 1.9936977445414439 loss= 2.529048006918997e-06 \n",
      "\n",
      "\tgrad1 =  -0.00875640685306145 1.0 3.0\n",
      "\tgrad2 =  -0.008581278716000895 1.0 3.0\n",
      "\tgrad1 =  -0.035091367524550776 2.0 8.0\n",
      "\tgrad2 =  -0.011931064958346838 2.0 8.0\n",
      "\tgrad1 =  0.05348469450188986 3.0 15.0\n",
      "\tgrad2 =  -0.011053503530376929 3.0 15.0\n",
      "progress: 99 w1= 1.0018276828307826 w2= 1.9940134030134908 loss= 2.282049773746724e-06 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]               # y = x^2 + 2x \n",
    "y_data = [3.0, 8.0, 15.0]\n",
    "\n",
    "w1_list = []\n",
    "w2_list = []\n",
    "l_list = []\n",
    "\n",
    "w1 = 1\n",
    "w2 = 1\n",
    "\n",
    "def forward(x):            \n",
    "    return w1*x*x + w2*x\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "def gradientw1(w2,x,y):   #로스에 대한 w1의 미분\n",
    "    return 2*(w1*x*x + w2*x - y) * x*x\n",
    "\n",
    "def gradientw2(w1,x,y):\n",
    "    return 2*(w1*x*x + w2*x - y) * x\n",
    "\n",
    "for epoch in range (100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad1 = gradientw1(w2, x_val, y_val)\n",
    "        w1 = w1 - 0.01*grad1\n",
    "        print(\"\\tgrad1 = \", grad1, x_val, y_val)\n",
    "        \n",
    "        grad2 = gradientw2(w1, x_val, y_val)\n",
    "        w2 = w2 - 0.01*grad2\n",
    "        print(\"\\tgrad2 = \", grad2, x_val, y_val)\n",
    "        \n",
    "        l = loss(x_val, y_val)\n",
    "        \n",
    "    print(\"progress:\", epoch, \"w1=\", w1, \"w2=\",w2, \"loss=\", l,\"\\n\")\n",
    "    \n",
    "    w1_list.append(w1)\n",
    "    w2_list.append(w2)\n",
    "    l_list.append(l)\n",
    "    \n",
    "plt.plot(w1_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w2_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgradw1: -5.6 1.0 3.0\n",
      "\tgradw2: -5.4879999999999995 1.0 3.0\n",
      "\tgradw1: -56.52992 2.0 8.0\n",
      "\tgradw2: -19.2201728 2.0 8.0\n",
      "\tgradw1: -134.40711628799997 3.0 15.0\n",
      "\tgradw2: 27.77747069951998 3.0 15.0\n",
      "progress: 0 w1= 2.0653703628799995 w2= 0.06930702100480024 loss= 14.411546929953138 \n",
      "\n",
      "\tgradw1: -1.7306452322304002 1.0 3.0\n",
      "\tgradw2: -1.696032327585792 1.0 3.0\n",
      "\tgradw1: 4.025935594964253 2.0 8.0\n",
      "\tgradw2: 1.3688181022878467 2.0 8.0\n",
      "\tgradw1: 64.7909032148512 3.0 15.0\n",
      "\tgradw2: -13.390119997735923 3.0 15.0\n",
      "progress: 1 w1= 1.394508427104149 w2= 0.2064803632351389 loss= 3.34883802315426 \n",
      "\n",
      "\tgradw1: -2.7980224193214243 1.0 3.0\n",
      "\tgradw2: -2.7420619709349956 1.0 3.0\n",
      "\tgradw1: -14.737947431372554 2.0 8.0\n",
      "\tgradw2: -5.010902126666668 2.0 8.0\n",
      "\tgradw1: -0.34482342360119134 3.0 15.0\n",
      "\tgradw2: 0.07126350754424493 3.0 15.0\n",
      "progress: 2 w1= 1.5733163598471007 w2= 0.2832973691357131 loss= 9.485486111247273e-05 \n",
      "\n",
      "\tgradw1: -2.2867725420343725 1.0 3.0\n",
      "\tgradw2: -2.241037091193685 1.0 3.0\n",
      "\tgradw1: -8.03078543067938 2.0 8.0\n",
      "\tgradw2: -2.730467046430988 2.0 8.0\n",
      "\tgradw1: 19.574364378672435 3.0 15.0\n",
      "\tgradw2: -4.045368638258957 3.0 15.0\n",
      "progress: 3 w1= 1.480748295787514 w2= 0.3734660968945494 loss= 0.30566197191140915 \n",
      "\n",
      "\tgradw1: -2.2915712146358733 1.0 3.0\n",
      "\tgradw2: -2.2457397903431557 1.0 3.0\n",
      "\tgradw1: -9.547975829348374 2.0 8.0\n",
      "\tgradw2: -3.2463117819784486 2.0 8.0\n",
      "\tgradw1: 12.19416721019105 3.0 15.0\n",
      "\tgradw2: -2.520127890106142 3.0 15.0\n",
      "progress: 4 w1= 1.477202094125446 w2= 0.4535878915188269 loss= 0.11862339936852334 \n",
      "\n",
      "\tgradw1: -2.138420028711454 1.0 3.0\n",
      "\tgradw2: -2.095651628137225 1.0 3.0\n",
      "\tgradw1: -8.452528053994875 2.0 8.0\n",
      "\tgradw2: -2.873859538358257 2.0 8.0\n",
      "\tgradw1: 13.641357314230728 3.0 15.0\n",
      "\tgradw2: -2.8192138449410216 3.0 15.0\n",
      "progress: 5 w1= 1.446698001810202 w2= 0.531475141633192 loss= 0.1484503558732833 \n",
      "\n",
      "\tgradw1: -2.043653713113212 1.0 3.0\n",
      "\tgradw2: -2.0027806388509477 1.0 3.0\n",
      "\tgradw1: -8.227647585530086 2.0 8.0\n",
      "\tgradw2: -2.7974001790802276 2.0 8.0\n",
      "\tgradw1: 12.296339686930114 3.0 15.0\n",
      "\tgradw2: -2.541243535298886 3.0 15.0\n",
      "progress: 6 w1= 1.426447617927334 w2= 0.6048893851654925 loss= 0.12061957049198929 \n",
      "\n",
      "\tgradw1: -1.9373259938143468 1.0 3.0\n",
      "\tgradw2: -1.8985794739380601 1.0 3.0\n",
      "\tgradw1: -7.751729029826748 2.0 8.0\n",
      "\tgradw2: -2.6355878701410944 2.0 8.0\n",
      "\tgradw1: 11.89326040726603 3.0 15.0\n",
      "\tgradw2: -2.4579404841683115 3.0 15.0\n",
      "progress: 7 w1= 1.4044055640910846 w2= 0.6748104634479671 loss= 0.11284126070291677 \n",
      "\n",
      "\tgradw1: -1.8415679449218967 1.0 3.0\n",
      "\tgradw2: -1.8047365860234583 1.0 3.0\n",
      "\tgradw1: -7.3839949377790575 2.0 8.0\n",
      "\tgradw2: -2.5105582788448793 2.0 8.0\n",
      "\tgradw1: 11.229137505950376 3.0 15.0\n",
      "\tgradw2: -2.320688417896406 3.0 15.0\n",
      "progress: 8 w1= 1.3843698178585904 w2= 0.7411702962756146 loss= 0.10059094162336954 \n",
      "\n",
      "\tgradw1: -1.7489197717315896 1.0 3.0\n",
      "\tgradw2: -1.7139413762969582 1.0 3.0\n",
      "\tgradw1: -7.007556140953653 2.0 8.0\n",
      "\tgradw2: -2.3825690879242423 2.0 8.0\n",
      "\tgradw1: 10.688713121204387 3.0 15.0\n",
      "\tgradw2: -2.2090007117155857 3.0 15.0\n",
      "progress: 9 w1= 1.365047445773399 w2= 0.8042254080349824 loss= 0.09114165607410113 \n",
      "\n",
      "\tgradw1: -1.6614542923832367 1.0 3.0\n",
      "\tgradw2: -1.6282252065355722 1.0 3.0\n",
      "\tgradw1: -6.658693800083185 2.0 8.0\n",
      "\tgradw2: -2.2639558920282816 2.0 8.0\n",
      "\tgradw1: 10.146275952199773 3.0 15.0\n",
      "\tgradw2: -2.0968970301212693 3.0 15.0\n",
      "progress: 10 w1= 1.3467861671760657 w2= 0.8641161893218336 loss= 0.08212576219377392 \n",
      "\n",
      "\tgradw1: -1.5781952870042009 1.0 3.0\n",
      "\tgradw2: -1.5466313812641168 1.0 3.0\n",
      "\tgradw1: -6.324500108372959 2.0 8.0\n",
      "\tgradw2: -2.1503300368468032 2.0 8.0\n",
      "\tgradw1: 9.640359012192555 3.0 15.0\n",
      "\tgradw2: -1.9923408625197823 3.0 15.0\n",
      "progress: 11 w1= 1.3294095310079117 w2= 0.9210092121281407 loss= 0.0741399841228391 \n",
      "\n",
      "\tgradw1: -1.499162513727895 1.0 3.0\n",
      "\tgradw2: -1.469179263453337 1.0 3.0\n",
      "\tgradw1: -6.00794692715111 2.0 8.0\n",
      "\tgradw2: -2.042701955231376 2.0 8.0\n",
      "\tgradw1: 9.15677463051506 3.0 15.0\n",
      "\tgradw2: -1.8924000903064524 3.0 15.0\n",
      "progress: 12 w1= 1.3129128791115514 w2= 0.9750520252180523 loss= 0.06688844876791177 \n",
      "\n",
      "\tgradw1: -1.4240701913407925 1.0 3.0\n",
      "\tgradw2: -1.3955887875139767 1.0 3.0\n",
      "\tgradw1: -5.706958797710229 2.0 8.0\n",
      "\tgradw2: -1.9403659912214763 2.0 8.0\n",
      "\tgradw1: 8.698378320625967 3.0 15.0\n",
      "\tgradw2: -1.797664852929362 3.0 15.0\n",
      "progress: 13 w1= 1.297239385795802 w2= 1.0263882215347004 loss= 0.06035908655924628 \n",
      "\n",
      "\tgradw1: -1.3527447853389951 1.0 3.0\n",
      "\tgradw2: -1.3256898896322156 1.0 3.0\n",
      "\tgradw1: -5.421139396329494 2.0 8.0\n",
      "\tgradw2: -1.8431873947520288 2.0 8.0\n",
      "\tgradw1: 8.26263056966419 3.0 15.0\n",
      "\tgradw2: -1.707610317730591 3.0 15.0\n",
      "progress: 14 w1= 1.282351921915845 w2= 1.0751530975558488 loss= 0.054463148536964635 \n",
      "\n",
      "\tgradw1: -1.2849899610566125 1.0 3.0\n",
      "\tgradw2: -1.2592901618354801 1.0 3.0\n",
      "\tgradw1: -5.149605724367589 2.0 8.0\n",
      "\tgradw2: -1.750865946284975 2.0 8.0\n",
      "\tgradw1: 7.848807927155033 3.0 15.0\n",
      "\tgradw2: -1.6220869716120454 3.0 15.0\n",
      "progress: 15 w1= 1.2682097994985368 w2= 1.1214755283531737 loss= 0.049144336524211706 \n",
      "\n",
      "\tgradw1: -1.2206293442965794 1.0 3.0\n",
      "\tgradw2: -1.1962167574106477 1.0 3.0\n",
      "\tgradw1: -4.891681891035432 2.0 8.0\n",
      "\tgradw2: -1.6631718429520461 2.0 8.0\n",
      "\tgradw1: 7.455680095268068 3.0 15.0\n",
      "\tgradw2: -1.540840553022072 3.0 15.0\n",
      "progress: 16 w1= 1.2547761108991764 w2= 1.1654778198870213 loss= 0.04434458593485071 \n",
      "\n",
      "\tgradw1: -1.1594921384276047 1.0 3.0\n",
      "\tgradw2: -1.1363022956590525 1.0 3.0\n",
      "\tgradw1: -4.646673481431733 2.0 8.0\n",
      "\tgradw2: -1.57986898368679 2.0 8.0\n",
      "\tgradw1: 7.082253034584614 3.0 15.0\n",
      "\tgradw2: -1.4636656271474884 3.0 15.0\n",
      "progress: 17 w1= 1.2420152367519237 w2= 1.2072761889519543 loss= 0.04001372212738286 \n",
      "\n",
      "\tgradw1: -1.101417148592244 1.0 3.0\n",
      "\tgradw2: -1.0793888056203986 1.0 3.0\n",
      "\tgradw1: -4.413937704258387 2.0 8.0\n",
      "\tgradw2: -1.5007388194478537 2.0 8.0\n",
      "\tgradw1: 6.72752633637208 3.0 15.0\n",
      "\tgradw2: -1.390355442850229 3.0 15.0\n",
      "progress: 18 w1= 1.2298935219167093 w2= 1.246981019631139 loss= 0.03610579289773046 \n",
      "\n",
      "\tgradw1: -1.0462509169043033 1.0 3.0\n",
      "\tgradw2: -1.0253258985662175 1.0 3.0\n",
      "\tgradw1: -4.192858547387104 2.0 8.0\n",
      "\tgradw2: -1.4255719061116139 2.0 8.0\n",
      "\tgradw1: 6.3905677572665525 3.0 15.0\n",
      "\tgradw2: -1.3207173365017546 3.0 15.0\n",
      "progress: 19 w1= 1.218378938986958 w2= 1.284697171042935 loss= 0.032579540995732535 \n",
      "\n",
      "\tgradw1: -0.9938477799402143 1.0 3.0\n",
      "\tgradw2: -0.9739708243414107 1.0 3.0\n",
      "\tgradw1: -3.9828525942548936 2.0 8.0\n",
      "\tgradw2: -1.354169882046662 2.0 8.0\n",
      "\tgradw1: 6.070485939851292 3.0 15.0\n",
      "\tgradw2: -1.2545670942359308 3.0 15.0\n",
      "progress: 20 w1= 1.2074410833303961 w2= 1.3205242490491749 loss= 0.02939767529347152 \n",
      "\n",
      "\tgradw1: -0.944069335240858 1.0 3.0\n",
      "\tgradw2: -0.925187948536041 1.0 3.0\n",
      "\tgradw1: -3.7833650895976874 2.0 8.0\n",
      "\tgradw2: -1.2863441304632133 2.0 8.0\n",
      "\tgradw1: 5.766436039077657 3.0 15.0\n",
      "\tgradw2: -1.1917301147427182 3.0 15.0\n",
      "progress: 21 w1= 1.197051067188005 w2= 1.3545568709865947 loss= 0.026526566002140543 \n",
      "\n",
      "\tgradw1: -0.8967841236508001 1.0 3.0\n",
      "\tgradw2: -0.8788484411777846 1.0 3.0\n",
      "\tgradw1: -3.5938692440416276 2.0 8.0\n",
      "\tgradw2: -1.221915542974152 2.0 8.0\n",
      "\tgradw1: 5.477614924836704 3.0 15.0\n",
      "\tgradw2: -1.1320404177995904 3.0 15.0\n",
      "progress: 22 w1= 1.1871814516165622 w2= 1.38688491500611 loss= 0.023935861868456757 \n",
      "\n",
      "\tgradw1: -0.8518672667546561 1.0 3.0\n",
      "\tgradw2: -0.834829921419562 1.0 3.0\n",
      "\tgradw1: -3.413864595383629 2.0 8.0\n",
      "\tgradw2: -1.1607139624304352 2.0 8.0\n",
      "\tgradw1: 5.203259886156037 3.0 15.0\n",
      "\tgradw2: -1.0753403764722478 3.0 15.0\n",
      "progress: 23 w1= 1.1778061713763845 w2= 1.4175937576093325 loss= 0.02159817768201513 \n",
      "\n",
      "\tgradw1: -0.8092001420285655 1.0 3.0\n",
      "\tgradw2: -0.7930161391879942 1.0 3.0\n",
      "\tgradw1: -3.2428757664871597 2.0 8.0\n",
      "\tgradw2: -1.1025777606056337 2.0 8.0\n",
      "\tgradw1: 4.942646351562274 3.0 15.0\n",
      "\tgradw2: -1.0214802459895367 3.0 15.0\n",
      "progress: 24 w1= 1.168900466945919 w2= 1.446764499067164 loss= 0.019488802244929392 \n",
      "\n",
      "\tgradw1: -0.7686700679738339 1.0 3.0\n",
      "\tgradw2: -0.7532966666143572 1.0 3.0\n",
      "\tgradw1: -3.0804511842460442 2.0 8.0\n",
      "\tgradw2: -1.047353402643651 2.0 8.0\n",
      "\tgradw1: 4.6950860608613 3.0 15.0\n",
      "\tgradw2: -0.9703177859113481 3.0 15.0\n",
      "progress: 25 w1= 1.1604408188595048 w2= 1.4744741776188577 loss= 0.01758543793452851 \n",
      "\n",
      "\tgradw1: -0.7301700070432755 1.0 3.0\n",
      "\tgradw2: -0.71556660690241 1.0 3.0\n",
      "\tgradw1: -2.926161895235893 2.0 8.0\n",
      "\tgradw2: -0.9948950443802005 2.0 8.0\n",
      "\tgradw1: 4.459925220042919 3.0 15.0\n",
      "\tgradw2: -0.9217178788088631 3.0 15.0\n",
      "progress: 26 w1= 1.1524048856818672 w2= 1.5007959729197724 loss= 0.015867964763142364 \n",
      "\n",
      "\tgradw1: -0.6935982827967209 1.0 3.0\n",
      "\tgradw2: -0.679726317140787 1.0 3.0\n",
      "\tgradw1: -2.7796004302264166 2.0 8.0\n",
      "\tgradw2: -0.9450641462769802 2.0 8.0\n",
      "\tgradw1: 4.2365427834732685 3.0 15.0\n",
      "\tgradw2: -0.875552175251137 3.0 15.0\n",
      "progress: 27 w1= 1.1447714449773658 w2= 1.5257993993064614 loss= 0.014318227767530344 \n",
      "\n",
      "\tgradw1: -0.6588583114323452 1.0 3.0\n",
      "\tgradw2: -0.6456811452036986 1.0 3.0\n",
      "\tgradw1: -2.6403797289299717 2.0 8.0\n",
      "\tgradw2: -0.8977291078361915 2.0 8.0\n",
      "\tgradw1: 4.024348810910666 3.0 15.0\n",
      "\tgradw2: -0.8316987542548766 3.0 15.0\n",
      "progress: 28 w1= 1.1375203372718823 w2= 1.549550489379409 loss= 0.012919845075230195 \n",
      "\n",
      "\tgradw1: -0.6258583466974175 1.0 3.0\n",
      "\tgradw2: -0.6133411797634691 1.0 3.0\n",
      "\tgradw1: -2.5081321175238998 2.0 8.0\n",
      "\tgradw2: -0.8527649199581262 2.0 8.0\n",
      "\tgradw1: 3.822782910421232 3.0 15.0\n",
      "\tgradw2: -0.790041801487078 3.0 15.0\n",
      "progress: 29 w1= 1.130632412809883 w2= 1.5721119683914955 loss= 0.011658034742788237 \n",
      "\n",
      "\tgradw1: -0.594511237597243 1.0 3.0\n",
      "\tgradw2: -0.5826210128452978 1.0 3.0\n",
      "\tgradw1: -2.382508337733455 2.0 8.0\n",
      "\tgradw2: -0.8100528348293707 2.0 8.0\n",
      "\tgradw1: 3.6313127581218794 3.0 15.0\n",
      "\tgradw2: -0.7504713033451935 3.0 15.0\n",
      "progress: 30 w1= 1.1240894809819713 w2= 1.5935434199016942 loss= 0.01051945849755671 \n",
      "\n",
      "\tgradw1: -0.564734198232669 1.0 3.0\n",
      "\tgradw2: -0.5534395142680157 1.0 3.0\n",
      "\tgradw1: -2.263176624432475 2.0 8.0\n",
      "\tgradw2: -0.7694800523070455 2.0 8.0\n",
      "\tgradw1: 3.449432692438876 3.0 15.0\n",
      "\tgradw2: -0.712882756437363 3.0 15.0\n",
      "progress: 31 w1= 1.117874262284234 w2= 1.6139014431318184 loss= 0.009492080742885108 \n",
      "\n",
      "\tgradw1: -0.536448589167895 1.0 3.0\n",
      "\tgradw2: -0.5257196173845369 1.0 3.0\n",
      "\tgradw1: -2.1498218294801603 2.0 8.0\n",
      "\tgradw2: -0.7309394220232548 2.0 8.0\n",
      "\tgradw1: 3.276662378654173 3.0 15.0\n",
      "\tgradw2: -0.677176891588541 3.0 15.0\n",
      "progress: 32 w1= 1.1119703426841727 w2= 1.6332398024417818 loss= 0.008565041332722723 \n",
      "\n",
      "\tgradw1: -0.509579709748091 1.0 3.0\n",
      "\tgradw2: -0.49938811555312945 1.0 3.0\n",
      "\tgradw1: -2.042144589430073 2.0 8.0\n",
      "\tgradw2: -0.6943291604062232 2.0 8.0\n",
      "\tgradw1: 3.112545540378875 3.0 15.0\n",
      "\tgradw2: -0.6432594116783008 3.0 15.0\n",
      "progress: 33 w1= 1.1063621302721658 w2= 1.6516095693181583 loss= 0.007728540771867338 \n",
      "\n",
      "\tgradw1: -0.4840566008193523 1.0 3.0\n",
      "\tgradw2: -0.47437546880296466 1.0 3.0\n",
      "\tgradw1: -1.939860534929494 2.0 8.0\n",
      "\tgradw2: -0.6595525818760279 2.0 8.0\n",
      "\tgradw1: 2.956648754551189 3.0 15.0\n",
      "\tgradw2: -0.6110407426072513 3.0 15.0\n",
      "progress: 34 w1= 1.1010348140841424 w2= 1.6690592572510206 loss= 0.006973736628009136 \n",
      "\n",
      "\tgradw1: -0.4598118573296741 1.0 3.0\n",
      "\tgradw2: -0.4506156201830809 1.0 3.0\n",
      "\tgradw1: -1.842699539716321 2.0 8.0\n",
      "\tgradw2: -0.6265178435035494 2.0 8.0\n",
      "\tgradw1: 2.8085603067914704 3.0 15.0\n",
      "\tgradw2: -0.5804357967369 3.0 15.0\n",
      "progress: 35 w1= 1.0959743249866878 w2= 1.6856349498552559 loss= 0.006292650060650624 \n",
      "\n",
      "\tgradw1: -0.43678145031611315 1.0 3.0\n",
      "\tgradw2: -0.42804582130979085 1.0 3.0\n",
      "\tgradw1: -1.7504050072311728 2.0 8.0\n",
      "\tgradw2: -0.5951377024585973 2.0 8.0\n",
      "\tgradw1: 2.6678891040888146 3.0 15.0\n",
      "\tgradw2: -0.551363748178364 3.0 15.0\n",
      "progress: 36 w1= 1.0911672985212726 w2= 1.7013804225747235 loss= 0.0056780814788411895 \n",
      "\n",
      "\tgradw1: -0.4149045578080077 1.0 3.0\n",
      "\tgradw2: -0.40660646665184785 1.0 3.0\n",
      "\tgradw1: -1.662733192960843 2.0 8.0\n",
      "\tgradw2: -0.5653292856066869 2.0 8.0\n",
      "\tgradw1: 2.534263641946424 3.0 15.0\n",
      "\tgradw2: -0.5237478193355969 3.0 15.0\n",
      "progress: 37 w1= 1.086601039609497 w2= 1.7163372582906649 loss= 0.0051235344361449525 \n",
      "\n",
      "\tgradw1: -0.39412340419967684 1.0 3.0\n",
      "\tgradw2: -0.38624093611568266 1.0 3.0\n",
      "\tgradw1: -1.5794525607230554 2.0 8.0\n",
      "\tgradw2: -0.5370138706458363 2.0 8.0\n",
      "\tgradw1: 2.40733102326044 3.0 15.0\n",
      "\tgradw2: -0.4975150781404807 3.0 15.0\n",
      "progress: 38 w1= 1.0822634890261198 w2= 1.730544957139685 loss= 0.00462314695838405 \n",
      "\n",
      "\tgradw1: -0.37438310766839056 1.0 3.0\n",
      "\tgradw2: -0.3668954455150226 1.0 3.0\n",
      "\tgradw1: -1.5003431711929167 2.0 8.0\n",
      "\tgradw2: -0.5101166782055913 2.0 8.0\n",
      "\tgradw1: 2.286756026338857 3.0 15.0\n",
      "\tgradw2: -0.47259624544335566 3.0 15.0\n",
      "progress: 39 w1= 1.0781431915513444 w2= 1.7440410408313247 loss= 0.004171629578213832 \n",
      "\n",
      "\tgradw1: -0.35563153523466173 1.0 3.0\n",
      "\tgradw2: -0.3485189045299686 1.0 3.0\n",
      "\tgradw1: -1.4251961010559029 2.0 8.0\n",
      "\tgradw2: -0.4845666743590087 2.0 8.0\n",
      "\tgradw1: 2.172220219600092 3.0 15.0\n",
      "\tgradw2: -0.44892551205069253 3.0 15.0\n",
      "progress: 40 w1= 1.074229265718249 w2= 1.7568611517407213 loss= 0.0037642094215215105 \n",
      "\n",
      "\tgradw1: -0.33781916508205967 1.0 3.0\n",
      "\tgradw2: -0.3310627817804175 1.0 3.0\n",
      "\tgradw1: -1.3538128912533622 2.0 8.0\n",
      "\tgradw2: -0.46029638302614373 2.0 8.0\n",
      "\tgradw1: 2.063421120614226 3.0 15.0\n",
      "\tgradw2: -0.4264403649269326 3.0 15.0\n",
      "progress: 41 w1= 1.0705113750754611 w2= 1.7690391470380562 loss= 0.003396579754604178 \n",
      "\n",
      "\tgradw1: -0.32089895577296534 1.0 3.0\n",
      "\tgradw2: -0.3144809766575065 1.0 3.0\n",
      "\tgradw1: -1.2860050228637903 2.0 8.0\n",
      "\tgradw2: -0.437241707773687 2.0 8.0\n",
      "\tgradw1: 1.9600713972641515 3.0 15.0\n",
      "\tgradw2: -0.40508142210126863 3.0 15.0\n",
      "progress: 42 w1= 1.0669797008891873 w2= 1.780607188103381 loss= 0.003064854458795405 \n",
      "\n",
      "\tgradw1: -0.30482622201486365 1.0 3.0\n",
      "\tgradw2: -0.2987296975745668 1.0 3.0\n",
      "\tgradw1: -1.2215934192352265 2.0 8.0\n",
      "\tgradw2: -0.41534176253997757 2.0 8.0\n",
      "\tgradw1: 1.8618981089178845 3.0 15.0\n",
      "\tgradw2: -0.3847922758430222 3.0 15.0\n",
      "progress: 43 w1= 1.0636249162125093 w2= 1.7915958254629565 loss= 0.0027655269512994857 \n",
      "\n",
      "\tgradw1: -0.28955851664906795 1.0 3.0\n",
      "\tgradw2: -0.283767346316087 1.0 3.0\n",
      "\tgradw1: -1.1604079730541201 2.0 8.0\n",
      "\tgradw2: -0.39453871083840397 2.0 8.0\n",
      "\tgradw1: 1.7686419856087454 3.0 15.0\n",
      "\tgradw2: -0.3655193436924762 3.0 15.0\n",
      "progress: 44 w1= 1.0604381612534537 w2= 1.802034079471426 loss= 0.0024954331180121105 \n",
      "\n",
      "\tgradw1: -0.275055518550241 1.0 3.0\n",
      "\tgradw2: -0.2695544081792356 1.0 3.0\n",
      "\tgradw1: -1.1022870971019074 2.0 8.0\n",
      "\tgradw2: -0.37477761301464696 2.0 8.0\n",
      "\tgradw1: 1.6800567433176994 3.0 15.0\n",
      "\tgradw2: -0.3472117269523203 3.0 15.0\n",
      "progress: 45 w1= 1.0574110199767983 w2= 1.811949516952888 loss= 0.002251717866479102 \n",
      "\n",
      "\tgradw1: -0.2612789261406272 1.0 3.0\n",
      "\tgradw2: -0.25605334761781506 1.0 3.0\n",
      "\tgradw1: -1.0470772975123879 2.0 8.0\n",
      "\tgradw2: -0.3560062811542153 2.0 8.0\n",
      "\tgradw1: 1.595908433552104 3.0 15.0\n",
      "\tgradw2: -0.32982107626744295 3.0 15.0\n",
      "progress: 46 w1= 1.0545354978778074 w2= 1.821368324003283 loss= 0.002031804945452293 \n",
      "\n",
      "\tgradw1: -0.2481923562378192 1.0 3.0\n",
      "\tgradw2: -0.24322850911306304 1.0 3.0\n",
      "\tgradw1: -0.9946327684034486 2.0 8.0\n",
      "\tgradw2: -0.3381751412571674 2.0 8.0\n",
      "\tgradw1: 1.5159748255008942 3.0 15.0\n",
      "\tgradw2: -0.3133014639368632 3.0 15.0\n",
      "progress: 47 w1= 1.051804000869211 w2= 1.830315375146354 loss= 0.0018333697119963146 \n",
      "\n",
      "\tgradw1: -0.23576124796887044 1.0 3.0\n",
      "\tgradw2: -0.23104602300949217 1.0 3.0\n",
      "\tgradw1: -0.9448150068120214 2.0 8.0\n",
      "\tgradw2: -0.3212371023160898 2.0 8.0\n",
      "\tgradw1: 1.4400448191362116 3.0 15.0\n",
      "\tgradw2: -0.2976092626214957 3.0 15.0\n",
      "progress: 48 w1= 1.0492093152256579 w2= 1.8388142990258247 loss= 0.001654314558289246 \n",
      "\n",
      "\tgradw1: -0.22395277149703485 1.0 3.0\n",
      "\tgradw2: -0.21947371606709432 1.0 3.0\n",
      "\tgradw1: -0.8974924469159689 2.0 8.0\n",
      "\tgradw2: -0.3051474319514291 2.0 8.0\n",
      "\tgradw1: 1.3679178877101776 3.0 15.0\n",
      "\tgradw2: -0.28270303012676834 3.0 15.0\n",
      "progress: 49 w1= 1.046744588532686 w2= 1.8468875408072776 loss= 0.0014927467383472458 \n",
      "\n",
      "\tgradw1: -0.21273574132007234 1.0 3.0\n",
      "\tgradw2: -0.20848102649367117 1.0 3.0\n",
      "\tgradw1: -0.8525401125761931 2.0 8.0\n",
      "\tgradw2: -0.2898636382759072 2.0 8.0\n",
      "\tgradw1: 1.2994035481756647 3.0 15.0\n",
      "\tgradw2: -0.26854339995630383 3.0 15.0\n",
      "progress: 50 w1= 1.044403311589892 w2= 1.8545564214545363 loss= 0.0013469583602957144 \n",
      "\n",
      "\tgradw1: -0.20208053391114333 1.0 3.0\n",
      "\tgradw2: -0.19803892323291983 1.0 3.0\n",
      "\tgradw1: -0.8098392872820384 2.0 8.0\n",
      "\tgradw2: -0.2753453576758922 2.0 8.0\n",
      "\tgradw1: 1.2343208581311629 3.0 15.0\n",
      "\tgradw2: -0.2550929773470827 3.0 15.0\n",
      "progress: 51 w1= 1.0421793012205125 w2= 1.8618411940370951 loss= 0.0012154083326813123 \n",
      "\n",
      "\tgradw1: -0.19195900948478517 1.0 3.0\n",
      "\tgradw2: -0.18811982929508897 1.0 3.0\n",
      "\tgradw1: -0.7692772006277266 2.0 8.0\n",
      "\tgradw2: -0.26155424821342876 2.0 8.0\n",
      "\tgradw1: 1.1724979379630582 3.0 15.0\n",
      "\tgradw2: -0.24231624051237688 3.0 15.0\n",
      "progress: 52 w1= 1.040066683942007 w2= 1.8687610972173043 loss= 0.0010967060739931623 \n",
      "\n",
      "\tgradw1: -0.18234443768137787 1.0 3.0\n",
      "\tgradw2: -0.17869754892775003 1.0 3.0\n",
      "\tgradw1: -0.7307467304924273 2.0 8.0\n",
      "\tgradw2: -0.248453888367429 2.0 8.0\n",
      "\tgradw1: 1.1137715169205116 3.0 15.0\n",
      "\tgradw2: -0.2301794468302525 3.0 15.0\n",
      "progress: 53 w1= 1.0380598804545398 w2= 1.8753344060585586 loss= 0.0009895968131791047 \n",
      "\n",
      "\tgradw1: -0.1732114269738032 1.0 3.0\n",
      "\tgradw2: -0.16974719843432773 1.0 3.0\n",
      "\tgradw1: -0.6941461201366792 2.0 8.0\n",
      "\tgradw2: -0.23600968084647178 2.0 8.0\n",
      "\tgradw1: 1.0579865019281804 3.0 15.0\n",
      "\tgradw2: -0.21865054373182247 3.0 15.0\n",
      "progress: 54 w1= 1.0361535909063626 w2= 1.8815784802886848 loss= 0.0008929483257885403 \n",
      "\n",
      "\tgradw1: -0.16453585760990563 1.0 3.0\n",
      "\tgradw2: -0.16124514045770688 1.0 3.0\n",
      "\tgradw1: -0.6593787094690384 2.0 8.0\n",
      "\tgradw2: -0.22418876121947307 2.0 8.0\n",
      "\tgradw1: 1.0049955679932836 3.0 15.0\n",
      "\tgradw2: -0.20769908405195636 3.0 15.0\n",
      "progress: 55 w1= 1.0343427808972192 w2= 1.8875098101459762 loss= 0.0008057389655159092 \n",
      "\n",
      "\tgradw1: -0.15629481791360966 1.0 3.0\n",
      "\tgradw2: -0.1531689215553369 1.0 3.0\n",
      "\tgradw1: -0.6263526797721539 2.0 8.0\n",
      "\tgradw2: -0.21295991112253176 2.0 8.0\n",
      "\tgradw1: 0.9546587691292459 3.0 15.0\n",
      "\tgradw2: -0.19729614562004372 3.0 15.0\n",
      "progress: 56 w1= 1.0326226681827846 w2= 1.8931440599289555 loss= 0.0007270468646403645 \n",
      "\n",
      "\tgradw1: -0.1484665437765198 1.0 3.0\n",
      "\tgradw2: -0.14549721290098994 1.0 3.0\n",
      "\tgradw1: -0.5949808112149668 2.0 8.0\n",
      "\tgradw2: -0.20229347581308588 2.0 8.0\n",
      "\tgradw1: 0.9068431687665068 3.0 15.0\n",
      "\tgradw2: -0.18741425487840502 3.0 15.0\n",
      "progress: 57 w1= 1.0309887100450343 w2= 1.8984961093648802 loss= 0.0006560401892007944 \n",
      "\n",
      "\tgradw1: -0.14103036118017087 1.0 3.0\n",
      "\tgradw2: -0.1382097539565681 1.0 3.0\n",
      "\tgradw1: -0.5651802525101175 2.0 8.0\n",
      "\tgradw2: -0.1921612858534374 2.0 8.0\n",
      "\tgradw1: 0.8614224886747301 3.0 15.0\n",
      "\tgradw2: -0.17802731432611196 3.0 15.0\n",
      "progress: 58 w1= 1.0294365912951897 w2= 1.9035800929062414 loss= 0.0005919683458912252 \n",
      "\n",
      "\tgradw1: -0.13396663159713817 1.0 3.0\n",
      "\tgradw2: -0.1312872989651943 1.0 3.0\n",
      "\tgradw1: -0.5368723021085486 2.0 8.0\n",
      "\tgradw2: -0.18253658271690654 2.0 8.0\n",
      "\tgradw1: 0.8182767754693465 3.0 15.0\n",
      "\tgradw2: -0.16911053359701 3.0 15.0\n",
      "progress: 59 w1= 1.0279622128775532 w2= 1.9084094370590323 loss= 0.0005341540477332578 \n",
      "\n",
      "\tgradw1: -0.12725670012682855 1.0 3.0\n",
      "\tgradw2: -0.1247115661242919 1.0 3.0\n",
      "\tgradw1: -0.5099822003533063 2.0 8.0\n",
      "\tgradw2: -0.17339394812012543 2.0 8.0\n",
      "\tgradw1: 0.7772920838211519 3.0 15.0\n",
      "\tgradw2: -0.1606403639896996 3.0 15.0\n",
      "progress: 60 w1= 1.026561681044143 w2= 1.9129968958413737 loss= 0.0004819861546483882 \n",
      "\n",
      "\tgradw1: -0.12088284622896683 1.0 3.0\n",
      "\tgradw2: -0.11846518930438776 1.0 3.0\n",
      "\tgradw1: -0.4844389320434743 2.0 8.0\n",
      "\tgradw2: -0.16470923689477956 2.0 8.0\n",
      "\tgradw1: 0.7383601755342362 3.0 15.0\n",
      "\tgradw2: -0.15259443627707014 3.0 15.0\n",
      "progress: 61 w1= 1.0252312970715252 w2= 1.917354584466136 loss= 0.00043491321325495454 \n",
      "\n",
      "\tgradw1: -0.11482823692467825 1.0 3.0\n",
      "\tgradw2: -0.11253167218618465 1.0 3.0\n",
      "\tgradw1: -0.46017503888732847 2.0 8.0\n",
      "\tgradw2: -0.15645951322169083 2.0 8.0\n",
      "\tgradw1: 0.701378233694129 3.0 15.0\n",
      "\tgradw2: -0.14495150163012127 3.0 15.0\n",
      "progress: 62 w1= 1.023967547492704 w2= 1.921494011336516 loss= 0.00039243762759480976 \n",
      "\n",
      "\tgradw1: -0.10907688234155977 1.0 3.0\n",
      "\tgradw2: -0.10689534469472939 1.0 3.0\n",
      "\tgradw1: -0.43712644134876655 2.0 8.0\n",
      "\tgradw2: -0.14862299005857693 2.0 8.0\n",
      "\tgradw1: 0.6662485911350196 3.0 15.0\n",
      "\tgradw2: -0.137691375501241 3.0 15.0\n",
      "progress: 63 w1= 1.022767094818257 w2= 1.9254261084390614 loss= 0.000354110399175117 \n",
      "\n",
      "\tgradw1: -0.10361359348536325 1.0 3.0\n",
      "\tgradw2: -0.10154132161565599 1.0 3.0\n",
      "\tgradw1: -0.41523226941697544 2.0 8.0\n",
      "\tgradw2: -0.14117897160176796 2.0 8.0\n",
      "\tgradw1: 0.632878472506178 3.0 15.0\n",
      "\tgradw2: -0.13079488431795028 3.0 15.0\n",
      "progress: 64 w1= 1.0216267687222187 w2= 1.9291612602144153 loss= 0.0003195263807206386 \n",
      "\n",
      "\tgradw1: -0.09842394212673256 1.0 3.0\n",
      "\tgradw2: -0.0964554632841974 1.0 3.0\n",
      "\tgradw1: -0.3944347018523331 2.0 8.0\n",
      "\tgradw2: -0.13410779862979183 2.0 8.0\n",
      "\tgradw1: 0.6011797492575468 3.0 15.0\n",
      "\tgradw2: -0.12424381484658653 3.0 15.0\n",
      "progress: 65 w1= 1.020543557669434 w2= 1.9327093309820211 loss= 0.00028831999346607003 \n",
      "\n",
      "\tgradw1: -0.09349422269708985 1.0 3.0\n",
      "\tgradw2: -0.09162433824314853 1.0 3.0\n",
      "\tgradw1: -0.37467881348380416 2.0 8.0\n",
      "\tgradw2: -0.1273907965844927 2.0 8.0\n",
      "\tgradw1: 0.5710687068974032 3.0 15.0\n",
      "\tgradw2: -0.11802086609212381 3.0 15.0\n",
      "progress: 66 w1= 1.0195146009622689 w2= 1.9360796909912188 loss= 0.0002601613627166732 \n",
      "\n",
      "\tgradw1: -0.08881141609302468 1.0 3.0\n",
      "\tgradw2: -0.08703518777116415 1.0 3.0\n",
      "\tgradw1: -0.3559124301547456 2.0 8.0\n",
      "\tgradw2: -0.12101022625261493 2.0 8.0\n",
      "\tgradw1: 0.5424658239075768 3.0 15.0\n",
      "\tgradw2: -0.11210960360756417 3.0 15.0\n",
      "progress: 67 w1= 1.0185371811856707 w2= 1.9392812411675322 loss= 0.00023475283082862158 \n",
      "\n",
      "\tgradw1: -0.08436315529359462 1.0 3.0\n",
      "\tgradw2: -0.08267589218772287 1.0 3.0\n",
      "\tgradw1: -0.338085990934033 2.0 8.0\n",
      "\tgradw2: -0.11494923691757464 2.0 8.0\n",
      "\tgradw1: 0.5152955617309942 3.0 15.0\n",
      "\tgradw2: -0.10649441609106702 3.0 15.0\n",
      "progress: 68 w1= 1.017608717030637 w2= 1.942322436619496 loss= 0.00021182581074514727 \n",
      "\n",
      "\tgradw1: -0.08013769269973459 1.0 3.0\n",
      "\tgradw2: -0.07853493884573925 1.0 3.0\n",
      "\tgradw1: -0.321152417228447 2.0 8.0\n",
      "\tgradw2: -0.10919182185767085 2.0 8.0\n",
      "\tgradw1: 0.4894861652794802 3.0 15.0\n",
      "\tgradw2: -0.10116047415775498 3.0 15.0\n",
      "progress: 69 w1= 1.016726756477124 w2= 1.9452113089681076 loss= 0.00019113794683327812 \n",
      "\n",
      "\tgradw1: -0.07612386910953717 1.0 3.0\n",
      "\tgradw2: -0.07460139172734603 1.0 3.0\n",
      "\tgradw1: -0.3050669884508821 2.0 8.0\n",
      "\tgradw2: -0.10372277607330105 2.0 8.0\n",
      "\tgradw1: 0.46496947343212724 3.0 15.0\n",
      "\tgradw2: -0.09609369117596955 3.0 15.0\n",
      "progress: 70 w1= 1.0158889703184069 w2= 1.947955487557874 loss= 0.00017247055300338943 \n",
      "\n",
      "\tgradw1: -0.07231108424743837 1.0 3.0\n",
      "\tgradw2: -0.07086486256248925 1.0 3.0\n",
      "\tgradw1: -0.28978722391582323 2.0 8.0\n",
      "\tgradw2: -0.09852765613138104 2.0 8.0\n",
      "\tgradw1: 0.441680739026296 3.0 15.0\n",
      "\tgradw2: -0.0912806860654456 3.0 15.0\n",
      "progress: 71 w1= 1.0150931460097763 w2= 1.9505622196054673 loss= 0.0001556263010362367 \n",
      "\n",
      "\tgradw1: -0.06868926876951242 1.0 3.0\n",
      "\tgradw2: -0.06731548339412274 1.0 3.0\n",
      "\tgradw1: -0.2752727706503819 2.0 8.0\n",
      "\tgradw2: -0.09359274202113 2.0 8.0\n",
      "\tgradw1: 0.4195584578633884 3.0 15.0\n",
      "\tgradw2: -0.08670874795841144 3.0 15.0\n",
      "progress: 72 w1= 1.0143371818253413 w2= 1.9530383893392038 loss= 0.00014042713467554623 \n",
      "\n",
      "\tgradw1: -0.06524885767090982 1.0 3.0\n",
      "\tgradw2: -0.06394388051749189 1.0 3.0\n",
      "\tgradw1: -0.26148529682432553 2.0 8.0\n",
      "\tgradw2: -0.08890500092027054 2.0 8.0\n",
      "\tgradw1: 0.39854420628095255 3.0 15.0\n",
      "\tgradw2: -0.0823658026314007 3.0 15.0\n",
      "progress: 73 w1= 1.0136190813074841 w2= 1.9553905361798953 loss= 0.00012671238744305465 \n",
      "\n",
      "\tgradw1: -0.061980765025241524 1.0 3.0\n",
      "\tgradw2: -0.06074114972473588 1.0 3.0\n",
      "\tgradw1: -0.24838839051814432 2.0 8.0\n",
      "\tgradw2: -0.08445205277617163 2.0 8.0\n",
      "\tgradw1: 0.37858248685754603 3.0 15.0\n",
      "\tgradw2: -0.07824038061722405 3.0 15.0\n",
      "progress: 74 w1= 1.0129369479943426 w2= 1.9576248720110767 loss= 0.00011433708427215756 \n",
      "\n",
      "\tgradw1: -0.05887635998916174 1.0 3.0\n",
      "\tgradw2: -0.05769883278937815 1.0 3.0\n",
      "\tgradw1: -0.23594746356097573 2.0 8.0\n",
      "\tgradw2: -0.0802221376107326 2.0 8.0\n",
      "\tgradw1: 0.35962058184895085 3.0 15.0\n",
      "\tgradw2: -0.07432158691545965 3.0 15.0\n",
      "progress: 75 w1= 1.0122889804113544 w2= 1.9597472975842325 loss= 0.00010317040901584416 \n",
      "\n",
      "\tgradw1: -0.055927444008826654 1.0 3.0\n",
      "\tgradw2: -0.05480889512864984 1.0 3.0\n",
      "\tgradw1: -0.2241296601855325 2.0 8.0\n",
      "\tgradw2: -0.07620408446308247 2.0 8.0\n",
      "\tgradw1: 0.34160841396232655 3.0 15.0\n",
      "\tgradw2: -0.07059907221888295 3.0 15.0\n",
      "progress: 76 w1= 1.0116734673136745 w2= 1.9617634181023387 loss= 9.309432162132837e-05 \n",
      "\n",
      "\tgradw1: -0.05312622916797416 1.0 3.0\n",
      "\tgradw2: -0.05206370458461418 1.0 3.0\n",
      "\tgradw1: -0.2129037702577108 2.0 8.0\n",
      "\tgradw2: -0.07238728188762167 2.0 8.0\n",
      "\tgradw1: 0.3244984141061593 3.0 15.0\n",
      "\tgradw2: -0.06706300558193234 3.0 15.0\n",
      "progress: 77 w1= 1.0110887831668698 w2= 1.9636785580228804 loss= 8.400231036027433e-05 \n",
      "\n",
      "\tgradw1: -0.05046531762049966 1.0 3.0\n",
      "\tgradw2: -0.04945601126808974 1.0 3.0\n",
      "\tgradw1: -0.20224014685263114 2.0 8.0\n",
      "\tgradw2: -0.06876164992988976 2.0 8.0\n",
      "\tgradw1: 0.3082453957618263 3.0 15.0\n",
      "\tgradw2: -0.0637040484574456 3.0 15.0\n",
      "progress: 78 w1= 1.010533383853983 w2= 1.9654977751194345 loss= 7.579826591965765e-05 \n",
      "\n",
      "\tgradw1: -0.047937682053165176 1.0 3.0\n",
      "\tgradw2: -0.04697892841210205 1.0 3.0\n",
      "\tgradw1: -0.1921106279586482 2.0 8.0\n",
      "\tgradw2: -0.06531761350593968 2.0 8.0\n",
      "\tgradw1: 0.292806435649581 3.0 15.0\n",
      "\tgradw2: -0.06051333003424375 3.0 15.0\n",
      "progress: 79 w1= 1.0100058025976053 w2= 1.9672258738389574 loss= 6.83954654554461e-05 \n",
      "\n",
      "\tgradw1: -0.045536647126874996 1.0 3.0\n",
      "\tgradw2: -0.044625914184337034 1.0 3.0\n",
      "\tgradw1: -0.18248846210322256 2.0 8.0\n",
      "\tgradw2: -0.06204607711509169 2.0 8.0\n",
      "\tgradw1: 0.2781407603702064 3.0 15.0\n",
      "\tgradw2: -0.05748242380984436 3.0 15.0\n",
      "progress: 80 w1= 1.0095046460862043 w2= 1.96886741799005 loss= 6.171565586773229e-05 \n",
      "\n",
      "\tgradw1: -0.043255871847491356 1.0 3.0\n",
      "\tgradw2: -0.042390754410542186 1.0 3.0\n",
      "\tgradw1: -0.17334823770377739 2.0 8.0\n",
      "\tgradw2: -0.058938400819286585 2.0 8.0\n",
      "\tgradw1: 0.2642096387249424 3.0 15.0\n",
      "\tgradw2: -0.0546033253364655 3.0 15.0\n",
      "progress: 81 w1= 1.0090285907944676 w2= 1.9704267427957132 loss= 5.5688226607138706e-05 \n",
      "\n",
      "\tgradw1: -0.041089332819638 1.0 3.0\n",
      "\tgradw2: -0.04026754616324624 1.0 3.0\n",
      "\tgradw1: -0.16466581595722118 2.0 8.0\n",
      "\tgradw2: -0.0559863774254552 2.0 8.0\n",
      "\tgradw1: 0.2509762794286665 3.0 15.0\n",
      "\tgradw2: -0.051868431081924626 3.0 15.0\n",
      "progress: 82 w1= 1.0085763794879494 w2= 1.9719079663424193 loss= 5.024946326906579e-05 \n",
      "\n",
      "\tgradw1: -0.03903130833926305 1.0 3.0\n",
      "\tgradw2: -0.03825068217247729 1.0 3.0\n",
      "\tgradw1: -0.1564182670907499 2.0 8.0\n",
      "\tgradw2: -0.05318221081085639 2.0 8.0\n",
      "\tgradw1: 0.23840573394604903 3.0 15.0\n",
      "\tgradw2: -0.04927051834884821 3.0 15.0\n",
      "progress: 83 w1= 1.008146817902789 w2= 1.973315000455741 loss= 4.534187408477618e-05 \n",
      "\n",
      "\tgradw1: -0.037076363282940505 1.0 3.0\n",
      "\tgradw2: -0.03633483601728127 1.0 3.0\n",
      "\tgradw1: -0.1485838098055865 2.0 8.0\n",
      "\tgradw2: -0.05051849533390396 2.0 8.0\n",
      "\tgradw1: 0.22646480419488668 3.0 15.0\n",
      "\tgradw2: -0.04680272620027637 3.0 15.0\n",
      "progress: 84 w1= 1.0077387715917254 w2= 1.9746515610312556 loss= 4.0913582191189354e-05 \n",
      "\n",
      "\tgradw1: -0.03521933475403749 1.0 3.0\n",
      "\tgradw2: -0.03451494805895727 1.0 3.0\n",
      "\tgradw1: -0.14114175375397053 2.0 8.0\n",
      "\tgradw2: -0.04798819627634998 2.0 8.0\n",
      "\tgradw1: 0.2151219548713712 3.0 15.0\n",
      "\tgradw2: -0.04445853734007699 3.0 15.0\n",
      "progress: 85 w1= 1.0073511629280918 w2= 1.9759211778480095 loss= 3.691777725343177e-05 \n",
      "\n",
      "\tgradw1: -0.03345531844779792 1.0 3.0\n",
      "\tgradw2: -0.03278621207884136 1.0 3.0\n",
      "\tgradw1: -0.13407244489700076 2.0 8.0\n",
      "\tgradw2: -0.04558463126497969 2.0 8.0\n",
      "\tgradw1: 0.20434723016762035 3.0 15.0\n",
      "\tgradw2: -0.04223176090129499 3.0 15.0\n",
      "progress: 86 w1= 1.0069829682598637 w2= 1.9771272038904608 loss= 3.3312220645048363e-05 \n",
      "\n",
      "\tgradw1: -0.03177965569935104 1.0 3.0\n",
      "\tgradw2: -0.03114406258536384 1.0 3.0\n",
      "\tgradw1: -0.127357213599538 2.0 8.0\n",
      "\tgradw2: -0.04330145262384377 2.0 8.0\n",
      "\tgradw1: 0.19411217465998476 3.0 15.0\n",
      "\tgradw2: -0.0401165160964041 3.0 15.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 87 w1= 1.0066332152062527 w2= 1.9782728242035168 loss= 3.00587989544408e-05 \n",
      "\n",
      "\tgradw1: -0.03018792118046143 1.0 3.0\n",
      "\tgradw2: -0.029584162756851384 1.0 3.0\n",
      "\tgradw1: -0.12097832532479913 2.0 8.0\n",
      "\tgradw2: -0.04113263061043426 2.0 8.0\n",
      "\tgradw1: 0.18438975815972114 3.0 15.0\n",
      "\tgradw2: -0.03810721668634898 3.0 15.0\n",
      "progress: 88 w1= 1.006300980089708 w2= 1.9793610643040531 loss= 2.71231210975375e-05 \n",
      "\n",
      "\tgradw1: -0.0286759112124777 1.0 3.0\n",
      "\tgradw2: -0.028102392988228253 1.0 3.0\n",
      "\tgradw1: -0.11491893379838558 2.0 8.0\n",
      "\tgradw2: -0.03907243749145195 2.0 8.0\n",
      "\tgradw1: 0.17515430432817425 3.0 15.0\n",
      "\tgradw2: -0.03619855622782353 3.0 15.0\n",
      "progress: 89 w1= 1.0059853854965348 w2= 1.9803947981711283 loss= 2.44741547786245e-05 \n",
      "\n",
      "\tgradw1: -0.027239632664674218 1.0 3.0\n",
      "\tgradw2: -0.02669484001138045 1.0 3.0\n",
      "\tgradw1: -0.10916303651831782 2.0 8.0\n",
      "\tgradw2: -0.037115432416229055 2.0 8.0\n",
      "\tgradw1: 0.16638142286689117 3.0 15.0\n",
      "\tgradw2: -0.03438549405915836 3.0 15.0\n",
      "progress: 90 w1= 1.0056855979596957 w2= 1.981376755835996 loss= 2.2083898456040972e-05 \n",
      "\n",
      "\tgradw1: -0.025875292408616524 1.0 3.0\n",
      "\tgradw2: -0.02535778656044485 1.0 3.0\n",
      "\tgradw1: -0.10369543249337454 2.0 8.0\n",
      "\tgradw2: -0.035256447047746775 2.0 8.0\n",
      "\tgradw1: 0.1580479451041228 3.0 15.0\n",
      "\tgradw2: -0.032663241988185376 3.0 15.0\n",
      "progress: 91 w1= 1.0054008257576743 w2= 1.9823095305919598 loss= 1.992708534486321e-05 \n",
      "\n",
      "\tgradw1: -0.024579287300731778 1.0 3.0\n",
      "\tgradw2: -0.024087701554717178 1.0 3.0\n",
      "\tgradw1: -0.09850168209807464 2.0 8.0\n",
      "\tgradw2: -0.03349057191334737 2.0 8.0\n",
      "\tgradw1: 0.15013186280789625 3.0 15.0\n",
      "\tgradw2: -0.031027251646960963 3.0 15.0\n",
      "progress: 92 w1= 1.0051303168235834 w2= 1.98319558584311 loss= 1.798091632831794e-05 \n",
      "\n",
      "\tgradw1: -0.023348194666612976 1.0 3.0\n",
      "\tgradw2: -0.022881230773281303 1.0 3.0\n",
      "\tgradw1: -0.09356806893853076 2.0 8.0\n",
      "\tgradw2: -0.03181314343910202 2.0 8.0\n",
      "\tgradw1: 0.14261227006342025 3.0 15.0\n",
      "\tgradw2: -0.029473202479763927 3.0 15.0\n",
      "progress: 93 w1= 1.0048733567590005 w2= 1.9840372616100315 loss= 1.6224818954202985e-05 \n",
      "\n",
      "\tgradw1: -0.022178763261935686 1.0 3.0\n",
      "\tgradw2: -0.021735187996696936 1.0 3.0\n",
      "\tgradw1: -0.08888156362819188 2.0 8.0\n",
      "\tgradw2: -0.030219731633586377 2.0 8.0\n",
      "\tgradw1: 0.13546930806211321 3.0 15.0\n",
      "\tgradw2: -0.027996990332830762 3.0 15.0\n",
      "progress: 94 w1= 1.0046292669472805 w2= 1.9848367807096627 loss= 1.4640229968868484e-05 \n",
      "\n",
      "\tgradw1: -0.02106790468611308 1.0 3.0\n",
      "\tgradw2: -0.02064654659239107 1.0 3.0\n",
      "\tgradw1: -0.08442978937807766 2.0 8.0\n",
      "\tgradw2: -0.028706128388545693 2.0 8.0\n",
      "\tgradw1: 0.1286841126549163 3.0 15.0\n",
      "\tgradw2: -0.026594716615356617 3.0 15.0\n",
      "progress: 95 w1= 1.0043974027613733 w2= 1.9855962546256256 loss= 1.3210399089575424e-05 \n",
      "\n",
      "\tgradw1: -0.020012685226001636 1.0 3.0\n",
      "\tgradw2: -0.019612431521482065 1.0 3.0\n",
      "\tgradw1: -0.08020098931028485 2.0 8.0\n",
      "\tgradw2: -0.027268336365498413 2.0 8.0\n",
      "\tgradw1: 0.12223876453403193 3.0 15.0\n",
      "\tgradw2: -0.025262678003720396 3.0 15.0\n",
      "progress: 96 w1= 1.0041771518613958 w2= 1.9863176890845327 loss= 1.1920211941829785e-05 \n",
      "\n",
      "\tgradw1: -0.01901031810814313 1.0 3.0\n",
      "\tgradw2: -0.018630111745980393 1.0 3.0\n",
      "\tgradw1: -0.07618399540885434 2.0 8.0\n",
      "\tgradw2: -0.02590255843900735 2.0 8.0\n",
      "\tgradw1: 0.11611624190831549 3.0 15.0\n",
      "\tgradw2: -0.023997356661062952 3.0 15.0\n",
      "progress: 97 w1= 1.0039679325774824 w2= 1.9870029893529932 loss= 1.0756030289030778e-05 \n",
      "\n",
      "\tgradw1: -0.018058156139048265 1.0 3.0\n",
      "\tgradw2: -0.01769699301626737 1.0 3.0\n",
      "\tgradw1: -0.07236819902557556 2.0 8.0\n",
      "\tgradw2: -0.02460518766869413 2.0 8.0\n",
      "\tgradw1: 0.110300375550338 3.0 15.0\n",
      "\tgradw2: -0.022795410947065164 3.0 15.0\n",
      "progress: 98 w1= 1.0037691923736254 w2= 1.9876539652693135 loss= 9.705547866354674e-06 \n",
      "\n",
      "\tgradw1: -0.017153684714122264 1.0 3.0\n",
      "\tgradw2: -0.016810611019839605 1.0 3.0\n",
      "\tgradw1: -0.06874352286327223 2.0 8.0\n",
      "\tgradw2: -0.023372797773511422 2.0 8.0\n",
      "\tgradw1: 0.10477580609406445 3.0 15.0\n",
      "\tgradw2: -0.02165366659278334 3.0 15.0\n",
      "progress: 99 w1= 1.0035804063884588 w2= 1.9882723360231749 loss= 8.757660294314735e-06 \n",
      "\n",
      "predict (after training) 4 hours 24.01037584630804\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]        # y = x^2 + 2x \n",
    "y_data = [3.0, 8.0, 15.0]\n",
    "w1 = 0.1\n",
    "w2 = 0.1\n",
    "\n",
    "def forward(x):\n",
    "    return w1*x*x + w2*x\n",
    "    \n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "    \n",
    "def gradientw1(x,y):\n",
    "    return 2*x*x*(w1*x*x + w2*x - y)\n",
    "\n",
    "def gradientw2(x,y):\n",
    "    return 2*x*(w1*x*x + w2*x - y)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grada = gradientw1(x_val, y_val)\n",
    "        w1 = w1 - grada * 0.01\n",
    "        gradb = gradientw2(x_val, y_val)\n",
    "        w2 = w2 - gradb * 0.01\n",
    "        print(\"\\tgradw1:\",grada, x_val, y_val)\n",
    "        print(\"\\tgradw2:\",gradb, x_val, y_val)\n",
    "        \n",
    "        l = loss(x_val, y_val)\n",
    "        \n",
    "    print(\"progress:\", epoch, \"w1=\", w1, \"w2=\", w2, \"loss=\", l,\"\\n\")\n",
    "\n",
    "print(\"predict (after training)\", \"4 hours\", forward(4))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([-2.]) -2.0\n",
      "\tgrad:  tensor(-2.) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-7.8400]) -7.840000152587891\n",
      "\tgrad:  tensor(-7.8400) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-16.2288]) -16.228801727294922\n",
      "\tgrad:  tensor(-16.2288) 3.0 6.0\n",
      "progress:  0 tensor(7.3159) tensor(1.2607) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.4786]) -1.478623867034912\n",
      "\tgrad:  tensor(-1.4786) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-5.7962]) -5.796205520629883\n",
      "\tgrad:  tensor(-5.7962) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-11.9981]) -11.998146057128906\n",
      "\tgrad:  tensor(-11.9981) 3.0 6.0\n",
      "progress:  1 tensor(3.9988) tensor(1.4534) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.0932]) -1.0931644439697266\n",
      "\tgrad:  tensor(-1.0932) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-4.2852]) -4.285204887390137\n",
      "\tgrad:  tensor(-4.2852) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-8.8704]) -8.870372772216797\n",
      "\tgrad:  tensor(-8.8704) 3.0 6.0\n",
      "progress:  2 tensor(2.1857) tensor(1.5959) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.8082]) -0.8081896305084229\n",
      "\tgrad:  tensor(-0.8082) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-3.1681]) -3.1681032180786133\n",
      "\tgrad:  tensor(-3.1681) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-6.5580]) -6.557973861694336\n",
      "\tgrad:  tensor(-6.5580) 3.0 6.0\n",
      "progress:  3 tensor(1.1946) tensor(1.7012) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.5975]) -0.5975041389465332\n",
      "\tgrad:  tensor(-0.5975) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-2.3422]) -2.3422164916992188\n",
      "\tgrad:  tensor(-2.3422) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-4.8484]) -4.848389625549316\n",
      "\tgrad:  tensor(-4.8484) 3.0 6.0\n",
      "progress:  4 tensor(0.6530) tensor(1.7791) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.4417]) -0.4417421817779541\n",
      "\tgrad:  tensor(-0.4417) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.7316]) -1.7316293716430664\n",
      "\tgrad:  tensor(-1.7316) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-3.5845]) -3.58447265625\n",
      "\tgrad:  tensor(-3.5845) 3.0 6.0\n",
      "progress:  5 tensor(0.3569) tensor(1.8367) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.3266]) -0.3265852928161621\n",
      "\tgrad:  tensor(-0.3266) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.2802]) -1.2802143096923828\n",
      "\tgrad:  tensor(-1.2802) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-2.6500]) -2.650045394897461\n",
      "\tgrad:  tensor(-2.6500) 3.0 6.0\n",
      "progress:  6 tensor(0.1951) tensor(1.8793) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.2414]) -0.24144840240478516\n",
      "\tgrad:  tensor(-0.2414) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.9465]) -0.9464778900146484\n",
      "\tgrad:  tensor(-0.9465) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.9592]) -1.9592113494873047\n",
      "\tgrad:  tensor(-1.9592) 3.0 6.0\n",
      "progress:  7 tensor(0.1066) tensor(1.9107) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.1785]) -0.17850565910339355\n",
      "\tgrad:  tensor(-0.1785) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.6997]) -0.699742317199707\n",
      "\tgrad:  tensor(-0.6997) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.4485]) -1.4484672546386719\n",
      "\tgrad:  tensor(-1.4485) 3.0 6.0\n",
      "progress:  8 tensor(0.0583) tensor(1.9340) \n",
      "\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.1320]) -0.1319713592529297\n",
      "\tgrad:  tensor(-0.1320) 1.0 2.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.5173]) -0.5173273086547852\n",
      "\tgrad:  tensor(-0.5173) 2.0 4.0\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-1.0709]) -1.070866584777832\n",
      "\tgrad:  tensor(-1.0709) 3.0 6.0\n",
      "progress:  9 tensor(0.0319) tensor(1.9512) \n",
      "\n",
      "prdict(after training) 4 tensor(7.8049)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "w_list = []\n",
    "l_list = []\n",
    "x_data = [1.0, 2.0, 3.0]          # y = 2x\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = Variable(torch.Tensor([1.0]), requires_grad = True)            # random value ? variable - 1.0을 백프롭 가능하게 바꿔준다\n",
    "                                                                    # w의 grad를 구한다. w에 대한 l의 grad를 구하려면 variable을 해야한다.  \n",
    "\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)*(y_pred - y)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        \n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(type(w.grad))\n",
    "        print(w.grad, w.grad.item())\n",
    "        print(\"\\tgrad: \", w.grad.data[0], x_val, y_val)                 # .data[0]의 의미 - > tensor를 벗겨낸다.\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "      \n",
    "        w.grad.data.zero_()\n",
    "    print(\"progress: \", epoch, l.data[0], w.data[0],\"\\n\")\n",
    "    \n",
    "    w_list.append(w.data[0])\n",
    "    l_list.append(l.data[0])\n",
    "    \n",
    "print(\"prdict(after training)\", 4, forward(4).data[0])\n",
    "\n",
    "\n",
    "plt.plot(w_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tw1grad:  tensor(-2.) 1.0 3.0\n",
      "\tw2grad:  tensor(-2.) 1.0 3.0\n",
      "\tw1grad:  tensor(-15.0400) 2.0 8.0\n",
      "\tw2grad:  tensor(-7.5200) 2.0 8.0\n",
      "\tw1grad:  tensor(-21.2544) 3.0 15.0\n",
      "\tw2grad:  tensor(-7.0848) 3.0 15.0\n",
      "progress:  0 tensor(1.3943) tensor(1.3829) tensor(1.1660) \n",
      "\n",
      "\tw1grad:  tensor(-0.9020) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9020) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6561) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3280) 2.0 8.0\n",
      "\tw1grad:  tensor(20.1918) 3.0 15.0\n",
      "\tw2grad:  tensor(6.7306) 3.0 15.0\n",
      "progress:  1 tensor(1.2584) tensor(1.1966) tensor(1.1110) \n",
      "\n",
      "\tw1grad:  tensor(-1.3847) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.3847) 1.0 3.0\n",
      "\tw1grad:  tensor(-7.2673) 2.0 8.0\n",
      "\tw2grad:  tensor(-3.6336) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5726) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1909) 3.0 15.0\n",
      "progress:  2 tensor(0.0010) tensor(1.2774) tensor(1.1593) \n",
      "\n",
      "\tw1grad:  tensor(-1.1266) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.1266) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.0334) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.0167) 2.0 8.0\n",
      "\tw1grad:  tensor(9.5984) 3.0 15.0\n",
      "\tw2grad:  tensor(3.1995) 3.0 15.0\n",
      "progress:  3 tensor(0.2843) tensor(1.2330) tensor(1.1588) \n",
      "\n",
      "\tw1grad:  tensor(-1.2165) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.2165) 1.0 3.0\n",
      "\tw1grad:  tensor(-5.4195) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.7098) 2.0 8.0\n",
      "\tw1grad:  tensor(5.1917) 3.0 15.0\n",
      "\tw2grad:  tensor(1.7306) 3.0 15.0\n",
      "progress:  4 tensor(0.0832) tensor(1.2475) tensor(1.1807) \n",
      "\n",
      "\tw1grad:  tensor(-1.1437) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.1437) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.6410) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.3205) 2.0 8.0\n",
      "\tw1grad:  tensor(7.0884) 3.0 15.0\n",
      "\tw2grad:  tensor(2.3628) 3.0 15.0\n",
      "progress:  5 tensor(0.1551) tensor(1.2344) tensor(1.1917) \n",
      "\n",
      "\tw1grad:  tensor(-1.1477) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.1477) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.8800) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.4400) 2.0 8.0\n",
      "\tw1grad:  tensor(6.0316) 3.0 15.0\n",
      "\tw2grad:  tensor(2.0105) 3.0 15.0\n",
      "progress:  6 tensor(0.1123) tensor(1.2344) tensor(1.2075) \n",
      "\n",
      "\tw1grad:  tensor(-1.1162) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.1162) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.6440) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.3220) 2.0 8.0\n",
      "\tw1grad:  tensor(6.3630) 3.0 15.0\n",
      "\tw2grad:  tensor(2.1210) 3.0 15.0\n",
      "progress:  7 tensor(0.1250) tensor(1.2284) tensor(1.2207) \n",
      "\n",
      "\tw1grad:  tensor(-1.1020) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.1020) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.6330) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.3165) 2.0 8.0\n",
      "\tw1grad:  tensor(6.0462) 3.0 15.0\n",
      "\tw2grad:  tensor(2.0154) 3.0 15.0\n",
      "progress:  8 tensor(0.1128) tensor(1.2252) tensor(1.2347) \n",
      "\n",
      "\tw1grad:  tensor(-1.0801) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.0801) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.5186) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.2593) 2.0 8.0\n",
      "\tw1grad:  tensor(6.0363) 3.0 15.0\n",
      "\tw2grad:  tensor(2.0121) 3.0 15.0\n",
      "progress:  9 tensor(0.1125) tensor(1.2209) tensor(1.2480) \n",
      "\n",
      "\tw1grad:  tensor(-1.0623) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.0623) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.4548) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.2274) 2.0 8.0\n",
      "\tw1grad:  tensor(5.8851) 3.0 15.0\n",
      "\tw2grad:  tensor(1.9617) 3.0 15.0\n",
      "progress:  10 tensor(0.1069) tensor(1.2172) tensor(1.2613) \n",
      "\n",
      "\tw1grad:  tensor(-1.0431) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.0431) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.3693) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.1846) 2.0 8.0\n",
      "\tw1grad:  tensor(5.8030) 3.0 15.0\n",
      "\tw2grad:  tensor(1.9343) 3.0 15.0\n",
      "progress:  11 tensor(0.1039) tensor(1.2133) tensor(1.2742) \n",
      "\n",
      "\tw1grad:  tensor(-1.0251) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.0251) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.2960) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.1480) 2.0 8.0\n",
      "\tw1grad:  tensor(5.6912) 3.0 15.0\n",
      "\tw2grad:  tensor(1.8971) 3.0 15.0\n",
      "progress:  12 tensor(0.1000) tensor(1.2096) tensor(1.2869) \n",
      "\n",
      "\tw1grad:  tensor(-1.0069) 1.0 3.0\n",
      "\tw2grad:  tensor(-1.0069) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.2190) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.1095) 2.0 8.0\n",
      "\tw1grad:  tensor(5.5959) 3.0 15.0\n",
      "\tw2grad:  tensor(1.8653) 3.0 15.0\n",
      "progress:  13 tensor(0.0966) tensor(1.2059) tensor(1.2995) \n",
      "\n",
      "\tw1grad:  tensor(-0.9893) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9893) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.1456) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.0728) 2.0 8.0\n",
      "\tw1grad:  tensor(5.4955) 3.0 15.0\n",
      "\tw2grad:  tensor(1.8318) 3.0 15.0\n",
      "progress:  14 tensor(0.0932) tensor(1.2023) tensor(1.3118) \n",
      "\n",
      "\tw1grad:  tensor(-0.9719) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9719) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.0725) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.0362) 2.0 8.0\n",
      "\tw1grad:  tensor(5.4000) 3.0 15.0\n",
      "\tw2grad:  tensor(1.8000) 3.0 15.0\n",
      "progress:  15 tensor(0.0900) tensor(1.1987) tensor(1.3238) \n",
      "\n",
      "\tw1grad:  tensor(-0.9549) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9549) 1.0 3.0\n",
      "\tw1grad:  tensor(-4.0012) 2.0 8.0\n",
      "\tw2grad:  tensor(-2.0006) 2.0 8.0\n",
      "\tw1grad:  tensor(5.3047) 3.0 15.0\n",
      "\tw2grad:  tensor(1.7682) 3.0 15.0\n",
      "progress:  16 tensor(0.0869) tensor(1.1952) tensor(1.3357) \n",
      "\n",
      "\tw1grad:  tensor(-0.9381) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9381) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.9308) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.9654) 2.0 8.0\n",
      "\tw1grad:  tensor(5.2118) 3.0 15.0\n",
      "\tw2grad:  tensor(1.7373) 3.0 15.0\n",
      "progress:  17 tensor(0.0838) tensor(1.1918) tensor(1.3474) \n",
      "\n",
      "\tw1grad:  tensor(-0.9216) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9216) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.8619) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.9309) 2.0 8.0\n",
      "\tw1grad:  tensor(5.1202) 3.0 15.0\n",
      "\tw2grad:  tensor(1.7067) 3.0 15.0\n",
      "progress:  18 tensor(0.0809) tensor(1.1884) tensor(1.3588) \n",
      "\n",
      "\tw1grad:  tensor(-0.9055) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.9055) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.7940) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.8970) 2.0 8.0\n",
      "\tw1grad:  tensor(5.0304) 3.0 15.0\n",
      "\tw2grad:  tensor(1.6768) 3.0 15.0\n",
      "progress:  19 tensor(0.0781) tensor(1.1851) tensor(1.3701) \n",
      "\n",
      "\tw1grad:  tensor(-0.8896) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8896) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.7274) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.8637) 2.0 8.0\n",
      "\tw1grad:  tensor(4.9420) 3.0 15.0\n",
      "\tw2grad:  tensor(1.6473) 3.0 15.0\n",
      "progress:  20 tensor(0.0754) tensor(1.1819) tensor(1.3812) \n",
      "\n",
      "\tw1grad:  tensor(-0.8739) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8739) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.6620) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.8310) 2.0 8.0\n",
      "\tw1grad:  tensor(4.8553) 3.0 15.0\n",
      "\tw2grad:  tensor(1.6184) 3.0 15.0\n",
      "progress:  21 tensor(0.0728) tensor(1.1787) tensor(1.3920) \n",
      "\n",
      "\tw1grad:  tensor(-0.8586) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8586) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.5977) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.7989) 2.0 8.0\n",
      "\tw1grad:  tensor(4.7700) 3.0 15.0\n",
      "\tw2grad:  tensor(1.5900) 3.0 15.0\n",
      "progress:  22 tensor(0.0702) tensor(1.1755) tensor(1.4027) \n",
      "\n",
      "\tw1grad:  tensor(-0.8435) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8435) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.5345) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.7673) 2.0 8.0\n",
      "\tw1grad:  tensor(4.6863) 3.0 15.0\n",
      "\tw2grad:  tensor(1.5621) 3.0 15.0\n",
      "progress:  23 tensor(0.0678) tensor(1.1725) tensor(1.4132) \n",
      "\n",
      "\tw1grad:  tensor(-0.8287) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8287) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.4725) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.7362) 2.0 8.0\n",
      "\tw1grad:  tensor(4.6040) 3.0 15.0\n",
      "\tw2grad:  tensor(1.5347) 3.0 15.0\n",
      "progress:  24 tensor(0.0654) tensor(1.1694) tensor(1.4235) \n",
      "\n",
      "\tw1grad:  tensor(-0.8142) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.8142) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.4115) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.7058) 2.0 8.0\n",
      "\tw1grad:  tensor(4.5231) 3.0 15.0\n",
      "\tw2grad:  tensor(1.5077) 3.0 15.0\n",
      "progress:  25 tensor(0.0631) tensor(1.1665) tensor(1.4336) \n",
      "\n",
      "\tw1grad:  tensor(-0.7999) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7999) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.3516) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.6758) 2.0 8.0\n",
      "\tw1grad:  tensor(4.4437) 3.0 15.0\n",
      "\tw2grad:  tensor(1.4812) 3.0 15.0\n",
      "progress:  26 tensor(0.0609) tensor(1.1635) tensor(1.4435) \n",
      "\n",
      "\tw1grad:  tensor(-0.7858) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7858) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.2928) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.6464) 2.0 8.0\n",
      "\tw1grad:  tensor(4.3657) 3.0 15.0\n",
      "\tw2grad:  tensor(1.4552) 3.0 15.0\n",
      "progress:  27 tensor(0.0588) tensor(1.1607) tensor(1.4533) \n",
      "\n",
      "\tw1grad:  tensor(-0.7720) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7720) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.2349) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.6175) 2.0 8.0\n",
      "\tw1grad:  tensor(4.2891) 3.0 15.0\n",
      "\tw2grad:  tensor(1.4297) 3.0 15.0\n",
      "progress:  28 tensor(0.0568) tensor(1.1578) tensor(1.4629) \n",
      "\n",
      "\tw1grad:  tensor(-0.7585) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7585) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.1782) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.5891) 2.0 8.0\n",
      "\tw1grad:  tensor(4.2138) 3.0 15.0\n",
      "\tw2grad:  tensor(1.4046) 3.0 15.0\n",
      "progress:  29 tensor(0.0548) tensor(1.1551) tensor(1.4723) \n",
      "\n",
      "\tw1grad:  tensor(-0.7452) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7452) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.1224) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.5612) 2.0 8.0\n",
      "\tw1grad:  tensor(4.1398) 3.0 15.0\n",
      "\tw2grad:  tensor(1.3799) 3.0 15.0\n",
      "progress:  30 tensor(0.0529) tensor(1.1524) tensor(1.4816) \n",
      "\n",
      "\tw1grad:  tensor(-0.7321) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7321) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.0675) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.5338) 2.0 8.0\n",
      "\tw1grad:  tensor(4.0671) 3.0 15.0\n",
      "\tw2grad:  tensor(1.3557) 3.0 15.0\n",
      "progress:  31 tensor(0.0511) tensor(1.1497) tensor(1.4907) \n",
      "\n",
      "\tw1grad:  tensor(-0.7192) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7192) 1.0 3.0\n",
      "\tw1grad:  tensor(-3.0137) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.5068) 2.0 8.0\n",
      "\tw1grad:  tensor(3.9957) 3.0 15.0\n",
      "\tw2grad:  tensor(1.3319) 3.0 15.0\n",
      "progress:  32 tensor(0.0493) tensor(1.1471) tensor(1.4997) \n",
      "\n",
      "\tw1grad:  tensor(-0.7066) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.7066) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.9608) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.4804) 2.0 8.0\n",
      "\tw1grad:  tensor(3.9255) 3.0 15.0\n",
      "\tw2grad:  tensor(1.3085) 3.0 15.0\n",
      "progress:  33 tensor(0.0476) tensor(1.1445) tensor(1.5084) \n",
      "\n",
      "\tw1grad:  tensor(-0.6942) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6942) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.9088) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.4544) 2.0 8.0\n",
      "\tw1grad:  tensor(3.8566) 3.0 15.0\n",
      "\tw2grad:  tensor(1.2855) 3.0 15.0\n",
      "progress:  34 tensor(0.0459) tensor(1.1419) tensor(1.5171) \n",
      "\n",
      "\tw1grad:  tensor(-0.6820) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6820) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.8577) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.4289) 2.0 8.0\n",
      "\tw1grad:  tensor(3.7889) 3.0 15.0\n",
      "\tw2grad:  tensor(1.2630) 3.0 15.0\n",
      "progress:  35 tensor(0.0443) tensor(1.1394) tensor(1.5255) \n",
      "\n",
      "\tw1grad:  tensor(-0.6700) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6700) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.8075) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.4038) 2.0 8.0\n",
      "\tw1grad:  tensor(3.7224) 3.0 15.0\n",
      "\tw2grad:  tensor(1.2408) 3.0 15.0\n",
      "progress:  36 tensor(0.0428) tensor(1.1370) tensor(1.5339) \n",
      "\n",
      "\tw1grad:  tensor(-0.6583) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6583) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.7583) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.3791) 2.0 8.0\n",
      "\tw1grad:  tensor(3.6570) 3.0 15.0\n",
      "\tw2grad:  tensor(1.2190) 3.0 15.0\n",
      "progress:  37 tensor(0.0413) tensor(1.1346) tensor(1.5421) \n",
      "\n",
      "\tw1grad:  tensor(-0.6467) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6467) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.7098) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.3549) 2.0 8.0\n",
      "\tw1grad:  tensor(3.5928) 3.0 15.0\n",
      "\tw2grad:  tensor(1.1976) 3.0 15.0\n",
      "progress:  38 tensor(0.0398) tensor(1.1322) tensor(1.5501) \n",
      "\n",
      "\tw1grad:  tensor(-0.6353) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6353) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.6622) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.3311) 2.0 8.0\n",
      "\tw1grad:  tensor(3.5297) 3.0 15.0\n",
      "\tw2grad:  tensor(1.1766) 3.0 15.0\n",
      "progress:  39 tensor(0.0385) tensor(1.1299) tensor(1.5580) \n",
      "\n",
      "\tw1grad:  tensor(-0.6242) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6242) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.6155) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.3078) 2.0 8.0\n",
      "\tw1grad:  tensor(3.4678) 3.0 15.0\n",
      "\tw2grad:  tensor(1.1559) 3.0 15.0\n",
      "progress:  40 tensor(0.0371) tensor(1.1276) tensor(1.5658) \n",
      "\n",
      "\tw1grad:  tensor(-0.6132) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6132) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.5696) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.2848) 2.0 8.0\n",
      "\tw1grad:  tensor(3.4069) 3.0 15.0\n",
      "\tw2grad:  tensor(1.1356) 3.0 15.0\n",
      "progress:  41 tensor(0.0358) tensor(1.1254) tensor(1.5734) \n",
      "\n",
      "\tw1grad:  tensor(-0.6025) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.6025) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.5245) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.2622) 2.0 8.0\n",
      "\tw1grad:  tensor(3.3471) 3.0 15.0\n",
      "\tw2grad:  tensor(1.1157) 3.0 15.0\n",
      "progress:  42 tensor(0.0346) tensor(1.1232) tensor(1.5809) \n",
      "\n",
      "\tw1grad:  tensor(-0.5919) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5919) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.4801) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.2401) 2.0 8.0\n",
      "\tw1grad:  tensor(3.2883) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0961) 3.0 15.0\n",
      "progress:  43 tensor(0.0334) tensor(1.1210) tensor(1.5882) \n",
      "\n",
      "\tw1grad:  tensor(-0.5815) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5815) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.4366) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.2183) 2.0 8.0\n",
      "\tw1grad:  tensor(3.2306) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0769) 3.0 15.0\n",
      "progress:  44 tensor(0.0322) tensor(1.1189) tensor(1.5955) \n",
      "\n",
      "\tw1grad:  tensor(-0.5713) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5713) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.3938) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.1969) 2.0 8.0\n",
      "\tw1grad:  tensor(3.1738) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0579) 3.0 15.0\n",
      "progress:  45 tensor(0.0311) tensor(1.1168) tensor(1.6026) \n",
      "\n",
      "\tw1grad:  tensor(-0.5613) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5613) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.3518) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.1759) 2.0 8.0\n",
      "\tw1grad:  tensor(3.1182) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0394) 3.0 15.0\n",
      "progress:  46 tensor(0.0300) tensor(1.1148) tensor(1.6095) \n",
      "\n",
      "\tw1grad:  tensor(-0.5514) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5514) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.3105) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.1553) 2.0 8.0\n",
      "\tw1grad:  tensor(3.0634) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0211) 3.0 15.0\n",
      "progress:  47 tensor(0.0290) tensor(1.1127) tensor(1.6164) \n",
      "\n",
      "\tw1grad:  tensor(-0.5417) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5417) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.2699) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.1350) 2.0 8.0\n",
      "\tw1grad:  tensor(3.0096) 3.0 15.0\n",
      "\tw2grad:  tensor(1.0032) 3.0 15.0\n",
      "progress:  48 tensor(0.0280) tensor(1.1108) tensor(1.6231) \n",
      "\n",
      "\tw1grad:  tensor(-0.5322) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5322) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.2301) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.1150) 2.0 8.0\n",
      "\tw1grad:  tensor(2.9568) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9856) 3.0 15.0\n",
      "progress:  49 tensor(0.0270) tensor(1.1088) tensor(1.6297) \n",
      "\n",
      "\tw1grad:  tensor(-0.5229) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5229) 1.0 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tw1grad:  tensor(-2.1909) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0955) 2.0 8.0\n",
      "\tw1grad:  tensor(2.9049) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9683) 3.0 15.0\n",
      "progress:  50 tensor(0.0260) tensor(1.1069) tensor(1.6363) \n",
      "\n",
      "\tw1grad:  tensor(-0.5137) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5137) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.1525) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0762) 2.0 8.0\n",
      "\tw1grad:  tensor(2.8538) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9513) 3.0 15.0\n",
      "progress:  51 tensor(0.0251) tensor(1.1050) tensor(1.6426) \n",
      "\n",
      "\tw1grad:  tensor(-0.5047) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.5047) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.1147) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0573) 2.0 8.0\n",
      "\tw1grad:  tensor(2.8037) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9346) 3.0 15.0\n",
      "progress:  52 tensor(0.0243) tensor(1.1032) tensor(1.6489) \n",
      "\n",
      "\tw1grad:  tensor(-0.4958) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4958) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.0775) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0388) 2.0 8.0\n",
      "\tw1grad:  tensor(2.7545) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9182) 3.0 15.0\n",
      "progress:  53 tensor(0.0234) tensor(1.1014) tensor(1.6551) \n",
      "\n",
      "\tw1grad:  tensor(-0.4871) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4871) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.0411) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0205) 2.0 8.0\n",
      "\tw1grad:  tensor(2.7061) 3.0 15.0\n",
      "\tw2grad:  tensor(0.9020) 3.0 15.0\n",
      "progress:  54 tensor(0.0226) tensor(1.0996) tensor(1.6611) \n",
      "\n",
      "\tw1grad:  tensor(-0.4786) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4786) 1.0 3.0\n",
      "\tw1grad:  tensor(-2.0052) 2.0 8.0\n",
      "\tw2grad:  tensor(-1.0026) 2.0 8.0\n",
      "\tw1grad:  tensor(2.6587) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8862) 3.0 15.0\n",
      "progress:  55 tensor(0.0218) tensor(1.0978) tensor(1.6671) \n",
      "\n",
      "\tw1grad:  tensor(-0.4702) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4702) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.9700) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9850) 2.0 8.0\n",
      "\tw1grad:  tensor(2.6119) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8706) 3.0 15.0\n",
      "progress:  56 tensor(0.0211) tensor(1.0961) tensor(1.6729) \n",
      "\n",
      "\tw1grad:  tensor(-0.4619) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4619) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.9354) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9677) 2.0 8.0\n",
      "\tw1grad:  tensor(2.5661) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8554) 3.0 15.0\n",
      "progress:  57 tensor(0.0203) tensor(1.0944) tensor(1.6787) \n",
      "\n",
      "\tw1grad:  tensor(-0.4538) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4538) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.9015) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9507) 2.0 8.0\n",
      "\tw1grad:  tensor(2.5210) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8403) 3.0 15.0\n",
      "progress:  58 tensor(0.0196) tensor(1.0928) tensor(1.6843) \n",
      "\n",
      "\tw1grad:  tensor(-0.4458) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4458) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.8681) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9340) 2.0 8.0\n",
      "\tw1grad:  tensor(2.4768) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8256) 3.0 15.0\n",
      "progress:  59 tensor(0.0189) tensor(1.0912) tensor(1.6899) \n",
      "\n",
      "\tw1grad:  tensor(-0.4380) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4380) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.8353) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9176) 2.0 8.0\n",
      "\tw1grad:  tensor(2.4333) 3.0 15.0\n",
      "\tw2grad:  tensor(0.8111) 3.0 15.0\n",
      "progress:  60 tensor(0.0183) tensor(1.0896) tensor(1.6953) \n",
      "\n",
      "\tw1grad:  tensor(-0.4303) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4303) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.8031) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.9015) 2.0 8.0\n",
      "\tw1grad:  tensor(2.3906) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7969) 3.0 15.0\n",
      "progress:  61 tensor(0.0176) tensor(1.0880) tensor(1.7006) \n",
      "\n",
      "\tw1grad:  tensor(-0.4227) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4227) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.7714) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8857) 2.0 8.0\n",
      "\tw1grad:  tensor(2.3486) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7829) 3.0 15.0\n",
      "progress:  62 tensor(0.0170) tensor(1.0864) tensor(1.7059) \n",
      "\n",
      "\tw1grad:  tensor(-0.4153) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4153) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.7403) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8702) 2.0 8.0\n",
      "\tw1grad:  tensor(2.3074) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7691) 3.0 15.0\n",
      "progress:  63 tensor(0.0164) tensor(1.0849) tensor(1.7111) \n",
      "\n",
      "\tw1grad:  tensor(-0.4080) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4080) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.7097) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8549) 2.0 8.0\n",
      "\tw1grad:  tensor(2.2669) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7556) 3.0 15.0\n",
      "progress:  64 tensor(0.0159) tensor(1.0834) tensor(1.7161) \n",
      "\n",
      "\tw1grad:  tensor(-0.4009) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.4009) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.6797) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8399) 2.0 8.0\n",
      "\tw1grad:  tensor(2.2271) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7424) 3.0 15.0\n",
      "progress:  65 tensor(0.0153) tensor(1.0820) tensor(1.7211) \n",
      "\n",
      "\tw1grad:  tensor(-0.3938) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3938) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.6502) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8251) 2.0 8.0\n",
      "\tw1grad:  tensor(2.1880) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7293) 3.0 15.0\n",
      "progress:  66 tensor(0.0148) tensor(1.0805) tensor(1.7260) \n",
      "\n",
      "\tw1grad:  tensor(-0.3869) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3869) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.6213) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.8106) 2.0 8.0\n",
      "\tw1grad:  tensor(2.1495) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7165) 3.0 15.0\n",
      "progress:  67 tensor(0.0143) tensor(1.0791) tensor(1.7308) \n",
      "\n",
      "\tw1grad:  tensor(-0.3801) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3801) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.5928) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7964) 2.0 8.0\n",
      "\tw1grad:  tensor(2.1118) 3.0 15.0\n",
      "\tw2grad:  tensor(0.7039) 3.0 15.0\n",
      "progress:  68 tensor(0.0138) tensor(1.0777) tensor(1.7356) \n",
      "\n",
      "\tw1grad:  tensor(-0.3735) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3735) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.5648) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7824) 2.0 8.0\n",
      "\tw1grad:  tensor(2.0747) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6916) 3.0 15.0\n",
      "progress:  69 tensor(0.0133) tensor(1.0764) tensor(1.7402) \n",
      "\n",
      "\tw1grad:  tensor(-0.3669) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3669) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.5374) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7687) 2.0 8.0\n",
      "\tw1grad:  tensor(2.0383) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6794) 3.0 15.0\n",
      "progress:  70 tensor(0.0128) tensor(1.0750) tensor(1.7448) \n",
      "\n",
      "\tw1grad:  tensor(-0.3605) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3605) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.5104) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7552) 2.0 8.0\n",
      "\tw1grad:  tensor(2.0025) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6675) 3.0 15.0\n",
      "progress:  71 tensor(0.0124) tensor(1.0737) tensor(1.7492) \n",
      "\n",
      "\tw1grad:  tensor(-0.3541) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3541) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.4838) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7419) 2.0 8.0\n",
      "\tw1grad:  tensor(1.9673) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6558) 3.0 15.0\n",
      "progress:  72 tensor(0.0119) tensor(1.0724) tensor(1.7536) \n",
      "\n",
      "\tw1grad:  tensor(-0.3479) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3479) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.4578) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7289) 2.0 8.0\n",
      "\tw1grad:  tensor(1.9328) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6443) 3.0 15.0\n",
      "progress:  73 tensor(0.0115) tensor(1.0711) tensor(1.7580) \n",
      "\n",
      "\tw1grad:  tensor(-0.3418) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3418) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.4322) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7161) 2.0 8.0\n",
      "\tw1grad:  tensor(1.8989) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6330) 3.0 15.0\n",
      "progress:  74 tensor(0.0111) tensor(1.0699) tensor(1.7622) \n",
      "\n",
      "\tw1grad:  tensor(-0.3358) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3358) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.4071) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.7035) 2.0 8.0\n",
      "\tw1grad:  tensor(1.8656) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6219) 3.0 15.0\n",
      "progress:  75 tensor(0.0107) tensor(1.0687) tensor(1.7664) \n",
      "\n",
      "\tw1grad:  tensor(-0.3299) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3299) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.3824) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6912) 2.0 8.0\n",
      "\tw1grad:  tensor(1.8328) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6109) 3.0 15.0\n",
      "progress:  76 tensor(0.0104) tensor(1.0675) tensor(1.7705) \n",
      "\n",
      "\tw1grad:  tensor(-0.3241) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3241) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.3581) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6790) 2.0 8.0\n",
      "\tw1grad:  tensor(1.8007) 3.0 15.0\n",
      "\tw2grad:  tensor(0.6002) 3.0 15.0\n",
      "progress:  77 tensor(0.0100) tensor(1.0663) tensor(1.7745) \n",
      "\n",
      "\tw1grad:  tensor(-0.3184) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3184) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.3343) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6671) 2.0 8.0\n",
      "\tw1grad:  tensor(1.7690) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5897) 3.0 15.0\n",
      "progress:  78 tensor(0.0097) tensor(1.0651) tensor(1.7785) \n",
      "\n",
      "\tw1grad:  tensor(-0.3128) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3128) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.3108) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6554) 2.0 8.0\n",
      "\tw1grad:  tensor(1.7380) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5793) 3.0 15.0\n",
      "progress:  79 tensor(0.0093) tensor(1.0640) tensor(1.7824) \n",
      "\n",
      "\tw1grad:  tensor(-0.3073) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3073) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.2878) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6439) 2.0 8.0\n",
      "\tw1grad:  tensor(1.7074) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5691) 3.0 15.0\n",
      "progress:  80 tensor(0.0090) tensor(1.0628) tensor(1.7862) \n",
      "\n",
      "\tw1grad:  tensor(-0.3019) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.3019) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.2652) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6326) 2.0 8.0\n",
      "\tw1grad:  tensor(1.6774) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5591) 3.0 15.0\n",
      "progress:  81 tensor(0.0087) tensor(1.0617) tensor(1.7899) \n",
      "\n",
      "\tw1grad:  tensor(-0.2966) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2966) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.2430) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6215) 2.0 8.0\n",
      "\tw1grad:  tensor(1.6480) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5493) 3.0 15.0\n",
      "progress:  82 tensor(0.0084) tensor(1.0607) tensor(1.7936) \n",
      "\n",
      "\tw1grad:  tensor(-0.2914) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2914) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.2212) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.6106) 2.0 8.0\n",
      "\tw1grad:  tensor(1.6191) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5397) 3.0 15.0\n",
      "progress:  83 tensor(0.0081) tensor(1.0596) tensor(1.7973) \n",
      "\n",
      "\tw1grad:  tensor(-0.2863) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2863) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.1997) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5999) 2.0 8.0\n",
      "\tw1grad:  tensor(1.5907) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5302) 3.0 15.0\n",
      "progress:  84 tensor(0.0078) tensor(1.0585) tensor(1.8008) \n",
      "\n",
      "\tw1grad:  tensor(-0.2813) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2813) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.1787) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5893) 2.0 8.0\n",
      "\tw1grad:  tensor(1.5627) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5209) 3.0 15.0\n",
      "progress:  85 tensor(0.0075) tensor(1.0575) tensor(1.8043) \n",
      "\n",
      "\tw1grad:  tensor(-0.2763) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2763) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.1580) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5790) 2.0 8.0\n",
      "\tw1grad:  tensor(1.5353) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5118) 3.0 15.0\n",
      "progress:  86 tensor(0.0073) tensor(1.0565) tensor(1.8077) \n",
      "\n",
      "\tw1grad:  tensor(-0.2715) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2715) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.1376) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5688) 2.0 8.0\n",
      "\tw1grad:  tensor(1.5083) 3.0 15.0\n",
      "\tw2grad:  tensor(0.5028) 3.0 15.0\n",
      "progress:  87 tensor(0.0070) tensor(1.0555) tensor(1.8111) \n",
      "\n",
      "\tw1grad:  tensor(-0.2667) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2667) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.1177) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5588) 2.0 8.0\n",
      "\tw1grad:  tensor(1.4818) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4939) 3.0 15.0\n",
      "progress:  88 tensor(0.0068) tensor(1.0545) tensor(1.8144) \n",
      "\n",
      "\tw1grad:  tensor(-0.2620) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2620) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0980) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5490) 2.0 8.0\n",
      "\tw1grad:  tensor(1.4558) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4853) 3.0 15.0\n",
      "progress:  89 tensor(0.0065) tensor(1.0536) tensor(1.8177) \n",
      "\n",
      "\tw1grad:  tensor(-0.2574) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2574) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0788) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5394) 2.0 8.0\n",
      "\tw1grad:  tensor(1.4302) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4767) 3.0 15.0\n",
      "progress:  90 tensor(0.0063) tensor(1.0526) tensor(1.8209) \n",
      "\n",
      "\tw1grad:  tensor(-0.2529) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2529) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0598) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5299) 2.0 8.0\n",
      "\tw1grad:  tensor(1.4052) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4684) 3.0 15.0\n",
      "progress:  91 tensor(0.0061) tensor(1.0517) tensor(1.8240) \n",
      "\n",
      "\tw1grad:  tensor(-0.2485) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2485) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0412) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5206) 2.0 8.0\n",
      "\tw1grad:  tensor(1.3805) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4602) 3.0 15.0\n",
      "progress:  92 tensor(0.0059) tensor(1.0508) tensor(1.8271) \n",
      "\n",
      "\tw1grad:  tensor(-0.2441) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2441) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0229) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5115) 2.0 8.0\n",
      "\tw1grad:  tensor(1.3563) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4521) 3.0 15.0\n",
      "progress:  93 tensor(0.0057) tensor(1.0499) tensor(1.8302) \n",
      "\n",
      "\tw1grad:  tensor(-0.2398) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2398) 1.0 3.0\n",
      "\tw1grad:  tensor(-1.0050) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.5025) 2.0 8.0\n",
      "\tw1grad:  tensor(1.3324) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4441) 3.0 15.0\n",
      "progress:  94 tensor(0.0055) tensor(1.0490) tensor(1.8332) \n",
      "\n",
      "\tw1grad:  tensor(-0.2356) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2356) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9873) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4937) 2.0 8.0\n",
      "\tw1grad:  tensor(1.3091) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4364) 3.0 15.0\n",
      "progress:  95 tensor(0.0053) tensor(1.0482) tensor(1.8361) \n",
      "\n",
      "\tw1grad:  tensor(-0.2315) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2315) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9700) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4850) 2.0 8.0\n",
      "\tw1grad:  tensor(1.2861) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4287) 3.0 15.0\n",
      "progress:  96 tensor(0.0051) tensor(1.0473) tensor(1.8390) \n",
      "\n",
      "\tw1grad:  tensor(-0.2274) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2274) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9530) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4765) 2.0 8.0\n",
      "\tw1grad:  tensor(1.2635) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4212) 3.0 15.0\n",
      "progress:  97 tensor(0.0049) tensor(1.0465) tensor(1.8418) \n",
      "\n",
      "\tw1grad:  tensor(-0.2234) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2234) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9362) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4681) 2.0 8.0\n",
      "\tw1grad:  tensor(1.2413) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4138) 3.0 15.0\n",
      "progress:  98 tensor(0.0048) tensor(1.0457) tensor(1.8446) \n",
      "\n",
      "\tw1grad:  tensor(-0.2195) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2195) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9198) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4599) 2.0 8.0\n",
      "\tw1grad:  tensor(1.2196) 3.0 15.0\n",
      "\tw2grad:  tensor(0.4065) 3.0 15.0\n",
      "progress:  99 tensor(0.0046) tensor(1.0449) tensor(1.8473) \n",
      "\n",
      "\tw1grad:  tensor(-0.2157) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2157) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.9036) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4518) 2.0 8.0\n",
      "\tw1grad:  tensor(1.1981) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3994) 3.0 15.0\n",
      "progress:  100 tensor(0.0044) tensor(1.0441) tensor(1.8500) \n",
      "\n",
      "\tw1grad:  tensor(-0.2119) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2119) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.8878) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4439) 2.0 8.0\n",
      "\tw1grad:  tensor(1.1771) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3924) 3.0 15.0\n",
      "progress:  101 tensor(0.0043) tensor(1.0433) tensor(1.8526) \n",
      "\n",
      "\tw1grad:  tensor(-0.2081) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2081) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.8722) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4361) 2.0 8.0\n",
      "\tw1grad:  tensor(1.1564) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3855) 3.0 15.0\n",
      "progress:  102 tensor(0.0041) tensor(1.0426) tensor(1.8552) \n",
      "\n",
      "\tw1grad:  tensor(-0.2045) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2045) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.8569) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4284) 2.0 8.0\n",
      "\tw1grad:  tensor(1.1361) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3787) 3.0 15.0\n",
      "progress:  103 tensor(0.0040) tensor(1.0418) tensor(1.8577) \n",
      "\n",
      "\tw1grad:  tensor(-0.2009) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.2009) 1.0 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tw1grad:  tensor(-0.8418) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4209) 2.0 8.0\n",
      "\tw1grad:  tensor(1.1161) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3720) 3.0 15.0\n",
      "progress:  104 tensor(0.0038) tensor(1.0411) tensor(1.8602) \n",
      "\n",
      "\tw1grad:  tensor(-0.1974) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1974) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.8271) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4135) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0965) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3655) 3.0 15.0\n",
      "progress:  105 tensor(0.0037) tensor(1.0404) tensor(1.8627) \n",
      "\n",
      "\tw1grad:  tensor(-0.1939) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1939) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.8125) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.4063) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0773) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3591) 3.0 15.0\n",
      "progress:  106 tensor(0.0036) tensor(1.0396) tensor(1.8651) \n",
      "\n",
      "\tw1grad:  tensor(-0.1905) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1905) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7983) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3991) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0584) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3528) 3.0 15.0\n",
      "progress:  107 tensor(0.0035) tensor(1.0390) tensor(1.8675) \n",
      "\n",
      "\tw1grad:  tensor(-0.1872) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1872) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7843) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3921) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0398) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3466) 3.0 15.0\n",
      "progress:  108 tensor(0.0033) tensor(1.0383) tensor(1.8698) \n",
      "\n",
      "\tw1grad:  tensor(-0.1839) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1839) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7705) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3852) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0216) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3405) 3.0 15.0\n",
      "progress:  109 tensor(0.0032) tensor(1.0376) tensor(1.8721) \n",
      "\n",
      "\tw1grad:  tensor(-0.1806) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1806) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7570) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3785) 2.0 8.0\n",
      "\tw1grad:  tensor(1.0036) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3345) 3.0 15.0\n",
      "progress:  110 tensor(0.0031) tensor(1.0369) tensor(1.8743) \n",
      "\n",
      "\tw1grad:  tensor(-0.1775) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1775) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7437) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3718) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9860) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3287) 3.0 15.0\n",
      "progress:  111 tensor(0.0030) tensor(1.0363) tensor(1.8765) \n",
      "\n",
      "\tw1grad:  tensor(-0.1744) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1744) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7306) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3653) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9687) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3229) 3.0 15.0\n",
      "progress:  112 tensor(0.0029) tensor(1.0356) tensor(1.8787) \n",
      "\n",
      "\tw1grad:  tensor(-0.1713) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1713) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7178) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3589) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9517) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3172) 3.0 15.0\n",
      "progress:  113 tensor(0.0028) tensor(1.0350) tensor(1.8808) \n",
      "\n",
      "\tw1grad:  tensor(-0.1683) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1683) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.7052) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3526) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9349) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3116) 3.0 15.0\n",
      "progress:  114 tensor(0.0027) tensor(1.0344) tensor(1.8829) \n",
      "\n",
      "\tw1grad:  tensor(-0.1653) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1653) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6928) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3464) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9186) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3062) 3.0 15.0\n",
      "progress:  115 tensor(0.0026) tensor(1.0338) tensor(1.8850) \n",
      "\n",
      "\tw1grad:  tensor(-0.1624) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1624) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6806) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3403) 2.0 8.0\n",
      "\tw1grad:  tensor(0.9024) 3.0 15.0\n",
      "\tw2grad:  tensor(0.3008) 3.0 15.0\n",
      "progress:  116 tensor(0.0025) tensor(1.0332) tensor(1.8870) \n",
      "\n",
      "\tw1grad:  tensor(-0.1596) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1596) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6687) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3343) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8866) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2955) 3.0 15.0\n",
      "progress:  117 tensor(0.0024) tensor(1.0326) tensor(1.8890) \n",
      "\n",
      "\tw1grad:  tensor(-0.1568) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1568) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6569) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3285) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8710) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2903) 3.0 15.0\n",
      "progress:  118 tensor(0.0023) tensor(1.0321) tensor(1.8909) \n",
      "\n",
      "\tw1grad:  tensor(-0.1540) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1540) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6454) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3227) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8557) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2852) 3.0 15.0\n",
      "progress:  119 tensor(0.0023) tensor(1.0315) tensor(1.8928) \n",
      "\n",
      "\tw1grad:  tensor(-0.1513) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1513) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6341) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3170) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8407) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2802) 3.0 15.0\n",
      "progress:  120 tensor(0.0022) tensor(1.0309) tensor(1.8947) \n",
      "\n",
      "\tw1grad:  tensor(-0.1487) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1487) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6229) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3115) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8259) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2753) 3.0 15.0\n",
      "progress:  121 tensor(0.0021) tensor(1.0304) tensor(1.8966) \n",
      "\n",
      "\tw1grad:  tensor(-0.1461) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1461) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6120) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3060) 2.0 8.0\n",
      "\tw1grad:  tensor(0.8114) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2705) 3.0 15.0\n",
      "progress:  122 tensor(0.0020) tensor(1.0299) tensor(1.8984) \n",
      "\n",
      "\tw1grad:  tensor(-0.1435) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1435) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.6013) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.3006) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7972) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2657) 3.0 15.0\n",
      "progress:  123 tensor(0.0020) tensor(1.0293) tensor(1.9002) \n",
      "\n",
      "\tw1grad:  tensor(-0.1410) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1410) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5907) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2953) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7832) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2611) 3.0 15.0\n",
      "progress:  124 tensor(0.0019) tensor(1.0288) tensor(1.9019) \n",
      "\n",
      "\tw1grad:  tensor(-0.1385) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1385) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5803) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2902) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7694) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2565) 3.0 15.0\n",
      "progress:  125 tensor(0.0018) tensor(1.0283) tensor(1.9037) \n",
      "\n",
      "\tw1grad:  tensor(-0.1361) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1361) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5701) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2851) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7559) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2520) 3.0 15.0\n",
      "progress:  126 tensor(0.0018) tensor(1.0278) tensor(1.9053) \n",
      "\n",
      "\tw1grad:  tensor(-0.1337) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1337) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5601) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2801) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7427) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2476) 3.0 15.0\n",
      "progress:  127 tensor(0.0017) tensor(1.0273) tensor(1.9070) \n",
      "\n",
      "\tw1grad:  tensor(-0.1313) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1313) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5503) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2752) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7296) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2432) 3.0 15.0\n",
      "progress:  128 tensor(0.0016) tensor(1.0269) tensor(1.9086) \n",
      "\n",
      "\tw1grad:  tensor(-0.1290) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1290) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5406) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2703) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7168) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2389) 3.0 15.0\n",
      "progress:  129 tensor(0.0016) tensor(1.0264) tensor(1.9102) \n",
      "\n",
      "\tw1grad:  tensor(-0.1268) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1268) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5311) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2656) 2.0 8.0\n",
      "\tw1grad:  tensor(0.7042) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2347) 3.0 15.0\n",
      "progress:  130 tensor(0.0015) tensor(1.0259) tensor(1.9118) \n",
      "\n",
      "\tw1grad:  tensor(-0.1245) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1245) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5218) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2609) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6918) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2306) 3.0 15.0\n",
      "progress:  131 tensor(0.0015) tensor(1.0255) tensor(1.9134) \n",
      "\n",
      "\tw1grad:  tensor(-0.1223) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1223) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5127) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2563) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6797) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2266) 3.0 15.0\n",
      "progress:  132 tensor(0.0014) tensor(1.0250) tensor(1.9149) \n",
      "\n",
      "\tw1grad:  tensor(-0.1202) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1202) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.5037) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2518) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6678) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2226) 3.0 15.0\n",
      "progress:  133 tensor(0.0014) tensor(1.0246) tensor(1.9164) \n",
      "\n",
      "\tw1grad:  tensor(-0.1181) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1181) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4948) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2474) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6560) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2187) 3.0 15.0\n",
      "progress:  134 tensor(0.0013) tensor(1.0241) tensor(1.9178) \n",
      "\n",
      "\tw1grad:  tensor(-0.1160) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1160) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4861) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2431) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6445) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2148) 3.0 15.0\n",
      "progress:  135 tensor(0.0013) tensor(1.0237) tensor(1.9193) \n",
      "\n",
      "\tw1grad:  tensor(-0.1140) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1140) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4776) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2388) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6332) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2111) 3.0 15.0\n",
      "progress:  136 tensor(0.0012) tensor(1.0233) tensor(1.9207) \n",
      "\n",
      "\tw1grad:  tensor(-0.1120) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1120) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4692) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2346) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6221) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2074) 3.0 15.0\n",
      "progress:  137 tensor(0.0012) tensor(1.0229) tensor(1.9221) \n",
      "\n",
      "\tw1grad:  tensor(-0.1100) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1100) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4610) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2305) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6111) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2037) 3.0 15.0\n",
      "progress:  138 tensor(0.0012) tensor(1.0225) tensor(1.9235) \n",
      "\n",
      "\tw1grad:  tensor(-0.1081) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1081) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4529) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2264) 2.0 8.0\n",
      "\tw1grad:  tensor(0.6005) 3.0 15.0\n",
      "\tw2grad:  tensor(0.2002) 3.0 15.0\n",
      "progress:  139 tensor(0.0011) tensor(1.0221) tensor(1.9248) \n",
      "\n",
      "\tw1grad:  tensor(-0.1062) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1062) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4449) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2225) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5899) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1966) 3.0 15.0\n",
      "progress:  140 tensor(0.0011) tensor(1.0217) tensor(1.9261) \n",
      "\n",
      "\tw1grad:  tensor(-0.1043) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1043) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4371) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2186) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5796) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1932) 3.0 15.0\n",
      "progress:  141 tensor(0.0010) tensor(1.0213) tensor(1.9274) \n",
      "\n",
      "\tw1grad:  tensor(-0.1025) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1025) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4294) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2147) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5694) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1898) 3.0 15.0\n",
      "progress:  142 tensor(0.0010) tensor(1.0210) tensor(1.9287) \n",
      "\n",
      "\tw1grad:  tensor(-0.1007) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.1007) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4219) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2110) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5594) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1865) 3.0 15.0\n",
      "progress:  143 tensor(0.0010) tensor(1.0206) tensor(1.9300) \n",
      "\n",
      "\tw1grad:  tensor(-0.0989) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0989) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4145) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2072) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5495) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1832) 3.0 15.0\n",
      "progress:  144 tensor(0.0009) tensor(1.0202) tensor(1.9312) \n",
      "\n",
      "\tw1grad:  tensor(-0.0972) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0972) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4072) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2036) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5399) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1800) 3.0 15.0\n",
      "progress:  145 tensor(0.0009) tensor(1.0199) tensor(1.9324) \n",
      "\n",
      "\tw1grad:  tensor(-0.0955) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0955) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.4001) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.2000) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5304) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1768) 3.0 15.0\n",
      "progress:  146 tensor(0.0009) tensor(1.0195) tensor(1.9336) \n",
      "\n",
      "\tw1grad:  tensor(-0.0938) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0938) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.3930) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.1965) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5211) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1737) 3.0 15.0\n",
      "progress:  147 tensor(0.0008) tensor(1.0192) tensor(1.9347) \n",
      "\n",
      "\tw1grad:  tensor(-0.0922) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0922) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.3862) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.1931) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5119) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1706) 3.0 15.0\n",
      "progress:  148 tensor(0.0008) tensor(1.0188) tensor(1.9359) \n",
      "\n",
      "\tw1grad:  tensor(-0.0905) 1.0 3.0\n",
      "\tw2grad:  tensor(-0.0905) 1.0 3.0\n",
      "\tw1grad:  tensor(-0.3794) 2.0 8.0\n",
      "\tw2grad:  tensor(-0.1897) 2.0 8.0\n",
      "\tw1grad:  tensor(0.5030) 3.0 15.0\n",
      "\tw2grad:  tensor(0.1677) 3.0 15.0\n",
      "progress:  149 tensor(0.0008) tensor(1.0185) tensor(1.9370) \n",
      "\n",
      "prdict(after training) 4 tensor(24.0442)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "w1_list = []\n",
    "w2_list = []\n",
    "l_list = []\n",
    "x_data = [1.0, 2.0, 3.0]          # y = x^2 + 2x \n",
    "y_data = [3.0, 8.0, 15.0]\n",
    "\n",
    "w1 = Variable(torch.Tensor([1.0]), requires_grad = True) # random value\n",
    "w2 = Variable(torch.Tensor([1.0]), requires_grad = True)\n",
    "\n",
    "def forward(x):\n",
    "    return  (w1*x*x) + (w2*x)\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)*(y_pred - y)\n",
    "\n",
    "for epoch in range(150):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        \n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        \n",
    "        print(\"\\tw1grad: \", w1.grad.data[0], x_val, y_val) # .data[0]의 의미?\n",
    "        w1.data = w1.data - 0.01 * w1.grad.data\n",
    "        print(\"\\tw2grad: \", w2.grad.data[0], x_val, y_val)\n",
    "        w2.data = w2.data - 0.01 * w2.grad.data\n",
    "        \n",
    "        w1.grad.data.zero_() # 왜 gradient를 초기화? 초기화 안하면 값이 더해짐?\n",
    "        w2.grad.data.zero_()\n",
    "    print(\"progress: \", epoch, l.data[0], w1.data[0], w2.data[0],\"\\n\")\n",
    "    \n",
    "    w1_list.append(w1.data[0])\n",
    "    w2_list.append(w2.data[0])\n",
    "    l_list.append(l.data[0])\n",
    "    \n",
    "    \n",
    "print(\"prdict(after training)\", 4, forward(4).data[0])\n",
    "\n",
    "\n",
    "plt.plot(w1_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w2_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad :  -2.0 1.0 2.0\n",
      "grad :  -7.84 2.0 4.0\n",
      "grad :  -16.2288 3.0 6.0\n",
      "epoch :  0 loss :  4.919240100095999 w :  1.260688 \n",
      "\n",
      "grad :  -1.478624 1.0 2.0\n",
      "grad :  -5.796206079999999 2.0 4.0\n",
      "grad :  -11.998146585599997 3.0 6.0\n",
      "epoch :  1 loss :  2.688769240265834 w :  1.453417766656 \n",
      "\n",
      "grad :  -1.093164466688 1.0 2.0\n",
      "grad :  -4.285204709416961 2.0 4.0\n",
      "grad :  -8.87037374849311 3.0 6.0\n",
      "epoch :  2 loss :  1.4696334962911515 w :  1.5959051959019805 \n",
      "\n",
      "grad :  -0.8081896081960389 1.0 2.0\n",
      "grad :  -3.1681032641284723 2.0 4.0\n",
      "grad :  -6.557973756745939 3.0 6.0\n",
      "epoch :  3 loss :  0.8032755585999681 w :  1.701247862192685 \n",
      "\n",
      "grad :  -0.59750427561463 1.0 2.0\n",
      "grad :  -2.3422167604093502 2.0 4.0\n",
      "grad :  -4.848388694047353 3.0 6.0\n",
      "epoch :  4 loss :  0.43905614881022015 w :  1.7791289594933983 \n",
      "\n",
      "grad :  -0.44174208101320334 1.0 2.0\n",
      "grad :  -1.7316289575717576 2.0 4.0\n",
      "grad :  -3.584471942173538 3.0 6.0\n",
      "epoch :  5 loss :  0.2399802903801062 w :  1.836707389300983 \n",
      "\n",
      "grad :  -0.3265852213980338 1.0 2.0\n",
      "grad :  -1.2802140678802925 2.0 4.0\n",
      "grad :  -2.650043120512205 3.0 6.0\n",
      "epoch :  6 loss :  0.1311689630744999 w :  1.8792758133988885 \n",
      "\n",
      "grad :  -0.241448373202223 1.0 2.0\n",
      "grad :  -0.946477622952715 2.0 4.0\n",
      "grad :  -1.9592086795121197 3.0 6.0\n",
      "epoch :  7 loss :  0.07169462478267678 w :  1.910747160155559 \n",
      "\n",
      "grad :  -0.17850567968888198 1.0 2.0\n",
      "grad :  -0.6997422643804168 2.0 4.0\n",
      "grad :  -1.4484664872674653 3.0 6.0\n",
      "epoch :  8 loss :  0.03918700813247573 w :  1.9340143044689266 \n",
      "\n",
      "grad :  -0.13197139106214673 1.0 2.0\n",
      "grad :  -0.5173278529636143 2.0 4.0\n",
      "grad :  -1.0708686556346834 3.0 6.0\n",
      "epoch :  9 loss :  0.021418922423117836 w :  1.9512159834655312 \n",
      "\n",
      "forward(4) :  7.804863933862125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]      # y = 2x\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "s= []\n",
    "yhat = []\n",
    "w = 1.0\n",
    "\n",
    "w_list = []\n",
    "l_list = []\n",
    "\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(s):\n",
    "    return s*s\n",
    "def sfunt(yhat,y):\n",
    "    return yhat - y\n",
    "def yhatfunt(x):\n",
    "    return x*w\n",
    "\n",
    "def gradientloss(s):\n",
    "    return 2*s\n",
    "def gradientyhat():\n",
    "    return 1\n",
    "def gradientw(x):\n",
    "    return x\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradientloss(sfunt(yhatfunt(x_val),y_val)) * gradientyhat() * gradientw(x_val)\n",
    "        w = w - 0.01*grad\n",
    "        l = loss(sfunt(yhatfunt(x_val),y_val))\n",
    "        print(\"grad : \", grad, x_val, y_val)\n",
    "        \n",
    "    print(\"epoch : \", epoch,\"loss : \", l,\"w : \",w, \"\\n\")\n",
    "    w_list.append(w)\n",
    "    l_list.append(l)\n",
    "    \n",
    "print(\"forward(4) : \",forward(4))\n",
    "\n",
    "plt.plot(w_list, l_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('w')\n",
    "plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 65.16978454589844\n",
      "1 29.01178741455078\n",
      "2 12.915275573730469\n",
      "3 5.749562740325928\n",
      "4 2.5595905780792236\n",
      "5 1.13950514793396\n",
      "6 0.5073227882385254\n",
      "7 0.22589260339736938\n",
      "8 0.10060711205005646\n",
      "9 0.04483290761709213\n",
      "10 0.02000313624739647\n",
      "11 0.008948974311351776\n",
      "12 0.004027341492474079\n",
      "13 0.0018357892986387014\n",
      "14 0.0008595334365963936\n",
      "15 0.0004243150178808719\n",
      "16 0.00022997929772827774\n",
      "17 0.00014287639351096004\n",
      "18 0.00010351849050493911\n",
      "19 8.542574505554512e-05\n",
      "20 7.680368435103446e-05\n",
      "21 7.241118146339431e-05\n",
      "22 6.99031152180396e-05\n",
      "23 6.824910815339535e-05\n",
      "24 6.697937351418659e-05\n",
      "25 6.588709220523015e-05\n",
      "26 6.487892096629366e-05\n",
      "27 6.392271461663768e-05\n",
      "28 6.299260712694377e-05\n",
      "29 6.208185368450359e-05\n",
      "30 6.118820601841435e-05\n",
      "31 6.030993245076388e-05\n",
      "32 5.943984433542937e-05\n",
      "33 5.8583860663929954e-05\n",
      "34 5.774656165158376e-05\n",
      "35 5.691268597729504e-05\n",
      "36 5.609883010038175e-05\n",
      "37 5.528824476641603e-05\n",
      "38 5.449686068459414e-05\n",
      "39 5.3712039516540244e-05\n",
      "40 5.294136644806713e-05\n",
      "41 5.217878788243979e-05\n",
      "42 5.143132511875592e-05\n",
      "43 5.068925747764297e-05\n",
      "44 4.996244751964696e-05\n",
      "45 4.9242920795222744e-05\n",
      "46 4.853550490224734e-05\n",
      "47 4.7838835598668084e-05\n",
      "48 4.715358591056429e-05\n",
      "49 4.6471697714878246e-05\n",
      "50 4.580264794640243e-05\n",
      "51 4.5148208300815895e-05\n",
      "52 4.449693733477034e-05\n",
      "53 4.385847205412574e-05\n",
      "54 4.322806853451766e-05\n",
      "55 4.260754576534964e-05\n",
      "56 4.199451723252423e-05\n",
      "57 4.139116936130449e-05\n",
      "58 4.079775681020692e-05\n",
      "59 4.021231870865449e-05\n",
      "60 3.9632574043935165e-05\n",
      "61 3.9062488212948665e-05\n",
      "62 3.8499783840961754e-05\n",
      "63 3.794653093791567e-05\n",
      "64 3.7402616726467386e-05\n",
      "65 3.686510171974078e-05\n",
      "66 3.633392771007493e-05\n",
      "67 3.581182681955397e-05\n",
      "68 3.529696186888032e-05\n",
      "69 3.478959479252808e-05\n",
      "70 3.4289649192942306e-05\n",
      "71 3.379534973646514e-05\n",
      "72 3.331235348014161e-05\n",
      "73 3.283250407548621e-05\n",
      "74 3.236109478166327e-05\n",
      "75 3.189802009728737e-05\n",
      "76 3.143795765936375e-05\n",
      "77 3.098674278589897e-05\n",
      "78 3.0538787541445345e-05\n",
      "79 3.0100469302851707e-05\n",
      "80 2.9668175557162613e-05\n",
      "81 2.9244032702990808e-05\n",
      "82 2.8822636522818357e-05\n",
      "83 2.8408636353560723e-05\n",
      "84 2.8000091333524324e-05\n",
      "85 2.759725794021506e-05\n",
      "86 2.7201280317967758e-05\n",
      "87 2.6810272174770944e-05\n",
      "88 2.642508661665488e-05\n",
      "89 2.6044470359920524e-05\n",
      "90 2.567132469266653e-05\n",
      "91 2.5302919311798178e-05\n",
      "92 2.4939208742580377e-05\n",
      "93 2.4580149329267442e-05\n",
      "94 2.4225699235103093e-05\n",
      "95 2.387893619015813e-05\n",
      "96 2.353608033445198e-05\n",
      "97 2.3195989342639223e-05\n",
      "98 2.286392918904312e-05\n",
      "99 2.25350922846701e-05\n",
      "100 2.221028262283653e-05\n",
      "101 2.1892181393923238e-05\n",
      "102 2.1578265659627505e-05\n",
      "103 2.126822801074013e-05\n",
      "104 2.0960698748240247e-05\n",
      "105 2.065990338451229e-05\n",
      "106 2.0362331270007417e-05\n",
      "107 2.0069781385245733e-05\n",
      "108 1.978244836209342e-05\n",
      "109 1.9495653759804554e-05\n",
      "110 1.9216044165659696e-05\n",
      "111 1.8940987501991913e-05\n",
      "112 1.866841921582818e-05\n",
      "113 1.840031472966075e-05\n",
      "114 1.813464768929407e-05\n",
      "115 1.7875094272312708e-05\n",
      "116 1.7618869605939835e-05\n",
      "117 1.736595186230261e-05\n",
      "118 1.7116784874815494e-05\n",
      "119 1.686990071902983e-05\n",
      "120 1.6628362573101185e-05\n",
      "121 1.6388334188377485e-05\n",
      "122 1.6153555407072417e-05\n",
      "123 1.5921626982162707e-05\n",
      "124 1.5693680325057358e-05\n",
      "125 1.546783823869191e-05\n",
      "126 1.5245896065607667e-05\n",
      "127 1.5024888853076845e-05\n",
      "128 1.48081780935172e-05\n",
      "129 1.4596591427107342e-05\n",
      "130 1.4386753719008993e-05\n",
      "131 1.4179527170199435e-05\n",
      "132 1.3975978617963847e-05\n",
      "133 1.3774978469882626e-05\n",
      "134 1.3575865523307584e-05\n",
      "135 1.3383090845309198e-05\n",
      "136 1.3189373021305073e-05\n",
      "137 1.3000840226595756e-05\n",
      "138 1.281179538636934e-05\n",
      "139 1.262888326891698e-05\n",
      "140 1.244626400875859e-05\n",
      "141 1.2269044418644626e-05\n",
      "142 1.2093095392629039e-05\n",
      "143 1.1919623830181081e-05\n",
      "144 1.1746608834073413e-05\n",
      "145 1.1578615158214234e-05\n",
      "146 1.1412422281864565e-05\n",
      "147 1.1249769158894196e-05\n",
      "148 1.1087317943747621e-05\n",
      "149 1.0927393304882571e-05\n",
      "150 1.0771491361083463e-05\n",
      "151 1.0615196515573189e-05\n",
      "152 1.0463801118021365e-05\n",
      "153 1.0312937774870079e-05\n",
      "154 1.016409441945143e-05\n",
      "155 1.0019275578088127e-05\n",
      "156 9.875133400782943e-06\n",
      "157 9.732580110721756e-06\n",
      "158 9.591962225385942e-06\n",
      "159 9.45415649766801e-06\n",
      "160 9.318056982010603e-06\n",
      "161 9.184881491819397e-06\n",
      "162 9.053364010469522e-06\n",
      "163 8.923317182052415e-06\n",
      "164 8.795418580120895e-06\n",
      "165 8.667929250805173e-06\n",
      "166 8.544428965251427e-06\n",
      "167 8.420298399869353e-06\n",
      "168 8.29975488159107e-06\n",
      "169 8.180079930752981e-06\n",
      "170 8.063585482886992e-06\n",
      "171 7.946779987832997e-06\n",
      "172 7.83196446718648e-06\n",
      "173 7.720893336227164e-06\n",
      "174 7.6099745456303935e-06\n",
      "175 7.499221737816697e-06\n",
      "176 7.392438874376239e-06\n",
      "177 7.285012088686926e-06\n",
      "178 7.181330147432163e-06\n",
      "179 7.077773716446245e-06\n",
      "180 6.9766579144925345e-06\n",
      "181 6.874900009279372e-06\n",
      "182 6.777063845220255e-06\n",
      "183 6.680231763311895e-06\n",
      "184 6.5839481067087036e-06\n",
      "185 6.48969444227987e-06\n",
      "186 6.395974196493626e-06\n",
      "187 6.303958343778504e-06\n",
      "188 6.213766937435139e-06\n",
      "189 6.124083483882714e-06\n",
      "190 6.0361930991348345e-06\n",
      "191 5.949931164650479e-06\n",
      "192 5.8647133300837595e-06\n",
      "193 5.779690127383219e-06\n",
      "194 5.697368578694295e-06\n",
      "195 5.614535893982975e-06\n",
      "196 5.534771844395436e-06\n",
      "197 5.454085112432949e-06\n",
      "198 5.376417448132997e-06\n",
      "199 5.298236828821246e-06\n",
      "200 5.222221261647064e-06\n",
      "201 5.148206582816783e-06\n",
      "202 5.0726262088574e-06\n",
      "203 5.00020223626052e-06\n",
      "204 4.928687303618062e-06\n",
      "205 4.8575602704659104e-06\n",
      "206 4.788983915204881e-06\n",
      "207 4.7188759708660655e-06\n",
      "208 4.6517907321685925e-06\n",
      "209 4.584814632835332e-06\n",
      "210 4.519064077612711e-06\n",
      "211 4.453666406334378e-06\n",
      "212 4.3895984163100366e-06\n",
      "213 4.326961516198935e-06\n",
      "214 4.264175458956743e-06\n",
      "215 4.203277512715431e-06\n",
      "216 4.142817488173023e-06\n",
      "217 4.082209670741577e-06\n",
      "218 4.024378540634643e-06\n",
      "219 3.966034910263261e-06\n",
      "220 3.910186478606192e-06\n",
      "221 3.854390797641827e-06\n",
      "222 3.7984307255101157e-06\n",
      "223 3.7436677757796133e-06\n",
      "224 3.689970299092238e-06\n",
      "225 3.636773726611864e-06\n",
      "226 3.584622163543827e-06\n",
      "227 3.5329583170096157e-06\n",
      "228 3.482644842733862e-06\n",
      "229 3.4325851174799027e-06\n",
      "230 3.3828878258646e-06\n",
      "231 3.3342962524329778e-06\n",
      "232 3.2868988455447834e-06\n",
      "233 3.2390041724283947e-06\n",
      "234 3.1930187560647028e-06\n",
      "235 3.146639983242494e-06\n",
      "236 3.101317361142719e-06\n",
      "237 3.0570352009817725e-06\n",
      "238 3.013071591340122e-06\n",
      "239 2.9687248570553493e-06\n",
      "240 2.9268946946103824e-06\n",
      "241 2.8848685360571835e-06\n",
      "242 2.8436354568839306e-06\n",
      "243 2.802117251121672e-06\n",
      "244 2.762158374025603e-06\n",
      "245 2.722486442507943e-06\n",
      "246 2.6826269277080428e-06\n",
      "247 2.644949972818722e-06\n",
      "248 2.6075399546243716e-06\n",
      "249 2.5691861083032563e-06\n",
      "250 2.5325039132439997e-06\n",
      "251 2.4959003894764464e-06\n",
      "252 2.4594730803073617e-06\n",
      "253 2.4242192466772394e-06\n",
      "254 2.3899383450043388e-06\n",
      "255 2.355901642658864e-06\n",
      "256 2.321134616067866e-06\n",
      "257 2.288208861500607e-06\n",
      "258 2.2555184386874316e-06\n",
      "259 2.2230631202546647e-06\n",
      "260 2.1907578684476903e-06\n",
      "261 2.160054691557889e-06\n",
      "262 2.128212372554117e-06\n",
      "263 2.097952119584079e-06\n",
      "264 2.0678260170825524e-06\n",
      "265 2.0373365714476677e-06\n",
      "266 2.008308683798532e-06\n",
      "267 1.9800620520982193e-06\n",
      "268 1.951446847670013e-06\n",
      "269 1.9236044863646384e-06\n",
      "270 1.8959622138936538e-06\n",
      "271 1.868440904218005e-06\n",
      "272 1.8418302261125064e-06\n",
      "273 1.8147061382478569e-06\n",
      "274 1.7891829884320032e-06\n",
      "275 1.7630679849389708e-06\n",
      "276 1.7382944861310534e-06\n",
      "277 1.7133163510152372e-06\n",
      "278 1.688292059043306e-06\n",
      "279 1.6642025002511218e-06\n",
      "280 1.6401359062001575e-06\n",
      "281 1.6163935470103752e-06\n",
      "282 1.5937771422613878e-06\n",
      "283 1.5712478216300951e-06\n",
      "284 1.5480109141208231e-06\n",
      "285 1.5254502159223193e-06\n",
      "286 1.5039806839922676e-06\n",
      "287 1.482239895267412e-06\n",
      "288 1.4605159321945393e-06\n",
      "289 1.4396503047464648e-06\n",
      "290 1.4194886261975626e-06\n",
      "291 1.3987125839776127e-06\n",
      "292 1.378772822135943e-06\n",
      "293 1.3589763057098025e-06\n",
      "294 1.338851916443673e-06\n",
      "295 1.3203466551203746e-06\n",
      "296 1.3013725492783124e-06\n",
      "297 1.2826023976231227e-06\n",
      "298 1.2639688975468744e-06\n",
      "299 1.245471821675892e-06\n",
      "300 1.228140945386258e-06\n",
      "301 1.2103566859877901e-06\n",
      "302 1.1927650120924227e-06\n",
      "303 1.1760582765418803e-06\n",
      "304 1.1591569091251586e-06\n",
      "305 1.1420677310525207e-06\n",
      "306 1.1257211554038804e-06\n",
      "307 1.1093100056314142e-06\n",
      "308 1.0938085779343965e-06\n",
      "309 1.0784165169752669e-06\n",
      "310 1.0626540642988402e-06\n",
      "311 1.0474836926732678e-06\n",
      "312 1.0318910881323973e-06\n",
      "313 1.0178221145906718e-06\n",
      "314 1.0030930752691347e-06\n",
      "315 9.882978702080436e-07\n",
      "316 9.74071326709236e-07\n",
      "317 9.60062607191503e-07\n",
      "318 9.464374670642428e-07\n",
      "319 9.329655767942313e-07\n",
      "320 9.195348980028939e-07\n",
      "321 9.063126640285191e-07\n",
      "322 8.93075821295497e-07\n",
      "323 8.803183391137281e-07\n",
      "324 8.678152880747803e-07\n",
      "325 8.5567012320098e-07\n",
      "326 8.4291718849272e-07\n",
      "327 8.305244136863621e-07\n",
      "328 8.191703386728477e-07\n",
      "329 8.069540058386337e-07\n",
      "330 7.957628440635744e-07\n",
      "331 7.840833973205008e-07\n",
      "332 7.73052533986629e-07\n",
      "333 7.620494670845801e-07\n",
      "334 7.510237196584058e-07\n",
      "335 7.396786259050714e-07\n",
      "336 7.293133421626408e-07\n",
      "337 7.190212727437029e-07\n",
      "338 7.082639967848081e-07\n",
      "339 6.985105756029952e-07\n",
      "340 6.883909122734622e-07\n",
      "341 6.787281563447323e-07\n",
      "342 6.686577762593515e-07\n",
      "343 6.591349688278569e-07\n",
      "344 6.49306002742378e-07\n",
      "345 6.401544965228823e-07\n",
      "346 6.311609581644007e-07\n",
      "347 6.222767297003884e-07\n",
      "348 6.134100658528041e-07\n",
      "349 6.041548772373062e-07\n",
      "350 5.958677320450079e-07\n",
      "351 5.870581389899598e-07\n",
      "352 5.784470431535738e-07\n",
      "353 5.702504495275207e-07\n",
      "354 5.620691467811412e-07\n",
      "355 5.539898779716168e-07\n",
      "356 5.462700300995493e-07\n",
      "357 5.382631229622348e-07\n",
      "358 5.306540060701082e-07\n",
      "359 5.227213932812447e-07\n",
      "360 5.152231210558966e-07\n",
      "361 5.081103608972626e-07\n",
      "362 5.006772880733479e-07\n",
      "363 4.932992396788904e-07\n",
      "364 4.863398430643429e-07\n",
      "365 4.793901666744205e-07\n",
      "366 4.724905124930956e-07\n",
      "367 4.6564088052036823e-07\n",
      "368 4.588021056406433e-07\n",
      "369 4.523653842625208e-07\n",
      "370 4.457418185666029e-07\n",
      "371 4.396674739837181e-07\n",
      "372 4.3302298990965937e-07\n",
      "373 4.267326403351035e-07\n",
      "374 4.2078960404978716e-07\n",
      "375 4.1458906707703136e-07\n",
      "376 4.087317506673571e-07\n",
      "377 4.029901106150646e-07\n",
      "378 3.9717912159176194e-07\n",
      "379 3.915197908099799e-07\n",
      "380 3.855395789287286e-07\n",
      "381 3.8042935557314195e-07\n",
      "382 3.7478389458556194e-07\n",
      "383 3.6918072510161437e-07\n",
      "384 3.642510932877485e-07\n",
      "385 3.5907623896491714e-07\n",
      "386 3.5386847230256535e-07\n",
      "387 3.4869890441768803e-07\n",
      "388 3.4353348610238754e-07\n",
      "389 3.3877881833177526e-07\n",
      "390 3.336877512083447e-07\n",
      "391 3.290019776613917e-07\n",
      "392 3.242496973143716e-07\n",
      "393 3.1976225045582396e-07\n",
      "394 3.151756118313642e-07\n",
      "395 3.104926236119354e-07\n",
      "396 3.0613369972343207e-07\n",
      "397 3.016144205503224e-07\n",
      "398 2.973823143292975e-07\n",
      "399 2.931167273345636e-07\n",
      "400 2.8860108614026103e-07\n",
      "401 2.846787197086087e-07\n",
      "402 2.805675762829196e-07\n",
      "403 2.7639435984383454e-07\n",
      "404 2.7249512868365855e-07\n",
      "405 2.686840616661357e-07\n",
      "406 2.6460065782885067e-07\n",
      "407 2.610830165394873e-07\n",
      "408 2.573528945504222e-07\n",
      "409 2.5341574882986606e-07\n",
      "410 2.4988594304886647e-07\n",
      "411 2.4623710714877234e-07\n",
      "412 2.427580056973966e-07\n",
      "413 2.3936081561259925e-07\n",
      "414 2.3593094056195696e-07\n",
      "415 2.325819536963536e-07\n",
      "416 2.290621523570735e-07\n",
      "417 2.2598351279157214e-07\n",
      "418 2.2243176545089227e-07\n",
      "419 2.1939814587312867e-07\n",
      "420 2.1616921230815933e-07\n",
      "421 2.130980760739476e-07\n",
      "422 2.1012903062000987e-07\n",
      "423 2.0694324120995589e-07\n",
      "424 2.0422726265678648e-07\n",
      "425 2.0103402675886173e-07\n",
      "426 1.9835761122521944e-07\n",
      "427 1.9546774865375482e-07\n",
      "428 1.9254804328738828e-07\n",
      "429 1.897010406537447e-07\n",
      "430 1.870762957878469e-07\n",
      "431 1.8427044778945856e-07\n",
      "432 1.8168367432735977e-07\n",
      "433 1.7931188267539255e-07\n",
      "434 1.766869104358193e-07\n",
      "435 1.739601884764852e-07\n",
      "436 1.7163966958833043e-07\n",
      "437 1.6914350453589577e-07\n",
      "438 1.6664193935866933e-07\n",
      "439 1.6418249515481875e-07\n",
      "440 1.6185822460101917e-07\n",
      "441 1.5964366184562095e-07\n",
      "442 1.5716727830294985e-07\n",
      "443 1.5493924365728162e-07\n",
      "444 1.5272712516889442e-07\n",
      "445 1.5053092283778824e-07\n",
      "446 1.483506366639631e-07\n",
      "447 1.4620815136368037e-07\n",
      "448 1.4421402738662437e-07\n",
      "449 1.4225543054635637e-07\n",
      "450 1.4024521988176275e-07\n",
      "451 1.3818390698361327e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 1.3609525240099174e-07\n",
      "453 1.3417161426332314e-07\n",
      "454 1.3228259376774076e-07\n",
      "455 1.3021855238548596e-07\n",
      "456 1.283574988519831e-07\n",
      "457 1.2675855032284744e-07\n",
      "458 1.2479932820497197e-07\n",
      "459 1.22916674172302e-07\n",
      "460 1.211295170833182e-07\n",
      "461 1.1947554412472527e-07\n",
      "462 1.1783305353674223e-07\n",
      "463 1.1604356586758513e-07\n",
      "464 1.1426783430579235e-07\n",
      "465 1.1279831824140274e-07\n",
      "466 1.1110614650533535e-07\n",
      "467 1.0946433803837863e-07\n",
      "468 1.078924469766207e-07\n",
      "469 1.0631310942699201e-07\n",
      "470 1.0476406941961613e-07\n",
      "471 1.0335730848964886e-07\n",
      "472 1.019600972540502e-07\n",
      "473 1.0029589248006232e-07\n",
      "474 9.897439667838626e-08\n",
      "475 9.76071987679461e-08\n",
      "476 9.623141750125797e-08\n",
      "477 9.47941884987813e-08\n",
      "478 9.345609441879787e-08\n",
      "479 9.195105121762026e-08\n",
      "480 9.063342076842673e-08\n",
      "481 8.949911034505931e-08\n",
      "482 8.819921504255035e-08\n",
      "483 8.690886943441001e-08\n",
      "484 8.561096365156118e-08\n",
      "485 8.433971743215807e-08\n",
      "486 8.32456521493441e-08\n",
      "487 8.199214107662556e-08\n",
      "488 8.073175195022486e-08\n",
      "489 7.974341542649199e-08\n",
      "490 7.854941941332072e-08\n",
      "491 7.746120900264941e-08\n",
      "492 7.636464260940556e-08\n",
      "493 7.514836397604086e-08\n",
      "494 7.419504299832624e-08\n",
      "495 7.316907613130752e-08\n",
      "496 7.197860441010562e-08\n",
      "497 7.092171472322661e-08\n",
      "498 6.999567858656519e-08\n",
      "499 6.899927029735409e-08\n",
      "500 6.807067620684393e-08\n",
      "501 6.696797072436311e-08\n",
      "502 6.606796887353994e-08\n",
      "503 6.505553074021009e-08\n",
      "504 6.415399411707767e-08\n",
      "505 6.315644895948935e-08\n",
      "506 6.228293614185532e-08\n",
      "507 6.154482434794772e-08\n",
      "508 6.049646117389784e-08\n",
      "509 5.962721161267837e-08\n",
      "510 5.8778141465154476e-08\n",
      "511 5.7963461586041376e-08\n",
      "512 5.71126292925328e-08\n",
      "513 5.619995135930367e-08\n",
      "514 5.5580585467396304e-08\n",
      "515 5.463903107738588e-08\n",
      "516 5.393422952693072e-08\n",
      "517 5.314063855621498e-08\n",
      "518 5.2326186050777324e-08\n",
      "519 5.153088977749576e-08\n",
      "520 5.083376208858681e-08\n",
      "521 5.0167273002443835e-08\n",
      "522 4.937601261190139e-08\n",
      "523 4.8732090363046154e-08\n",
      "524 4.805428943654988e-08\n",
      "525 4.736835990115651e-08\n",
      "526 4.6637126160931075e-08\n",
      "527 4.596154212777037e-08\n",
      "528 4.532813591140439e-08\n",
      "529 4.467420922082965e-08\n",
      "530 4.396434860609588e-08\n",
      "531 4.3405179894762114e-08\n",
      "532 4.27655777457403e-08\n",
      "533 4.2154454149567755e-08\n",
      "534 4.151229404669721e-08\n",
      "535 4.0886789065552875e-08\n",
      "536 4.038275847051409e-08\n",
      "537 3.9754240788170137e-08\n",
      "538 3.925725877707009e-08\n",
      "539 3.8637608668068424e-08\n",
      "540 3.814767524090712e-08\n",
      "541 3.753689270524774e-08\n",
      "542 3.7054007862025173e-08\n",
      "543 3.645209289970808e-08\n",
      "544 3.5976256640424253e-08\n",
      "545 3.5383209251449443e-08\n",
      "546 3.490390554361511e-08\n",
      "547 3.441641638346482e-08\n",
      "548 3.39434791385429e-08\n",
      "549 3.345240884300438e-08\n",
      "550 3.296509021311067e-08\n",
      "551 3.250215740990825e-08\n",
      "552 3.2052923870651284e-08\n",
      "553 3.157583705615252e-08\n",
      "554 3.1102501907298574e-08\n",
      "555 3.073438392675598e-08\n",
      "556 3.018635652551893e-08\n",
      "557 2.9823695513186976e-08\n",
      "558 2.936377541118418e-08\n",
      "559 2.8926763206982287e-08\n",
      "560 2.85718328996154e-08\n",
      "561 2.812157617881894e-08\n",
      "562 2.7771648092311807e-08\n",
      "563 2.734691406658385e-08\n",
      "564 2.6896941562881693e-08\n",
      "565 2.6535701636021258e-08\n",
      "566 2.6120517304661917e-08\n",
      "567 2.5774397727218457e-08\n",
      "568 2.5420433757972205e-08\n",
      "569 2.5087786070798757e-08\n",
      "570 2.472989990565111e-08\n",
      "571 2.4329267489520134e-08\n",
      "572 2.400389575996087e-08\n",
      "573 2.3653740299778292e-08\n",
      "574 2.333291604372789e-08\n",
      "575 2.2987762804405065e-08\n",
      "576 2.267148602186353e-08\n",
      "577 2.2331335003400454e-08\n",
      "578 2.2019605694367783e-08\n",
      "579 2.168445689676446e-08\n",
      "580 2.1377275061240653e-08\n",
      "581 2.1131427274667658e-08\n",
      "582 2.0736024453071877e-08\n",
      "583 2.0502284314716235e-08\n",
      "584 2.0195386696286732e-08\n",
      "585 1.987433506656089e-08\n",
      "586 1.957255335582886e-08\n",
      "587 1.93208506971132e-08\n",
      "588 1.903094926092308e-08\n",
      "589 1.8799084955389844e-08\n",
      "590 1.8489402009436162e-08\n",
      "591 1.8198306861449964e-08\n",
      "592 1.8018226910498925e-08\n",
      "593 1.7730428680806654e-08\n",
      "594 1.7452805423090467e-08\n",
      "595 1.7269030649913475e-08\n",
      "596 1.698737150945817e-08\n",
      "597 1.671565996730351e-08\n",
      "598 1.653575054660905e-08\n",
      "599 1.626767698326148e-08\n",
      "600 1.603126520421938e-08\n",
      "601 1.5759951565996744e-08\n",
      "602 1.5498244465561584e-08\n",
      "603 1.53250425682927e-08\n",
      "604 1.5116938811843283e-08\n",
      "605 1.4910312984284246e-08\n",
      "606 1.4740635378984734e-08\n",
      "607 1.4480349364021095e-08\n",
      "608 1.42781573231332e-08\n",
      "609 1.4077443211135687e-08\n",
      "610 1.3857516023563221e-08\n",
      "611 1.365975776934647e-08\n",
      "612 1.34634774440201e-08\n",
      "613 1.3254975783638656e-08\n",
      "614 1.3061537629255326e-08\n",
      "615 1.2863267784268828e-08\n",
      "616 1.2711836916423636e-08\n",
      "617 1.251584080819157e-08\n",
      "618 1.2379587133182213e-08\n",
      "619 1.2173416052974062e-08\n",
      "620 1.1937345334445126e-08\n",
      "621 1.1804161204054253e-08\n",
      "622 1.1602878657868132e-08\n",
      "623 1.1471740890556248e-08\n",
      "624 1.1285749224043684e-08\n",
      "625 1.1156316759297624e-08\n",
      "626 1.0960604868159862e-08\n",
      "627 1.0833218766492791e-08\n",
      "628 1.0682470019673929e-08\n",
      "629 1.0556789220572682e-08\n",
      "630 1.0378073511674302e-08\n",
      "631 1.025409801513888e-08\n",
      "632 1.0066571576317074e-08\n",
      "633 9.938560197042534e-09\n",
      "634 9.81731318461243e-09\n",
      "635 9.690893421065994e-09\n",
      "636 9.508596576779382e-09\n",
      "637 9.384223176311934e-09\n",
      "638 9.26638676901348e-09\n",
      "639 9.143604984274134e-09\n",
      "640 8.966537734522717e-09\n",
      "641 8.845802312862361e-09\n",
      "642 8.725976385903778e-09\n",
      "643 8.6122327047633e-09\n",
      "644 8.49399839353282e-09\n",
      "645 8.376673577004112e-09\n",
      "646 8.207109658542322e-09\n",
      "647 8.08108779892791e-09\n",
      "648 7.966491466504522e-09\n",
      "649 7.852804628782906e-09\n",
      "650 7.744858976366231e-09\n",
      "651 7.632763754372718e-09\n",
      "652 7.546589131379733e-09\n",
      "653 7.435858151438879e-09\n",
      "654 7.330982043640688e-09\n",
      "655 7.1825070335762575e-09\n",
      "656 7.098833521013148e-09\n",
      "657 7.030394044704735e-09\n",
      "658 6.923528417246416e-09\n",
      "659 6.808079433540115e-09\n",
      "660 6.750497050234117e-09\n",
      "661 6.636412308580475e-09\n",
      "662 6.5278982219751924e-09\n",
      "663 6.429502263927134e-09\n",
      "664 6.3274114836531226e-09\n",
      "665 6.2489675656252075e-09\n",
      "666 6.184848189150216e-09\n",
      "667 6.084576398279751e-09\n",
      "668 6.0079514696553815e-09\n",
      "669 5.9090439208375756e-09\n",
      "670 5.8110458667215426e-09\n",
      "671 5.7492002270009834e-09\n",
      "672 5.6748490351310465e-09\n",
      "673 5.578669970418559e-09\n",
      "674 5.51818857275066e-09\n",
      "675 5.423373750090832e-09\n",
      "676 5.329468422132777e-09\n",
      "677 5.299853000906296e-09\n",
      "678 5.19457898917608e-09\n",
      "679 5.102720024297014e-09\n",
      "680 5.04473973705899e-09\n",
      "681 4.987214197171852e-09\n",
      "682 4.925652774545597e-09\n",
      "683 4.836294920096407e-09\n",
      "684 4.7478465603489894e-09\n",
      "685 4.719822754850611e-09\n",
      "686 4.620460458681919e-09\n",
      "687 4.5340584620134905e-09\n",
      "688 4.510411599767394e-09\n",
      "689 4.394223651615903e-09\n",
      "690 4.359435479273088e-09\n",
      "691 4.301966782804811e-09\n",
      "692 4.218520643917145e-09\n",
      "693 4.162302502663806e-09\n",
      "694 4.139565135119483e-09\n",
      "695 4.028379407827742e-09\n",
      "696 3.994955477537587e-09\n",
      "697 3.939987891499186e-09\n",
      "698 3.885588739649393e-09\n",
      "699 3.834884410025552e-09\n",
      "700 3.802824721788056e-09\n",
      "701 3.695731720654294e-09\n",
      "702 3.6710048334498424e-09\n",
      "703 3.6218921195541043e-09\n",
      "704 3.542027116054669e-09\n",
      "705 3.5211087379138917e-09\n",
      "706 3.469551757007139e-09\n",
      "707 3.4115714697691146e-09\n",
      "708 3.360810296726413e-09\n",
      "709 3.313743945909664e-09\n",
      "710 3.2671323424438015e-09\n",
      "711 3.2342200029233936e-09\n",
      "712 3.194372766301967e-09\n",
      "713 3.112745616817847e-09\n",
      "714 3.0900650926923845e-09\n",
      "715 3.0450451049546245e-09\n",
      "716 3.022705641342327e-09\n",
      "717 2.943352228612639e-09\n",
      "718 2.9213538255135063e-09\n",
      "719 2.8742306312778965e-09\n",
      "720 2.830802259268239e-09\n",
      "721 2.809258603519993e-09\n",
      "722 2.763044903986156e-09\n",
      "723 2.6961970434058458e-09\n",
      "724 2.6905695449386258e-09\n",
      "725 2.654132913448848e-09\n",
      "726 2.609397142805392e-09\n",
      "727 2.5591475605324376e-09\n",
      "728 2.515207597753033e-09\n",
      "729 2.494800810382003e-09\n",
      "730 2.4543282961531077e-09\n",
      "731 2.4342625692952424e-09\n",
      "732 2.3913457880553324e-09\n",
      "733 2.3433699425368104e-09\n",
      "734 2.3012489691609517e-09\n",
      "735 2.2817516764916945e-09\n",
      "736 2.2403128241421655e-09\n",
      "737 2.2210429051483516e-09\n",
      "738 2.1802861738251522e-09\n",
      "739 2.1639152691932395e-09\n",
      "740 2.123499598383205e-09\n",
      "741 2.104798113577999e-09\n",
      "742 2.0650645637942944e-09\n",
      "743 2.0465904526645318e-09\n",
      "744 2.0075390239071567e-09\n",
      "745 1.9838921616610605e-09\n",
      "746 1.9451817934168503e-09\n",
      "747 1.907039859361248e-09\n",
      "748 1.889247869257815e-09\n",
      "749 1.871569565992104e-09\n",
      "750 1.834223439800553e-09\n",
      "751 1.7919319361681119e-09\n",
      "752 1.774708380253287e-09\n",
      "753 1.738271748763509e-09\n",
      "754 1.7212755665241275e-09\n",
      "755 1.7099068827519659e-09\n",
      "756 1.6687522474967409e-09\n",
      "757 1.6709691408323124e-09\n",
      "758 1.635555690882029e-09\n",
      "759 1.6146373127412517e-09\n",
      "760 1.5957652976794634e-09\n",
      "761 1.5611476555932313e-09\n",
      "762 1.5450609680556227e-09\n",
      "763 1.5181740309344605e-09\n",
      "764 1.4952661331335548e-09\n",
      "765 1.4638885659223888e-09\n",
      "766 1.4417764759855345e-09\n",
      "767 1.4263719094742555e-09\n",
      "768 1.4154579730529804e-09\n",
      "769 1.3959038369648624e-09\n",
      "770 1.3783960639557336e-09\n",
      "771 1.3362750905798748e-09\n",
      "772 1.3313297131389845e-09\n",
      "773 1.3164935808163136e-09\n",
      "774 1.2810232874471694e-09\n",
      "775 1.2871623766841367e-09\n",
      "776 1.2560690265672747e-09\n",
      "777 1.235548552358523e-09\n",
      "778 1.211276412504958e-09\n",
      "779 1.1909833119716495e-09\n",
      "780 1.1930865184694994e-09\n",
      "781 1.17694298751303e-09\n",
      "782 1.1492033991089556e-09\n",
      "783 1.1198153515579179e-09\n",
      "784 1.116234216169687e-09\n",
      "785 1.1062297744501848e-09\n",
      "786 1.1027623258996755e-09\n",
      "787 1.0641656444931868e-09\n",
      "788 1.0452367860125378e-09\n",
      "789 1.0321059562556911e-09\n",
      "790 1.0343228495912626e-09\n",
      "791 1.004309524432756e-09\n",
      "792 1.0061853572551627e-09\n",
      "793 9.933955880114809e-10\n",
      "794 9.642917575547472e-10\n",
      "795 9.51615675148787e-10\n",
      "796 9.53377821133472e-10\n",
      "797 9.356995178677607e-10\n",
      "798 9.266045708500315e-10\n",
      "799 9.142695489572361e-10\n",
      "800 8.96818619366968e-10\n",
      "801 8.708411769475788e-10\n",
      "802 8.588472155679483e-10\n",
      "803 8.608367352280766e-10\n",
      "804 8.335518941748887e-10\n",
      "805 8.352003533218522e-10\n",
      "806 8.235474524553865e-10\n",
      "807 7.985931915754918e-10\n",
      "808 7.985931915754918e-10\n",
      "809 7.823928172001615e-10\n",
      "810 7.710809768468607e-10\n",
      "811 7.598828233312815e-10\n",
      "812 7.469225238310173e-10\n",
      "813 7.48798356653424e-10\n",
      "814 7.37827576813288e-10\n",
      "815 7.12361725163646e-10\n",
      "816 7.015046321612317e-10\n",
      "817 7.015046321612317e-10\n",
      "818 6.90761225996539e-10\n",
      "819 6.801315066695679e-10\n",
      "820 6.801315066695679e-10\n",
      "821 6.696154741803184e-10\n",
      "822 6.471623237302992e-10\n",
      "823 6.471623237302992e-10\n",
      "824 6.325535650830716e-10\n",
      "825 6.22378593106987e-10\n",
      "826 6.22378593106987e-10\n",
      "827 6.007212505210191e-10\n",
      "828 6.023697096679825e-10\n",
      "829 5.907736522203777e-10\n",
      "830 5.809397407574579e-10\n",
      "831 5.697984306607395e-10\n",
      "832 5.600782060355414e-10\n",
      "833 5.616129783447832e-10\n",
      "834 5.504716682480648e-10\n",
      "835 5.409788172983099e-10\n",
      "836 5.409788172983099e-10\n",
      "837 5.315996531862766e-10\n",
      "838 5.209130904404446e-10\n",
      "839 5.116476131661329e-10\n",
      "840 5.014157977711875e-10\n",
      "841 5.024958227295429e-10\n",
      "842 4.832259037357289e-10\n",
      "843 4.832259037357289e-10\n",
      "844 4.743014869745821e-10\n",
      "845 4.743014869745821e-10\n",
      "846 4.5571368900709786e-10\n",
      "847 4.5571368900709786e-10\n",
      "848 4.376943252282217e-10\n",
      "849 4.3456793719087727e-10\n",
      "850 4.3456793719087727e-10\n",
      "851 4.260982677806169e-10\n",
      "852 4.1677594708744437e-10\n",
      "853 4.177422852080781e-10\n",
      "854 4.084199645149056e-10\n",
      "855 4.001776687800884e-10\n",
      "856 3.913100954378024e-10\n",
      "857 3.920490598829929e-10\n",
      "858 3.751665644813329e-10\n",
      "859 3.7272229747031815e-10\n",
      "860 3.7272229747031815e-10\n",
      "861 3.7272229747031815e-10\n",
      "862 3.560671757441014e-10\n",
      "863 3.6493474908638746e-10\n",
      "864 3.594777808757499e-10\n",
      "865 3.433910933381412e-10\n",
      "866 3.4083313948940486e-10\n",
      "867 3.3242031349800527e-10\n",
      "868 3.249738256272394e-10\n",
      "869 3.249738256272394e-10\n",
      "870 3.249738256272394e-10\n",
      "871 3.0968294595368207e-10\n",
      "872 3.1042191039887257e-10\n",
      "873 3.1042191039887257e-10\n",
      "874 3.0246383175835945e-10\n",
      "875 3.0331648304127157e-10\n",
      "876 2.9535840440075845e-10\n",
      "877 2.9336888474063016e-10\n",
      "878 2.8836666388087906e-10\n",
      "879 2.7398527890909463e-10\n",
      "880 2.717683855735231e-10\n",
      "881 2.717683855735231e-10\n",
      "882 2.717683855735231e-10\n",
      "883 2.672209120646585e-10\n",
      "884 2.576143742771819e-10\n",
      "885 2.651177055668086e-10\n",
      "886 2.51077381108189e-10\n",
      "887 2.469846549502108e-10\n",
      "888 2.446540747769177e-10\n",
      "889 2.376054908381775e-10\n",
      "890 2.38344455283368e-10\n",
      "891 2.312958713446278e-10\n",
      "892 2.2509993868879974e-10\n",
      "893 2.2964741219766438e-10\n",
      "894 2.3214852262753993e-10\n",
      "895 2.1901769287069328e-10\n",
      "896 2.1901769287069328e-10\n",
      "897 2.1901769287069328e-10\n",
      "898 2.1242385628283955e-10\n",
      "899 2.1304913389030844e-10\n",
      "900 2.064552973024547e-10\n",
      "901 2.0060042515979148e-10\n",
      "902 1.9895196601282805e-10\n",
      "903 1.9235812942497432e-10\n",
      "904 1.887201506178826e-10\n",
      "905 1.8673063095775433e-10\n",
      "906 1.8673063095775433e-10\n",
      "907 1.8309265215066262e-10\n",
      "908 1.8673063095775433e-10\n",
      "909 1.7507773009128869e-10\n",
      "910 1.7507773009128869e-10\n",
      "911 1.758166945364792e-10\n",
      "912 1.758166945364792e-10\n",
      "913 1.6967760529951192e-10\n",
      "914 1.7053025658242404e-10\n",
      "915 1.6439116734545678e-10\n",
      "916 1.6439116734545678e-10\n",
      "917 1.5921841622912325e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918 1.5921841622912325e-10\n",
      "919 1.5353407434304245e-10\n",
      "920 1.4847501006443053e-10\n",
      "921 1.5211298887152225e-10\n",
      "922 1.5415935195051134e-10\n",
      "923 1.4847501006443053e-10\n",
      "924 1.4352963262354024e-10\n",
      "925 1.4233592082746327e-10\n",
      "926 1.3665157894138247e-10\n",
      "927 1.3869794202037156e-10\n",
      "928 1.4233592082746327e-10\n",
      "929 1.3869794202037156e-10\n",
      "930 1.319335751759354e-10\n",
      "931 1.2875034371973015e-10\n",
      "932 1.319335751759354e-10\n",
      "933 1.2875034371973015e-10\n",
      "934 1.2209966371301562e-10\n",
      "935 1.2209966371301562e-10\n",
      "936 1.2283862815820612e-10\n",
      "937 1.1760903362301178e-10\n",
      "938 1.1760903362301178e-10\n",
      "939 1.1323209037072957e-10\n",
      "940 1.1687006917782128e-10\n",
      "941 1.184616849059239e-10\n",
      "942 1.1323209037072957e-10\n",
      "943 1.0896883395616896e-10\n",
      "944 1.0896883395616896e-10\n",
      "945 1.0896883395616896e-10\n",
      "946 1.1050360626541078e-10\n",
      "947 1.0419398677186109e-10\n",
      "948 1.0481926437932998e-10\n",
      "949 1.0419398677186109e-10\n",
      "950 1.000444171950221e-10\n",
      "951 1.000444171950221e-10\n",
      "952 9.600853445590474e-11\n",
      "953 9.919176591210999e-11\n",
      "954 9.600853445590474e-11\n",
      "955 9.049472282640636e-11\n",
      "956 8.776623872108757e-11\n",
      "957 9.049472282640636e-11\n",
      "958 9.208633855450898e-11\n",
      "959 9.208633855450898e-11\n",
      "960 8.668621376273222e-11\n",
      "961 8.395772965741344e-11\n",
      "962 8.668621376273222e-11\n",
      "963 8.395772965741344e-11\n",
      "964 7.867129170335829e-11\n",
      "965 7.867129170335829e-11\n",
      "966 7.867129170335829e-11\n",
      "967 7.94102561485488e-11\n",
      "968 7.94102561485488e-11\n",
      "969 8.026290743146092e-11\n",
      "970 7.509015631512739e-11\n",
      "971 7.509015631512739e-11\n",
      "972 7.594280759803951e-11\n",
      "973 7.509015631512739e-11\n",
      "974 7.16227077646181e-11\n",
      "975 7.16227077646181e-11\n",
      "976 6.826894605183043e-11\n",
      "977 6.775735528208315e-11\n",
      "978 6.826894605183043e-11\n",
      "979 6.440359356929548e-11\n",
      "980 6.440359356929548e-11\n",
      "981 6.440359356929548e-11\n",
      "982 6.116351869422942e-11\n",
      "983 6.389200279954821e-11\n",
      "984 6.502887117676437e-11\n",
      "985 6.116351869422942e-11\n",
      "986 6.116351869422942e-11\n",
      "987 6.116351869422942e-11\n",
      "988 5.803713065688498e-11\n",
      "989 6.076561476220377e-11\n",
      "990 5.803713065688498e-11\n",
      "991 5.803713065688498e-11\n",
      "992 5.3887561080046e-11\n",
      "993 5.803713065688498e-11\n",
      "994 5.502442945726216e-11\n",
      "995 5.775291356258094e-11\n",
      "996 5.502442945726216e-11\n",
      "997 5.502442945726216e-11\n",
      "998 5.502442945726216e-11\n",
      "999 5.098854671814479e-11\n",
      "predict (after training) 4 7.9999918937683105\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "# w_list = []\n",
    "# l_list = []\n",
    "\n",
    "%matplotlib inline\n",
    "x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0]])) # 1행 3열의 의미?\n",
    "y_data = Variable(torch.Tensor([[2.0],[4.0],[6.0]]))\n",
    "\n",
    "class Model(torch.nn.Module):   #괄호 안이 다른 class를 상속받는다.\n",
    "    def __init__(self):         # __init__ 이 포멧 자체가 class를 이렇게 정의했다.  mdel = Model()이렇게 class를 생성할때 init이 자동으로 실행된다.\n",
    "        super(Model, self).__init__() # super - 파이썬 고유함수 - 상속받은 class에 init이 연속되서 실행되는것을 방지.\n",
    "        self.linear = torch.nn.Linear(1,1) # 상속받은거 안에 있는 def. 여기는 정해진 형식 ㄴㄴ linear - >fc 1자리. \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average = False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())  # 문법 조심 or loss.data\n",
    "    \n",
    "    optimizer.zero_grad()   # 문법 조심\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "hour_val = Variable(torch.Tensor([4.0]))\n",
    "print(\"predict (after training)\", 4, model.forward(hour_val).item())\n",
    "\n",
    "\n",
    "#plt.plot(grad, loss)    w과 l 함수 어떻게 그래프로 나타낼수 있는지?\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('w')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.4397],\n",
      "        [0.3013],\n",
      "        [0.1915],\n",
      "        [0.1152]]) 1.1879518032073975\n",
      "1 tensor([[0.4433],\n",
      "        [0.3070],\n",
      "        [0.1977],\n",
      "        [0.1205]]) 1.1723308563232422\n",
      "2 tensor([[0.4469],\n",
      "        [0.3127],\n",
      "        [0.2039],\n",
      "        [0.1260]]) 1.1570711135864258\n",
      "3 tensor([[0.4504],\n",
      "        [0.3184],\n",
      "        [0.2102],\n",
      "        [0.1317]]) 1.1421725749969482\n",
      "4 tensor([[0.4539],\n",
      "        [0.3240],\n",
      "        [0.2166],\n",
      "        [0.1375]]) 1.1276353597640991\n",
      "5 tensor([[0.4574],\n",
      "        [0.3297],\n",
      "        [0.2230],\n",
      "        [0.1434]]) 1.1134587526321411\n",
      "6 tensor([[0.4608],\n",
      "        [0.3353],\n",
      "        [0.2295],\n",
      "        [0.1495]]) 1.0996416807174683\n",
      "7 tensor([[0.4641],\n",
      "        [0.3409],\n",
      "        [0.2360],\n",
      "        [0.1557]]) 1.086182713508606\n",
      "8 tensor([[0.4675],\n",
      "        [0.3464],\n",
      "        [0.2425],\n",
      "        [0.1620]]) 1.0730799436569214\n",
      "9 tensor([[0.4707],\n",
      "        [0.3520],\n",
      "        [0.2491],\n",
      "        [0.1684]]) 1.060331106185913\n",
      "10 tensor([[0.4739],\n",
      "        [0.3574],\n",
      "        [0.2557],\n",
      "        [0.1750]]) 1.0479334592819214\n",
      "11 tensor([[0.4771],\n",
      "        [0.3629],\n",
      "        [0.2623],\n",
      "        [0.1816]]) 1.0358837842941284\n",
      "12 tensor([[0.4802],\n",
      "        [0.3683],\n",
      "        [0.2689],\n",
      "        [0.1883]]) 1.0241787433624268\n",
      "13 tensor([[0.4833],\n",
      "        [0.3736],\n",
      "        [0.2755],\n",
      "        [0.1951]]) 1.0128144025802612\n",
      "14 tensor([[0.4863],\n",
      "        [0.3789],\n",
      "        [0.2821],\n",
      "        [0.2020]]) 1.001786470413208\n",
      "15 tensor([[0.4893],\n",
      "        [0.3841],\n",
      "        [0.2887],\n",
      "        [0.2090]]) 0.9910904169082642\n",
      "16 tensor([[0.4922],\n",
      "        [0.3892],\n",
      "        [0.2953],\n",
      "        [0.2160]]) 0.9807211756706238\n",
      "17 tensor([[0.4951],\n",
      "        [0.3944],\n",
      "        [0.3019],\n",
      "        [0.2231]]) 0.9706737995147705\n",
      "18 tensor([[0.4979],\n",
      "        [0.3994],\n",
      "        [0.3084],\n",
      "        [0.2302]]) 0.9609425067901611\n",
      "19 tensor([[0.5006],\n",
      "        [0.4044],\n",
      "        [0.3149],\n",
      "        [0.2374]]) 0.9515219330787659\n",
      "20 tensor([[0.5034],\n",
      "        [0.4093],\n",
      "        [0.3214],\n",
      "        [0.2446]]) 0.9424057602882385\n",
      "21 tensor([[0.5060],\n",
      "        [0.4141],\n",
      "        [0.3278],\n",
      "        [0.2518]]) 0.933587908744812\n",
      "22 tensor([[0.5086],\n",
      "        [0.4189],\n",
      "        [0.3342],\n",
      "        [0.2590]]) 0.9250620007514954\n",
      "23 tensor([[0.5112],\n",
      "        [0.4236],\n",
      "        [0.3405],\n",
      "        [0.2662]]) 0.9168217182159424\n",
      "24 tensor([[0.5137],\n",
      "        [0.4282],\n",
      "        [0.3468],\n",
      "        [0.2735]]) 0.9088600873947144\n",
      "25 tensor([[0.5161],\n",
      "        [0.4328],\n",
      "        [0.3530],\n",
      "        [0.2807]]) 0.901170551776886\n",
      "26 tensor([[0.5186],\n",
      "        [0.4372],\n",
      "        [0.3592],\n",
      "        [0.2879]]) 0.8937462568283081\n",
      "27 tensor([[0.5209],\n",
      "        [0.4416],\n",
      "        [0.3652],\n",
      "        [0.2951]]) 0.886580228805542\n",
      "28 tensor([[0.5232],\n",
      "        [0.4460],\n",
      "        [0.3713],\n",
      "        [0.3022]]) 0.8796654343605042\n",
      "29 tensor([[0.5255],\n",
      "        [0.4502],\n",
      "        [0.3772],\n",
      "        [0.3093]]) 0.8729948997497559\n",
      "30 tensor([[0.5277],\n",
      "        [0.4544],\n",
      "        [0.3831],\n",
      "        [0.3164]]) 0.8665617108345032\n",
      "31 tensor([[0.5298],\n",
      "        [0.4585],\n",
      "        [0.3888],\n",
      "        [0.3234]]) 0.8603588938713074\n",
      "32 tensor([[0.5320],\n",
      "        [0.4625],\n",
      "        [0.3946],\n",
      "        [0.3304]]) 0.8543793559074402\n",
      "33 tensor([[0.5340],\n",
      "        [0.4665],\n",
      "        [0.4002],\n",
      "        [0.3373]]) 0.8486162424087524\n",
      "34 tensor([[0.5360],\n",
      "        [0.4704],\n",
      "        [0.4057],\n",
      "        [0.3442]]) 0.8430628776550293\n",
      "35 tensor([[0.5380],\n",
      "        [0.4742],\n",
      "        [0.4112],\n",
      "        [0.3510]]) 0.837712287902832\n",
      "36 tensor([[0.5399],\n",
      "        [0.4779],\n",
      "        [0.4165],\n",
      "        [0.3577]]) 0.8325579166412354\n",
      "37 tensor([[0.5418],\n",
      "        [0.4816],\n",
      "        [0.4218],\n",
      "        [0.3643]]) 0.827593207359314\n",
      "38 tensor([[0.5437],\n",
      "        [0.4851],\n",
      "        [0.4270],\n",
      "        [0.3708]]) 0.822811484336853\n",
      "39 tensor([[0.5455],\n",
      "        [0.4886],\n",
      "        [0.4321],\n",
      "        [0.3773]]) 0.8182066679000854\n",
      "40 tensor([[0.5472],\n",
      "        [0.4921],\n",
      "        [0.4371],\n",
      "        [0.3837]]) 0.8137723803520203\n",
      "41 tensor([[0.5489],\n",
      "        [0.4954],\n",
      "        [0.4421],\n",
      "        [0.3900]]) 0.8095026016235352\n",
      "42 tensor([[0.5506],\n",
      "        [0.4987],\n",
      "        [0.4469],\n",
      "        [0.3962]]) 0.8053914308547974\n",
      "43 tensor([[0.5522],\n",
      "        [0.5020],\n",
      "        [0.4517],\n",
      "        [0.4024]]) 0.8014329075813293\n",
      "44 tensor([[0.5538],\n",
      "        [0.5051],\n",
      "        [0.4563],\n",
      "        [0.4084]]) 0.7976216077804565\n",
      "45 tensor([[0.5554],\n",
      "        [0.5082],\n",
      "        [0.4609],\n",
      "        [0.4143]]) 0.7939518094062805\n",
      "46 tensor([[0.5569],\n",
      "        [0.5112],\n",
      "        [0.4654],\n",
      "        [0.4202]]) 0.790418267250061\n",
      "47 tensor([[0.5583],\n",
      "        [0.5142],\n",
      "        [0.4698],\n",
      "        [0.4259]]) 0.7870157957077026\n",
      "48 tensor([[0.5598],\n",
      "        [0.5171],\n",
      "        [0.4741],\n",
      "        [0.4316]]) 0.7837393879890442\n",
      "49 tensor([[0.5612],\n",
      "        [0.5199],\n",
      "        [0.4784],\n",
      "        [0.4371]]) 0.7805839776992798\n",
      "50 tensor([[0.5625],\n",
      "        [0.5227],\n",
      "        [0.4825],\n",
      "        [0.4426]]) 0.7775450348854065\n",
      "51 tensor([[0.5639],\n",
      "        [0.5254],\n",
      "        [0.4866],\n",
      "        [0.4480]]) 0.7746177911758423\n",
      "52 tensor([[0.5652],\n",
      "        [0.5280],\n",
      "        [0.4906],\n",
      "        [0.4532]]) 0.7717981934547424\n",
      "53 tensor([[0.5664],\n",
      "        [0.5306],\n",
      "        [0.4945],\n",
      "        [0.4584]]) 0.7690815329551697\n",
      "54 tensor([[0.5677],\n",
      "        [0.5331],\n",
      "        [0.4983],\n",
      "        [0.4635]]) 0.7664638757705688\n",
      "55 tensor([[0.5689],\n",
      "        [0.5356],\n",
      "        [0.5020],\n",
      "        [0.4684]]) 0.76394122838974\n",
      "56 tensor([[0.5700],\n",
      "        [0.5380],\n",
      "        [0.5057],\n",
      "        [0.4733]]) 0.7615098357200623\n",
      "57 tensor([[0.5712],\n",
      "        [0.5404],\n",
      "        [0.5093],\n",
      "        [0.4781]]) 0.7591657638549805\n",
      "58 tensor([[0.5723],\n",
      "        [0.5427],\n",
      "        [0.5128],\n",
      "        [0.4828]]) 0.7569056749343872\n",
      "59 tensor([[0.5734],\n",
      "        [0.5449],\n",
      "        [0.5162],\n",
      "        [0.4874]]) 0.7547260522842407\n",
      "60 tensor([[0.5744],\n",
      "        [0.5471],\n",
      "        [0.5196],\n",
      "        [0.4920]]) 0.7526235580444336\n",
      "61 tensor([[0.5754],\n",
      "        [0.5493],\n",
      "        [0.5229],\n",
      "        [0.4964]]) 0.7505950927734375\n",
      "62 tensor([[0.5764],\n",
      "        [0.5514],\n",
      "        [0.5261],\n",
      "        [0.5007]]) 0.7486376166343689\n",
      "63 tensor([[0.5774],\n",
      "        [0.5535],\n",
      "        [0.5293],\n",
      "        [0.5050]]) 0.7467482089996338\n",
      "64 tensor([[0.5783],\n",
      "        [0.5555],\n",
      "        [0.5324],\n",
      "        [0.5091]]) 0.7449239492416382\n",
      "65 tensor([[0.5792],\n",
      "        [0.5574],\n",
      "        [0.5354],\n",
      "        [0.5132]]) 0.7431620359420776\n",
      "66 tensor([[0.5801],\n",
      "        [0.5593],\n",
      "        [0.5383],\n",
      "        [0.5172]]) 0.7414602041244507\n",
      "67 tensor([[0.5810],\n",
      "        [0.5612],\n",
      "        [0.5412],\n",
      "        [0.5211]]) 0.7398157715797424\n",
      "68 tensor([[0.5818],\n",
      "        [0.5630],\n",
      "        [0.5441],\n",
      "        [0.5250]]) 0.7382263541221619\n",
      "69 tensor([[0.5827],\n",
      "        [0.5648],\n",
      "        [0.5468],\n",
      "        [0.5287]]) 0.7366896867752075\n",
      "70 tensor([[0.5835],\n",
      "        [0.5666],\n",
      "        [0.5495],\n",
      "        [0.5324]]) 0.7352035641670227\n",
      "71 tensor([[0.5842],\n",
      "        [0.5683],\n",
      "        [0.5522],\n",
      "        [0.5360]]) 0.7337658405303955\n",
      "72 tensor([[0.5850],\n",
      "        [0.5699],\n",
      "        [0.5548],\n",
      "        [0.5395]]) 0.7323744893074036\n",
      "73 tensor([[0.5857],\n",
      "        [0.5716],\n",
      "        [0.5573],\n",
      "        [0.5430]]) 0.7310277223587036\n",
      "74 tensor([[0.5864],\n",
      "        [0.5732],\n",
      "        [0.5598],\n",
      "        [0.5464]]) 0.7297234535217285\n",
      "75 tensor([[0.5871],\n",
      "        [0.5747],\n",
      "        [0.5622],\n",
      "        [0.5497]]) 0.7284600734710693\n",
      "76 tensor([[0.5878],\n",
      "        [0.5762],\n",
      "        [0.5646],\n",
      "        [0.5529]]) 0.7272359132766724\n",
      "77 tensor([[0.5884],\n",
      "        [0.5777],\n",
      "        [0.5669],\n",
      "        [0.5561]]) 0.7260491847991943\n",
      "78 tensor([[0.5891],\n",
      "        [0.5792],\n",
      "        [0.5692],\n",
      "        [0.5592]]) 0.7248984575271606\n",
      "79 tensor([[0.5897],\n",
      "        [0.5806],\n",
      "        [0.5714],\n",
      "        [0.5622]]) 0.7237821221351624\n",
      "80 tensor([[0.5903],\n",
      "        [0.5820],\n",
      "        [0.5736],\n",
      "        [0.5652]]) 0.7226988077163696\n",
      "81 tensor([[0.5908],\n",
      "        [0.5833],\n",
      "        [0.5757],\n",
      "        [0.5681]]) 0.7216471433639526\n",
      "82 tensor([[0.5914],\n",
      "        [0.5846],\n",
      "        [0.5778],\n",
      "        [0.5710]]) 0.7206258177757263\n",
      "83 tensor([[0.5919],\n",
      "        [0.5859],\n",
      "        [0.5798],\n",
      "        [0.5738]]) 0.7196335792541504\n",
      "84 tensor([[0.5925],\n",
      "        [0.5872],\n",
      "        [0.5818],\n",
      "        [0.5765]]) 0.7186691761016846\n",
      "85 tensor([[0.5930],\n",
      "        [0.5884],\n",
      "        [0.5838],\n",
      "        [0.5792]]) 0.7177315354347229\n",
      "86 tensor([[0.5935],\n",
      "        [0.5896],\n",
      "        [0.5857],\n",
      "        [0.5818]]) 0.7168195247650146\n",
      "87 tensor([[0.5939],\n",
      "        [0.5908],\n",
      "        [0.5876],\n",
      "        [0.5844]]) 0.7159320116043091\n",
      "88 tensor([[0.5944],\n",
      "        [0.5919],\n",
      "        [0.5894],\n",
      "        [0.5869]]) 0.715067982673645\n",
      "89 tensor([[0.5949],\n",
      "        [0.5930],\n",
      "        [0.5912],\n",
      "        [0.5893]]) 0.7142266631126404\n",
      "90 tensor([[0.5953],\n",
      "        [0.5941],\n",
      "        [0.5929],\n",
      "        [0.5917]]) 0.7134069204330444\n",
      "91 tensor([[0.5957],\n",
      "        [0.5952],\n",
      "        [0.5946],\n",
      "        [0.5941]]) 0.7126078605651855\n",
      "92 tensor([[0.5961],\n",
      "        [0.5962],\n",
      "        [0.5963],\n",
      "        [0.5964]]) 0.7118288278579712\n",
      "93 tensor([[0.5965],\n",
      "        [0.5972],\n",
      "        [0.5979],\n",
      "        [0.5987]]) 0.711068868637085\n",
      "94 tensor([[0.5969],\n",
      "        [0.5982],\n",
      "        [0.5996],\n",
      "        [0.6009]]) 0.7103271484375\n",
      "95 tensor([[0.5973],\n",
      "        [0.5992],\n",
      "        [0.6011],\n",
      "        [0.6031]]) 0.7096031308174133\n",
      "96 tensor([[0.5976],\n",
      "        [0.6001],\n",
      "        [0.6027],\n",
      "        [0.6052]]) 0.7088958024978638\n",
      "97 tensor([[0.5979],\n",
      "        [0.6011],\n",
      "        [0.6042],\n",
      "        [0.6073]]) 0.7082047462463379\n",
      "98 tensor([[0.5983],\n",
      "        [0.6020],\n",
      "        [0.6056],\n",
      "        [0.6093]]) 0.7075292468070984\n",
      "99 tensor([[0.5986],\n",
      "        [0.6028],\n",
      "        [0.6071],\n",
      "        [0.6113]]) 0.7068685293197632\n",
      "100 tensor([[0.5989],\n",
      "        [0.6037],\n",
      "        [0.6085],\n",
      "        [0.6133]]) 0.7062221765518188\n",
      "101 tensor([[0.5992],\n",
      "        [0.6045],\n",
      "        [0.6099],\n",
      "        [0.6152]]) 0.7055894136428833\n",
      "102 tensor([[0.5995],\n",
      "        [0.6054],\n",
      "        [0.6112],\n",
      "        [0.6170]]) 0.7049698829650879\n",
      "103 tensor([[0.5998],\n",
      "        [0.6062],\n",
      "        [0.6125],\n",
      "        [0.6189]]) 0.7043629884719849\n",
      "104 tensor([[0.6000],\n",
      "        [0.6070],\n",
      "        [0.6138],\n",
      "        [0.6207]]) 0.7037681937217712\n",
      "105 tensor([[0.6003],\n",
      "        [0.6077],\n",
      "        [0.6151],\n",
      "        [0.6225]]) 0.703184962272644\n",
      "106 tensor([[0.6005],\n",
      "        [0.6085],\n",
      "        [0.6164],\n",
      "        [0.6242]]) 0.7026130557060242\n",
      "107 tensor([[0.6007],\n",
      "        [0.6092],\n",
      "        [0.6176],\n",
      "        [0.6259]]) 0.7020518779754639\n",
      "108 tensor([[0.6010],\n",
      "        [0.6099],\n",
      "        [0.6188],\n",
      "        [0.6276]]) 0.7015009522438049\n",
      "109 tensor([[0.6012],\n",
      "        [0.6106],\n",
      "        [0.6199],\n",
      "        [0.6292]]) 0.7009598612785339\n",
      "110 tensor([[0.6014],\n",
      "        [0.6113],\n",
      "        [0.6211],\n",
      "        [0.6308]]) 0.7004283666610718\n",
      "111 tensor([[0.6016],\n",
      "        [0.6119],\n",
      "        [0.6222],\n",
      "        [0.6324]]) 0.6999059915542603\n",
      "112 tensor([[0.6018],\n",
      "        [0.6126],\n",
      "        [0.6233],\n",
      "        [0.6339]]) 0.6993923783302307\n",
      "113 tensor([[0.6019],\n",
      "        [0.6132],\n",
      "        [0.6244],\n",
      "        [0.6354]]) 0.6988872289657593\n",
      "114 tensor([[0.6021],\n",
      "        [0.6138],\n",
      "        [0.6254],\n",
      "        [0.6369]]) 0.6983901262283325\n",
      "115 tensor([[0.6023],\n",
      "        [0.6144],\n",
      "        [0.6265],\n",
      "        [0.6383]]) 0.6979007720947266\n",
      "116 tensor([[0.6024],\n",
      "        [0.6150],\n",
      "        [0.6275],\n",
      "        [0.6397]]) 0.6974190473556519\n",
      "117 tensor([[0.6026],\n",
      "        [0.6156],\n",
      "        [0.6285],\n",
      "        [0.6411]]) 0.6969442963600159\n",
      "118 tensor([[0.6027],\n",
      "        [0.6161],\n",
      "        [0.6294],\n",
      "        [0.6425]]) 0.6964766383171082\n",
      "119 tensor([[0.6028],\n",
      "        [0.6167],\n",
      "        [0.6304],\n",
      "        [0.6438]]) 0.6960155367851257\n",
      "120 tensor([[0.6030],\n",
      "        [0.6172],\n",
      "        [0.6313],\n",
      "        [0.6452]]) 0.695560872554779\n",
      "121 tensor([[0.6031],\n",
      "        [0.6177],\n",
      "        [0.6322],\n",
      "        [0.6464]]) 0.6951123476028442\n",
      "122 tensor([[0.6032],\n",
      "        [0.6183],\n",
      "        [0.6331],\n",
      "        [0.6477]]) 0.6946696639060974\n",
      "123 tensor([[0.6033],\n",
      "        [0.6187],\n",
      "        [0.6340],\n",
      "        [0.6490]]) 0.694232702255249\n",
      "124 tensor([[0.6034],\n",
      "        [0.6192],\n",
      "        [0.6348],\n",
      "        [0.6502]]) 0.6938011646270752\n",
      "125 tensor([[0.6035],\n",
      "        [0.6197],\n",
      "        [0.6357],\n",
      "        [0.6514]]) 0.6933749318122864\n",
      "126 tensor([[0.6035],\n",
      "        [0.6202],\n",
      "        [0.6365],\n",
      "        [0.6525]]) 0.6929538249969482\n",
      "127 tensor([[0.6036],\n",
      "        [0.6206],\n",
      "        [0.6373],\n",
      "        [0.6537]]) 0.6925375461578369\n",
      "128 tensor([[0.6037],\n",
      "        [0.6210],\n",
      "        [0.6381],\n",
      "        [0.6548]]) 0.6921259164810181\n",
      "129 tensor([[0.6037],\n",
      "        [0.6215],\n",
      "        [0.6389],\n",
      "        [0.6559]]) 0.6917188167572021\n",
      "130 tensor([[0.6038],\n",
      "        [0.6219],\n",
      "        [0.6396],\n",
      "        [0.6570]]) 0.6913160085678101\n",
      "131 tensor([[0.6038],\n",
      "        [0.6223],\n",
      "        [0.6404],\n",
      "        [0.6581]]) 0.6909173727035522\n",
      "132 tensor([[0.6039],\n",
      "        [0.6227],\n",
      "        [0.6411],\n",
      "        [0.6591]]) 0.6905229091644287\n",
      "133 tensor([[0.6039],\n",
      "        [0.6231],\n",
      "        [0.6418],\n",
      "        [0.6602]]) 0.6901321411132812\n",
      "134 tensor([[0.6040],\n",
      "        [0.6234],\n",
      "        [0.6425],\n",
      "        [0.6612]]) 0.6897452473640442\n",
      "135 tensor([[0.6040],\n",
      "        [0.6238],\n",
      "        [0.6432],\n",
      "        [0.6622]]) 0.6893618106842041\n",
      "136 tensor([[0.6040],\n",
      "        [0.6242],\n",
      "        [0.6439],\n",
      "        [0.6632]]) 0.6889819502830505\n",
      "137 tensor([[0.6040],\n",
      "        [0.6245],\n",
      "        [0.6446],\n",
      "        [0.6641]]) 0.6886053085327148\n",
      "138 tensor([[0.6040],\n",
      "        [0.6248],\n",
      "        [0.6452],\n",
      "        [0.6651]]) 0.6882320046424866\n",
      "139 tensor([[0.6040],\n",
      "        [0.6252],\n",
      "        [0.6458],\n",
      "        [0.6660]]) 0.6878616809844971\n",
      "140 tensor([[0.6040],\n",
      "        [0.6255],\n",
      "        [0.6465],\n",
      "        [0.6669]]) 0.6874943971633911\n",
      "141 tensor([[0.6040],\n",
      "        [0.6258],\n",
      "        [0.6471],\n",
      "        [0.6678]]) 0.6871299743652344\n",
      "142 tensor([[0.6040],\n",
      "        [0.6261],\n",
      "        [0.6477],\n",
      "        [0.6687]]) 0.6867682933807373\n",
      "143 tensor([[0.6040],\n",
      "        [0.6264],\n",
      "        [0.6483],\n",
      "        [0.6695]]) 0.6864093542098999\n",
      "144 tensor([[0.6040],\n",
      "        [0.6267],\n",
      "        [0.6488],\n",
      "        [0.6704]]) 0.6860530376434326\n",
      "145 tensor([[0.6040],\n",
      "        [0.6270],\n",
      "        [0.6494],\n",
      "        [0.6712]]) 0.6856991052627563\n",
      "146 tensor([[0.6040],\n",
      "        [0.6273],\n",
      "        [0.6500],\n",
      "        [0.6720]]) 0.6853476166725159\n",
      "147 tensor([[0.6039],\n",
      "        [0.6275],\n",
      "        [0.6505],\n",
      "        [0.6728]]) 0.6849984526634216\n",
      "148 tensor([[0.6039],\n",
      "        [0.6278],\n",
      "        [0.6510],\n",
      "        [0.6736]]) 0.6846514940261841\n",
      "149 tensor([[0.6039],\n",
      "        [0.6280],\n",
      "        [0.6516],\n",
      "        [0.6744]]) 0.6843066811561584\n",
      "150 tensor([[0.6038],\n",
      "        [0.6283],\n",
      "        [0.6521],\n",
      "        [0.6752]]) 0.6839639544487\n",
      "151 tensor([[0.6038],\n",
      "        [0.6285],\n",
      "        [0.6526],\n",
      "        [0.6759]]) 0.6836233139038086\n",
      "152 tensor([[0.6037],\n",
      "        [0.6287],\n",
      "        [0.6531],\n",
      "        [0.6766]]) 0.6832845211029053\n",
      "153 tensor([[0.6037],\n",
      "        [0.6290],\n",
      "        [0.6536],\n",
      "        [0.6774]]) 0.6829476356506348\n",
      "154 tensor([[0.6036],\n",
      "        [0.6292],\n",
      "        [0.6540],\n",
      "        [0.6781]]) 0.6826125383377075\n",
      "155 tensor([[0.6035],\n",
      "        [0.6294],\n",
      "        [0.6545],\n",
      "        [0.6788]]) 0.6822792291641235\n",
      "156 tensor([[0.6035],\n",
      "        [0.6296],\n",
      "        [0.6550],\n",
      "        [0.6795]]) 0.6819475293159485\n",
      "157 tensor([[0.6034],\n",
      "        [0.6298],\n",
      "        [0.6554],\n",
      "        [0.6802]]) 0.6816175580024719\n",
      "158 tensor([[0.6033],\n",
      "        [0.6300],\n",
      "        [0.6559],\n",
      "        [0.6808]]) 0.6812891364097595\n",
      "159 tensor([[0.6033],\n",
      "        [0.6302],\n",
      "        [0.6563],\n",
      "        [0.6815]]) 0.6809622645378113\n",
      "160 tensor([[0.6032],\n",
      "        [0.6304],\n",
      "        [0.6567],\n",
      "        [0.6821]]) 0.6806368231773376\n",
      "161 tensor([[0.6031],\n",
      "        [0.6305],\n",
      "        [0.6571],\n",
      "        [0.6828]]) 0.6803128123283386\n",
      "162 tensor([[0.6030],\n",
      "        [0.6307],\n",
      "        [0.6575],\n",
      "        [0.6834]]) 0.6799902319908142\n",
      "163 tensor([[0.6029],\n",
      "        [0.6309],\n",
      "        [0.6579],\n",
      "        [0.6840]]) 0.6796689033508301\n",
      "164 tensor([[0.6029],\n",
      "        [0.6310],\n",
      "        [0.6583],\n",
      "        [0.6846]]) 0.6793489456176758\n",
      "165 tensor([[0.6028],\n",
      "        [0.6312],\n",
      "        [0.6587],\n",
      "        [0.6852]]) 0.6790302395820618\n",
      "166 tensor([[0.6027],\n",
      "        [0.6313],\n",
      "        [0.6591],\n",
      "        [0.6858]]) 0.6787127256393433\n",
      "167 tensor([[0.6026],\n",
      "        [0.6315],\n",
      "        [0.6595],\n",
      "        [0.6864]]) 0.6783963441848755\n",
      "168 tensor([[0.6025],\n",
      "        [0.6316],\n",
      "        [0.6598],\n",
      "        [0.6870]]) 0.678081214427948\n",
      "169 tensor([[0.6024],\n",
      "        [0.6318],\n",
      "        [0.6602],\n",
      "        [0.6875]]) 0.6777670979499817\n",
      "170 tensor([[0.6023],\n",
      "        [0.6319],\n",
      "        [0.6606],\n",
      "        [0.6881]]) 0.6774540543556213\n",
      "171 tensor([[0.6021],\n",
      "        [0.6320],\n",
      "        [0.6609],\n",
      "        [0.6886]]) 0.6771420240402222\n",
      "172 tensor([[0.6020],\n",
      "        [0.6321],\n",
      "        [0.6612],\n",
      "        [0.6892]]) 0.6768310070037842\n",
      "173 tensor([[0.6019],\n",
      "        [0.6322],\n",
      "        [0.6616],\n",
      "        [0.6897]]) 0.6765210032463074\n",
      "174 tensor([[0.6018],\n",
      "        [0.6324],\n",
      "        [0.6619],\n",
      "        [0.6902]]) 0.6762118935585022\n",
      "175 tensor([[0.6017],\n",
      "        [0.6325],\n",
      "        [0.6622],\n",
      "        [0.6907]]) 0.6759037971496582\n",
      "176 tensor([[0.6016],\n",
      "        [0.6326],\n",
      "        [0.6625],\n",
      "        [0.6912]]) 0.6755965948104858\n",
      "177 tensor([[0.6014],\n",
      "        [0.6327],\n",
      "        [0.6628],\n",
      "        [0.6917]]) 0.6752901077270508\n",
      "178 tensor([[0.6013],\n",
      "        [0.6328],\n",
      "        [0.6631],\n",
      "        [0.6922]]) 0.6749845147132874\n",
      "179 tensor([[0.6012],\n",
      "        [0.6329],\n",
      "        [0.6634],\n",
      "        [0.6927]]) 0.6746797561645508\n",
      "180 tensor([[0.6010],\n",
      "        [0.6330],\n",
      "        [0.6637],\n",
      "        [0.6932]]) 0.6743758320808411\n",
      "181 tensor([[0.6009],\n",
      "        [0.6330],\n",
      "        [0.6640],\n",
      "        [0.6937]]) 0.6740726828575134\n",
      "182 tensor([[0.6008],\n",
      "        [0.6331],\n",
      "        [0.6643],\n",
      "        [0.6941]]) 0.6737701892852783\n",
      "183 tensor([[0.6006],\n",
      "        [0.6332],\n",
      "        [0.6646],\n",
      "        [0.6946]]) 0.6734685301780701\n",
      "184 tensor([[0.6005],\n",
      "        [0.6333],\n",
      "        [0.6649],\n",
      "        [0.6950]]) 0.6731675863265991\n",
      "185 tensor([[0.6004],\n",
      "        [0.6333],\n",
      "        [0.6651],\n",
      "        [0.6955]]) 0.6728671789169312\n",
      "186 tensor([[0.6002],\n",
      "        [0.6334],\n",
      "        [0.6654],\n",
      "        [0.6959]]) 0.6725675463676453\n",
      "187 tensor([[0.6001],\n",
      "        [0.6335],\n",
      "        [0.6657],\n",
      "        [0.6964]]) 0.6722685098648071\n",
      "188 tensor([[0.5999],\n",
      "        [0.6335],\n",
      "        [0.6659],\n",
      "        [0.6968]]) 0.6719701886177063\n",
      "189 tensor([[0.5998],\n",
      "        [0.6336],\n",
      "        [0.6662],\n",
      "        [0.6972]]) 0.6716724038124084\n",
      "190 tensor([[0.5996],\n",
      "        [0.6337],\n",
      "        [0.6664],\n",
      "        [0.6976]]) 0.6713752746582031\n",
      "191 tensor([[0.5995],\n",
      "        [0.6337],\n",
      "        [0.6666],\n",
      "        [0.6980]]) 0.6710787415504456\n",
      "192 tensor([[0.5993],\n",
      "        [0.6338],\n",
      "        [0.6669],\n",
      "        [0.6984]]) 0.6707828044891357\n",
      "193 tensor([[0.5992],\n",
      "        [0.6338],\n",
      "        [0.6671],\n",
      "        [0.6988]]) 0.6704874038696289\n",
      "194 tensor([[0.5990],\n",
      "        [0.6338],\n",
      "        [0.6673],\n",
      "        [0.6992]]) 0.670192539691925\n",
      "195 tensor([[0.5988],\n",
      "        [0.6339],\n",
      "        [0.6676],\n",
      "        [0.6996]]) 0.669898271560669\n",
      "196 tensor([[0.5987],\n",
      "        [0.6339],\n",
      "        [0.6678],\n",
      "        [0.7000]]) 0.6696044206619263\n",
      "197 tensor([[0.5985],\n",
      "        [0.6340],\n",
      "        [0.6680],\n",
      "        [0.7004]]) 0.6693111658096313\n",
      "198 tensor([[0.5984],\n",
      "        [0.6340],\n",
      "        [0.6682],\n",
      "        [0.7007]]) 0.6690182685852051\n",
      "199 tensor([[0.5982],\n",
      "        [0.6340],\n",
      "        [0.6684],\n",
      "        [0.7011]]) 0.6687259674072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 tensor([[0.5980],\n",
      "        [0.6340],\n",
      "        [0.6686],\n",
      "        [0.7015]]) 0.668434202671051\n",
      "201 tensor([[0.5979],\n",
      "        [0.6341],\n",
      "        [0.6688],\n",
      "        [0.7018]]) 0.6681428551673889\n",
      "202 tensor([[0.5977],\n",
      "        [0.6341],\n",
      "        [0.6690],\n",
      "        [0.7022]]) 0.6678519248962402\n",
      "203 tensor([[0.5975],\n",
      "        [0.6341],\n",
      "        [0.6692],\n",
      "        [0.7025]]) 0.6675614714622498\n",
      "204 tensor([[0.5973],\n",
      "        [0.6341],\n",
      "        [0.6694],\n",
      "        [0.7029]]) 0.6672713756561279\n",
      "205 tensor([[0.5972],\n",
      "        [0.6341],\n",
      "        [0.6696],\n",
      "        [0.7032]]) 0.6669818162918091\n",
      "206 tensor([[0.5970],\n",
      "        [0.6342],\n",
      "        [0.6698],\n",
      "        [0.7036]]) 0.6666926741600037\n",
      "207 tensor([[0.5968],\n",
      "        [0.6342],\n",
      "        [0.6700],\n",
      "        [0.7039]]) 0.6664038300514221\n",
      "208 tensor([[0.5966],\n",
      "        [0.6342],\n",
      "        [0.6701],\n",
      "        [0.7042]]) 0.6661155223846436\n",
      "209 tensor([[0.5965],\n",
      "        [0.6342],\n",
      "        [0.6703],\n",
      "        [0.7045]]) 0.6658275127410889\n",
      "210 tensor([[0.5963],\n",
      "        [0.6342],\n",
      "        [0.6705],\n",
      "        [0.7049]]) 0.6655399799346924\n",
      "211 tensor([[0.5961],\n",
      "        [0.6342],\n",
      "        [0.6707],\n",
      "        [0.7052]]) 0.6652527451515198\n",
      "212 tensor([[0.5959],\n",
      "        [0.6342],\n",
      "        [0.6708],\n",
      "        [0.7055]]) 0.6649659276008606\n",
      "213 tensor([[0.5957],\n",
      "        [0.6342],\n",
      "        [0.6710],\n",
      "        [0.7058]]) 0.6646794676780701\n",
      "214 tensor([[0.5956],\n",
      "        [0.6342],\n",
      "        [0.6712],\n",
      "        [0.7061]]) 0.6643933057785034\n",
      "215 tensor([[0.5954],\n",
      "        [0.6342],\n",
      "        [0.6713],\n",
      "        [0.7064]]) 0.664107620716095\n",
      "216 tensor([[0.5952],\n",
      "        [0.6342],\n",
      "        [0.6715],\n",
      "        [0.7067]]) 0.6638221144676208\n",
      "217 tensor([[0.5950],\n",
      "        [0.6342],\n",
      "        [0.6716],\n",
      "        [0.7070]]) 0.6635370254516602\n",
      "218 tensor([[0.5948],\n",
      "        [0.6341],\n",
      "        [0.6718],\n",
      "        [0.7073]]) 0.6632523536682129\n",
      "219 tensor([[0.5946],\n",
      "        [0.6341],\n",
      "        [0.6719],\n",
      "        [0.7076]]) 0.6629679799079895\n",
      "220 tensor([[0.5944],\n",
      "        [0.6341],\n",
      "        [0.6721],\n",
      "        [0.7079]]) 0.66268390417099\n",
      "221 tensor([[0.5942],\n",
      "        [0.6341],\n",
      "        [0.6722],\n",
      "        [0.7082]]) 0.6624001264572144\n",
      "222 tensor([[0.5940],\n",
      "        [0.6341],\n",
      "        [0.6723],\n",
      "        [0.7085]]) 0.6621166467666626\n",
      "223 tensor([[0.5938],\n",
      "        [0.6341],\n",
      "        [0.6725],\n",
      "        [0.7087]]) 0.6618335247039795\n",
      "224 tensor([[0.5936],\n",
      "        [0.6340],\n",
      "        [0.6726],\n",
      "        [0.7090]]) 0.6615508198738098\n",
      "225 tensor([[0.5935],\n",
      "        [0.6340],\n",
      "        [0.6728],\n",
      "        [0.7093]]) 0.6612682342529297\n",
      "226 tensor([[0.5933],\n",
      "        [0.6340],\n",
      "        [0.6729],\n",
      "        [0.7096]]) 0.660986065864563\n",
      "227 tensor([[0.5931],\n",
      "        [0.6340],\n",
      "        [0.6730],\n",
      "        [0.7098]]) 0.6607041954994202\n",
      "228 tensor([[0.5929],\n",
      "        [0.6339],\n",
      "        [0.6731],\n",
      "        [0.7101]]) 0.6604224443435669\n",
      "229 tensor([[0.5927],\n",
      "        [0.6339],\n",
      "        [0.6733],\n",
      "        [0.7103]]) 0.6601411700248718\n",
      "230 tensor([[0.5925],\n",
      "        [0.6339],\n",
      "        [0.6734],\n",
      "        [0.7106]]) 0.6598601937294006\n",
      "231 tensor([[0.5923],\n",
      "        [0.6338],\n",
      "        [0.6735],\n",
      "        [0.7109]]) 0.659579336643219\n",
      "232 tensor([[0.5921],\n",
      "        [0.6338],\n",
      "        [0.6736],\n",
      "        [0.7111]]) 0.6592989563941956\n",
      "233 tensor([[0.5919],\n",
      "        [0.6338],\n",
      "        [0.6738],\n",
      "        [0.7114]]) 0.6590186953544617\n",
      "234 tensor([[0.5916],\n",
      "        [0.6337],\n",
      "        [0.6739],\n",
      "        [0.7116]]) 0.6587387323379517\n",
      "235 tensor([[0.5914],\n",
      "        [0.6337],\n",
      "        [0.6740],\n",
      "        [0.7119]]) 0.6584590673446655\n",
      "236 tensor([[0.5912],\n",
      "        [0.6337],\n",
      "        [0.6741],\n",
      "        [0.7121]]) 0.6581795811653137\n",
      "237 tensor([[0.5910],\n",
      "        [0.6336],\n",
      "        [0.6742],\n",
      "        [0.7123]]) 0.6579005718231201\n",
      "238 tensor([[0.5908],\n",
      "        [0.6336],\n",
      "        [0.6743],\n",
      "        [0.7126]]) 0.6576216220855713\n",
      "239 tensor([[0.5906],\n",
      "        [0.6335],\n",
      "        [0.6744],\n",
      "        [0.7128]]) 0.6573429107666016\n",
      "240 tensor([[0.5904],\n",
      "        [0.6335],\n",
      "        [0.6745],\n",
      "        [0.7131]]) 0.65706467628479\n",
      "241 tensor([[0.5902],\n",
      "        [0.6334],\n",
      "        [0.6746],\n",
      "        [0.7133]]) 0.6567865014076233\n",
      "242 tensor([[0.5900],\n",
      "        [0.6334],\n",
      "        [0.6747],\n",
      "        [0.7135]]) 0.6565086245536804\n",
      "243 tensor([[0.5898],\n",
      "        [0.6333],\n",
      "        [0.6748],\n",
      "        [0.7138]]) 0.6562310457229614\n",
      "244 tensor([[0.5896],\n",
      "        [0.6333],\n",
      "        [0.6749],\n",
      "        [0.7140]]) 0.6559536457061768\n",
      "245 tensor([[0.5894],\n",
      "        [0.6333],\n",
      "        [0.6750],\n",
      "        [0.7142]]) 0.655676543712616\n",
      "246 tensor([[0.5892],\n",
      "        [0.6332],\n",
      "        [0.6751],\n",
      "        [0.7144]]) 0.6553996205329895\n",
      "247 tensor([[0.5889],\n",
      "        [0.6331],\n",
      "        [0.6752],\n",
      "        [0.7146]]) 0.6551229953765869\n",
      "248 tensor([[0.5887],\n",
      "        [0.6331],\n",
      "        [0.6753],\n",
      "        [0.7149]]) 0.6548465490341187\n",
      "249 tensor([[0.5885],\n",
      "        [0.6330],\n",
      "        [0.6754],\n",
      "        [0.7151]]) 0.6545703411102295\n",
      "250 tensor([[0.5883],\n",
      "        [0.6330],\n",
      "        [0.6755],\n",
      "        [0.7153]]) 0.6542944312095642\n",
      "251 tensor([[0.5881],\n",
      "        [0.6329],\n",
      "        [0.6756],\n",
      "        [0.7155]]) 0.654018759727478\n",
      "252 tensor([[0.5879],\n",
      "        [0.6329],\n",
      "        [0.6757],\n",
      "        [0.7157]]) 0.6537432074546814\n",
      "253 tensor([[0.5877],\n",
      "        [0.6328],\n",
      "        [0.6758],\n",
      "        [0.7159]]) 0.6534680128097534\n",
      "254 tensor([[0.5874],\n",
      "        [0.6328],\n",
      "        [0.6758],\n",
      "        [0.7161]]) 0.6531929969787598\n",
      "255 tensor([[0.5872],\n",
      "        [0.6327],\n",
      "        [0.6759],\n",
      "        [0.7164]]) 0.6529181599617004\n",
      "256 tensor([[0.5870],\n",
      "        [0.6326],\n",
      "        [0.6760],\n",
      "        [0.7166]]) 0.652643620967865\n",
      "257 tensor([[0.5868],\n",
      "        [0.6326],\n",
      "        [0.6761],\n",
      "        [0.7168]]) 0.6523693203926086\n",
      "258 tensor([[0.5866],\n",
      "        [0.6325],\n",
      "        [0.6762],\n",
      "        [0.7170]]) 0.6520951390266418\n",
      "259 tensor([[0.5864],\n",
      "        [0.6325],\n",
      "        [0.6763],\n",
      "        [0.7172]]) 0.6518211960792542\n",
      "260 tensor([[0.5861],\n",
      "        [0.6324],\n",
      "        [0.6763],\n",
      "        [0.7174]]) 0.6515476107597351\n",
      "261 tensor([[0.5859],\n",
      "        [0.6323],\n",
      "        [0.6764],\n",
      "        [0.7176]]) 0.6512740850448608\n",
      "262 tensor([[0.5857],\n",
      "        [0.6323],\n",
      "        [0.6765],\n",
      "        [0.7178]]) 0.6510008573532104\n",
      "263 tensor([[0.5855],\n",
      "        [0.6322],\n",
      "        [0.6766],\n",
      "        [0.7180]]) 0.6507278680801392\n",
      "264 tensor([[0.5853],\n",
      "        [0.6321],\n",
      "        [0.6766],\n",
      "        [0.7181]]) 0.6504549384117126\n",
      "265 tensor([[0.5850],\n",
      "        [0.6321],\n",
      "        [0.6767],\n",
      "        [0.7183]]) 0.6501823663711548\n",
      "266 tensor([[0.5848],\n",
      "        [0.6320],\n",
      "        [0.6768],\n",
      "        [0.7185]]) 0.649910032749176\n",
      "267 tensor([[0.5846],\n",
      "        [0.6319],\n",
      "        [0.6768],\n",
      "        [0.7187]]) 0.6496378183364868\n",
      "268 tensor([[0.5844],\n",
      "        [0.6319],\n",
      "        [0.6769],\n",
      "        [0.7189]]) 0.6493659019470215\n",
      "269 tensor([[0.5841],\n",
      "        [0.6318],\n",
      "        [0.6770],\n",
      "        [0.7191]]) 0.6490941047668457\n",
      "270 tensor([[0.5839],\n",
      "        [0.6317],\n",
      "        [0.6770],\n",
      "        [0.7193]]) 0.648822546005249\n",
      "271 tensor([[0.5837],\n",
      "        [0.6316],\n",
      "        [0.6771],\n",
      "        [0.7195]]) 0.6485512256622314\n",
      "272 tensor([[0.5835],\n",
      "        [0.6316],\n",
      "        [0.6772],\n",
      "        [0.7196]]) 0.6482800245285034\n",
      "273 tensor([[0.5833],\n",
      "        [0.6315],\n",
      "        [0.6772],\n",
      "        [0.7198]]) 0.648009181022644\n",
      "274 tensor([[0.5830],\n",
      "        [0.6314],\n",
      "        [0.6773],\n",
      "        [0.7200]]) 0.6477384567260742\n",
      "275 tensor([[0.5828],\n",
      "        [0.6313],\n",
      "        [0.6774],\n",
      "        [0.7202]]) 0.6474679708480835\n",
      "276 tensor([[0.5826],\n",
      "        [0.6313],\n",
      "        [0.6774],\n",
      "        [0.7204]]) 0.6471976041793823\n",
      "277 tensor([[0.5824],\n",
      "        [0.6312],\n",
      "        [0.6775],\n",
      "        [0.7205]]) 0.6469274759292603\n",
      "278 tensor([[0.5821],\n",
      "        [0.6311],\n",
      "        [0.6776],\n",
      "        [0.7207]]) 0.6466575860977173\n",
      "279 tensor([[0.5819],\n",
      "        [0.6310],\n",
      "        [0.6776],\n",
      "        [0.7209]]) 0.6463879346847534\n",
      "280 tensor([[0.5817],\n",
      "        [0.6310],\n",
      "        [0.6777],\n",
      "        [0.7211]]) 0.6461184024810791\n",
      "281 tensor([[0.5814],\n",
      "        [0.6309],\n",
      "        [0.6777],\n",
      "        [0.7212]]) 0.6458491683006287\n",
      "282 tensor([[0.5812],\n",
      "        [0.6308],\n",
      "        [0.6778],\n",
      "        [0.7214]]) 0.6455800533294678\n",
      "283 tensor([[0.5810],\n",
      "        [0.6307],\n",
      "        [0.6778],\n",
      "        [0.7216]]) 0.6453111171722412\n",
      "284 tensor([[0.5808],\n",
      "        [0.6307],\n",
      "        [0.6779],\n",
      "        [0.7218]]) 0.6450424790382385\n",
      "285 tensor([[0.5805],\n",
      "        [0.6306],\n",
      "        [0.6780],\n",
      "        [0.7219]]) 0.6447739601135254\n",
      "286 tensor([[0.5803],\n",
      "        [0.6305],\n",
      "        [0.6780],\n",
      "        [0.7221]]) 0.6445056200027466\n",
      "287 tensor([[0.5801],\n",
      "        [0.6304],\n",
      "        [0.6781],\n",
      "        [0.7223]]) 0.6442375183105469\n",
      "288 tensor([[0.5799],\n",
      "        [0.6303],\n",
      "        [0.6781],\n",
      "        [0.7224]]) 0.6439696550369263\n",
      "289 tensor([[0.5796],\n",
      "        [0.6303],\n",
      "        [0.6782],\n",
      "        [0.7226]]) 0.64370197057724\n",
      "290 tensor([[0.5794],\n",
      "        [0.6302],\n",
      "        [0.6782],\n",
      "        [0.7228]]) 0.643434464931488\n",
      "291 tensor([[0.5792],\n",
      "        [0.6301],\n",
      "        [0.6783],\n",
      "        [0.7229]]) 0.6431671380996704\n",
      "292 tensor([[0.5789],\n",
      "        [0.6300],\n",
      "        [0.6783],\n",
      "        [0.7231]]) 0.6428999900817871\n",
      "293 tensor([[0.5787],\n",
      "        [0.6299],\n",
      "        [0.6784],\n",
      "        [0.7233]]) 0.6426330208778381\n",
      "294 tensor([[0.5785],\n",
      "        [0.6298],\n",
      "        [0.6784],\n",
      "        [0.7234]]) 0.642366349697113\n",
      "295 tensor([[0.5782],\n",
      "        [0.6298],\n",
      "        [0.6785],\n",
      "        [0.7236]]) 0.6420997381210327\n",
      "296 tensor([[0.5780],\n",
      "        [0.6297],\n",
      "        [0.6785],\n",
      "        [0.7237]]) 0.6418333649635315\n",
      "297 tensor([[0.5778],\n",
      "        [0.6296],\n",
      "        [0.6786],\n",
      "        [0.7239]]) 0.6415672898292542\n",
      "298 tensor([[0.5776],\n",
      "        [0.6295],\n",
      "        [0.6786],\n",
      "        [0.7241]]) 0.6413012742996216\n",
      "299 tensor([[0.5773],\n",
      "        [0.6294],\n",
      "        [0.6787],\n",
      "        [0.7242]]) 0.6410354971885681\n",
      "300 tensor([[0.5771],\n",
      "        [0.6293],\n",
      "        [0.6787],\n",
      "        [0.7244]]) 0.6407699584960938\n",
      "301 tensor([[0.5769],\n",
      "        [0.6292],\n",
      "        [0.6787],\n",
      "        [0.7245]]) 0.6405045390129089\n",
      "302 tensor([[0.5766],\n",
      "        [0.6292],\n",
      "        [0.6788],\n",
      "        [0.7247]]) 0.640239417552948\n",
      "303 tensor([[0.5764],\n",
      "        [0.6291],\n",
      "        [0.6788],\n",
      "        [0.7248]]) 0.6399743556976318\n",
      "304 tensor([[0.5762],\n",
      "        [0.6290],\n",
      "        [0.6789],\n",
      "        [0.7250]]) 0.6397095918655396\n",
      "305 tensor([[0.5759],\n",
      "        [0.6289],\n",
      "        [0.6789],\n",
      "        [0.7251]]) 0.6394450068473816\n",
      "306 tensor([[0.5757],\n",
      "        [0.6288],\n",
      "        [0.6790],\n",
      "        [0.7253]]) 0.6391805410385132\n",
      "307 tensor([[0.5755],\n",
      "        [0.6287],\n",
      "        [0.6790],\n",
      "        [0.7254]]) 0.6389162540435791\n",
      "308 tensor([[0.5752],\n",
      "        [0.6286],\n",
      "        [0.6790],\n",
      "        [0.7256]]) 0.6386522054672241\n",
      "309 tensor([[0.5750],\n",
      "        [0.6285],\n",
      "        [0.6791],\n",
      "        [0.7258]]) 0.6383883953094482\n",
      "310 tensor([[0.5748],\n",
      "        [0.6284],\n",
      "        [0.6791],\n",
      "        [0.7259]]) 0.6381246447563171\n",
      "311 tensor([[0.5745],\n",
      "        [0.6284],\n",
      "        [0.6792],\n",
      "        [0.7261]]) 0.6378611922264099\n",
      "312 tensor([[0.5743],\n",
      "        [0.6283],\n",
      "        [0.6792],\n",
      "        [0.7262]]) 0.6375978589057922\n",
      "313 tensor([[0.5741],\n",
      "        [0.6282],\n",
      "        [0.6792],\n",
      "        [0.7264]]) 0.6373347640037537\n",
      "314 tensor([[0.5738],\n",
      "        [0.6281],\n",
      "        [0.6793],\n",
      "        [0.7265]]) 0.6370718479156494\n",
      "315 tensor([[0.5736],\n",
      "        [0.6280],\n",
      "        [0.6793],\n",
      "        [0.7266]]) 0.6368091106414795\n",
      "316 tensor([[0.5734],\n",
      "        [0.6279],\n",
      "        [0.6794],\n",
      "        [0.7268]]) 0.6365465521812439\n",
      "317 tensor([[0.5731],\n",
      "        [0.6278],\n",
      "        [0.6794],\n",
      "        [0.7269]]) 0.6362841725349426\n",
      "318 tensor([[0.5729],\n",
      "        [0.6277],\n",
      "        [0.6794],\n",
      "        [0.7271]]) 0.6360220313072205\n",
      "319 tensor([[0.5727],\n",
      "        [0.6276],\n",
      "        [0.6795],\n",
      "        [0.7272]]) 0.6357600688934326\n",
      "320 tensor([[0.5724],\n",
      "        [0.6275],\n",
      "        [0.6795],\n",
      "        [0.7274]]) 0.6354982852935791\n",
      "321 tensor([[0.5722],\n",
      "        [0.6274],\n",
      "        [0.6795],\n",
      "        [0.7275]]) 0.6352366209030151\n",
      "322 tensor([[0.5720],\n",
      "        [0.6274],\n",
      "        [0.6796],\n",
      "        [0.7277]]) 0.6349751949310303\n",
      "323 tensor([[0.5717],\n",
      "        [0.6273],\n",
      "        [0.6796],\n",
      "        [0.7278]]) 0.6347139477729797\n",
      "324 tensor([[0.5715],\n",
      "        [0.6272],\n",
      "        [0.6796],\n",
      "        [0.7279]]) 0.6344528198242188\n",
      "325 tensor([[0.5713],\n",
      "        [0.6271],\n",
      "        [0.6797],\n",
      "        [0.7281]]) 0.6341919898986816\n",
      "326 tensor([[0.5710],\n",
      "        [0.6270],\n",
      "        [0.6797],\n",
      "        [0.7282]]) 0.6339312791824341\n",
      "327 tensor([[0.5708],\n",
      "        [0.6269],\n",
      "        [0.6798],\n",
      "        [0.7284]]) 0.6336708068847656\n",
      "328 tensor([[0.5706],\n",
      "        [0.6268],\n",
      "        [0.6798],\n",
      "        [0.7285]]) 0.6334103941917419\n",
      "329 tensor([[0.5703],\n",
      "        [0.6267],\n",
      "        [0.6798],\n",
      "        [0.7287]]) 0.6331502795219421\n",
      "330 tensor([[0.5701],\n",
      "        [0.6266],\n",
      "        [0.6799],\n",
      "        [0.7288]]) 0.6328903436660767\n",
      "331 tensor([[0.5699],\n",
      "        [0.6265],\n",
      "        [0.6799],\n",
      "        [0.7289]]) 0.6326305270195007\n",
      "332 tensor([[0.5696],\n",
      "        [0.6264],\n",
      "        [0.6799],\n",
      "        [0.7291]]) 0.6323710083961487\n",
      "333 tensor([[0.5694],\n",
      "        [0.6263],\n",
      "        [0.6800],\n",
      "        [0.7292]]) 0.6321115493774414\n",
      "334 tensor([[0.5692],\n",
      "        [0.6262],\n",
      "        [0.6800],\n",
      "        [0.7294]]) 0.6318523287773132\n",
      "335 tensor([[0.5689],\n",
      "        [0.6261],\n",
      "        [0.6800],\n",
      "        [0.7295]]) 0.6315932869911194\n",
      "336 tensor([[0.5687],\n",
      "        [0.6260],\n",
      "        [0.6800],\n",
      "        [0.7296]]) 0.6313344836235046\n",
      "337 tensor([[0.5685],\n",
      "        [0.6259],\n",
      "        [0.6801],\n",
      "        [0.7298]]) 0.6310757994651794\n",
      "338 tensor([[0.5682],\n",
      "        [0.6258],\n",
      "        [0.6801],\n",
      "        [0.7299]]) 0.6308172941207886\n",
      "339 tensor([[0.5680],\n",
      "        [0.6257],\n",
      "        [0.6801],\n",
      "        [0.7300]]) 0.630558967590332\n",
      "340 tensor([[0.5677],\n",
      "        [0.6257],\n",
      "        [0.6802],\n",
      "        [0.7302]]) 0.630300760269165\n",
      "341 tensor([[0.5675],\n",
      "        [0.6256],\n",
      "        [0.6802],\n",
      "        [0.7303]]) 0.6300429105758667\n",
      "342 tensor([[0.5673],\n",
      "        [0.6255],\n",
      "        [0.6802],\n",
      "        [0.7304]]) 0.6297850608825684\n",
      "343 tensor([[0.5670],\n",
      "        [0.6254],\n",
      "        [0.6803],\n",
      "        [0.7306]]) 0.6295275092124939\n",
      "344 tensor([[0.5668],\n",
      "        [0.6253],\n",
      "        [0.6803],\n",
      "        [0.7307]]) 0.629270076751709\n",
      "345 tensor([[0.5666],\n",
      "        [0.6252],\n",
      "        [0.6803],\n",
      "        [0.7308]]) 0.6290128827095032\n",
      "346 tensor([[0.5663],\n",
      "        [0.6251],\n",
      "        [0.6803],\n",
      "        [0.7310]]) 0.6287558674812317\n",
      "347 tensor([[0.5661],\n",
      "        [0.6250],\n",
      "        [0.6804],\n",
      "        [0.7311]]) 0.6284989714622498\n",
      "348 tensor([[0.5659],\n",
      "        [0.6249],\n",
      "        [0.6804],\n",
      "        [0.7312]]) 0.6282422542572021\n",
      "349 tensor([[0.5656],\n",
      "        [0.6248],\n",
      "        [0.6804],\n",
      "        [0.7314]]) 0.6279857754707336\n",
      "350 tensor([[0.5654],\n",
      "        [0.6247],\n",
      "        [0.6805],\n",
      "        [0.7315]]) 0.6277294754981995\n",
      "351 tensor([[0.5652],\n",
      "        [0.6246],\n",
      "        [0.6805],\n",
      "        [0.7316]]) 0.6274733543395996\n",
      "352 tensor([[0.5649],\n",
      "        [0.6245],\n",
      "        [0.6805],\n",
      "        [0.7318]]) 0.6272174119949341\n",
      "353 tensor([[0.5647],\n",
      "        [0.6244],\n",
      "        [0.6805],\n",
      "        [0.7319]]) 0.6269615292549133\n",
      "354 tensor([[0.5644],\n",
      "        [0.6243],\n",
      "        [0.6806],\n",
      "        [0.7320]]) 0.6267059445381165\n",
      "355 tensor([[0.5642],\n",
      "        [0.6242],\n",
      "        [0.6806],\n",
      "        [0.7322]]) 0.6264505386352539\n",
      "356 tensor([[0.5640],\n",
      "        [0.6241],\n",
      "        [0.6806],\n",
      "        [0.7323]]) 0.6261952519416809\n",
      "357 tensor([[0.5637],\n",
      "        [0.6240],\n",
      "        [0.6807],\n",
      "        [0.7324]]) 0.625940203666687\n",
      "358 tensor([[0.5635],\n",
      "        [0.6239],\n",
      "        [0.6807],\n",
      "        [0.7326]]) 0.6256852746009827\n",
      "359 tensor([[0.5633],\n",
      "        [0.6238],\n",
      "        [0.6807],\n",
      "        [0.7327]]) 0.6254306435585022\n",
      "360 tensor([[0.5630],\n",
      "        [0.6237],\n",
      "        [0.6807],\n",
      "        [0.7328]]) 0.6251761317253113\n",
      "361 tensor([[0.5628],\n",
      "        [0.6236],\n",
      "        [0.6808],\n",
      "        [0.7329]]) 0.6249217391014099\n",
      "362 tensor([[0.5626],\n",
      "        [0.6235],\n",
      "        [0.6808],\n",
      "        [0.7331]]) 0.6246675252914429\n",
      "363 tensor([[0.5623],\n",
      "        [0.6234],\n",
      "        [0.6808],\n",
      "        [0.7332]]) 0.6244135499000549\n",
      "364 tensor([[0.5621],\n",
      "        [0.6233],\n",
      "        [0.6808],\n",
      "        [0.7333]]) 0.6241597533226013\n",
      "365 tensor([[0.5618],\n",
      "        [0.6232],\n",
      "        [0.6809],\n",
      "        [0.7335]]) 0.623906135559082\n",
      "366 tensor([[0.5616],\n",
      "        [0.6231],\n",
      "        [0.6809],\n",
      "        [0.7336]]) 0.6236526370048523\n",
      "367 tensor([[0.5614],\n",
      "        [0.6230],\n",
      "        [0.6809],\n",
      "        [0.7337]]) 0.6233994364738464\n",
      "368 tensor([[0.5611],\n",
      "        [0.6229],\n",
      "        [0.6809],\n",
      "        [0.7338]]) 0.6231462955474854\n",
      "369 tensor([[0.5609],\n",
      "        [0.6228],\n",
      "        [0.6810],\n",
      "        [0.7340]]) 0.6228933334350586\n",
      "370 tensor([[0.5607],\n",
      "        [0.6227],\n",
      "        [0.6810],\n",
      "        [0.7341]]) 0.6226405501365662\n",
      "371 tensor([[0.5604],\n",
      "        [0.6226],\n",
      "        [0.6810],\n",
      "        [0.7342]]) 0.6223879456520081\n",
      "372 tensor([[0.5602],\n",
      "        [0.6225],\n",
      "        [0.6810],\n",
      "        [0.7344]]) 0.6221356391906738\n",
      "373 tensor([[0.5600],\n",
      "        [0.6224],\n",
      "        [0.6811],\n",
      "        [0.7345]]) 0.6218833923339844\n",
      "374 tensor([[0.5597],\n",
      "        [0.6223],\n",
      "        [0.6811],\n",
      "        [0.7346]]) 0.6216312646865845\n",
      "375 tensor([[0.5595],\n",
      "        [0.6222],\n",
      "        [0.6811],\n",
      "        [0.7347]]) 0.6213794350624084\n",
      "376 tensor([[0.5592],\n",
      "        [0.6221],\n",
      "        [0.6811],\n",
      "        [0.7349]]) 0.6211277842521667\n",
      "377 tensor([[0.5590],\n",
      "        [0.6220],\n",
      "        [0.6812],\n",
      "        [0.7350]]) 0.6208763122558594\n",
      "378 tensor([[0.5588],\n",
      "        [0.6219],\n",
      "        [0.6812],\n",
      "        [0.7351]]) 0.620624840259552\n",
      "379 tensor([[0.5585],\n",
      "        [0.6218],\n",
      "        [0.6812],\n",
      "        [0.7352]]) 0.6203737258911133\n",
      "380 tensor([[0.5583],\n",
      "        [0.6217],\n",
      "        [0.6812],\n",
      "        [0.7354]]) 0.6201228499412537\n",
      "381 tensor([[0.5581],\n",
      "        [0.6216],\n",
      "        [0.6812],\n",
      "        [0.7355]]) 0.6198720335960388\n",
      "382 tensor([[0.5578],\n",
      "        [0.6215],\n",
      "        [0.6813],\n",
      "        [0.7356]]) 0.6196213364601135\n",
      "383 tensor([[0.5576],\n",
      "        [0.6214],\n",
      "        [0.6813],\n",
      "        [0.7357]]) 0.6193709373474121\n",
      "384 tensor([[0.5574],\n",
      "        [0.6213],\n",
      "        [0.6813],\n",
      "        [0.7359]]) 0.6191205978393555\n",
      "385 tensor([[0.5571],\n",
      "        [0.6212],\n",
      "        [0.6813],\n",
      "        [0.7360]]) 0.6188705563545227\n",
      "386 tensor([[0.5569],\n",
      "        [0.6211],\n",
      "        [0.6814],\n",
      "        [0.7361]]) 0.6186205148696899\n",
      "387 tensor([[0.5566],\n",
      "        [0.6210],\n",
      "        [0.6814],\n",
      "        [0.7362]]) 0.618370771408081\n",
      "388 tensor([[0.5564],\n",
      "        [0.6209],\n",
      "        [0.6814],\n",
      "        [0.7363]]) 0.6181212067604065\n",
      "389 tensor([[0.5562],\n",
      "        [0.6208],\n",
      "        [0.6814],\n",
      "        [0.7365]]) 0.617871880531311\n",
      "390 tensor([[0.5559],\n",
      "        [0.6207],\n",
      "        [0.6815],\n",
      "        [0.7366]]) 0.6176224946975708\n",
      "391 tensor([[0.5557],\n",
      "        [0.6206],\n",
      "        [0.6815],\n",
      "        [0.7367]]) 0.617373526096344\n",
      "392 tensor([[0.5555],\n",
      "        [0.6205],\n",
      "        [0.6815],\n",
      "        [0.7368]]) 0.617124617099762\n",
      "393 tensor([[0.5552],\n",
      "        [0.6204],\n",
      "        [0.6815],\n",
      "        [0.7370]]) 0.616875946521759\n",
      "394 tensor([[0.5550],\n",
      "        [0.6203],\n",
      "        [0.6815],\n",
      "        [0.7371]]) 0.6166274547576904\n",
      "395 tensor([[0.5548],\n",
      "        [0.6202],\n",
      "        [0.6816],\n",
      "        [0.7372]]) 0.6163790822029114\n",
      "396 tensor([[0.5545],\n",
      "        [0.6201],\n",
      "        [0.6816],\n",
      "        [0.7373]]) 0.6161308288574219\n",
      "397 tensor([[0.5543],\n",
      "        [0.6200],\n",
      "        [0.6816],\n",
      "        [0.7374]]) 0.6158828139305115\n",
      "398 tensor([[0.5540],\n",
      "        [0.6199],\n",
      "        [0.6816],\n",
      "        [0.7376]]) 0.6156349778175354\n",
      "399 tensor([[0.5538],\n",
      "        [0.6198],\n",
      "        [0.6817],\n",
      "        [0.7377]]) 0.6153873801231384\n",
      "400 tensor([[0.5536],\n",
      "        [0.6197],\n",
      "        [0.6817],\n",
      "        [0.7378]]) 0.6151398420333862\n",
      "401 tensor([[0.5533],\n",
      "        [0.6196],\n",
      "        [0.6817],\n",
      "        [0.7379]]) 0.6148925423622131\n",
      "402 tensor([[0.5531],\n",
      "        [0.6195],\n",
      "        [0.6817],\n",
      "        [0.7381]]) 0.6146453619003296\n",
      "403 tensor([[0.5529],\n",
      "        [0.6194],\n",
      "        [0.6817],\n",
      "        [0.7382]]) 0.6143983602523804\n",
      "404 tensor([[0.5526],\n",
      "        [0.6193],\n",
      "        [0.6818],\n",
      "        [0.7383]]) 0.6141515970230103\n",
      "405 tensor([[0.5524],\n",
      "        [0.6192],\n",
      "        [0.6818],\n",
      "        [0.7384]]) 0.6139050126075745\n",
      "406 tensor([[0.5522],\n",
      "        [0.6191],\n",
      "        [0.6818],\n",
      "        [0.7385]]) 0.6136584877967834\n",
      "407 tensor([[0.5519],\n",
      "        [0.6190],\n",
      "        [0.6818],\n",
      "        [0.7387]]) 0.6134122014045715\n",
      "408 tensor([[0.5517],\n",
      "        [0.6189],\n",
      "        [0.6818],\n",
      "        [0.7388]]) 0.613166093826294\n",
      "409 tensor([[0.5515],\n",
      "        [0.6188],\n",
      "        [0.6819],\n",
      "        [0.7389]]) 0.6129201650619507\n",
      "410 tensor([[0.5512],\n",
      "        [0.6187],\n",
      "        [0.6819],\n",
      "        [0.7390]]) 0.6126744151115417\n",
      "411 tensor([[0.5510],\n",
      "        [0.6186],\n",
      "        [0.6819],\n",
      "        [0.7391]]) 0.6124287843704224\n",
      "412 tensor([[0.5507],\n",
      "        [0.6185],\n",
      "        [0.6819],\n",
      "        [0.7393]]) 0.6121833324432373\n",
      "413 tensor([[0.5505],\n",
      "        [0.6184],\n",
      "        [0.6819],\n",
      "        [0.7394]]) 0.6119381189346313\n",
      "414 tensor([[0.5503],\n",
      "        [0.6183],\n",
      "        [0.6820],\n",
      "        [0.7395]]) 0.6116930246353149\n",
      "415 tensor([[0.5500],\n",
      "        [0.6182],\n",
      "        [0.6820],\n",
      "        [0.7396]]) 0.6114481091499329\n",
      "416 tensor([[0.5498],\n",
      "        [0.6181],\n",
      "        [0.6820],\n",
      "        [0.7397]]) 0.6112033128738403\n",
      "417 tensor([[0.5496],\n",
      "        [0.6180],\n",
      "        [0.6820],\n",
      "        [0.7399]]) 0.6109588146209717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 tensor([[0.5493],\n",
      "        [0.6179],\n",
      "        [0.6820],\n",
      "        [0.7400]]) 0.6107143759727478\n",
      "419 tensor([[0.5491],\n",
      "        [0.6178],\n",
      "        [0.6821],\n",
      "        [0.7401]]) 0.6104702353477478\n",
      "420 tensor([[0.5489],\n",
      "        [0.6177],\n",
      "        [0.6821],\n",
      "        [0.7402]]) 0.6102261543273926\n",
      "421 tensor([[0.5486],\n",
      "        [0.6176],\n",
      "        [0.6821],\n",
      "        [0.7403]]) 0.6099821925163269\n",
      "422 tensor([[0.5484],\n",
      "        [0.6175],\n",
      "        [0.6821],\n",
      "        [0.7404]]) 0.6097385883331299\n",
      "423 tensor([[0.5482],\n",
      "        [0.6174],\n",
      "        [0.6821],\n",
      "        [0.7406]]) 0.6094949841499329\n",
      "424 tensor([[0.5479],\n",
      "        [0.6173],\n",
      "        [0.6822],\n",
      "        [0.7407]]) 0.6092516183853149\n",
      "425 tensor([[0.5477],\n",
      "        [0.6172],\n",
      "        [0.6822],\n",
      "        [0.7408]]) 0.6090084314346313\n",
      "426 tensor([[0.5474],\n",
      "        [0.6171],\n",
      "        [0.6822],\n",
      "        [0.7409]]) 0.6087654829025269\n",
      "427 tensor([[0.5472],\n",
      "        [0.6170],\n",
      "        [0.6822],\n",
      "        [0.7410]]) 0.6085224747657776\n",
      "428 tensor([[0.5470],\n",
      "        [0.6169],\n",
      "        [0.6822],\n",
      "        [0.7411]]) 0.6082798838615417\n",
      "429 tensor([[0.5467],\n",
      "        [0.6168],\n",
      "        [0.6823],\n",
      "        [0.7413]]) 0.6080373525619507\n",
      "430 tensor([[0.5465],\n",
      "        [0.6167],\n",
      "        [0.6823],\n",
      "        [0.7414]]) 0.607795000076294\n",
      "431 tensor([[0.5463],\n",
      "        [0.6166],\n",
      "        [0.6823],\n",
      "        [0.7415]]) 0.6075528264045715\n",
      "432 tensor([[0.5460],\n",
      "        [0.6165],\n",
      "        [0.6823],\n",
      "        [0.7416]]) 0.6073108315467834\n",
      "433 tensor([[0.5458],\n",
      "        [0.6164],\n",
      "        [0.6823],\n",
      "        [0.7417]]) 0.6070689558982849\n",
      "434 tensor([[0.5456],\n",
      "        [0.6163],\n",
      "        [0.6824],\n",
      "        [0.7419]]) 0.6068273186683655\n",
      "435 tensor([[0.5453],\n",
      "        [0.6162],\n",
      "        [0.6824],\n",
      "        [0.7420]]) 0.6065858006477356\n",
      "436 tensor([[0.5451],\n",
      "        [0.6161],\n",
      "        [0.6824],\n",
      "        [0.7421]]) 0.60634446144104\n",
      "437 tensor([[0.5449],\n",
      "        [0.6160],\n",
      "        [0.6824],\n",
      "        [0.7422]]) 0.6061033010482788\n",
      "438 tensor([[0.5446],\n",
      "        [0.6159],\n",
      "        [0.6824],\n",
      "        [0.7423]]) 0.6058622598648071\n",
      "439 tensor([[0.5444],\n",
      "        [0.6158],\n",
      "        [0.6825],\n",
      "        [0.7424]]) 0.6056215167045593\n",
      "440 tensor([[0.5442],\n",
      "        [0.6157],\n",
      "        [0.6825],\n",
      "        [0.7425]]) 0.6053807735443115\n",
      "441 tensor([[0.5439],\n",
      "        [0.6156],\n",
      "        [0.6825],\n",
      "        [0.7427]]) 0.6051403880119324\n",
      "442 tensor([[0.5437],\n",
      "        [0.6155],\n",
      "        [0.6825],\n",
      "        [0.7428]]) 0.604900062084198\n",
      "443 tensor([[0.5435],\n",
      "        [0.6154],\n",
      "        [0.6825],\n",
      "        [0.7429]]) 0.604659914970398\n",
      "444 tensor([[0.5432],\n",
      "        [0.6153],\n",
      "        [0.6826],\n",
      "        [0.7430]]) 0.6044198870658875\n",
      "445 tensor([[0.5430],\n",
      "        [0.6152],\n",
      "        [0.6826],\n",
      "        [0.7431]]) 0.604180097579956\n",
      "446 tensor([[0.5428],\n",
      "        [0.6151],\n",
      "        [0.6826],\n",
      "        [0.7432]]) 0.6039403676986694\n",
      "447 tensor([[0.5425],\n",
      "        [0.6149],\n",
      "        [0.6826],\n",
      "        [0.7434]]) 0.6037009358406067\n",
      "448 tensor([[0.5423],\n",
      "        [0.6148],\n",
      "        [0.6826],\n",
      "        [0.7435]]) 0.6034615635871887\n",
      "449 tensor([[0.5421],\n",
      "        [0.6147],\n",
      "        [0.6827],\n",
      "        [0.7436]]) 0.6032224297523499\n",
      "450 tensor([[0.5418],\n",
      "        [0.6146],\n",
      "        [0.6827],\n",
      "        [0.7437]]) 0.6029835343360901\n",
      "451 tensor([[0.5416],\n",
      "        [0.6145],\n",
      "        [0.6827],\n",
      "        [0.7438]]) 0.6027447581291199\n",
      "452 tensor([[0.5414],\n",
      "        [0.6144],\n",
      "        [0.6827],\n",
      "        [0.7439]]) 0.6025060415267944\n",
      "453 tensor([[0.5411],\n",
      "        [0.6143],\n",
      "        [0.6827],\n",
      "        [0.7440]]) 0.6022675633430481\n",
      "454 tensor([[0.5409],\n",
      "        [0.6142],\n",
      "        [0.6828],\n",
      "        [0.7442]]) 0.6020292639732361\n",
      "455 tensor([[0.5407],\n",
      "        [0.6141],\n",
      "        [0.6828],\n",
      "        [0.7443]]) 0.6017911434173584\n",
      "456 tensor([[0.5404],\n",
      "        [0.6140],\n",
      "        [0.6828],\n",
      "        [0.7444]]) 0.6015530824661255\n",
      "457 tensor([[0.5402],\n",
      "        [0.6139],\n",
      "        [0.6828],\n",
      "        [0.7445]]) 0.6013153791427612\n",
      "458 tensor([[0.5400],\n",
      "        [0.6138],\n",
      "        [0.6828],\n",
      "        [0.7446]]) 0.601077675819397\n",
      "459 tensor([[0.5397],\n",
      "        [0.6137],\n",
      "        [0.6828],\n",
      "        [0.7447]]) 0.6008402109146118\n",
      "460 tensor([[0.5395],\n",
      "        [0.6136],\n",
      "        [0.6829],\n",
      "        [0.7448]]) 0.600602924823761\n",
      "461 tensor([[0.5393],\n",
      "        [0.6135],\n",
      "        [0.6829],\n",
      "        [0.7450]]) 0.6003658175468445\n",
      "462 tensor([[0.5390],\n",
      "        [0.6134],\n",
      "        [0.6829],\n",
      "        [0.7451]]) 0.6001288294792175\n",
      "463 tensor([[0.5388],\n",
      "        [0.6133],\n",
      "        [0.6829],\n",
      "        [0.7452]]) 0.5998920202255249\n",
      "464 tensor([[0.5386],\n",
      "        [0.6132],\n",
      "        [0.6829],\n",
      "        [0.7453]]) 0.5996553301811218\n",
      "465 tensor([[0.5383],\n",
      "        [0.6131],\n",
      "        [0.6830],\n",
      "        [0.7454]]) 0.5994188189506531\n",
      "466 tensor([[0.5381],\n",
      "        [0.6130],\n",
      "        [0.6830],\n",
      "        [0.7455]]) 0.5991825461387634\n",
      "467 tensor([[0.5379],\n",
      "        [0.6129],\n",
      "        [0.6830],\n",
      "        [0.7456]]) 0.5989463329315186\n",
      "468 tensor([[0.5376],\n",
      "        [0.6128],\n",
      "        [0.6830],\n",
      "        [0.7458]]) 0.5987103581428528\n",
      "469 tensor([[0.5374],\n",
      "        [0.6127],\n",
      "        [0.6830],\n",
      "        [0.7459]]) 0.5984745621681213\n",
      "470 tensor([[0.5372],\n",
      "        [0.6126],\n",
      "        [0.6831],\n",
      "        [0.7460]]) 0.5982388854026794\n",
      "471 tensor([[0.5369],\n",
      "        [0.6125],\n",
      "        [0.6831],\n",
      "        [0.7461]]) 0.5980035066604614\n",
      "472 tensor([[0.5367],\n",
      "        [0.6124],\n",
      "        [0.6831],\n",
      "        [0.7462]]) 0.5977681279182434\n",
      "473 tensor([[0.5365],\n",
      "        [0.6123],\n",
      "        [0.6831],\n",
      "        [0.7463]]) 0.5975330471992493\n",
      "474 tensor([[0.5362],\n",
      "        [0.6122],\n",
      "        [0.6831],\n",
      "        [0.7464]]) 0.5972979068756104\n",
      "475 tensor([[0.5360],\n",
      "        [0.6121],\n",
      "        [0.6831],\n",
      "        [0.7466]]) 0.5970630645751953\n",
      "476 tensor([[0.5358],\n",
      "        [0.6120],\n",
      "        [0.6832],\n",
      "        [0.7467]]) 0.5968284606933594\n",
      "477 tensor([[0.5355],\n",
      "        [0.6119],\n",
      "        [0.6832],\n",
      "        [0.7468]]) 0.596593976020813\n",
      "478 tensor([[0.5353],\n",
      "        [0.6118],\n",
      "        [0.6832],\n",
      "        [0.7469]]) 0.5963596105575562\n",
      "479 tensor([[0.5351],\n",
      "        [0.6117],\n",
      "        [0.6832],\n",
      "        [0.7470]]) 0.5961254835128784\n",
      "480 tensor([[0.5348],\n",
      "        [0.6116],\n",
      "        [0.6832],\n",
      "        [0.7471]]) 0.5958914756774902\n",
      "481 tensor([[0.5346],\n",
      "        [0.6115],\n",
      "        [0.6833],\n",
      "        [0.7472]]) 0.5956575870513916\n",
      "482 tensor([[0.5344],\n",
      "        [0.6114],\n",
      "        [0.6833],\n",
      "        [0.7473]]) 0.5954239368438721\n",
      "483 tensor([[0.5341],\n",
      "        [0.6113],\n",
      "        [0.6833],\n",
      "        [0.7475]]) 0.5951904654502869\n",
      "484 tensor([[0.5339],\n",
      "        [0.6112],\n",
      "        [0.6833],\n",
      "        [0.7476]]) 0.5949570536613464\n",
      "485 tensor([[0.5337],\n",
      "        [0.6111],\n",
      "        [0.6833],\n",
      "        [0.7477]]) 0.5947238802909851\n",
      "486 tensor([[0.5334],\n",
      "        [0.6110],\n",
      "        [0.6834],\n",
      "        [0.7478]]) 0.5944908261299133\n",
      "487 tensor([[0.5332],\n",
      "        [0.6109],\n",
      "        [0.6834],\n",
      "        [0.7479]]) 0.5942580103874207\n",
      "488 tensor([[0.5330],\n",
      "        [0.6108],\n",
      "        [0.6834],\n",
      "        [0.7480]]) 0.5940252542495728\n",
      "489 tensor([[0.5327],\n",
      "        [0.6107],\n",
      "        [0.6834],\n",
      "        [0.7481]]) 0.5937927961349487\n",
      "490 tensor([[0.5325],\n",
      "        [0.6106],\n",
      "        [0.6834],\n",
      "        [0.7482]]) 0.5935603976249695\n",
      "491 tensor([[0.5323],\n",
      "        [0.6105],\n",
      "        [0.6834],\n",
      "        [0.7483]]) 0.5933281183242798\n",
      "492 tensor([[0.5320],\n",
      "        [0.6104],\n",
      "        [0.6835],\n",
      "        [0.7485]]) 0.5930960774421692\n",
      "493 tensor([[0.5318],\n",
      "        [0.6103],\n",
      "        [0.6835],\n",
      "        [0.7486]]) 0.5928642153739929\n",
      "494 tensor([[0.5316],\n",
      "        [0.6102],\n",
      "        [0.6835],\n",
      "        [0.7487]]) 0.592632532119751\n",
      "495 tensor([[0.5314],\n",
      "        [0.6101],\n",
      "        [0.6835],\n",
      "        [0.7488]]) 0.5924009084701538\n",
      "496 tensor([[0.5311],\n",
      "        [0.6100],\n",
      "        [0.6835],\n",
      "        [0.7489]]) 0.592169463634491\n",
      "497 tensor([[0.5309],\n",
      "        [0.6099],\n",
      "        [0.6836],\n",
      "        [0.7490]]) 0.5919382572174072\n",
      "498 tensor([[0.5307],\n",
      "        [0.6098],\n",
      "        [0.6836],\n",
      "        [0.7491]]) 0.591707170009613\n",
      "499 tensor([[0.5304],\n",
      "        [0.6097],\n",
      "        [0.6836],\n",
      "        [0.7492]]) 0.591476321220398\n",
      "500 tensor([[0.5302],\n",
      "        [0.6096],\n",
      "        [0.6836],\n",
      "        [0.7494]]) 0.5912455320358276\n",
      "501 tensor([[0.5300],\n",
      "        [0.6095],\n",
      "        [0.6836],\n",
      "        [0.7495]]) 0.5910149812698364\n",
      "502 tensor([[0.5297],\n",
      "        [0.6094],\n",
      "        [0.6836],\n",
      "        [0.7496]]) 0.59078449010849\n",
      "503 tensor([[0.5295],\n",
      "        [0.6093],\n",
      "        [0.6837],\n",
      "        [0.7497]]) 0.5905542373657227\n",
      "504 tensor([[0.5293],\n",
      "        [0.6092],\n",
      "        [0.6837],\n",
      "        [0.7498]]) 0.5903240442276001\n",
      "505 tensor([[0.5290],\n",
      "        [0.6091],\n",
      "        [0.6837],\n",
      "        [0.7499]]) 0.5900941491127014\n",
      "506 tensor([[0.5288],\n",
      "        [0.6090],\n",
      "        [0.6837],\n",
      "        [0.7500]]) 0.5898644328117371\n",
      "507 tensor([[0.5286],\n",
      "        [0.6089],\n",
      "        [0.6837],\n",
      "        [0.7501]]) 0.5896347165107727\n",
      "508 tensor([[0.5284],\n",
      "        [0.6088],\n",
      "        [0.6838],\n",
      "        [0.7502]]) 0.589405357837677\n",
      "509 tensor([[0.5281],\n",
      "        [0.6087],\n",
      "        [0.6838],\n",
      "        [0.7503]]) 0.5891759991645813\n",
      "510 tensor([[0.5279],\n",
      "        [0.6086],\n",
      "        [0.6838],\n",
      "        [0.7505]]) 0.5889468193054199\n",
      "511 tensor([[0.5277],\n",
      "        [0.6085],\n",
      "        [0.6838],\n",
      "        [0.7506]]) 0.5887178778648376\n",
      "512 tensor([[0.5274],\n",
      "        [0.6084],\n",
      "        [0.6838],\n",
      "        [0.7507]]) 0.5884890556335449\n",
      "513 tensor([[0.5272],\n",
      "        [0.6083],\n",
      "        [0.6839],\n",
      "        [0.7508]]) 0.5882603526115417\n",
      "514 tensor([[0.5270],\n",
      "        [0.6082],\n",
      "        [0.6839],\n",
      "        [0.7509]]) 0.5880318880081177\n",
      "515 tensor([[0.5267],\n",
      "        [0.6081],\n",
      "        [0.6839],\n",
      "        [0.7510]]) 0.5878035426139832\n",
      "516 tensor([[0.5265],\n",
      "        [0.6080],\n",
      "        [0.6839],\n",
      "        [0.7511]]) 0.587575376033783\n",
      "517 tensor([[0.5263],\n",
      "        [0.6079],\n",
      "        [0.6839],\n",
      "        [0.7512]]) 0.5873472690582275\n",
      "518 tensor([[0.5261],\n",
      "        [0.6078],\n",
      "        [0.6839],\n",
      "        [0.7513]]) 0.587119460105896\n",
      "519 tensor([[0.5258],\n",
      "        [0.6077],\n",
      "        [0.6840],\n",
      "        [0.7514]]) 0.586891770362854\n",
      "520 tensor([[0.5256],\n",
      "        [0.6076],\n",
      "        [0.6840],\n",
      "        [0.7516]]) 0.5866641998291016\n",
      "521 tensor([[0.5254],\n",
      "        [0.6075],\n",
      "        [0.6840],\n",
      "        [0.7517]]) 0.5864368677139282\n",
      "522 tensor([[0.5251],\n",
      "        [0.6074],\n",
      "        [0.6840],\n",
      "        [0.7518]]) 0.5862096548080444\n",
      "523 tensor([[0.5249],\n",
      "        [0.6073],\n",
      "        [0.6840],\n",
      "        [0.7519]]) 0.5859825611114502\n",
      "524 tensor([[0.5247],\n",
      "        [0.6072],\n",
      "        [0.6841],\n",
      "        [0.7520]]) 0.5857556462287903\n",
      "525 tensor([[0.5245],\n",
      "        [0.6071],\n",
      "        [0.6841],\n",
      "        [0.7521]]) 0.5855288505554199\n",
      "526 tensor([[0.5242],\n",
      "        [0.6070],\n",
      "        [0.6841],\n",
      "        [0.7522]]) 0.5853022933006287\n",
      "527 tensor([[0.5240],\n",
      "        [0.6069],\n",
      "        [0.6841],\n",
      "        [0.7523]]) 0.585075855255127\n",
      "528 tensor([[0.5238],\n",
      "        [0.6068],\n",
      "        [0.6841],\n",
      "        [0.7524]]) 0.5848495960235596\n",
      "529 tensor([[0.5235],\n",
      "        [0.6067],\n",
      "        [0.6841],\n",
      "        [0.7525]]) 0.584623396396637\n",
      "530 tensor([[0.5233],\n",
      "        [0.6066],\n",
      "        [0.6842],\n",
      "        [0.7527]]) 0.5843974351882935\n",
      "531 tensor([[0.5231],\n",
      "        [0.6065],\n",
      "        [0.6842],\n",
      "        [0.7528]]) 0.5841716527938843\n",
      "532 tensor([[0.5229],\n",
      "        [0.6064],\n",
      "        [0.6842],\n",
      "        [0.7529]]) 0.5839461088180542\n",
      "533 tensor([[0.5226],\n",
      "        [0.6063],\n",
      "        [0.6842],\n",
      "        [0.7530]]) 0.5837205648422241\n",
      "534 tensor([[0.5224],\n",
      "        [0.6062],\n",
      "        [0.6842],\n",
      "        [0.7531]]) 0.5834953188896179\n",
      "535 tensor([[0.5222],\n",
      "        [0.6061],\n",
      "        [0.6843],\n",
      "        [0.7532]]) 0.5832700729370117\n",
      "536 tensor([[0.5219],\n",
      "        [0.6060],\n",
      "        [0.6843],\n",
      "        [0.7533]]) 0.5830450654029846\n",
      "537 tensor([[0.5217],\n",
      "        [0.6059],\n",
      "        [0.6843],\n",
      "        [0.7534]]) 0.5828201770782471\n",
      "538 tensor([[0.5215],\n",
      "        [0.6058],\n",
      "        [0.6843],\n",
      "        [0.7535]]) 0.5825955867767334\n",
      "539 tensor([[0.5213],\n",
      "        [0.6057],\n",
      "        [0.6843],\n",
      "        [0.7536]]) 0.5823709964752197\n",
      "540 tensor([[0.5210],\n",
      "        [0.6056],\n",
      "        [0.6844],\n",
      "        [0.7537]]) 0.5821466445922852\n",
      "541 tensor([[0.5208],\n",
      "        [0.6055],\n",
      "        [0.6844],\n",
      "        [0.7539]]) 0.5819223523139954\n",
      "542 tensor([[0.5206],\n",
      "        [0.6054],\n",
      "        [0.6844],\n",
      "        [0.7540]]) 0.5816982984542847\n",
      "543 tensor([[0.5203],\n",
      "        [0.6053],\n",
      "        [0.6844],\n",
      "        [0.7541]]) 0.5814744234085083\n",
      "544 tensor([[0.5201],\n",
      "        [0.6052],\n",
      "        [0.6844],\n",
      "        [0.7542]]) 0.5812506079673767\n",
      "545 tensor([[0.5199],\n",
      "        [0.6051],\n",
      "        [0.6844],\n",
      "        [0.7543]]) 0.5810270309448242\n",
      "546 tensor([[0.5197],\n",
      "        [0.6050],\n",
      "        [0.6845],\n",
      "        [0.7544]]) 0.5808035731315613\n",
      "547 tensor([[0.5194],\n",
      "        [0.6049],\n",
      "        [0.6845],\n",
      "        [0.7545]]) 0.5805802345275879\n",
      "548 tensor([[0.5192],\n",
      "        [0.6048],\n",
      "        [0.6845],\n",
      "        [0.7546]]) 0.5803571343421936\n",
      "549 tensor([[0.5190],\n",
      "        [0.6047],\n",
      "        [0.6845],\n",
      "        [0.7547]]) 0.5801341533660889\n",
      "550 tensor([[0.5188],\n",
      "        [0.6046],\n",
      "        [0.6845],\n",
      "        [0.7548]]) 0.5799113512039185\n",
      "551 tensor([[0.5185],\n",
      "        [0.6046],\n",
      "        [0.6846],\n",
      "        [0.7549]]) 0.5796887278556824\n",
      "552 tensor([[0.5183],\n",
      "        [0.6045],\n",
      "        [0.6846],\n",
      "        [0.7550]]) 0.5794662237167358\n",
      "553 tensor([[0.5181],\n",
      "        [0.6044],\n",
      "        [0.6846],\n",
      "        [0.7551]]) 0.5792438983917236\n",
      "554 tensor([[0.5178],\n",
      "        [0.6043],\n",
      "        [0.6846],\n",
      "        [0.7553]]) 0.579021692276001\n",
      "555 tensor([[0.5176],\n",
      "        [0.6042],\n",
      "        [0.6846],\n",
      "        [0.7554]]) 0.5787996053695679\n",
      "556 tensor([[0.5174],\n",
      "        [0.6041],\n",
      "        [0.6846],\n",
      "        [0.7555]]) 0.5785777568817139\n",
      "557 tensor([[0.5172],\n",
      "        [0.6040],\n",
      "        [0.6847],\n",
      "        [0.7556]]) 0.5783559679985046\n",
      "558 tensor([[0.5169],\n",
      "        [0.6039],\n",
      "        [0.6847],\n",
      "        [0.7557]]) 0.5781343579292297\n",
      "559 tensor([[0.5167],\n",
      "        [0.6038],\n",
      "        [0.6847],\n",
      "        [0.7558]]) 0.5779129862785339\n",
      "560 tensor([[0.5165],\n",
      "        [0.6037],\n",
      "        [0.6847],\n",
      "        [0.7559]]) 0.5776917338371277\n",
      "561 tensor([[0.5163],\n",
      "        [0.6036],\n",
      "        [0.6847],\n",
      "        [0.7560]]) 0.577470600605011\n",
      "562 tensor([[0.5160],\n",
      "        [0.6035],\n",
      "        [0.6848],\n",
      "        [0.7561]]) 0.5772497057914734\n",
      "563 tensor([[0.5158],\n",
      "        [0.6034],\n",
      "        [0.6848],\n",
      "        [0.7562]]) 0.5770288705825806\n",
      "564 tensor([[0.5156],\n",
      "        [0.6033],\n",
      "        [0.6848],\n",
      "        [0.7563]]) 0.5768082737922668\n",
      "565 tensor([[0.5154],\n",
      "        [0.6032],\n",
      "        [0.6848],\n",
      "        [0.7564]]) 0.5765877366065979\n",
      "566 tensor([[0.5151],\n",
      "        [0.6031],\n",
      "        [0.6848],\n",
      "        [0.7565]]) 0.5763674378395081\n",
      "567 tensor([[0.5149],\n",
      "        [0.6030],\n",
      "        [0.6849],\n",
      "        [0.7567]]) 0.576147198677063\n",
      "568 tensor([[0.5147],\n",
      "        [0.6029],\n",
      "        [0.6849],\n",
      "        [0.7568]]) 0.5759272575378418\n",
      "569 tensor([[0.5145],\n",
      "        [0.6028],\n",
      "        [0.6849],\n",
      "        [0.7569]]) 0.5757073163986206\n",
      "570 tensor([[0.5142],\n",
      "        [0.6027],\n",
      "        [0.6849],\n",
      "        [0.7570]]) 0.5754876136779785\n",
      "571 tensor([[0.5140],\n",
      "        [0.6026],\n",
      "        [0.6849],\n",
      "        [0.7571]]) 0.5752679705619812\n",
      "572 tensor([[0.5138],\n",
      "        [0.6025],\n",
      "        [0.6849],\n",
      "        [0.7572]]) 0.5750486850738525\n",
      "573 tensor([[0.5136],\n",
      "        [0.6024],\n",
      "        [0.6850],\n",
      "        [0.7573]]) 0.5748293399810791\n",
      "574 tensor([[0.5133],\n",
      "        [0.6023],\n",
      "        [0.6850],\n",
      "        [0.7574]]) 0.5746102333068848\n",
      "575 tensor([[0.5131],\n",
      "        [0.6022],\n",
      "        [0.6850],\n",
      "        [0.7575]]) 0.57439124584198\n",
      "576 tensor([[0.5129],\n",
      "        [0.6021],\n",
      "        [0.6850],\n",
      "        [0.7576]]) 0.5741724371910095\n",
      "577 tensor([[0.5127],\n",
      "        [0.6020],\n",
      "        [0.6850],\n",
      "        [0.7577]]) 0.5739538073539734\n",
      "578 tensor([[0.5124],\n",
      "        [0.6019],\n",
      "        [0.6851],\n",
      "        [0.7578]]) 0.5737354159355164\n",
      "579 tensor([[0.5122],\n",
      "        [0.6018],\n",
      "        [0.6851],\n",
      "        [0.7579]]) 0.5735169649124146\n",
      "580 tensor([[0.5120],\n",
      "        [0.6017],\n",
      "        [0.6851],\n",
      "        [0.7580]]) 0.5732987523078918\n",
      "581 tensor([[0.5118],\n",
      "        [0.6016],\n",
      "        [0.6851],\n",
      "        [0.7581]]) 0.5730807781219482\n",
      "582 tensor([[0.5115],\n",
      "        [0.6015],\n",
      "        [0.6851],\n",
      "        [0.7583]]) 0.5728628635406494\n",
      "583 tensor([[0.5113],\n",
      "        [0.6014],\n",
      "        [0.6852],\n",
      "        [0.7584]]) 0.5726451277732849\n",
      "584 tensor([[0.5111],\n",
      "        [0.6013],\n",
      "        [0.6852],\n",
      "        [0.7585]]) 0.5724275708198547\n",
      "585 tensor([[0.5109],\n",
      "        [0.6012],\n",
      "        [0.6852],\n",
      "        [0.7586]]) 0.5722100734710693\n",
      "586 tensor([[0.5106],\n",
      "        [0.6011],\n",
      "        [0.6852],\n",
      "        [0.7587]]) 0.5719928741455078\n",
      "587 tensor([[0.5104],\n",
      "        [0.6010],\n",
      "        [0.6852],\n",
      "        [0.7588]]) 0.5717757344245911\n",
      "588 tensor([[0.5102],\n",
      "        [0.6009],\n",
      "        [0.6852],\n",
      "        [0.7589]]) 0.5715587139129639\n",
      "589 tensor([[0.5100],\n",
      "        [0.6008],\n",
      "        [0.6853],\n",
      "        [0.7590]]) 0.5713419318199158\n",
      "590 tensor([[0.5097],\n",
      "        [0.6007],\n",
      "        [0.6853],\n",
      "        [0.7591]]) 0.5711252093315125\n",
      "591 tensor([[0.5095],\n",
      "        [0.6006],\n",
      "        [0.6853],\n",
      "        [0.7592]]) 0.5709087252616882\n",
      "592 tensor([[0.5093],\n",
      "        [0.6005],\n",
      "        [0.6853],\n",
      "        [0.7593]]) 0.5706923007965088\n",
      "593 tensor([[0.5091],\n",
      "        [0.6004],\n",
      "        [0.6853],\n",
      "        [0.7594]]) 0.5704761743545532\n",
      "594 tensor([[0.5088],\n",
      "        [0.6004],\n",
      "        [0.6854],\n",
      "        [0.7595]]) 0.5702601075172424\n",
      "595 tensor([[0.5086],\n",
      "        [0.6003],\n",
      "        [0.6854],\n",
      "        [0.7596]]) 0.5700441598892212\n",
      "596 tensor([[0.5084],\n",
      "        [0.6002],\n",
      "        [0.6854],\n",
      "        [0.7597]]) 0.5698283910751343\n",
      "597 tensor([[0.5082],\n",
      "        [0.6001],\n",
      "        [0.6854],\n",
      "        [0.7598]]) 0.5696127414703369\n",
      "598 tensor([[0.5079],\n",
      "        [0.6000],\n",
      "        [0.6854],\n",
      "        [0.7599]]) 0.5693972110748291\n",
      "599 tensor([[0.5077],\n",
      "        [0.5999],\n",
      "        [0.6855],\n",
      "        [0.7600]]) 0.5691820383071899\n",
      "600 tensor([[0.5075],\n",
      "        [0.5998],\n",
      "        [0.6855],\n",
      "        [0.7602]]) 0.568966805934906\n",
      "601 tensor([[0.5073],\n",
      "        [0.5997],\n",
      "        [0.6855],\n",
      "        [0.7603]]) 0.5687518119812012\n",
      "602 tensor([[0.5071],\n",
      "        [0.5996],\n",
      "        [0.6855],\n",
      "        [0.7604]]) 0.5685369372367859\n",
      "603 tensor([[0.5068],\n",
      "        [0.5995],\n",
      "        [0.6855],\n",
      "        [0.7605]]) 0.5683222413063049\n",
      "604 tensor([[0.5066],\n",
      "        [0.5994],\n",
      "        [0.6855],\n",
      "        [0.7606]]) 0.5681076049804688\n",
      "605 tensor([[0.5064],\n",
      "        [0.5993],\n",
      "        [0.6856],\n",
      "        [0.7607]]) 0.5678932070732117\n",
      "606 tensor([[0.5062],\n",
      "        [0.5992],\n",
      "        [0.6856],\n",
      "        [0.7608]]) 0.5676789879798889\n",
      "607 tensor([[0.5059],\n",
      "        [0.5991],\n",
      "        [0.6856],\n",
      "        [0.7609]]) 0.5674648284912109\n",
      "608 tensor([[0.5057],\n",
      "        [0.5990],\n",
      "        [0.6856],\n",
      "        [0.7610]]) 0.5672509074211121\n",
      "609 tensor([[0.5055],\n",
      "        [0.5989],\n",
      "        [0.6856],\n",
      "        [0.7611]]) 0.5670371055603027\n",
      "610 tensor([[0.5053],\n",
      "        [0.5988],\n",
      "        [0.6857],\n",
      "        [0.7612]]) 0.566823422908783\n",
      "611 tensor([[0.5051],\n",
      "        [0.5987],\n",
      "        [0.6857],\n",
      "        [0.7613]]) 0.5666099190711975\n",
      "612 tensor([[0.5048],\n",
      "        [0.5986],\n",
      "        [0.6857],\n",
      "        [0.7614]]) 0.5663965344429016\n",
      "613 tensor([[0.5046],\n",
      "        [0.5985],\n",
      "        [0.6857],\n",
      "        [0.7615]]) 0.56618332862854\n",
      "614 tensor([[0.5044],\n",
      "        [0.5984],\n",
      "        [0.6857],\n",
      "        [0.7616]]) 0.565970242023468\n",
      "615 tensor([[0.5042],\n",
      "        [0.5983],\n",
      "        [0.6858],\n",
      "        [0.7617]]) 0.5657573342323303\n",
      "616 tensor([[0.5039],\n",
      "        [0.5982],\n",
      "        [0.6858],\n",
      "        [0.7618]]) 0.5655444860458374\n",
      "617 tensor([[0.5037],\n",
      "        [0.5981],\n",
      "        [0.6858],\n",
      "        [0.7619]]) 0.5653319954872131\n",
      "618 tensor([[0.5035],\n",
      "        [0.5980],\n",
      "        [0.6858],\n",
      "        [0.7620]]) 0.5651195049285889\n",
      "619 tensor([[0.5033],\n",
      "        [0.5979],\n",
      "        [0.6858],\n",
      "        [0.7621]]) 0.5649071931838989\n",
      "620 tensor([[0.5031],\n",
      "        [0.5978],\n",
      "        [0.6858],\n",
      "        [0.7622]]) 0.5646950006484985\n",
      "621 tensor([[0.5028],\n",
      "        [0.5977],\n",
      "        [0.6859],\n",
      "        [0.7624]]) 0.5644828677177429\n",
      "622 tensor([[0.5026],\n",
      "        [0.5977],\n",
      "        [0.6859],\n",
      "        [0.7625]]) 0.5642710328102112\n",
      "623 tensor([[0.5024],\n",
      "        [0.5976],\n",
      "        [0.6859],\n",
      "        [0.7626]]) 0.5640592575073242\n",
      "624 tensor([[0.5022],\n",
      "        [0.5975],\n",
      "        [0.6859],\n",
      "        [0.7627]]) 0.5638476610183716\n",
      "625 tensor([[0.5019],\n",
      "        [0.5974],\n",
      "        [0.6859],\n",
      "        [0.7628]]) 0.5636362433433533\n",
      "626 tensor([[0.5017],\n",
      "        [0.5973],\n",
      "        [0.6860],\n",
      "        [0.7629]]) 0.5634249448776245\n",
      "627 tensor([[0.5015],\n",
      "        [0.5972],\n",
      "        [0.6860],\n",
      "        [0.7630]]) 0.5632138252258301\n",
      "628 tensor([[0.5013],\n",
      "        [0.5971],\n",
      "        [0.6860],\n",
      "        [0.7631]]) 0.5630028247833252\n",
      "629 tensor([[0.5011],\n",
      "        [0.5970],\n",
      "        [0.6860],\n",
      "        [0.7632]]) 0.5627919435501099\n",
      "630 tensor([[0.5008],\n",
      "        [0.5969],\n",
      "        [0.6860],\n",
      "        [0.7633]]) 0.5625812411308289\n",
      "631 tensor([[0.5006],\n",
      "        [0.5968],\n",
      "        [0.6861],\n",
      "        [0.7634]]) 0.5623706579208374\n",
      "632 tensor([[0.5004],\n",
      "        [0.5967],\n",
      "        [0.6861],\n",
      "        [0.7635]]) 0.5621602535247803\n",
      "633 tensor([[0.5002],\n",
      "        [0.5966],\n",
      "        [0.6861],\n",
      "        [0.7636]]) 0.5619499683380127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 tensor([[0.5000],\n",
      "        [0.5965],\n",
      "        [0.6861],\n",
      "        [0.7637]]) 0.5617399215698242\n",
      "635 tensor([[0.4997],\n",
      "        [0.5964],\n",
      "        [0.6861],\n",
      "        [0.7638]]) 0.5615299344062805\n",
      "636 tensor([[0.4995],\n",
      "        [0.5963],\n",
      "        [0.6862],\n",
      "        [0.7639]]) 0.5613200664520264\n",
      "637 tensor([[0.4993],\n",
      "        [0.5962],\n",
      "        [0.6862],\n",
      "        [0.7640]]) 0.5611103773117065\n",
      "638 tensor([[0.4991],\n",
      "        [0.5961],\n",
      "        [0.6862],\n",
      "        [0.7641]]) 0.5609009265899658\n",
      "639 tensor([[0.4989],\n",
      "        [0.5960],\n",
      "        [0.6862],\n",
      "        [0.7642]]) 0.5606914758682251\n",
      "640 tensor([[0.4986],\n",
      "        [0.5959],\n",
      "        [0.6862],\n",
      "        [0.7643]]) 0.5604822635650635\n",
      "641 tensor([[0.4984],\n",
      "        [0.5958],\n",
      "        [0.6862],\n",
      "        [0.7644]]) 0.5602731704711914\n",
      "642 tensor([[0.4982],\n",
      "        [0.5957],\n",
      "        [0.6863],\n",
      "        [0.7645]]) 0.5600641965866089\n",
      "643 tensor([[0.4980],\n",
      "        [0.5956],\n",
      "        [0.6863],\n",
      "        [0.7646]]) 0.5598553419113159\n",
      "644 tensor([[0.4978],\n",
      "        [0.5956],\n",
      "        [0.6863],\n",
      "        [0.7647]]) 0.559646725654602\n",
      "645 tensor([[0.4975],\n",
      "        [0.5955],\n",
      "        [0.6863],\n",
      "        [0.7648]]) 0.5594382286071777\n",
      "646 tensor([[0.4973],\n",
      "        [0.5954],\n",
      "        [0.6863],\n",
      "        [0.7649]]) 0.5592299103736877\n",
      "647 tensor([[0.4971],\n",
      "        [0.5953],\n",
      "        [0.6864],\n",
      "        [0.7650]]) 0.5590215921401978\n",
      "648 tensor([[0.4969],\n",
      "        [0.5952],\n",
      "        [0.6864],\n",
      "        [0.7651]]) 0.5588135719299316\n",
      "649 tensor([[0.4967],\n",
      "        [0.5951],\n",
      "        [0.6864],\n",
      "        [0.7652]]) 0.5586055517196655\n",
      "650 tensor([[0.4964],\n",
      "        [0.5950],\n",
      "        [0.6864],\n",
      "        [0.7654]]) 0.5583977699279785\n",
      "651 tensor([[0.4962],\n",
      "        [0.5949],\n",
      "        [0.6864],\n",
      "        [0.7655]]) 0.5581901669502258\n",
      "652 tensor([[0.4960],\n",
      "        [0.5948],\n",
      "        [0.6865],\n",
      "        [0.7656]]) 0.5579826831817627\n",
      "653 tensor([[0.4958],\n",
      "        [0.5947],\n",
      "        [0.6865],\n",
      "        [0.7657]]) 0.5577753186225891\n",
      "654 tensor([[0.4956],\n",
      "        [0.5946],\n",
      "        [0.6865],\n",
      "        [0.7658]]) 0.5575681328773499\n",
      "655 tensor([[0.4954],\n",
      "        [0.5945],\n",
      "        [0.6865],\n",
      "        [0.7659]]) 0.5573610663414001\n",
      "656 tensor([[0.4951],\n",
      "        [0.5944],\n",
      "        [0.6865],\n",
      "        [0.7660]]) 0.5571540594100952\n",
      "657 tensor([[0.4949],\n",
      "        [0.5943],\n",
      "        [0.6866],\n",
      "        [0.7661]]) 0.5569473505020142\n",
      "658 tensor([[0.4947],\n",
      "        [0.5942],\n",
      "        [0.6866],\n",
      "        [0.7662]]) 0.5567406415939331\n",
      "659 tensor([[0.4945],\n",
      "        [0.5941],\n",
      "        [0.6866],\n",
      "        [0.7663]]) 0.5565341711044312\n",
      "660 tensor([[0.4943],\n",
      "        [0.5940],\n",
      "        [0.6866],\n",
      "        [0.7664]]) 0.5563279390335083\n",
      "661 tensor([[0.4940],\n",
      "        [0.5939],\n",
      "        [0.6866],\n",
      "        [0.7665]]) 0.5561216473579407\n",
      "662 tensor([[0.4938],\n",
      "        [0.5938],\n",
      "        [0.6866],\n",
      "        [0.7666]]) 0.5559155941009521\n",
      "663 tensor([[0.4936],\n",
      "        [0.5938],\n",
      "        [0.6867],\n",
      "        [0.7667]]) 0.555709719657898\n",
      "664 tensor([[0.4934],\n",
      "        [0.5937],\n",
      "        [0.6867],\n",
      "        [0.7668]]) 0.5555039644241333\n",
      "665 tensor([[0.4932],\n",
      "        [0.5936],\n",
      "        [0.6867],\n",
      "        [0.7669]]) 0.5552982687950134\n",
      "666 tensor([[0.4930],\n",
      "        [0.5935],\n",
      "        [0.6867],\n",
      "        [0.7670]]) 0.5550928115844727\n",
      "667 tensor([[0.4927],\n",
      "        [0.5934],\n",
      "        [0.6867],\n",
      "        [0.7671]]) 0.5548874139785767\n",
      "668 tensor([[0.4925],\n",
      "        [0.5933],\n",
      "        [0.6868],\n",
      "        [0.7672]]) 0.5546822547912598\n",
      "669 tensor([[0.4923],\n",
      "        [0.5932],\n",
      "        [0.6868],\n",
      "        [0.7673]]) 0.5544772148132324\n",
      "670 tensor([[0.4921],\n",
      "        [0.5931],\n",
      "        [0.6868],\n",
      "        [0.7674]]) 0.5542722344398499\n",
      "671 tensor([[0.4919],\n",
      "        [0.5930],\n",
      "        [0.6868],\n",
      "        [0.7675]]) 0.5540675520896912\n",
      "672 tensor([[0.4917],\n",
      "        [0.5929],\n",
      "        [0.6868],\n",
      "        [0.7676]]) 0.5538628697395325\n",
      "673 tensor([[0.4914],\n",
      "        [0.5928],\n",
      "        [0.6869],\n",
      "        [0.7677]]) 0.5536583662033081\n",
      "674 tensor([[0.4912],\n",
      "        [0.5927],\n",
      "        [0.6869],\n",
      "        [0.7678]]) 0.5534541010856628\n",
      "675 tensor([[0.4910],\n",
      "        [0.5926],\n",
      "        [0.6869],\n",
      "        [0.7679]]) 0.5532498359680176\n",
      "676 tensor([[0.4908],\n",
      "        [0.5925],\n",
      "        [0.6869],\n",
      "        [0.7680]]) 0.5530458092689514\n",
      "677 tensor([[0.4906],\n",
      "        [0.5924],\n",
      "        [0.6869],\n",
      "        [0.7681]]) 0.55284184217453\n",
      "678 tensor([[0.4904],\n",
      "        [0.5923],\n",
      "        [0.6870],\n",
      "        [0.7682]]) 0.5526381134986877\n",
      "679 tensor([[0.4901],\n",
      "        [0.5923],\n",
      "        [0.6870],\n",
      "        [0.7683]]) 0.5524344444274902\n",
      "680 tensor([[0.4899],\n",
      "        [0.5922],\n",
      "        [0.6870],\n",
      "        [0.7684]]) 0.5522310137748718\n",
      "681 tensor([[0.4897],\n",
      "        [0.5921],\n",
      "        [0.6870],\n",
      "        [0.7685]]) 0.5520275831222534\n",
      "682 tensor([[0.4895],\n",
      "        [0.5920],\n",
      "        [0.6870],\n",
      "        [0.7686]]) 0.5518243908882141\n",
      "683 tensor([[0.4893],\n",
      "        [0.5919],\n",
      "        [0.6871],\n",
      "        [0.7687]]) 0.5516213178634644\n",
      "684 tensor([[0.4891],\n",
      "        [0.5918],\n",
      "        [0.6871],\n",
      "        [0.7688]]) 0.5514183640480042\n",
      "685 tensor([[0.4888],\n",
      "        [0.5917],\n",
      "        [0.6871],\n",
      "        [0.7689]]) 0.5512155890464783\n",
      "686 tensor([[0.4886],\n",
      "        [0.5916],\n",
      "        [0.6871],\n",
      "        [0.7690]]) 0.5510129332542419\n",
      "687 tensor([[0.4884],\n",
      "        [0.5915],\n",
      "        [0.6871],\n",
      "        [0.7691]]) 0.5508104562759399\n",
      "688 tensor([[0.4882],\n",
      "        [0.5914],\n",
      "        [0.6872],\n",
      "        [0.7692]]) 0.5506080985069275\n",
      "689 tensor([[0.4880],\n",
      "        [0.5913],\n",
      "        [0.6872],\n",
      "        [0.7693]]) 0.5504058599472046\n",
      "690 tensor([[0.4878],\n",
      "        [0.5912],\n",
      "        [0.6872],\n",
      "        [0.7694]]) 0.5502037405967712\n",
      "691 tensor([[0.4875],\n",
      "        [0.5911],\n",
      "        [0.6872],\n",
      "        [0.7695]]) 0.5500018000602722\n",
      "692 tensor([[0.4873],\n",
      "        [0.5910],\n",
      "        [0.6872],\n",
      "        [0.7696]]) 0.549799919128418\n",
      "693 tensor([[0.4871],\n",
      "        [0.5909],\n",
      "        [0.6872],\n",
      "        [0.7697]]) 0.5495983362197876\n",
      "694 tensor([[0.4869],\n",
      "        [0.5908],\n",
      "        [0.6873],\n",
      "        [0.7698]]) 0.5493968725204468\n",
      "695 tensor([[0.4867],\n",
      "        [0.5908],\n",
      "        [0.6873],\n",
      "        [0.7699]]) 0.5491954684257507\n",
      "696 tensor([[0.4865],\n",
      "        [0.5907],\n",
      "        [0.6873],\n",
      "        [0.7700]]) 0.5489941835403442\n",
      "697 tensor([[0.4863],\n",
      "        [0.5906],\n",
      "        [0.6873],\n",
      "        [0.7701]]) 0.5487930774688721\n",
      "698 tensor([[0.4860],\n",
      "        [0.5905],\n",
      "        [0.6873],\n",
      "        [0.7702]]) 0.5485921502113342\n",
      "699 tensor([[0.4858],\n",
      "        [0.5904],\n",
      "        [0.6874],\n",
      "        [0.7703]]) 0.5483912825584412\n",
      "700 tensor([[0.4856],\n",
      "        [0.5903],\n",
      "        [0.6874],\n",
      "        [0.7704]]) 0.5481905937194824\n",
      "701 tensor([[0.4854],\n",
      "        [0.5902],\n",
      "        [0.6874],\n",
      "        [0.7705]]) 0.547990083694458\n",
      "702 tensor([[0.4852],\n",
      "        [0.5901],\n",
      "        [0.6874],\n",
      "        [0.7706]]) 0.5477896928787231\n",
      "703 tensor([[0.4850],\n",
      "        [0.5900],\n",
      "        [0.6874],\n",
      "        [0.7707]]) 0.5475893616676331\n",
      "704 tensor([[0.4847],\n",
      "        [0.5899],\n",
      "        [0.6875],\n",
      "        [0.7708]]) 0.5473892688751221\n",
      "705 tensor([[0.4845],\n",
      "        [0.5898],\n",
      "        [0.6875],\n",
      "        [0.7709]]) 0.5471892356872559\n",
      "706 tensor([[0.4843],\n",
      "        [0.5897],\n",
      "        [0.6875],\n",
      "        [0.7710]]) 0.546989381313324\n",
      "707 tensor([[0.4841],\n",
      "        [0.5896],\n",
      "        [0.6875],\n",
      "        [0.7711]]) 0.5467897057533264\n",
      "708 tensor([[0.4839],\n",
      "        [0.5895],\n",
      "        [0.6875],\n",
      "        [0.7712]]) 0.5465900897979736\n",
      "709 tensor([[0.4837],\n",
      "        [0.5895],\n",
      "        [0.6876],\n",
      "        [0.7713]]) 0.5463907122612\n",
      "710 tensor([[0.4835],\n",
      "        [0.5894],\n",
      "        [0.6876],\n",
      "        [0.7714]]) 0.546191394329071\n",
      "711 tensor([[0.4833],\n",
      "        [0.5893],\n",
      "        [0.6876],\n",
      "        [0.7715]]) 0.5459922552108765\n",
      "712 tensor([[0.4830],\n",
      "        [0.5892],\n",
      "        [0.6876],\n",
      "        [0.7716]]) 0.5457931756973267\n",
      "713 tensor([[0.4828],\n",
      "        [0.5891],\n",
      "        [0.6876],\n",
      "        [0.7717]]) 0.545594334602356\n",
      "714 tensor([[0.4826],\n",
      "        [0.5890],\n",
      "        [0.6877],\n",
      "        [0.7718]]) 0.5453956127166748\n",
      "715 tensor([[0.4824],\n",
      "        [0.5889],\n",
      "        [0.6877],\n",
      "        [0.7719]]) 0.5451968908309937\n",
      "716 tensor([[0.4822],\n",
      "        [0.5888],\n",
      "        [0.6877],\n",
      "        [0.7720]]) 0.5449985265731812\n",
      "717 tensor([[0.4820],\n",
      "        [0.5887],\n",
      "        [0.6877],\n",
      "        [0.7721]]) 0.5448001623153687\n",
      "718 tensor([[0.4818],\n",
      "        [0.5886],\n",
      "        [0.6877],\n",
      "        [0.7722]]) 0.5446019172668457\n",
      "719 tensor([[0.4815],\n",
      "        [0.5885],\n",
      "        [0.6878],\n",
      "        [0.7723]]) 0.5444038510322571\n",
      "720 tensor([[0.4813],\n",
      "        [0.5884],\n",
      "        [0.6878],\n",
      "        [0.7724]]) 0.5442060232162476\n",
      "721 tensor([[0.4811],\n",
      "        [0.5883],\n",
      "        [0.6878],\n",
      "        [0.7725]]) 0.544008195400238\n",
      "722 tensor([[0.4809],\n",
      "        [0.5883],\n",
      "        [0.6878],\n",
      "        [0.7726]]) 0.5438105463981628\n",
      "723 tensor([[0.4807],\n",
      "        [0.5882],\n",
      "        [0.6878],\n",
      "        [0.7727]]) 0.5436130166053772\n",
      "724 tensor([[0.4805],\n",
      "        [0.5881],\n",
      "        [0.6879],\n",
      "        [0.7728]]) 0.5434157252311707\n",
      "725 tensor([[0.4803],\n",
      "        [0.5880],\n",
      "        [0.6879],\n",
      "        [0.7729]]) 0.5432184934616089\n",
      "726 tensor([[0.4801],\n",
      "        [0.5879],\n",
      "        [0.6879],\n",
      "        [0.7730]]) 0.5430213212966919\n",
      "727 tensor([[0.4798],\n",
      "        [0.5878],\n",
      "        [0.6879],\n",
      "        [0.7731]]) 0.542824387550354\n",
      "728 tensor([[0.4796],\n",
      "        [0.5877],\n",
      "        [0.6879],\n",
      "        [0.7732]]) 0.5426275730133057\n",
      "729 tensor([[0.4794],\n",
      "        [0.5876],\n",
      "        [0.6880],\n",
      "        [0.7733]]) 0.5424308180809021\n",
      "730 tensor([[0.4792],\n",
      "        [0.5875],\n",
      "        [0.6880],\n",
      "        [0.7734]]) 0.5422343015670776\n",
      "731 tensor([[0.4790],\n",
      "        [0.5874],\n",
      "        [0.6880],\n",
      "        [0.7735]]) 0.5420379042625427\n",
      "732 tensor([[0.4788],\n",
      "        [0.5873],\n",
      "        [0.6880],\n",
      "        [0.7736]]) 0.5418416261672974\n",
      "733 tensor([[0.4786],\n",
      "        [0.5872],\n",
      "        [0.6880],\n",
      "        [0.7737]]) 0.5416454672813416\n",
      "734 tensor([[0.4784],\n",
      "        [0.5872],\n",
      "        [0.6881],\n",
      "        [0.7738]]) 0.5414494276046753\n",
      "735 tensor([[0.4781],\n",
      "        [0.5871],\n",
      "        [0.6881],\n",
      "        [0.7739]]) 0.5412535667419434\n",
      "736 tensor([[0.4779],\n",
      "        [0.5870],\n",
      "        [0.6881],\n",
      "        [0.7740]]) 0.541057825088501\n",
      "737 tensor([[0.4777],\n",
      "        [0.5869],\n",
      "        [0.6881],\n",
      "        [0.7741]]) 0.5408622026443481\n",
      "738 tensor([[0.4775],\n",
      "        [0.5868],\n",
      "        [0.6881],\n",
      "        [0.7742]]) 0.5406666994094849\n",
      "739 tensor([[0.4773],\n",
      "        [0.5867],\n",
      "        [0.6881],\n",
      "        [0.7743]]) 0.5404714345932007\n",
      "740 tensor([[0.4771],\n",
      "        [0.5866],\n",
      "        [0.6882],\n",
      "        [0.7744]]) 0.5402762293815613\n",
      "741 tensor([[0.4769],\n",
      "        [0.5865],\n",
      "        [0.6882],\n",
      "        [0.7745]]) 0.5400811433792114\n",
      "742 tensor([[0.4767],\n",
      "        [0.5864],\n",
      "        [0.6882],\n",
      "        [0.7746]]) 0.5398862361907959\n",
      "743 tensor([[0.4765],\n",
      "        [0.5863],\n",
      "        [0.6882],\n",
      "        [0.7747]]) 0.5396914482116699\n",
      "744 tensor([[0.4762],\n",
      "        [0.5862],\n",
      "        [0.6882],\n",
      "        [0.7748]]) 0.5394968390464783\n",
      "745 tensor([[0.4760],\n",
      "        [0.5861],\n",
      "        [0.6883],\n",
      "        [0.7749]]) 0.5393023490905762\n",
      "746 tensor([[0.4758],\n",
      "        [0.5861],\n",
      "        [0.6883],\n",
      "        [0.7750]]) 0.5391079187393188\n",
      "747 tensor([[0.4756],\n",
      "        [0.5860],\n",
      "        [0.6883],\n",
      "        [0.7751]]) 0.5389136672019958\n",
      "748 tensor([[0.4754],\n",
      "        [0.5859],\n",
      "        [0.6883],\n",
      "        [0.7752]]) 0.5387195348739624\n",
      "749 tensor([[0.4752],\n",
      "        [0.5858],\n",
      "        [0.6883],\n",
      "        [0.7753]]) 0.5385254621505737\n",
      "750 tensor([[0.4750],\n",
      "        [0.5857],\n",
      "        [0.6884],\n",
      "        [0.7754]]) 0.5383316278457642\n",
      "751 tensor([[0.4748],\n",
      "        [0.5856],\n",
      "        [0.6884],\n",
      "        [0.7755]]) 0.5381379723548889\n",
      "752 tensor([[0.4746],\n",
      "        [0.5855],\n",
      "        [0.6884],\n",
      "        [0.7756]]) 0.5379443764686584\n",
      "753 tensor([[0.4744],\n",
      "        [0.5854],\n",
      "        [0.6884],\n",
      "        [0.7756]]) 0.5377509593963623\n",
      "754 tensor([[0.4741],\n",
      "        [0.5853],\n",
      "        [0.6884],\n",
      "        [0.7757]]) 0.5375576019287109\n",
      "755 tensor([[0.4739],\n",
      "        [0.5852],\n",
      "        [0.6885],\n",
      "        [0.7758]]) 0.5373644232749939\n",
      "756 tensor([[0.4737],\n",
      "        [0.5851],\n",
      "        [0.6885],\n",
      "        [0.7759]]) 0.5371713638305664\n",
      "757 tensor([[0.4735],\n",
      "        [0.5851],\n",
      "        [0.6885],\n",
      "        [0.7760]]) 0.5369784832000732\n",
      "758 tensor([[0.4733],\n",
      "        [0.5850],\n",
      "        [0.6885],\n",
      "        [0.7761]]) 0.5367857217788696\n",
      "759 tensor([[0.4731],\n",
      "        [0.5849],\n",
      "        [0.6885],\n",
      "        [0.7762]]) 0.5365930199623108\n",
      "760 tensor([[0.4729],\n",
      "        [0.5848],\n",
      "        [0.6886],\n",
      "        [0.7763]]) 0.536400556564331\n",
      "761 tensor([[0.4727],\n",
      "        [0.5847],\n",
      "        [0.6886],\n",
      "        [0.7764]]) 0.5362080931663513\n",
      "762 tensor([[0.4725],\n",
      "        [0.5846],\n",
      "        [0.6886],\n",
      "        [0.7765]]) 0.5360158681869507\n",
      "763 tensor([[0.4723],\n",
      "        [0.5845],\n",
      "        [0.6886],\n",
      "        [0.7766]]) 0.5358237624168396\n",
      "764 tensor([[0.4720],\n",
      "        [0.5844],\n",
      "        [0.6886],\n",
      "        [0.7767]]) 0.5356317758560181\n",
      "765 tensor([[0.4718],\n",
      "        [0.5843],\n",
      "        [0.6887],\n",
      "        [0.7768]]) 0.5354399681091309\n",
      "766 tensor([[0.4716],\n",
      "        [0.5842],\n",
      "        [0.6887],\n",
      "        [0.7769]]) 0.5352482199668884\n",
      "767 tensor([[0.4714],\n",
      "        [0.5841],\n",
      "        [0.6887],\n",
      "        [0.7770]]) 0.5350566506385803\n",
      "768 tensor([[0.4712],\n",
      "        [0.5841],\n",
      "        [0.6887],\n",
      "        [0.7771]]) 0.5348652005195618\n",
      "769 tensor([[0.4710],\n",
      "        [0.5840],\n",
      "        [0.6887],\n",
      "        [0.7772]]) 0.5346738696098328\n",
      "770 tensor([[0.4708],\n",
      "        [0.5839],\n",
      "        [0.6888],\n",
      "        [0.7773]]) 0.5344826579093933\n",
      "771 tensor([[0.4706],\n",
      "        [0.5838],\n",
      "        [0.6888],\n",
      "        [0.7774]]) 0.5342916250228882\n",
      "772 tensor([[0.4704],\n",
      "        [0.5837],\n",
      "        [0.6888],\n",
      "        [0.7775]]) 0.5341007113456726\n",
      "773 tensor([[0.4702],\n",
      "        [0.5836],\n",
      "        [0.6888],\n",
      "        [0.7776]]) 0.5339099168777466\n",
      "774 tensor([[0.4700],\n",
      "        [0.5835],\n",
      "        [0.6888],\n",
      "        [0.7777]]) 0.5337193012237549\n",
      "775 tensor([[0.4698],\n",
      "        [0.5834],\n",
      "        [0.6889],\n",
      "        [0.7778]]) 0.5335286855697632\n",
      "776 tensor([[0.4695],\n",
      "        [0.5833],\n",
      "        [0.6889],\n",
      "        [0.7779]]) 0.5333383083343506\n",
      "777 tensor([[0.4693],\n",
      "        [0.5832],\n",
      "        [0.6889],\n",
      "        [0.7780]]) 0.5331479907035828\n",
      "778 tensor([[0.4691],\n",
      "        [0.5832],\n",
      "        [0.6889],\n",
      "        [0.7781]]) 0.532957911491394\n",
      "779 tensor([[0.4689],\n",
      "        [0.5831],\n",
      "        [0.6889],\n",
      "        [0.7782]]) 0.5327678322792053\n",
      "780 tensor([[0.4687],\n",
      "        [0.5830],\n",
      "        [0.6890],\n",
      "        [0.7783]]) 0.5325779914855957\n",
      "781 tensor([[0.4685],\n",
      "        [0.5829],\n",
      "        [0.6890],\n",
      "        [0.7784]]) 0.5323882102966309\n",
      "782 tensor([[0.4683],\n",
      "        [0.5828],\n",
      "        [0.6890],\n",
      "        [0.7785]]) 0.5321986675262451\n",
      "783 tensor([[0.4681],\n",
      "        [0.5827],\n",
      "        [0.6890],\n",
      "        [0.7786]]) 0.5320091247558594\n",
      "784 tensor([[0.4679],\n",
      "        [0.5826],\n",
      "        [0.6890],\n",
      "        [0.7786]]) 0.5318198204040527\n",
      "785 tensor([[0.4677],\n",
      "        [0.5825],\n",
      "        [0.6891],\n",
      "        [0.7787]]) 0.5316306352615356\n",
      "786 tensor([[0.4675],\n",
      "        [0.5824],\n",
      "        [0.6891],\n",
      "        [0.7788]]) 0.5314415097236633\n",
      "787 tensor([[0.4673],\n",
      "        [0.5823],\n",
      "        [0.6891],\n",
      "        [0.7789]]) 0.5312525629997253\n",
      "788 tensor([[0.4671],\n",
      "        [0.5823],\n",
      "        [0.6891],\n",
      "        [0.7790]]) 0.5310637354850769\n",
      "789 tensor([[0.4668],\n",
      "        [0.5822],\n",
      "        [0.6891],\n",
      "        [0.7791]]) 0.5308750867843628\n",
      "790 tensor([[0.4666],\n",
      "        [0.5821],\n",
      "        [0.6892],\n",
      "        [0.7792]]) 0.5306864976882935\n",
      "791 tensor([[0.4664],\n",
      "        [0.5820],\n",
      "        [0.6892],\n",
      "        [0.7793]]) 0.5304980278015137\n",
      "792 tensor([[0.4662],\n",
      "        [0.5819],\n",
      "        [0.6892],\n",
      "        [0.7794]]) 0.5303096771240234\n",
      "793 tensor([[0.4660],\n",
      "        [0.5818],\n",
      "        [0.6892],\n",
      "        [0.7795]]) 0.5301215648651123\n",
      "794 tensor([[0.4658],\n",
      "        [0.5817],\n",
      "        [0.6892],\n",
      "        [0.7796]]) 0.529933512210846\n",
      "795 tensor([[0.4656],\n",
      "        [0.5816],\n",
      "        [0.6893],\n",
      "        [0.7797]]) 0.5297455787658691\n",
      "796 tensor([[0.4654],\n",
      "        [0.5815],\n",
      "        [0.6893],\n",
      "        [0.7798]]) 0.5295577645301819\n",
      "797 tensor([[0.4652],\n",
      "        [0.5814],\n",
      "        [0.6893],\n",
      "        [0.7799]]) 0.529370129108429\n",
      "798 tensor([[0.4650],\n",
      "        [0.5814],\n",
      "        [0.6893],\n",
      "        [0.7800]]) 0.5291825532913208\n",
      "799 tensor([[0.4648],\n",
      "        [0.5813],\n",
      "        [0.6893],\n",
      "        [0.7801]]) 0.528995156288147\n",
      "800 tensor([[0.4646],\n",
      "        [0.5812],\n",
      "        [0.6894],\n",
      "        [0.7802]]) 0.5288078784942627\n",
      "801 tensor([[0.4644],\n",
      "        [0.5811],\n",
      "        [0.6894],\n",
      "        [0.7803]]) 0.528620719909668\n",
      "802 tensor([[0.4642],\n",
      "        [0.5810],\n",
      "        [0.6894],\n",
      "        [0.7804]]) 0.5284336805343628\n",
      "803 tensor([[0.4640],\n",
      "        [0.5809],\n",
      "        [0.6894],\n",
      "        [0.7805]]) 0.5282468199729919\n",
      "804 tensor([[0.4638],\n",
      "        [0.5808],\n",
      "        [0.6894],\n",
      "        [0.7806]]) 0.5280600786209106\n",
      "805 tensor([[0.4635],\n",
      "        [0.5807],\n",
      "        [0.6895],\n",
      "        [0.7806]]) 0.5278734564781189\n",
      "806 tensor([[0.4633],\n",
      "        [0.5806],\n",
      "        [0.6895],\n",
      "        [0.7807]]) 0.5276870131492615\n",
      "807 tensor([[0.4631],\n",
      "        [0.5806],\n",
      "        [0.6895],\n",
      "        [0.7808]]) 0.527500569820404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808 tensor([[0.4629],\n",
      "        [0.5805],\n",
      "        [0.6895],\n",
      "        [0.7809]]) 0.527314305305481\n",
      "809 tensor([[0.4627],\n",
      "        [0.5804],\n",
      "        [0.6895],\n",
      "        [0.7810]]) 0.5271282196044922\n",
      "810 tensor([[0.4625],\n",
      "        [0.5803],\n",
      "        [0.6896],\n",
      "        [0.7811]]) 0.5269421935081482\n",
      "811 tensor([[0.4623],\n",
      "        [0.5802],\n",
      "        [0.6896],\n",
      "        [0.7812]]) 0.5267563462257385\n",
      "812 tensor([[0.4621],\n",
      "        [0.5801],\n",
      "        [0.6896],\n",
      "        [0.7813]]) 0.5265706181526184\n",
      "813 tensor([[0.4619],\n",
      "        [0.5800],\n",
      "        [0.6896],\n",
      "        [0.7814]]) 0.5263850092887878\n",
      "814 tensor([[0.4617],\n",
      "        [0.5799],\n",
      "        [0.6896],\n",
      "        [0.7815]]) 0.5261995196342468\n",
      "815 tensor([[0.4615],\n",
      "        [0.5798],\n",
      "        [0.6897],\n",
      "        [0.7816]]) 0.5260141491889954\n",
      "816 tensor([[0.4613],\n",
      "        [0.5798],\n",
      "        [0.6897],\n",
      "        [0.7817]]) 0.5258288979530334\n",
      "817 tensor([[0.4611],\n",
      "        [0.5797],\n",
      "        [0.6897],\n",
      "        [0.7818]]) 0.5256438255310059\n",
      "818 tensor([[0.4609],\n",
      "        [0.5796],\n",
      "        [0.6897],\n",
      "        [0.7819]]) 0.5254588723182678\n",
      "819 tensor([[0.4607],\n",
      "        [0.5795],\n",
      "        [0.6897],\n",
      "        [0.7820]]) 0.5252740979194641\n",
      "820 tensor([[0.4605],\n",
      "        [0.5794],\n",
      "        [0.6898],\n",
      "        [0.7821]]) 0.5250893235206604\n",
      "821 tensor([[0.4603],\n",
      "        [0.5793],\n",
      "        [0.6898],\n",
      "        [0.7822]]) 0.5249046683311462\n",
      "822 tensor([[0.4601],\n",
      "        [0.5792],\n",
      "        [0.6898],\n",
      "        [0.7823]]) 0.5247202515602112\n",
      "823 tensor([[0.4599],\n",
      "        [0.5791],\n",
      "        [0.6898],\n",
      "        [0.7823]]) 0.5245358943939209\n",
      "824 tensor([[0.4597],\n",
      "        [0.5790],\n",
      "        [0.6898],\n",
      "        [0.7824]]) 0.5243517160415649\n",
      "825 tensor([[0.4595],\n",
      "        [0.5790],\n",
      "        [0.6899],\n",
      "        [0.7825]]) 0.5241675972938538\n",
      "826 tensor([[0.4593],\n",
      "        [0.5789],\n",
      "        [0.6899],\n",
      "        [0.7826]]) 0.5239837169647217\n",
      "827 tensor([[0.4591],\n",
      "        [0.5788],\n",
      "        [0.6899],\n",
      "        [0.7827]]) 0.5237998962402344\n",
      "828 tensor([[0.4588],\n",
      "        [0.5787],\n",
      "        [0.6899],\n",
      "        [0.7828]]) 0.5236161351203918\n",
      "829 tensor([[0.4586],\n",
      "        [0.5786],\n",
      "        [0.6899],\n",
      "        [0.7829]]) 0.5234324932098389\n",
      "830 tensor([[0.4584],\n",
      "        [0.5785],\n",
      "        [0.6900],\n",
      "        [0.7830]]) 0.523249089717865\n",
      "831 tensor([[0.4582],\n",
      "        [0.5784],\n",
      "        [0.6900],\n",
      "        [0.7831]]) 0.5230658054351807\n",
      "832 tensor([[0.4580],\n",
      "        [0.5783],\n",
      "        [0.6900],\n",
      "        [0.7832]]) 0.5228825807571411\n",
      "833 tensor([[0.4578],\n",
      "        [0.5782],\n",
      "        [0.6900],\n",
      "        [0.7833]]) 0.5226994752883911\n",
      "834 tensor([[0.4576],\n",
      "        [0.5782],\n",
      "        [0.6901],\n",
      "        [0.7834]]) 0.5225164890289307\n",
      "835 tensor([[0.4574],\n",
      "        [0.5781],\n",
      "        [0.6901],\n",
      "        [0.7835]]) 0.5223338007926941\n",
      "836 tensor([[0.4572],\n",
      "        [0.5780],\n",
      "        [0.6901],\n",
      "        [0.7836]]) 0.5221510529518127\n",
      "837 tensor([[0.4570],\n",
      "        [0.5779],\n",
      "        [0.6901],\n",
      "        [0.7837]]) 0.521968424320221\n",
      "838 tensor([[0.4568],\n",
      "        [0.5778],\n",
      "        [0.6901],\n",
      "        [0.7838]]) 0.5217860341072083\n",
      "839 tensor([[0.4566],\n",
      "        [0.5777],\n",
      "        [0.6902],\n",
      "        [0.7838]]) 0.5216037034988403\n",
      "840 tensor([[0.4564],\n",
      "        [0.5776],\n",
      "        [0.6902],\n",
      "        [0.7839]]) 0.5214214324951172\n",
      "841 tensor([[0.4562],\n",
      "        [0.5775],\n",
      "        [0.6902],\n",
      "        [0.7840]]) 0.5212393999099731\n",
      "842 tensor([[0.4560],\n",
      "        [0.5775],\n",
      "        [0.6902],\n",
      "        [0.7841]]) 0.5210574269294739\n",
      "843 tensor([[0.4558],\n",
      "        [0.5774],\n",
      "        [0.6902],\n",
      "        [0.7842]]) 0.5208756923675537\n",
      "844 tensor([[0.4556],\n",
      "        [0.5773],\n",
      "        [0.6903],\n",
      "        [0.7843]]) 0.5206939578056335\n",
      "845 tensor([[0.4554],\n",
      "        [0.5772],\n",
      "        [0.6903],\n",
      "        [0.7844]]) 0.5205124020576477\n",
      "846 tensor([[0.4552],\n",
      "        [0.5771],\n",
      "        [0.6903],\n",
      "        [0.7845]]) 0.5203309059143066\n",
      "847 tensor([[0.4550],\n",
      "        [0.5770],\n",
      "        [0.6903],\n",
      "        [0.7846]]) 0.5201496481895447\n",
      "848 tensor([[0.4548],\n",
      "        [0.5769],\n",
      "        [0.6903],\n",
      "        [0.7847]]) 0.5199684500694275\n",
      "849 tensor([[0.4546],\n",
      "        [0.5768],\n",
      "        [0.6904],\n",
      "        [0.7848]]) 0.5197873115539551\n",
      "850 tensor([[0.4544],\n",
      "        [0.5768],\n",
      "        [0.6904],\n",
      "        [0.7849]]) 0.519606351852417\n",
      "851 tensor([[0.4542],\n",
      "        [0.5767],\n",
      "        [0.6904],\n",
      "        [0.7850]]) 0.5194255113601685\n",
      "852 tensor([[0.4540],\n",
      "        [0.5766],\n",
      "        [0.6904],\n",
      "        [0.7851]]) 0.5192447900772095\n",
      "853 tensor([[0.4538],\n",
      "        [0.5765],\n",
      "        [0.6904],\n",
      "        [0.7851]]) 0.5190643072128296\n",
      "854 tensor([[0.4536],\n",
      "        [0.5764],\n",
      "        [0.6905],\n",
      "        [0.7852]]) 0.5188837647438049\n",
      "855 tensor([[0.4534],\n",
      "        [0.5763],\n",
      "        [0.6905],\n",
      "        [0.7853]]) 0.5187035202980042\n",
      "856 tensor([[0.4532],\n",
      "        [0.5762],\n",
      "        [0.6905],\n",
      "        [0.7854]]) 0.5185232758522034\n",
      "857 tensor([[0.4530],\n",
      "        [0.5761],\n",
      "        [0.6905],\n",
      "        [0.7855]]) 0.5183431506156921\n",
      "858 tensor([[0.4528],\n",
      "        [0.5761],\n",
      "        [0.6905],\n",
      "        [0.7856]]) 0.5181632041931152\n",
      "859 tensor([[0.4526],\n",
      "        [0.5760],\n",
      "        [0.6906],\n",
      "        [0.7857]]) 0.5179832577705383\n",
      "860 tensor([[0.4524],\n",
      "        [0.5759],\n",
      "        [0.6906],\n",
      "        [0.7858]]) 0.5178036689758301\n",
      "861 tensor([[0.4522],\n",
      "        [0.5758],\n",
      "        [0.6906],\n",
      "        [0.7859]]) 0.517624020576477\n",
      "862 tensor([[0.4520],\n",
      "        [0.5757],\n",
      "        [0.6906],\n",
      "        [0.7860]]) 0.5174445509910583\n",
      "863 tensor([[0.4518],\n",
      "        [0.5756],\n",
      "        [0.6906],\n",
      "        [0.7861]]) 0.5172652006149292\n",
      "864 tensor([[0.4516],\n",
      "        [0.5755],\n",
      "        [0.6907],\n",
      "        [0.7862]]) 0.5170860290527344\n",
      "865 tensor([[0.4514],\n",
      "        [0.5754],\n",
      "        [0.6907],\n",
      "        [0.7863]]) 0.5169069170951843\n",
      "866 tensor([[0.4512],\n",
      "        [0.5754],\n",
      "        [0.6907],\n",
      "        [0.7863]]) 0.5167279243469238\n",
      "867 tensor([[0.4510],\n",
      "        [0.5753],\n",
      "        [0.6907],\n",
      "        [0.7864]]) 0.5165490508079529\n",
      "868 tensor([[0.4508],\n",
      "        [0.5752],\n",
      "        [0.6907],\n",
      "        [0.7865]]) 0.5163702964782715\n",
      "869 tensor([[0.4506],\n",
      "        [0.5751],\n",
      "        [0.6908],\n",
      "        [0.7866]]) 0.5161916613578796\n",
      "870 tensor([[0.4504],\n",
      "        [0.5750],\n",
      "        [0.6908],\n",
      "        [0.7867]]) 0.5160132646560669\n",
      "871 tensor([[0.4502],\n",
      "        [0.5749],\n",
      "        [0.6908],\n",
      "        [0.7868]]) 0.5158348679542542\n",
      "872 tensor([[0.4500],\n",
      "        [0.5748],\n",
      "        [0.6908],\n",
      "        [0.7869]]) 0.515656590461731\n",
      "873 tensor([[0.4498],\n",
      "        [0.5748],\n",
      "        [0.6908],\n",
      "        [0.7870]]) 0.5154784917831421\n",
      "874 tensor([[0.4496],\n",
      "        [0.5747],\n",
      "        [0.6909],\n",
      "        [0.7871]]) 0.5153003931045532\n",
      "875 tensor([[0.4494],\n",
      "        [0.5746],\n",
      "        [0.6909],\n",
      "        [0.7872]]) 0.5151225924491882\n",
      "876 tensor([[0.4492],\n",
      "        [0.5745],\n",
      "        [0.6909],\n",
      "        [0.7873]]) 0.5149447917938232\n",
      "877 tensor([[0.4490],\n",
      "        [0.5744],\n",
      "        [0.6909],\n",
      "        [0.7874]]) 0.5147671699523926\n",
      "878 tensor([[0.4488],\n",
      "        [0.5743],\n",
      "        [0.6909],\n",
      "        [0.7874]]) 0.5145896673202515\n",
      "879 tensor([[0.4486],\n",
      "        [0.5742],\n",
      "        [0.6910],\n",
      "        [0.7875]]) 0.5144122242927551\n",
      "880 tensor([[0.4484],\n",
      "        [0.5741],\n",
      "        [0.6910],\n",
      "        [0.7876]]) 0.5142349600791931\n",
      "881 tensor([[0.4482],\n",
      "        [0.5741],\n",
      "        [0.6910],\n",
      "        [0.7877]]) 0.5140578746795654\n",
      "882 tensor([[0.4480],\n",
      "        [0.5740],\n",
      "        [0.6910],\n",
      "        [0.7878]]) 0.5138807892799377\n",
      "883 tensor([[0.4478],\n",
      "        [0.5739],\n",
      "        [0.6910],\n",
      "        [0.7879]]) 0.5137038230895996\n",
      "884 tensor([[0.4476],\n",
      "        [0.5738],\n",
      "        [0.6911],\n",
      "        [0.7880]]) 0.5135270953178406\n",
      "885 tensor([[0.4474],\n",
      "        [0.5737],\n",
      "        [0.6911],\n",
      "        [0.7881]]) 0.5133504271507263\n",
      "886 tensor([[0.4472],\n",
      "        [0.5736],\n",
      "        [0.6911],\n",
      "        [0.7882]]) 0.5131738781929016\n",
      "887 tensor([[0.4470],\n",
      "        [0.5735],\n",
      "        [0.6911],\n",
      "        [0.7883]]) 0.5129973888397217\n",
      "888 tensor([[0.4468],\n",
      "        [0.5735],\n",
      "        [0.6912],\n",
      "        [0.7884]]) 0.5128210783004761\n",
      "889 tensor([[0.4466],\n",
      "        [0.5734],\n",
      "        [0.6912],\n",
      "        [0.7884]]) 0.5126449465751648\n",
      "890 tensor([[0.4464],\n",
      "        [0.5733],\n",
      "        [0.6912],\n",
      "        [0.7885]]) 0.5124688744544983\n",
      "891 tensor([[0.4462],\n",
      "        [0.5732],\n",
      "        [0.6912],\n",
      "        [0.7886]]) 0.5122928619384766\n",
      "892 tensor([[0.4460],\n",
      "        [0.5731],\n",
      "        [0.6912],\n",
      "        [0.7887]]) 0.5121170282363892\n",
      "893 tensor([[0.4458],\n",
      "        [0.5730],\n",
      "        [0.6913],\n",
      "        [0.7888]]) 0.5119413733482361\n",
      "894 tensor([[0.4456],\n",
      "        [0.5729],\n",
      "        [0.6913],\n",
      "        [0.7889]]) 0.5117657780647278\n",
      "895 tensor([[0.4454],\n",
      "        [0.5729],\n",
      "        [0.6913],\n",
      "        [0.7890]]) 0.511590301990509\n",
      "896 tensor([[0.4452],\n",
      "        [0.5728],\n",
      "        [0.6913],\n",
      "        [0.7891]]) 0.5114150047302246\n",
      "897 tensor([[0.4450],\n",
      "        [0.5727],\n",
      "        [0.6913],\n",
      "        [0.7892]]) 0.511239767074585\n",
      "898 tensor([[0.4448],\n",
      "        [0.5726],\n",
      "        [0.6914],\n",
      "        [0.7893]]) 0.5110646486282349\n",
      "899 tensor([[0.4446],\n",
      "        [0.5725],\n",
      "        [0.6914],\n",
      "        [0.7894]]) 0.5108895897865295\n",
      "900 tensor([[0.4444],\n",
      "        [0.5724],\n",
      "        [0.6914],\n",
      "        [0.7894]]) 0.5107147097587585\n",
      "901 tensor([[0.4442],\n",
      "        [0.5723],\n",
      "        [0.6914],\n",
      "        [0.7895]]) 0.5105399489402771\n",
      "902 tensor([[0.4440],\n",
      "        [0.5723],\n",
      "        [0.6914],\n",
      "        [0.7896]]) 0.5103653073310852\n",
      "903 tensor([[0.4438],\n",
      "        [0.5722],\n",
      "        [0.6915],\n",
      "        [0.7897]]) 0.5101907849311829\n",
      "904 tensor([[0.4436],\n",
      "        [0.5721],\n",
      "        [0.6915],\n",
      "        [0.7898]]) 0.5100164413452148\n",
      "905 tensor([[0.4435],\n",
      "        [0.5720],\n",
      "        [0.6915],\n",
      "        [0.7899]]) 0.5098421573638916\n",
      "906 tensor([[0.4433],\n",
      "        [0.5719],\n",
      "        [0.6915],\n",
      "        [0.7900]]) 0.5096679925918579\n",
      "907 tensor([[0.4431],\n",
      "        [0.5718],\n",
      "        [0.6915],\n",
      "        [0.7901]]) 0.5094939470291138\n",
      "908 tensor([[0.4429],\n",
      "        [0.5717],\n",
      "        [0.6916],\n",
      "        [0.7902]]) 0.5093200206756592\n",
      "909 tensor([[0.4427],\n",
      "        [0.5717],\n",
      "        [0.6916],\n",
      "        [0.7903]]) 0.5091462135314941\n",
      "910 tensor([[0.4425],\n",
      "        [0.5716],\n",
      "        [0.6916],\n",
      "        [0.7903]]) 0.5089724659919739\n",
      "911 tensor([[0.4423],\n",
      "        [0.5715],\n",
      "        [0.6916],\n",
      "        [0.7904]]) 0.5087989568710327\n",
      "912 tensor([[0.4421],\n",
      "        [0.5714],\n",
      "        [0.6916],\n",
      "        [0.7905]]) 0.5086255669593811\n",
      "913 tensor([[0.4419],\n",
      "        [0.5713],\n",
      "        [0.6917],\n",
      "        [0.7906]]) 0.5084521770477295\n",
      "914 tensor([[0.4417],\n",
      "        [0.5712],\n",
      "        [0.6917],\n",
      "        [0.7907]]) 0.5082789063453674\n",
      "915 tensor([[0.4415],\n",
      "        [0.5711],\n",
      "        [0.6917],\n",
      "        [0.7908]]) 0.5081058144569397\n",
      "916 tensor([[0.4413],\n",
      "        [0.5711],\n",
      "        [0.6917],\n",
      "        [0.7909]]) 0.5079328417778015\n",
      "917 tensor([[0.4411],\n",
      "        [0.5710],\n",
      "        [0.6917],\n",
      "        [0.7910]]) 0.5077599883079529\n",
      "918 tensor([[0.4409],\n",
      "        [0.5709],\n",
      "        [0.6918],\n",
      "        [0.7911]]) 0.5075872540473938\n",
      "919 tensor([[0.4407],\n",
      "        [0.5708],\n",
      "        [0.6918],\n",
      "        [0.7912]]) 0.5074146389961243\n",
      "920 tensor([[0.4405],\n",
      "        [0.5707],\n",
      "        [0.6918],\n",
      "        [0.7912]]) 0.5072421431541443\n",
      "921 tensor([[0.4403],\n",
      "        [0.5706],\n",
      "        [0.6918],\n",
      "        [0.7913]]) 0.5070697069168091\n",
      "922 tensor([[0.4401],\n",
      "        [0.5705],\n",
      "        [0.6919],\n",
      "        [0.7914]]) 0.5068974494934082\n",
      "923 tensor([[0.4399],\n",
      "        [0.5705],\n",
      "        [0.6919],\n",
      "        [0.7915]]) 0.5067252516746521\n",
      "924 tensor([[0.4397],\n",
      "        [0.5704],\n",
      "        [0.6919],\n",
      "        [0.7916]]) 0.5065532326698303\n",
      "925 tensor([[0.4395],\n",
      "        [0.5703],\n",
      "        [0.6919],\n",
      "        [0.7917]]) 0.5063813328742981\n",
      "926 tensor([[0.4393],\n",
      "        [0.5702],\n",
      "        [0.6919],\n",
      "        [0.7918]]) 0.5062094926834106\n",
      "927 tensor([[0.4392],\n",
      "        [0.5701],\n",
      "        [0.6920],\n",
      "        [0.7919]]) 0.5060377717018127\n",
      "928 tensor([[0.4390],\n",
      "        [0.5700],\n",
      "        [0.6920],\n",
      "        [0.7920]]) 0.5058662295341492\n",
      "929 tensor([[0.4388],\n",
      "        [0.5699],\n",
      "        [0.6920],\n",
      "        [0.7920]]) 0.5056947469711304\n",
      "930 tensor([[0.4386],\n",
      "        [0.5699],\n",
      "        [0.6920],\n",
      "        [0.7921]]) 0.5055234432220459\n",
      "931 tensor([[0.4384],\n",
      "        [0.5698],\n",
      "        [0.6920],\n",
      "        [0.7922]]) 0.505352258682251\n",
      "932 tensor([[0.4382],\n",
      "        [0.5697],\n",
      "        [0.6921],\n",
      "        [0.7923]]) 0.505181074142456\n",
      "933 tensor([[0.4380],\n",
      "        [0.5696],\n",
      "        [0.6921],\n",
      "        [0.7924]]) 0.5050100684165955\n",
      "934 tensor([[0.4378],\n",
      "        [0.5695],\n",
      "        [0.6921],\n",
      "        [0.7925]]) 0.5048391819000244\n",
      "935 tensor([[0.4376],\n",
      "        [0.5694],\n",
      "        [0.6921],\n",
      "        [0.7926]]) 0.5046684145927429\n",
      "936 tensor([[0.4374],\n",
      "        [0.5694],\n",
      "        [0.6921],\n",
      "        [0.7927]]) 0.5044978260993958\n",
      "937 tensor([[0.4372],\n",
      "        [0.5693],\n",
      "        [0.6922],\n",
      "        [0.7928]]) 0.5043272376060486\n",
      "938 tensor([[0.4370],\n",
      "        [0.5692],\n",
      "        [0.6922],\n",
      "        [0.7928]]) 0.5041568875312805\n",
      "939 tensor([[0.4368],\n",
      "        [0.5691],\n",
      "        [0.6922],\n",
      "        [0.7929]]) 0.5039865374565125\n",
      "940 tensor([[0.4366],\n",
      "        [0.5690],\n",
      "        [0.6922],\n",
      "        [0.7930]]) 0.5038163661956787\n",
      "941 tensor([[0.4364],\n",
      "        [0.5689],\n",
      "        [0.6922],\n",
      "        [0.7931]]) 0.5036463141441345\n",
      "942 tensor([[0.4362],\n",
      "        [0.5688],\n",
      "        [0.6923],\n",
      "        [0.7932]]) 0.5034763813018799\n",
      "943 tensor([[0.4361],\n",
      "        [0.5688],\n",
      "        [0.6923],\n",
      "        [0.7933]]) 0.50330650806427\n",
      "944 tensor([[0.4359],\n",
      "        [0.5687],\n",
      "        [0.6923],\n",
      "        [0.7934]]) 0.5031368136405945\n",
      "945 tensor([[0.4357],\n",
      "        [0.5686],\n",
      "        [0.6923],\n",
      "        [0.7935]]) 0.5029671788215637\n",
      "946 tensor([[0.4355],\n",
      "        [0.5685],\n",
      "        [0.6923],\n",
      "        [0.7935]]) 0.5027977228164673\n",
      "947 tensor([[0.4353],\n",
      "        [0.5684],\n",
      "        [0.6924],\n",
      "        [0.7936]]) 0.5026282668113708\n",
      "948 tensor([[0.4351],\n",
      "        [0.5683],\n",
      "        [0.6924],\n",
      "        [0.7937]]) 0.5024590492248535\n",
      "949 tensor([[0.4349],\n",
      "        [0.5683],\n",
      "        [0.6924],\n",
      "        [0.7938]]) 0.502289891242981\n",
      "950 tensor([[0.4347],\n",
      "        [0.5682],\n",
      "        [0.6924],\n",
      "        [0.7939]]) 0.502120852470398\n",
      "951 tensor([[0.4345],\n",
      "        [0.5681],\n",
      "        [0.6925],\n",
      "        [0.7940]]) 0.5019518733024597\n",
      "952 tensor([[0.4343],\n",
      "        [0.5680],\n",
      "        [0.6925],\n",
      "        [0.7941]]) 0.5017831325531006\n",
      "953 tensor([[0.4341],\n",
      "        [0.5679],\n",
      "        [0.6925],\n",
      "        [0.7942]]) 0.5016143918037415\n",
      "954 tensor([[0.4339],\n",
      "        [0.5678],\n",
      "        [0.6925],\n",
      "        [0.7943]]) 0.5014458298683167\n",
      "955 tensor([[0.4337],\n",
      "        [0.5678],\n",
      "        [0.6925],\n",
      "        [0.7943]]) 0.5012773871421814\n",
      "956 tensor([[0.4336],\n",
      "        [0.5677],\n",
      "        [0.6926],\n",
      "        [0.7944]]) 0.5011090040206909\n",
      "957 tensor([[0.4334],\n",
      "        [0.5676],\n",
      "        [0.6926],\n",
      "        [0.7945]]) 0.5009407997131348\n",
      "958 tensor([[0.4332],\n",
      "        [0.5675],\n",
      "        [0.6926],\n",
      "        [0.7946]]) 0.5007726550102234\n",
      "959 tensor([[0.4330],\n",
      "        [0.5674],\n",
      "        [0.6926],\n",
      "        [0.7947]]) 0.5006046891212463\n",
      "960 tensor([[0.4328],\n",
      "        [0.5673],\n",
      "        [0.6926],\n",
      "        [0.7948]]) 0.5004367828369141\n",
      "961 tensor([[0.4326],\n",
      "        [0.5673],\n",
      "        [0.6927],\n",
      "        [0.7949]]) 0.5002689361572266\n",
      "962 tensor([[0.4324],\n",
      "        [0.5672],\n",
      "        [0.6927],\n",
      "        [0.7950]]) 0.5001013278961182\n",
      "963 tensor([[0.4322],\n",
      "        [0.5671],\n",
      "        [0.6927],\n",
      "        [0.7950]]) 0.49993371963500977\n",
      "964 tensor([[0.4320],\n",
      "        [0.5670],\n",
      "        [0.6927],\n",
      "        [0.7951]]) 0.4997663199901581\n",
      "965 tensor([[0.4318],\n",
      "        [0.5669],\n",
      "        [0.6927],\n",
      "        [0.7952]]) 0.4995989501476288\n",
      "966 tensor([[0.4316],\n",
      "        [0.5668],\n",
      "        [0.6928],\n",
      "        [0.7953]]) 0.4994317293167114\n",
      "967 tensor([[0.4314],\n",
      "        [0.5667],\n",
      "        [0.6928],\n",
      "        [0.7954]]) 0.499264657497406\n",
      "968 tensor([[0.4313],\n",
      "        [0.5667],\n",
      "        [0.6928],\n",
      "        [0.7955]]) 0.49909764528274536\n",
      "969 tensor([[0.4311],\n",
      "        [0.5666],\n",
      "        [0.6928],\n",
      "        [0.7956]]) 0.49893075227737427\n",
      "970 tensor([[0.4309],\n",
      "        [0.5665],\n",
      "        [0.6928],\n",
      "        [0.7957]]) 0.4987640082836151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971 tensor([[0.4307],\n",
      "        [0.5664],\n",
      "        [0.6929],\n",
      "        [0.7957]]) 0.49859732389450073\n",
      "972 tensor([[0.4305],\n",
      "        [0.5663],\n",
      "        [0.6929],\n",
      "        [0.7958]]) 0.4984307885169983\n",
      "973 tensor([[0.4303],\n",
      "        [0.5662],\n",
      "        [0.6929],\n",
      "        [0.7959]]) 0.4982643127441406\n",
      "974 tensor([[0.4301],\n",
      "        [0.5662],\n",
      "        [0.6929],\n",
      "        [0.7960]]) 0.49809807538986206\n",
      "975 tensor([[0.4299],\n",
      "        [0.5661],\n",
      "        [0.6929],\n",
      "        [0.7961]]) 0.4979318380355835\n",
      "976 tensor([[0.4297],\n",
      "        [0.5660],\n",
      "        [0.6930],\n",
      "        [0.7962]]) 0.49776574969291687\n",
      "977 tensor([[0.4295],\n",
      "        [0.5659],\n",
      "        [0.6930],\n",
      "        [0.7963]]) 0.4975998103618622\n",
      "978 tensor([[0.4294],\n",
      "        [0.5658],\n",
      "        [0.6930],\n",
      "        [0.7963]]) 0.49743393063545227\n",
      "979 tensor([[0.4292],\n",
      "        [0.5657],\n",
      "        [0.6930],\n",
      "        [0.7964]]) 0.4972681403160095\n",
      "980 tensor([[0.4290],\n",
      "        [0.5657],\n",
      "        [0.6931],\n",
      "        [0.7965]]) 0.4971025586128235\n",
      "981 tensor([[0.4288],\n",
      "        [0.5656],\n",
      "        [0.6931],\n",
      "        [0.7966]]) 0.49693700671195984\n",
      "982 tensor([[0.4286],\n",
      "        [0.5655],\n",
      "        [0.6931],\n",
      "        [0.7967]]) 0.4967714846134186\n",
      "983 tensor([[0.4284],\n",
      "        [0.5654],\n",
      "        [0.6931],\n",
      "        [0.7968]]) 0.49660632014274597\n",
      "984 tensor([[0.4282],\n",
      "        [0.5653],\n",
      "        [0.6931],\n",
      "        [0.7969]]) 0.4964410662651062\n",
      "985 tensor([[0.4280],\n",
      "        [0.5653],\n",
      "        [0.6932],\n",
      "        [0.7970]]) 0.49627596139907837\n",
      "986 tensor([[0.4278],\n",
      "        [0.5652],\n",
      "        [0.6932],\n",
      "        [0.7970]]) 0.4961110055446625\n",
      "987 tensor([[0.4276],\n",
      "        [0.5651],\n",
      "        [0.6932],\n",
      "        [0.7971]]) 0.49594613909721375\n",
      "988 tensor([[0.4275],\n",
      "        [0.5650],\n",
      "        [0.6932],\n",
      "        [0.7972]]) 0.4957813620567322\n",
      "989 tensor([[0.4273],\n",
      "        [0.5649],\n",
      "        [0.6932],\n",
      "        [0.7973]]) 0.4956167936325073\n",
      "990 tensor([[0.4271],\n",
      "        [0.5648],\n",
      "        [0.6933],\n",
      "        [0.7974]]) 0.4954521954059601\n",
      "991 tensor([[0.4269],\n",
      "        [0.5648],\n",
      "        [0.6933],\n",
      "        [0.7975]]) 0.49528777599334717\n",
      "992 tensor([[0.4267],\n",
      "        [0.5647],\n",
      "        [0.6933],\n",
      "        [0.7976]]) 0.4951235055923462\n",
      "993 tensor([[0.4265],\n",
      "        [0.5646],\n",
      "        [0.6933],\n",
      "        [0.7976]]) 0.49495929479599\n",
      "994 tensor([[0.4263],\n",
      "        [0.5645],\n",
      "        [0.6933],\n",
      "        [0.7977]]) 0.49479520320892334\n",
      "995 tensor([[0.4261],\n",
      "        [0.5644],\n",
      "        [0.6934],\n",
      "        [0.7978]]) 0.49463117122650146\n",
      "996 tensor([[0.4259],\n",
      "        [0.5643],\n",
      "        [0.6934],\n",
      "        [0.7979]]) 0.4944673776626587\n",
      "997 tensor([[0.4258],\n",
      "        [0.5643],\n",
      "        [0.6934],\n",
      "        [0.7980]]) 0.4943035840988159\n",
      "998 tensor([[0.4256],\n",
      "        [0.5642],\n",
      "        [0.6934],\n",
      "        [0.7981]]) 0.49413996934890747\n",
      "999 tensor([[0.4254],\n",
      "        [0.5641],\n",
      "        [0.6934],\n",
      "        [0.7982]]) 0.4939763844013214\n",
      "1000 tensor([[0.4252],\n",
      "        [0.5640],\n",
      "        [0.6935],\n",
      "        [0.7982]]) 0.4938129484653473\n",
      "1001 tensor([[0.4250],\n",
      "        [0.5639],\n",
      "        [0.6935],\n",
      "        [0.7983]]) 0.4936496615409851\n",
      "1002 tensor([[0.4248],\n",
      "        [0.5638],\n",
      "        [0.6935],\n",
      "        [0.7984]]) 0.4934864342212677\n",
      "1003 tensor([[0.4246],\n",
      "        [0.5638],\n",
      "        [0.6935],\n",
      "        [0.7985]]) 0.493323415517807\n",
      "1004 tensor([[0.4244],\n",
      "        [0.5637],\n",
      "        [0.6936],\n",
      "        [0.7986]]) 0.4931604266166687\n",
      "1005 tensor([[0.4243],\n",
      "        [0.5636],\n",
      "        [0.6936],\n",
      "        [0.7987]]) 0.49299749732017517\n",
      "1006 tensor([[0.4241],\n",
      "        [0.5635],\n",
      "        [0.6936],\n",
      "        [0.7988]]) 0.49283474683761597\n",
      "1007 tensor([[0.4239],\n",
      "        [0.5634],\n",
      "        [0.6936],\n",
      "        [0.7988]]) 0.4926720857620239\n",
      "1008 tensor([[0.4237],\n",
      "        [0.5634],\n",
      "        [0.6936],\n",
      "        [0.7989]]) 0.49250954389572144\n",
      "1009 tensor([[0.4235],\n",
      "        [0.5633],\n",
      "        [0.6937],\n",
      "        [0.7990]]) 0.4923470616340637\n",
      "1010 tensor([[0.4233],\n",
      "        [0.5632],\n",
      "        [0.6937],\n",
      "        [0.7991]]) 0.49218475818634033\n",
      "1011 tensor([[0.4231],\n",
      "        [0.5631],\n",
      "        [0.6937],\n",
      "        [0.7992]]) 0.49202245473861694\n",
      "1012 tensor([[0.4229],\n",
      "        [0.5630],\n",
      "        [0.6937],\n",
      "        [0.7993]]) 0.49186038970947266\n",
      "1013 tensor([[0.4228],\n",
      "        [0.5629],\n",
      "        [0.6937],\n",
      "        [0.7994]]) 0.49169838428497314\n",
      "1014 tensor([[0.4226],\n",
      "        [0.5629],\n",
      "        [0.6938],\n",
      "        [0.7994]]) 0.4915364980697632\n",
      "1015 tensor([[0.4224],\n",
      "        [0.5628],\n",
      "        [0.6938],\n",
      "        [0.7995]]) 0.4913747310638428\n",
      "1016 tensor([[0.4222],\n",
      "        [0.5627],\n",
      "        [0.6938],\n",
      "        [0.7996]]) 0.49121302366256714\n",
      "1017 tensor([[0.4220],\n",
      "        [0.5626],\n",
      "        [0.6938],\n",
      "        [0.7997]]) 0.49105149507522583\n",
      "1018 tensor([[0.4218],\n",
      "        [0.5625],\n",
      "        [0.6938],\n",
      "        [0.7998]]) 0.4908899962902069\n",
      "1019 tensor([[0.4216],\n",
      "        [0.5624],\n",
      "        [0.6939],\n",
      "        [0.7999]]) 0.4907286465167999\n",
      "1020 tensor([[0.4215],\n",
      "        [0.5624],\n",
      "        [0.6939],\n",
      "        [0.7999]]) 0.4905674159526825\n",
      "1021 tensor([[0.4213],\n",
      "        [0.5623],\n",
      "        [0.6939],\n",
      "        [0.8000]]) 0.490406334400177\n",
      "1022 tensor([[0.4211],\n",
      "        [0.5622],\n",
      "        [0.6939],\n",
      "        [0.8001]]) 0.49024519324302673\n",
      "1023 tensor([[0.4209],\n",
      "        [0.5621],\n",
      "        [0.6940],\n",
      "        [0.8002]]) 0.49008435010910034\n",
      "1024 tensor([[0.4207],\n",
      "        [0.5620],\n",
      "        [0.6940],\n",
      "        [0.8003]]) 0.4899234473705292\n",
      "1025 tensor([[0.4205],\n",
      "        [0.5620],\n",
      "        [0.6940],\n",
      "        [0.8004]]) 0.4897628128528595\n",
      "1026 tensor([[0.4203],\n",
      "        [0.5619],\n",
      "        [0.6940],\n",
      "        [0.8005]]) 0.48960214853286743\n",
      "1027 tensor([[0.4202],\n",
      "        [0.5618],\n",
      "        [0.6940],\n",
      "        [0.8005]]) 0.48944172263145447\n",
      "1028 tensor([[0.4200],\n",
      "        [0.5617],\n",
      "        [0.6941],\n",
      "        [0.8006]]) 0.4892812967300415\n",
      "1029 tensor([[0.4198],\n",
      "        [0.5616],\n",
      "        [0.6941],\n",
      "        [0.8007]]) 0.4891210198402405\n",
      "1030 tensor([[0.4196],\n",
      "        [0.5616],\n",
      "        [0.6941],\n",
      "        [0.8008]]) 0.4889608323574066\n",
      "1031 tensor([[0.4194],\n",
      "        [0.5615],\n",
      "        [0.6941],\n",
      "        [0.8009]]) 0.4888008236885071\n",
      "1032 tensor([[0.4192],\n",
      "        [0.5614],\n",
      "        [0.6941],\n",
      "        [0.8010]]) 0.48864084482192993\n",
      "1033 tensor([[0.4190],\n",
      "        [0.5613],\n",
      "        [0.6942],\n",
      "        [0.8010]]) 0.48848098516464233\n",
      "1034 tensor([[0.4189],\n",
      "        [0.5612],\n",
      "        [0.6942],\n",
      "        [0.8011]]) 0.4883212447166443\n",
      "1035 tensor([[0.4187],\n",
      "        [0.5611],\n",
      "        [0.6942],\n",
      "        [0.8012]]) 0.4881616532802582\n",
      "1036 tensor([[0.4185],\n",
      "        [0.5611],\n",
      "        [0.6942],\n",
      "        [0.8013]]) 0.48800209164619446\n",
      "1037 tensor([[0.4183],\n",
      "        [0.5610],\n",
      "        [0.6942],\n",
      "        [0.8014]]) 0.4878426790237427\n",
      "1038 tensor([[0.4181],\n",
      "        [0.5609],\n",
      "        [0.6943],\n",
      "        [0.8015]]) 0.48768338561058044\n",
      "1039 tensor([[0.4179],\n",
      "        [0.5608],\n",
      "        [0.6943],\n",
      "        [0.8015]]) 0.487524151802063\n",
      "1040 tensor([[0.4177],\n",
      "        [0.5607],\n",
      "        [0.6943],\n",
      "        [0.8016]]) 0.48736506700515747\n",
      "1041 tensor([[0.4176],\n",
      "        [0.5607],\n",
      "        [0.6943],\n",
      "        [0.8017]]) 0.4872061014175415\n",
      "1042 tensor([[0.4174],\n",
      "        [0.5606],\n",
      "        [0.6944],\n",
      "        [0.8018]]) 0.4870471656322479\n",
      "1043 tensor([[0.4172],\n",
      "        [0.5605],\n",
      "        [0.6944],\n",
      "        [0.8019]]) 0.48688843846321106\n",
      "1044 tensor([[0.4170],\n",
      "        [0.5604],\n",
      "        [0.6944],\n",
      "        [0.8020]]) 0.4867297410964966\n",
      "1045 tensor([[0.4168],\n",
      "        [0.5603],\n",
      "        [0.6944],\n",
      "        [0.8020]]) 0.48657119274139404\n",
      "1046 tensor([[0.4166],\n",
      "        [0.5603],\n",
      "        [0.6944],\n",
      "        [0.8021]]) 0.4864126741886139\n",
      "1047 tensor([[0.4165],\n",
      "        [0.5602],\n",
      "        [0.6945],\n",
      "        [0.8022]]) 0.48625439405441284\n",
      "1048 tensor([[0.4163],\n",
      "        [0.5601],\n",
      "        [0.6945],\n",
      "        [0.8023]]) 0.4860960841178894\n",
      "1049 tensor([[0.4161],\n",
      "        [0.5600],\n",
      "        [0.6945],\n",
      "        [0.8024]]) 0.4859379231929779\n",
      "1050 tensor([[0.4159],\n",
      "        [0.5599],\n",
      "        [0.6945],\n",
      "        [0.8025]]) 0.48577988147735596\n",
      "1051 tensor([[0.4157],\n",
      "        [0.5598],\n",
      "        [0.6945],\n",
      "        [0.8026]]) 0.48562192916870117\n",
      "1052 tensor([[0.4155],\n",
      "        [0.5598],\n",
      "        [0.6946],\n",
      "        [0.8026]]) 0.4854641258716583\n",
      "1053 tensor([[0.4154],\n",
      "        [0.5597],\n",
      "        [0.6946],\n",
      "        [0.8027]]) 0.48530638217926025\n",
      "1054 tensor([[0.4152],\n",
      "        [0.5596],\n",
      "        [0.6946],\n",
      "        [0.8028]]) 0.4851488173007965\n",
      "1055 tensor([[0.4150],\n",
      "        [0.5595],\n",
      "        [0.6946],\n",
      "        [0.8029]]) 0.48499125242233276\n",
      "1056 tensor([[0.4148],\n",
      "        [0.5594],\n",
      "        [0.6946],\n",
      "        [0.8030]]) 0.48483386635780334\n",
      "1057 tensor([[0.4146],\n",
      "        [0.5594],\n",
      "        [0.6947],\n",
      "        [0.8030]]) 0.4846765398979187\n",
      "1058 tensor([[0.4144],\n",
      "        [0.5593],\n",
      "        [0.6947],\n",
      "        [0.8031]]) 0.48451942205429077\n",
      "1059 tensor([[0.4143],\n",
      "        [0.5592],\n",
      "        [0.6947],\n",
      "        [0.8032]]) 0.48436224460601807\n",
      "1060 tensor([[0.4141],\n",
      "        [0.5591],\n",
      "        [0.6947],\n",
      "        [0.8033]]) 0.4842052757740021\n",
      "1061 tensor([[0.4139],\n",
      "        [0.5590],\n",
      "        [0.6947],\n",
      "        [0.8034]]) 0.48404839634895325\n",
      "1062 tensor([[0.4137],\n",
      "        [0.5590],\n",
      "        [0.6948],\n",
      "        [0.8035]]) 0.48389169573783875\n",
      "1063 tensor([[0.4135],\n",
      "        [0.5589],\n",
      "        [0.6948],\n",
      "        [0.8035]]) 0.4837349057197571\n",
      "1064 tensor([[0.4134],\n",
      "        [0.5588],\n",
      "        [0.6948],\n",
      "        [0.8036]]) 0.4835783839225769\n",
      "1065 tensor([[0.4132],\n",
      "        [0.5587],\n",
      "        [0.6948],\n",
      "        [0.8037]]) 0.48342186212539673\n",
      "1066 tensor([[0.4130],\n",
      "        [0.5586],\n",
      "        [0.6949],\n",
      "        [0.8038]]) 0.48326554894447327\n",
      "1067 tensor([[0.4128],\n",
      "        [0.5586],\n",
      "        [0.6949],\n",
      "        [0.8039]]) 0.4831092953681946\n",
      "1068 tensor([[0.4126],\n",
      "        [0.5585],\n",
      "        [0.6949],\n",
      "        [0.8040]]) 0.48295313119888306\n",
      "1069 tensor([[0.4124],\n",
      "        [0.5584],\n",
      "        [0.6949],\n",
      "        [0.8040]]) 0.4827970564365387\n",
      "1070 tensor([[0.4123],\n",
      "        [0.5583],\n",
      "        [0.6949],\n",
      "        [0.8041]]) 0.4826411306858063\n",
      "1071 tensor([[0.4121],\n",
      "        [0.5582],\n",
      "        [0.6950],\n",
      "        [0.8042]]) 0.48248526453971863\n",
      "1072 tensor([[0.4119],\n",
      "        [0.5582],\n",
      "        [0.6950],\n",
      "        [0.8043]]) 0.4823295772075653\n",
      "1073 tensor([[0.4117],\n",
      "        [0.5581],\n",
      "        [0.6950],\n",
      "        [0.8044]]) 0.482173889875412\n",
      "1074 tensor([[0.4115],\n",
      "        [0.5580],\n",
      "        [0.6950],\n",
      "        [0.8045]]) 0.482018381357193\n",
      "1075 tensor([[0.4114],\n",
      "        [0.5579],\n",
      "        [0.6950],\n",
      "        [0.8045]]) 0.4818629324436188\n",
      "1076 tensor([[0.4112],\n",
      "        [0.5578],\n",
      "        [0.6951],\n",
      "        [0.8046]]) 0.4817076623439789\n",
      "1077 tensor([[0.4110],\n",
      "        [0.5578],\n",
      "        [0.6951],\n",
      "        [0.8047]]) 0.4815524220466614\n",
      "1078 tensor([[0.4108],\n",
      "        [0.5577],\n",
      "        [0.6951],\n",
      "        [0.8048]]) 0.48139724135398865\n",
      "1079 tensor([[0.4106],\n",
      "        [0.5576],\n",
      "        [0.6951],\n",
      "        [0.8049]]) 0.481242299079895\n",
      "1080 tensor([[0.4104],\n",
      "        [0.5575],\n",
      "        [0.6951],\n",
      "        [0.8049]]) 0.48108741641044617\n",
      "1081 tensor([[0.4103],\n",
      "        [0.5574],\n",
      "        [0.6952],\n",
      "        [0.8050]]) 0.4809325635433197\n",
      "1082 tensor([[0.4101],\n",
      "        [0.5574],\n",
      "        [0.6952],\n",
      "        [0.8051]]) 0.4807778000831604\n",
      "1083 tensor([[0.4099],\n",
      "        [0.5573],\n",
      "        [0.6952],\n",
      "        [0.8052]]) 0.4806232452392578\n",
      "1084 tensor([[0.4097],\n",
      "        [0.5572],\n",
      "        [0.6952],\n",
      "        [0.8053]]) 0.48046875\n",
      "1085 tensor([[0.4095],\n",
      "        [0.5571],\n",
      "        [0.6953],\n",
      "        [0.8054]]) 0.48031437397003174\n",
      "1086 tensor([[0.4094],\n",
      "        [0.5570],\n",
      "        [0.6953],\n",
      "        [0.8054]]) 0.48016002774238586\n",
      "1087 tensor([[0.4092],\n",
      "        [0.5570],\n",
      "        [0.6953],\n",
      "        [0.8055]]) 0.4800058603286743\n",
      "1088 tensor([[0.4090],\n",
      "        [0.5569],\n",
      "        [0.6953],\n",
      "        [0.8056]]) 0.47985178232192993\n",
      "1089 tensor([[0.4088],\n",
      "        [0.5568],\n",
      "        [0.6953],\n",
      "        [0.8057]]) 0.47969773411750793\n",
      "1090 tensor([[0.4086],\n",
      "        [0.5567],\n",
      "        [0.6954],\n",
      "        [0.8058]]) 0.47954386472702026\n",
      "1091 tensor([[0.4085],\n",
      "        [0.5566],\n",
      "        [0.6954],\n",
      "        [0.8058]]) 0.47939008474349976\n",
      "1092 tensor([[0.4083],\n",
      "        [0.5566],\n",
      "        [0.6954],\n",
      "        [0.8059]]) 0.4792363941669464\n",
      "1093 tensor([[0.4081],\n",
      "        [0.5565],\n",
      "        [0.6954],\n",
      "        [0.8060]]) 0.47908279299736023\n",
      "1094 tensor([[0.4079],\n",
      "        [0.5564],\n",
      "        [0.6954],\n",
      "        [0.8061]]) 0.4789293110370636\n",
      "1095 tensor([[0.4077],\n",
      "        [0.5563],\n",
      "        [0.6955],\n",
      "        [0.8062]]) 0.4787759780883789\n",
      "1096 tensor([[0.4076],\n",
      "        [0.5562],\n",
      "        [0.6955],\n",
      "        [0.8063]]) 0.4786227345466614\n",
      "1097 tensor([[0.4074],\n",
      "        [0.5562],\n",
      "        [0.6955],\n",
      "        [0.8063]]) 0.478469580411911\n",
      "1098 tensor([[0.4072],\n",
      "        [0.5561],\n",
      "        [0.6955],\n",
      "        [0.8064]]) 0.47831642627716064\n",
      "1099 tensor([[0.4070],\n",
      "        [0.5560],\n",
      "        [0.6955],\n",
      "        [0.8065]]) 0.478163480758667\n",
      "1100 tensor([[0.4068],\n",
      "        [0.5559],\n",
      "        [0.6956],\n",
      "        [0.8066]]) 0.4780106246471405\n",
      "1101 tensor([[0.4067],\n",
      "        [0.5558],\n",
      "        [0.6956],\n",
      "        [0.8067]]) 0.47785788774490356\n",
      "1102 tensor([[0.4065],\n",
      "        [0.5558],\n",
      "        [0.6956],\n",
      "        [0.8067]]) 0.4777052104473114\n",
      "1103 tensor([[0.4063],\n",
      "        [0.5557],\n",
      "        [0.6956],\n",
      "        [0.8068]]) 0.477552592754364\n",
      "1104 tensor([[0.4061],\n",
      "        [0.5556],\n",
      "        [0.6957],\n",
      "        [0.8069]]) 0.47740015387535095\n",
      "1105 tensor([[0.4060],\n",
      "        [0.5555],\n",
      "        [0.6957],\n",
      "        [0.8070]]) 0.47724783420562744\n",
      "1106 tensor([[0.4058],\n",
      "        [0.5555],\n",
      "        [0.6957],\n",
      "        [0.8071]]) 0.4770955443382263\n",
      "1107 tensor([[0.4056],\n",
      "        [0.5554],\n",
      "        [0.6957],\n",
      "        [0.8071]]) 0.47694340348243713\n",
      "1108 tensor([[0.4054],\n",
      "        [0.5553],\n",
      "        [0.6957],\n",
      "        [0.8072]]) 0.4767913222312927\n",
      "1109 tensor([[0.4052],\n",
      "        [0.5552],\n",
      "        [0.6958],\n",
      "        [0.8073]]) 0.47663936018943787\n",
      "1110 tensor([[0.4051],\n",
      "        [0.5551],\n",
      "        [0.6958],\n",
      "        [0.8074]]) 0.47648748755455017\n",
      "1111 tensor([[0.4049],\n",
      "        [0.5551],\n",
      "        [0.6958],\n",
      "        [0.8075]]) 0.4763357639312744\n",
      "1112 tensor([[0.4047],\n",
      "        [0.5550],\n",
      "        [0.6958],\n",
      "        [0.8076]]) 0.47618401050567627\n",
      "1113 tensor([[0.4045],\n",
      "        [0.5549],\n",
      "        [0.6958],\n",
      "        [0.8076]]) 0.4760324954986572\n",
      "1114 tensor([[0.4044],\n",
      "        [0.5548],\n",
      "        [0.6959],\n",
      "        [0.8077]]) 0.47588106989860535\n",
      "1115 tensor([[0.4042],\n",
      "        [0.5547],\n",
      "        [0.6959],\n",
      "        [0.8078]]) 0.47572967410087585\n",
      "1116 tensor([[0.4040],\n",
      "        [0.5547],\n",
      "        [0.6959],\n",
      "        [0.8079]]) 0.4755784273147583\n",
      "1117 tensor([[0.4038],\n",
      "        [0.5546],\n",
      "        [0.6959],\n",
      "        [0.8080]]) 0.4754272699356079\n",
      "1118 tensor([[0.4036],\n",
      "        [0.5545],\n",
      "        [0.6960],\n",
      "        [0.8080]]) 0.4752761721611023\n",
      "1119 tensor([[0.4035],\n",
      "        [0.5544],\n",
      "        [0.6960],\n",
      "        [0.8081]]) 0.47512516379356384\n",
      "1120 tensor([[0.4033],\n",
      "        [0.5543],\n",
      "        [0.6960],\n",
      "        [0.8082]]) 0.4749743640422821\n",
      "1121 tensor([[0.4031],\n",
      "        [0.5543],\n",
      "        [0.6960],\n",
      "        [0.8083]]) 0.47482365369796753\n",
      "1122 tensor([[0.4029],\n",
      "        [0.5542],\n",
      "        [0.6960],\n",
      "        [0.8084]]) 0.47467294335365295\n",
      "1123 tensor([[0.4028],\n",
      "        [0.5541],\n",
      "        [0.6961],\n",
      "        [0.8084]]) 0.4745224416255951\n",
      "1124 tensor([[0.4026],\n",
      "        [0.5540],\n",
      "        [0.6961],\n",
      "        [0.8085]]) 0.4743719696998596\n",
      "1125 tensor([[0.4024],\n",
      "        [0.5540],\n",
      "        [0.6961],\n",
      "        [0.8086]]) 0.4742215871810913\n",
      "1126 tensor([[0.4022],\n",
      "        [0.5539],\n",
      "        [0.6961],\n",
      "        [0.8087]]) 0.47407132387161255\n",
      "1127 tensor([[0.4020],\n",
      "        [0.5538],\n",
      "        [0.6961],\n",
      "        [0.8088]]) 0.47392112016677856\n",
      "1128 tensor([[0.4019],\n",
      "        [0.5537],\n",
      "        [0.6962],\n",
      "        [0.8088]]) 0.4737711250782013\n",
      "1129 tensor([[0.4017],\n",
      "        [0.5536],\n",
      "        [0.6962],\n",
      "        [0.8089]]) 0.473621129989624\n",
      "1130 tensor([[0.4015],\n",
      "        [0.5536],\n",
      "        [0.6962],\n",
      "        [0.8090]]) 0.4734712839126587\n",
      "1131 tensor([[0.4013],\n",
      "        [0.5535],\n",
      "        [0.6962],\n",
      "        [0.8091]]) 0.47332146763801575\n",
      "1132 tensor([[0.4012],\n",
      "        [0.5534],\n",
      "        [0.6962],\n",
      "        [0.8092]]) 0.4731718599796295\n",
      "1133 tensor([[0.4010],\n",
      "        [0.5533],\n",
      "        [0.6963],\n",
      "        [0.8092]]) 0.4730222821235657\n",
      "1134 tensor([[0.4008],\n",
      "        [0.5532],\n",
      "        [0.6963],\n",
      "        [0.8093]]) 0.472872793674469\n",
      "1135 tensor([[0.4006],\n",
      "        [0.5532],\n",
      "        [0.6963],\n",
      "        [0.8094]]) 0.4727233946323395\n",
      "1136 tensor([[0.4005],\n",
      "        [0.5531],\n",
      "        [0.6963],\n",
      "        [0.8095]]) 0.4725741446018219\n",
      "1137 tensor([[0.4003],\n",
      "        [0.5530],\n",
      "        [0.6964],\n",
      "        [0.8096]]) 0.47242501378059387\n",
      "1138 tensor([[0.4001],\n",
      "        [0.5529],\n",
      "        [0.6964],\n",
      "        [0.8096]]) 0.47227588295936584\n",
      "1139 tensor([[0.3999],\n",
      "        [0.5529],\n",
      "        [0.6964],\n",
      "        [0.8097]]) 0.47212696075439453\n",
      "1140 tensor([[0.3998],\n",
      "        [0.5528],\n",
      "        [0.6964],\n",
      "        [0.8098]]) 0.47197800874710083\n",
      "1141 tensor([[0.3996],\n",
      "        [0.5527],\n",
      "        [0.6964],\n",
      "        [0.8099]]) 0.47182929515838623\n",
      "1142 tensor([[0.3994],\n",
      "        [0.5526],\n",
      "        [0.6965],\n",
      "        [0.8100]]) 0.47168058156967163\n",
      "1143 tensor([[0.3992],\n",
      "        [0.5525],\n",
      "        [0.6965],\n",
      "        [0.8100]]) 0.4715319573879242\n",
      "1144 tensor([[0.3991],\n",
      "        [0.5525],\n",
      "        [0.6965],\n",
      "        [0.8101]]) 0.47138354182243347\n",
      "1145 tensor([[0.3989],\n",
      "        [0.5524],\n",
      "        [0.6965],\n",
      "        [0.8102]]) 0.47123509645462036\n",
      "1146 tensor([[0.3987],\n",
      "        [0.5523],\n",
      "        [0.6965],\n",
      "        [0.8103]]) 0.4710868000984192\n",
      "1147 tensor([[0.3985],\n",
      "        [0.5522],\n",
      "        [0.6966],\n",
      "        [0.8103]]) 0.47093862295150757\n",
      "1148 tensor([[0.3984],\n",
      "        [0.5522],\n",
      "        [0.6966],\n",
      "        [0.8104]]) 0.4707905650138855\n",
      "1149 tensor([[0.3982],\n",
      "        [0.5521],\n",
      "        [0.6966],\n",
      "        [0.8105]]) 0.4706425070762634\n",
      "1150 tensor([[0.3980],\n",
      "        [0.5520],\n",
      "        [0.6966],\n",
      "        [0.8106]]) 0.4704945981502533\n",
      "1151 tensor([[0.3978],\n",
      "        [0.5519],\n",
      "        [0.6966],\n",
      "        [0.8107]]) 0.4703468680381775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152 tensor([[0.3977],\n",
      "        [0.5518],\n",
      "        [0.6967],\n",
      "        [0.8107]]) 0.4701991081237793\n",
      "1153 tensor([[0.3975],\n",
      "        [0.5518],\n",
      "        [0.6967],\n",
      "        [0.8108]]) 0.47005146741867065\n",
      "1154 tensor([[0.3973],\n",
      "        [0.5517],\n",
      "        [0.6967],\n",
      "        [0.8109]]) 0.46990397572517395\n",
      "1155 tensor([[0.3971],\n",
      "        [0.5516],\n",
      "        [0.6967],\n",
      "        [0.8110]]) 0.4697565734386444\n",
      "1156 tensor([[0.3970],\n",
      "        [0.5515],\n",
      "        [0.6968],\n",
      "        [0.8111]]) 0.46960923075675964\n",
      "1157 tensor([[0.3968],\n",
      "        [0.5515],\n",
      "        [0.6968],\n",
      "        [0.8111]]) 0.46946197748184204\n",
      "1158 tensor([[0.3966],\n",
      "        [0.5514],\n",
      "        [0.6968],\n",
      "        [0.8112]]) 0.469314843416214\n",
      "1159 tensor([[0.3964],\n",
      "        [0.5513],\n",
      "        [0.6968],\n",
      "        [0.8113]]) 0.4691678285598755\n",
      "1160 tensor([[0.3963],\n",
      "        [0.5512],\n",
      "        [0.6968],\n",
      "        [0.8114]]) 0.46902090311050415\n",
      "1161 tensor([[0.3961],\n",
      "        [0.5511],\n",
      "        [0.6969],\n",
      "        [0.8115]]) 0.4688740372657776\n",
      "1162 tensor([[0.3959],\n",
      "        [0.5511],\n",
      "        [0.6969],\n",
      "        [0.8115]]) 0.46872738003730774\n",
      "1163 tensor([[0.3957],\n",
      "        [0.5510],\n",
      "        [0.6969],\n",
      "        [0.8116]]) 0.4685806632041931\n",
      "1164 tensor([[0.3956],\n",
      "        [0.5509],\n",
      "        [0.6969],\n",
      "        [0.8117]]) 0.4684341549873352\n",
      "1165 tensor([[0.3954],\n",
      "        [0.5508],\n",
      "        [0.6969],\n",
      "        [0.8118]]) 0.4682876765727997\n",
      "1166 tensor([[0.3952],\n",
      "        [0.5508],\n",
      "        [0.6970],\n",
      "        [0.8118]]) 0.4681413173675537\n",
      "1167 tensor([[0.3951],\n",
      "        [0.5507],\n",
      "        [0.6970],\n",
      "        [0.8119]]) 0.4679950475692749\n",
      "1168 tensor([[0.3949],\n",
      "        [0.5506],\n",
      "        [0.6970],\n",
      "        [0.8120]]) 0.46784886717796326\n",
      "1169 tensor([[0.3947],\n",
      "        [0.5505],\n",
      "        [0.6970],\n",
      "        [0.8121]]) 0.46770283579826355\n",
      "1170 tensor([[0.3945],\n",
      "        [0.5505],\n",
      "        [0.6971],\n",
      "        [0.8122]]) 0.4675568640232086\n",
      "1171 tensor([[0.3944],\n",
      "        [0.5504],\n",
      "        [0.6971],\n",
      "        [0.8122]]) 0.46741098165512085\n",
      "1172 tensor([[0.3942],\n",
      "        [0.5503],\n",
      "        [0.6971],\n",
      "        [0.8123]]) 0.467265248298645\n",
      "1173 tensor([[0.3940],\n",
      "        [0.5502],\n",
      "        [0.6971],\n",
      "        [0.8124]]) 0.4671195149421692\n",
      "1174 tensor([[0.3938],\n",
      "        [0.5501],\n",
      "        [0.6971],\n",
      "        [0.8125]]) 0.4669739305973053\n",
      "1175 tensor([[0.3937],\n",
      "        [0.5501],\n",
      "        [0.6972],\n",
      "        [0.8125]]) 0.46682843565940857\n",
      "1176 tensor([[0.3935],\n",
      "        [0.5500],\n",
      "        [0.6972],\n",
      "        [0.8126]]) 0.4666830003261566\n",
      "1177 tensor([[0.3933],\n",
      "        [0.5499],\n",
      "        [0.6972],\n",
      "        [0.8127]]) 0.4665377140045166\n",
      "1178 tensor([[0.3932],\n",
      "        [0.5498],\n",
      "        [0.6972],\n",
      "        [0.8128]]) 0.46639251708984375\n",
      "1179 tensor([[0.3930],\n",
      "        [0.5498],\n",
      "        [0.6972],\n",
      "        [0.8129]]) 0.4662473201751709\n",
      "1180 tensor([[0.3928],\n",
      "        [0.5497],\n",
      "        [0.6973],\n",
      "        [0.8129]]) 0.4661024212837219\n",
      "1181 tensor([[0.3926],\n",
      "        [0.5496],\n",
      "        [0.6973],\n",
      "        [0.8130]]) 0.4659574031829834\n",
      "1182 tensor([[0.3925],\n",
      "        [0.5495],\n",
      "        [0.6973],\n",
      "        [0.8131]]) 0.4658125638961792\n",
      "1183 tensor([[0.3923],\n",
      "        [0.5495],\n",
      "        [0.6973],\n",
      "        [0.8132]]) 0.4656677842140198\n",
      "1184 tensor([[0.3921],\n",
      "        [0.5494],\n",
      "        [0.6973],\n",
      "        [0.8132]]) 0.46552321314811707\n",
      "1185 tensor([[0.3920],\n",
      "        [0.5493],\n",
      "        [0.6974],\n",
      "        [0.8133]]) 0.46537870168685913\n",
      "1186 tensor([[0.3918],\n",
      "        [0.5492],\n",
      "        [0.6974],\n",
      "        [0.8134]]) 0.4652342200279236\n",
      "1187 tensor([[0.3916],\n",
      "        [0.5491],\n",
      "        [0.6974],\n",
      "        [0.8135]]) 0.4650898277759552\n",
      "1188 tensor([[0.3914],\n",
      "        [0.5491],\n",
      "        [0.6974],\n",
      "        [0.8136]]) 0.46494555473327637\n",
      "1189 tensor([[0.3913],\n",
      "        [0.5490],\n",
      "        [0.6975],\n",
      "        [0.8136]]) 0.4648014008998871\n",
      "1190 tensor([[0.3911],\n",
      "        [0.5489],\n",
      "        [0.6975],\n",
      "        [0.8137]]) 0.4646573066711426\n",
      "1191 tensor([[0.3909],\n",
      "        [0.5488],\n",
      "        [0.6975],\n",
      "        [0.8138]]) 0.46451336145401\n",
      "1192 tensor([[0.3908],\n",
      "        [0.5488],\n",
      "        [0.6975],\n",
      "        [0.8139]]) 0.46436944603919983\n",
      "1193 tensor([[0.3906],\n",
      "        [0.5487],\n",
      "        [0.6975],\n",
      "        [0.8139]]) 0.464225709438324\n",
      "1194 tensor([[0.3904],\n",
      "        [0.5486],\n",
      "        [0.6976],\n",
      "        [0.8140]]) 0.4640820026397705\n",
      "1195 tensor([[0.3902],\n",
      "        [0.5485],\n",
      "        [0.6976],\n",
      "        [0.8141]]) 0.46393832564353943\n",
      "1196 tensor([[0.3901],\n",
      "        [0.5485],\n",
      "        [0.6976],\n",
      "        [0.8142]]) 0.46379485726356506\n",
      "1197 tensor([[0.3899],\n",
      "        [0.5484],\n",
      "        [0.6976],\n",
      "        [0.8143]]) 0.4636514484882355\n",
      "1198 tensor([[0.3897],\n",
      "        [0.5483],\n",
      "        [0.6976],\n",
      "        [0.8143]]) 0.46350812911987305\n",
      "1199 tensor([[0.3896],\n",
      "        [0.5482],\n",
      "        [0.6977],\n",
      "        [0.8144]]) 0.4633648693561554\n",
      "1200 tensor([[0.3894],\n",
      "        [0.5482],\n",
      "        [0.6977],\n",
      "        [0.8145]]) 0.4632217586040497\n",
      "1201 tensor([[0.3892],\n",
      "        [0.5481],\n",
      "        [0.6977],\n",
      "        [0.8146]]) 0.46307873725891113\n",
      "1202 tensor([[0.3890],\n",
      "        [0.5480],\n",
      "        [0.6977],\n",
      "        [0.8146]]) 0.4629356861114502\n",
      "1203 tensor([[0.3889],\n",
      "        [0.5479],\n",
      "        [0.6978],\n",
      "        [0.8147]]) 0.46279287338256836\n",
      "1204 tensor([[0.3887],\n",
      "        [0.5478],\n",
      "        [0.6978],\n",
      "        [0.8148]]) 0.4626501202583313\n",
      "1205 tensor([[0.3885],\n",
      "        [0.5478],\n",
      "        [0.6978],\n",
      "        [0.8149]]) 0.4625074565410614\n",
      "1206 tensor([[0.3884],\n",
      "        [0.5477],\n",
      "        [0.6978],\n",
      "        [0.8149]]) 0.4623648524284363\n",
      "1207 tensor([[0.3882],\n",
      "        [0.5476],\n",
      "        [0.6978],\n",
      "        [0.8150]]) 0.4622223973274231\n",
      "1208 tensor([[0.3880],\n",
      "        [0.5475],\n",
      "        [0.6979],\n",
      "        [0.8151]]) 0.4620799720287323\n",
      "1209 tensor([[0.3879],\n",
      "        [0.5475],\n",
      "        [0.6979],\n",
      "        [0.8152]]) 0.46193766593933105\n",
      "1210 tensor([[0.3877],\n",
      "        [0.5474],\n",
      "        [0.6979],\n",
      "        [0.8153]]) 0.46179550886154175\n",
      "1211 tensor([[0.3875],\n",
      "        [0.5473],\n",
      "        [0.6979],\n",
      "        [0.8153]]) 0.46165338158607483\n",
      "1212 tensor([[0.3873],\n",
      "        [0.5472],\n",
      "        [0.6979],\n",
      "        [0.8154]]) 0.4615113139152527\n",
      "1213 tensor([[0.3872],\n",
      "        [0.5472],\n",
      "        [0.6980],\n",
      "        [0.8155]]) 0.46136945486068726\n",
      "1214 tensor([[0.3870],\n",
      "        [0.5471],\n",
      "        [0.6980],\n",
      "        [0.8156]]) 0.46122753620147705\n",
      "1215 tensor([[0.3868],\n",
      "        [0.5470],\n",
      "        [0.6980],\n",
      "        [0.8156]]) 0.46108585596084595\n",
      "1216 tensor([[0.3867],\n",
      "        [0.5469],\n",
      "        [0.6980],\n",
      "        [0.8157]]) 0.46094411611557007\n",
      "1217 tensor([[0.3865],\n",
      "        [0.5469],\n",
      "        [0.6980],\n",
      "        [0.8158]]) 0.4608025848865509\n",
      "1218 tensor([[0.3863],\n",
      "        [0.5468],\n",
      "        [0.6981],\n",
      "        [0.8159]]) 0.4606611430644989\n",
      "1219 tensor([[0.3862],\n",
      "        [0.5467],\n",
      "        [0.6981],\n",
      "        [0.8159]]) 0.4605197310447693\n",
      "1220 tensor([[0.3860],\n",
      "        [0.5466],\n",
      "        [0.6981],\n",
      "        [0.8160]]) 0.4603784680366516\n",
      "1221 tensor([[0.3858],\n",
      "        [0.5466],\n",
      "        [0.6981],\n",
      "        [0.8161]]) 0.4602372944355011\n",
      "1222 tensor([[0.3857],\n",
      "        [0.5465],\n",
      "        [0.6982],\n",
      "        [0.8162]]) 0.46009618043899536\n",
      "1223 tensor([[0.3855],\n",
      "        [0.5464],\n",
      "        [0.6982],\n",
      "        [0.8162]]) 0.4599551260471344\n",
      "1224 tensor([[0.3853],\n",
      "        [0.5463],\n",
      "        [0.6982],\n",
      "        [0.8163]]) 0.45981425046920776\n",
      "1225 tensor([[0.3852],\n",
      "        [0.5463],\n",
      "        [0.6982],\n",
      "        [0.8164]]) 0.45967337489128113\n",
      "1226 tensor([[0.3850],\n",
      "        [0.5462],\n",
      "        [0.6982],\n",
      "        [0.8165]]) 0.4595326781272888\n",
      "1227 tensor([[0.3848],\n",
      "        [0.5461],\n",
      "        [0.6983],\n",
      "        [0.8165]]) 0.4593920111656189\n",
      "1228 tensor([[0.3847],\n",
      "        [0.5460],\n",
      "        [0.6983],\n",
      "        [0.8166]]) 0.45925143361091614\n",
      "1229 tensor([[0.3845],\n",
      "        [0.5460],\n",
      "        [0.6983],\n",
      "        [0.8167]]) 0.45911097526550293\n",
      "1230 tensor([[0.3843],\n",
      "        [0.5459],\n",
      "        [0.6983],\n",
      "        [0.8168]]) 0.4589706361293793\n",
      "1231 tensor([[0.3841],\n",
      "        [0.5458],\n",
      "        [0.6983],\n",
      "        [0.8168]]) 0.4588303565979004\n",
      "1232 tensor([[0.3840],\n",
      "        [0.5457],\n",
      "        [0.6984],\n",
      "        [0.8169]]) 0.45869019627571106\n",
      "1233 tensor([[0.3838],\n",
      "        [0.5457],\n",
      "        [0.6984],\n",
      "        [0.8170]]) 0.4585500657558441\n",
      "1234 tensor([[0.3836],\n",
      "        [0.5456],\n",
      "        [0.6984],\n",
      "        [0.8171]]) 0.4584100544452667\n",
      "1235 tensor([[0.3835],\n",
      "        [0.5455],\n",
      "        [0.6984],\n",
      "        [0.8171]]) 0.4582701623439789\n",
      "1236 tensor([[0.3833],\n",
      "        [0.5454],\n",
      "        [0.6985],\n",
      "        [0.8172]]) 0.4581303596496582\n",
      "1237 tensor([[0.3831],\n",
      "        [0.5454],\n",
      "        [0.6985],\n",
      "        [0.8173]]) 0.4579905867576599\n",
      "1238 tensor([[0.3830],\n",
      "        [0.5453],\n",
      "        [0.6985],\n",
      "        [0.8174]]) 0.45785096287727356\n",
      "1239 tensor([[0.3828],\n",
      "        [0.5452],\n",
      "        [0.6985],\n",
      "        [0.8175]]) 0.457711398601532\n",
      "1240 tensor([[0.3826],\n",
      "        [0.5451],\n",
      "        [0.6985],\n",
      "        [0.8175]]) 0.45757192373275757\n",
      "1241 tensor([[0.3825],\n",
      "        [0.5451],\n",
      "        [0.6986],\n",
      "        [0.8176]]) 0.4574325382709503\n",
      "1242 tensor([[0.3823],\n",
      "        [0.5450],\n",
      "        [0.6986],\n",
      "        [0.8177]]) 0.4572932720184326\n",
      "1243 tensor([[0.3821],\n",
      "        [0.5449],\n",
      "        [0.6986],\n",
      "        [0.8178]]) 0.45715412497520447\n",
      "1244 tensor([[0.3820],\n",
      "        [0.5448],\n",
      "        [0.6986],\n",
      "        [0.8178]]) 0.45701494812965393\n",
      "1245 tensor([[0.3818],\n",
      "        [0.5448],\n",
      "        [0.6986],\n",
      "        [0.8179]]) 0.4568759500980377\n",
      "1246 tensor([[0.3816],\n",
      "        [0.5447],\n",
      "        [0.6987],\n",
      "        [0.8180]]) 0.4567370116710663\n",
      "1247 tensor([[0.3815],\n",
      "        [0.5446],\n",
      "        [0.6987],\n",
      "        [0.8181]]) 0.4565982222557068\n",
      "1248 tensor([[0.3813],\n",
      "        [0.5445],\n",
      "        [0.6987],\n",
      "        [0.8181]]) 0.4564593732357025\n",
      "1249 tensor([[0.3811],\n",
      "        [0.5445],\n",
      "        [0.6987],\n",
      "        [0.8182]]) 0.45632079243659973\n",
      "1250 tensor([[0.3810],\n",
      "        [0.5444],\n",
      "        [0.6987],\n",
      "        [0.8183]]) 0.45618221163749695\n",
      "1251 tensor([[0.3808],\n",
      "        [0.5443],\n",
      "        [0.6988],\n",
      "        [0.8184]]) 0.4560438394546509\n",
      "1252 tensor([[0.3806],\n",
      "        [0.5442],\n",
      "        [0.6988],\n",
      "        [0.8184]]) 0.45590537786483765\n",
      "1253 tensor([[0.3805],\n",
      "        [0.5442],\n",
      "        [0.6988],\n",
      "        [0.8185]]) 0.45576712489128113\n",
      "1254 tensor([[0.3803],\n",
      "        [0.5441],\n",
      "        [0.6988],\n",
      "        [0.8186]]) 0.455628901720047\n",
      "1255 tensor([[0.3802],\n",
      "        [0.5440],\n",
      "        [0.6989],\n",
      "        [0.8186]]) 0.4554907977581024\n",
      "1256 tensor([[0.3800],\n",
      "        [0.5439],\n",
      "        [0.6989],\n",
      "        [0.8187]]) 0.455352783203125\n",
      "1257 tensor([[0.3798],\n",
      "        [0.5439],\n",
      "        [0.6989],\n",
      "        [0.8188]]) 0.45521482825279236\n",
      "1258 tensor([[0.3797],\n",
      "        [0.5438],\n",
      "        [0.6989],\n",
      "        [0.8189]]) 0.4550769627094269\n",
      "1259 tensor([[0.3795],\n",
      "        [0.5437],\n",
      "        [0.6989],\n",
      "        [0.8189]]) 0.45493921637535095\n",
      "1260 tensor([[0.3793],\n",
      "        [0.5436],\n",
      "        [0.6990],\n",
      "        [0.8190]]) 0.4548015892505646\n",
      "1261 tensor([[0.3792],\n",
      "        [0.5436],\n",
      "        [0.6990],\n",
      "        [0.8191]]) 0.4546639919281006\n",
      "1262 tensor([[0.3790],\n",
      "        [0.5435],\n",
      "        [0.6990],\n",
      "        [0.8192]]) 0.45452651381492615\n",
      "1263 tensor([[0.3788],\n",
      "        [0.5434],\n",
      "        [0.6990],\n",
      "        [0.8192]]) 0.45438912510871887\n",
      "1264 tensor([[0.3787],\n",
      "        [0.5433],\n",
      "        [0.6990],\n",
      "        [0.8193]]) 0.454251766204834\n",
      "1265 tensor([[0.3785],\n",
      "        [0.5433],\n",
      "        [0.6991],\n",
      "        [0.8194]]) 0.45411452651023865\n",
      "1266 tensor([[0.3783],\n",
      "        [0.5432],\n",
      "        [0.6991],\n",
      "        [0.8195]]) 0.45397740602493286\n",
      "1267 tensor([[0.3782],\n",
      "        [0.5431],\n",
      "        [0.6991],\n",
      "        [0.8195]]) 0.45384034514427185\n",
      "1268 tensor([[0.3780],\n",
      "        [0.5430],\n",
      "        [0.6991],\n",
      "        [0.8196]]) 0.4537034034729004\n",
      "1269 tensor([[0.3778],\n",
      "        [0.5430],\n",
      "        [0.6992],\n",
      "        [0.8197]]) 0.4535665214061737\n",
      "1270 tensor([[0.3777],\n",
      "        [0.5429],\n",
      "        [0.6992],\n",
      "        [0.8198]]) 0.4534297287464142\n",
      "1271 tensor([[0.3775],\n",
      "        [0.5428],\n",
      "        [0.6992],\n",
      "        [0.8198]]) 0.45329299569129944\n",
      "1272 tensor([[0.3773],\n",
      "        [0.5427],\n",
      "        [0.6992],\n",
      "        [0.8199]]) 0.45315641164779663\n",
      "1273 tensor([[0.3772],\n",
      "        [0.5427],\n",
      "        [0.6992],\n",
      "        [0.8200]]) 0.4530198872089386\n",
      "1274 tensor([[0.3770],\n",
      "        [0.5426],\n",
      "        [0.6993],\n",
      "        [0.8201]]) 0.45288345217704773\n",
      "1275 tensor([[0.3769],\n",
      "        [0.5425],\n",
      "        [0.6993],\n",
      "        [0.8201]]) 0.452747106552124\n",
      "1276 tensor([[0.3767],\n",
      "        [0.5424],\n",
      "        [0.6993],\n",
      "        [0.8202]]) 0.4526108205318451\n",
      "1277 tensor([[0.3765],\n",
      "        [0.5424],\n",
      "        [0.6993],\n",
      "        [0.8203]]) 0.4524746835231781\n",
      "1278 tensor([[0.3764],\n",
      "        [0.5423],\n",
      "        [0.6993],\n",
      "        [0.8204]]) 0.45233863592147827\n",
      "1279 tensor([[0.3762],\n",
      "        [0.5422],\n",
      "        [0.6994],\n",
      "        [0.8204]]) 0.45220261812210083\n",
      "1280 tensor([[0.3760],\n",
      "        [0.5421],\n",
      "        [0.6994],\n",
      "        [0.8205]]) 0.45206668972969055\n",
      "1281 tensor([[0.3759],\n",
      "        [0.5421],\n",
      "        [0.6994],\n",
      "        [0.8206]]) 0.4519308805465698\n",
      "1282 tensor([[0.3757],\n",
      "        [0.5420],\n",
      "        [0.6994],\n",
      "        [0.8207]]) 0.45179513096809387\n",
      "1283 tensor([[0.3755],\n",
      "        [0.5419],\n",
      "        [0.6994],\n",
      "        [0.8207]]) 0.45165950059890747\n",
      "1284 tensor([[0.3754],\n",
      "        [0.5419],\n",
      "        [0.6995],\n",
      "        [0.8208]]) 0.45152390003204346\n",
      "1285 tensor([[0.3752],\n",
      "        [0.5418],\n",
      "        [0.6995],\n",
      "        [0.8209]]) 0.451388418674469\n",
      "1286 tensor([[0.3751],\n",
      "        [0.5417],\n",
      "        [0.6995],\n",
      "        [0.8209]]) 0.45125308632850647\n",
      "1287 tensor([[0.3749],\n",
      "        [0.5416],\n",
      "        [0.6995],\n",
      "        [0.8210]]) 0.45111772418022156\n",
      "1288 tensor([[0.3747],\n",
      "        [0.5416],\n",
      "        [0.6996],\n",
      "        [0.8211]]) 0.45098257064819336\n",
      "1289 tensor([[0.3746],\n",
      "        [0.5415],\n",
      "        [0.6996],\n",
      "        [0.8212]]) 0.45084744691848755\n",
      "1290 tensor([[0.3744],\n",
      "        [0.5414],\n",
      "        [0.6996],\n",
      "        [0.8212]]) 0.4507124423980713\n",
      "1291 tensor([[0.3742],\n",
      "        [0.5413],\n",
      "        [0.6996],\n",
      "        [0.8213]]) 0.4505775272846222\n",
      "1292 tensor([[0.3741],\n",
      "        [0.5413],\n",
      "        [0.6996],\n",
      "        [0.8214]]) 0.4504426121711731\n",
      "1293 tensor([[0.3739],\n",
      "        [0.5412],\n",
      "        [0.6997],\n",
      "        [0.8215]]) 0.4503078758716583\n",
      "1294 tensor([[0.3738],\n",
      "        [0.5411],\n",
      "        [0.6997],\n",
      "        [0.8215]]) 0.45017316937446594\n",
      "1295 tensor([[0.3736],\n",
      "        [0.5410],\n",
      "        [0.6997],\n",
      "        [0.8216]]) 0.45003852248191833\n",
      "1296 tensor([[0.3734],\n",
      "        [0.5410],\n",
      "        [0.6997],\n",
      "        [0.8217]]) 0.4499039947986603\n",
      "1297 tensor([[0.3733],\n",
      "        [0.5409],\n",
      "        [0.6997],\n",
      "        [0.8217]]) 0.44976961612701416\n",
      "1298 tensor([[0.3731],\n",
      "        [0.5408],\n",
      "        [0.6998],\n",
      "        [0.8218]]) 0.44963526725769043\n",
      "1299 tensor([[0.3729],\n",
      "        [0.5407],\n",
      "        [0.6998],\n",
      "        [0.8219]]) 0.4495009481906891\n",
      "1300 tensor([[0.3728],\n",
      "        [0.5407],\n",
      "        [0.6998],\n",
      "        [0.8220]]) 0.44936680793762207\n",
      "1301 tensor([[0.3726],\n",
      "        [0.5406],\n",
      "        [0.6998],\n",
      "        [0.8220]]) 0.4492327570915222\n",
      "1302 tensor([[0.3725],\n",
      "        [0.5405],\n",
      "        [0.6999],\n",
      "        [0.8221]]) 0.44909870624542236\n",
      "1303 tensor([[0.3723],\n",
      "        [0.5405],\n",
      "        [0.6999],\n",
      "        [0.8222]]) 0.44896480441093445\n",
      "1304 tensor([[0.3721],\n",
      "        [0.5404],\n",
      "        [0.6999],\n",
      "        [0.8223]]) 0.44883090257644653\n",
      "1305 tensor([[0.3720],\n",
      "        [0.5403],\n",
      "        [0.6999],\n",
      "        [0.8223]]) 0.44869720935821533\n",
      "1306 tensor([[0.3718],\n",
      "        [0.5402],\n",
      "        [0.6999],\n",
      "        [0.8224]]) 0.4485635459423065\n",
      "1307 tensor([[0.3717],\n",
      "        [0.5402],\n",
      "        [0.7000],\n",
      "        [0.8225]]) 0.44842997193336487\n",
      "1308 tensor([[0.3715],\n",
      "        [0.5401],\n",
      "        [0.7000],\n",
      "        [0.8225]]) 0.448296457529068\n",
      "1309 tensor([[0.3713],\n",
      "        [0.5400],\n",
      "        [0.7000],\n",
      "        [0.8226]]) 0.44816309213638306\n",
      "1310 tensor([[0.3712],\n",
      "        [0.5399],\n",
      "        [0.7000],\n",
      "        [0.8227]]) 0.4480297565460205\n",
      "1311 tensor([[0.3710],\n",
      "        [0.5399],\n",
      "        [0.7000],\n",
      "        [0.8228]]) 0.4478965699672699\n",
      "1312 tensor([[0.3709],\n",
      "        [0.5398],\n",
      "        [0.7001],\n",
      "        [0.8228]]) 0.4477634131908417\n",
      "1313 tensor([[0.3707],\n",
      "        [0.5397],\n",
      "        [0.7001],\n",
      "        [0.8229]]) 0.4476303458213806\n",
      "1314 tensor([[0.3705],\n",
      "        [0.5397],\n",
      "        [0.7001],\n",
      "        [0.8230]]) 0.4474973976612091\n",
      "1315 tensor([[0.3704],\n",
      "        [0.5396],\n",
      "        [0.7001],\n",
      "        [0.8231]]) 0.4473645091056824\n",
      "1316 tensor([[0.3702],\n",
      "        [0.5395],\n",
      "        [0.7002],\n",
      "        [0.8231]]) 0.4472316801548004\n",
      "1317 tensor([[0.3700],\n",
      "        [0.5394],\n",
      "        [0.7002],\n",
      "        [0.8232]]) 0.44709891080856323\n",
      "1318 tensor([[0.3699],\n",
      "        [0.5394],\n",
      "        [0.7002],\n",
      "        [0.8233]]) 0.4469662606716156\n",
      "1319 tensor([[0.3697],\n",
      "        [0.5393],\n",
      "        [0.7002],\n",
      "        [0.8233]]) 0.4468337297439575\n",
      "1320 tensor([[0.3696],\n",
      "        [0.5392],\n",
      "        [0.7002],\n",
      "        [0.8234]]) 0.4467012584209442\n",
      "1321 tensor([[0.3694],\n",
      "        [0.5391],\n",
      "        [0.7003],\n",
      "        [0.8235]]) 0.44656887650489807\n",
      "1322 tensor([[0.3692],\n",
      "        [0.5391],\n",
      "        [0.7003],\n",
      "        [0.8236]]) 0.4464366137981415\n",
      "1323 tensor([[0.3691],\n",
      "        [0.5390],\n",
      "        [0.7003],\n",
      "        [0.8236]]) 0.4463043510913849\n",
      "1324 tensor([[0.3689],\n",
      "        [0.5389],\n",
      "        [0.7003],\n",
      "        [0.8237]]) 0.44617217779159546\n",
      "1325 tensor([[0.3688],\n",
      "        [0.5388],\n",
      "        [0.7003],\n",
      "        [0.8238]]) 0.44604018330574036\n",
      "1326 tensor([[0.3686],\n",
      "        [0.5388],\n",
      "        [0.7004],\n",
      "        [0.8238]]) 0.44590818881988525\n",
      "1327 tensor([[0.3685],\n",
      "        [0.5387],\n",
      "        [0.7004],\n",
      "        [0.8239]]) 0.4457763731479645\n",
      "1328 tensor([[0.3683],\n",
      "        [0.5386],\n",
      "        [0.7004],\n",
      "        [0.8240]]) 0.4456445574760437\n",
      "1329 tensor([[0.3681],\n",
      "        [0.5386],\n",
      "        [0.7004],\n",
      "        [0.8241]]) 0.44551289081573486\n",
      "1330 tensor([[0.3680],\n",
      "        [0.5385],\n",
      "        [0.7004],\n",
      "        [0.8241]]) 0.4453812539577484\n",
      "1331 tensor([[0.3678],\n",
      "        [0.5384],\n",
      "        [0.7005],\n",
      "        [0.8242]]) 0.44524967670440674\n",
      "1332 tensor([[0.3677],\n",
      "        [0.5383],\n",
      "        [0.7005],\n",
      "        [0.8243]]) 0.445118248462677\n",
      "1333 tensor([[0.3675],\n",
      "        [0.5383],\n",
      "        [0.7005],\n",
      "        [0.8243]]) 0.44498687982559204\n",
      "1334 tensor([[0.3673],\n",
      "        [0.5382],\n",
      "        [0.7005],\n",
      "        [0.8244]]) 0.44485557079315186\n",
      "1335 tensor([[0.3672],\n",
      "        [0.5381],\n",
      "        [0.7006],\n",
      "        [0.8245]]) 0.4447243809700012\n",
      "1336 tensor([[0.3670],\n",
      "        [0.5381],\n",
      "        [0.7006],\n",
      "        [0.8246]]) 0.444593220949173\n",
      "1337 tensor([[0.3669],\n",
      "        [0.5380],\n",
      "        [0.7006],\n",
      "        [0.8246]]) 0.44446220993995667\n",
      "1338 tensor([[0.3667],\n",
      "        [0.5379],\n",
      "        [0.7006],\n",
      "        [0.8247]]) 0.44433125853538513\n",
      "1339 tensor([[0.3665],\n",
      "        [0.5378],\n",
      "        [0.7006],\n",
      "        [0.8248]]) 0.44420039653778076\n",
      "1340 tensor([[0.3664],\n",
      "        [0.5378],\n",
      "        [0.7007],\n",
      "        [0.8248]]) 0.4440695345401764\n",
      "1341 tensor([[0.3662],\n",
      "        [0.5377],\n",
      "        [0.7007],\n",
      "        [0.8249]]) 0.44393885135650635\n",
      "1342 tensor([[0.3661],\n",
      "        [0.5376],\n",
      "        [0.7007],\n",
      "        [0.8250]]) 0.4438082277774811\n",
      "1343 tensor([[0.3659],\n",
      "        [0.5375],\n",
      "        [0.7007],\n",
      "        [0.8251]]) 0.443677693605423\n",
      "1344 tensor([[0.3658],\n",
      "        [0.5375],\n",
      "        [0.7007],\n",
      "        [0.8251]]) 0.44354721903800964\n",
      "1345 tensor([[0.3656],\n",
      "        [0.5374],\n",
      "        [0.7008],\n",
      "        [0.8252]]) 0.4434168338775635\n",
      "1346 tensor([[0.3654],\n",
      "        [0.5373],\n",
      "        [0.7008],\n",
      "        [0.8253]]) 0.4432865381240845\n",
      "1347 tensor([[0.3653],\n",
      "        [0.5373],\n",
      "        [0.7008],\n",
      "        [0.8253]]) 0.443156361579895\n",
      "1348 tensor([[0.3651],\n",
      "        [0.5372],\n",
      "        [0.7008],\n",
      "        [0.8254]]) 0.44302624464035034\n",
      "1349 tensor([[0.3650],\n",
      "        [0.5371],\n",
      "        [0.7009],\n",
      "        [0.8255]]) 0.4428962171077728\n",
      "1350 tensor([[0.3648],\n",
      "        [0.5370],\n",
      "        [0.7009],\n",
      "        [0.8256]]) 0.4427662491798401\n",
      "1351 tensor([[0.3646],\n",
      "        [0.5370],\n",
      "        [0.7009],\n",
      "        [0.8256]]) 0.4426363706588745\n",
      "1352 tensor([[0.3645],\n",
      "        [0.5369],\n",
      "        [0.7009],\n",
      "        [0.8257]]) 0.4425065517425537\n",
      "1353 tensor([[0.3643],\n",
      "        [0.5368],\n",
      "        [0.7009],\n",
      "        [0.8258]]) 0.4423767924308777\n",
      "1354 tensor([[0.3642],\n",
      "        [0.5368],\n",
      "        [0.7010],\n",
      "        [0.8258]]) 0.4422471821308136\n",
      "1355 tensor([[0.3640],\n",
      "        [0.5367],\n",
      "        [0.7010],\n",
      "        [0.8259]]) 0.4421176612377167\n",
      "1356 tensor([[0.3639],\n",
      "        [0.5366],\n",
      "        [0.7010],\n",
      "        [0.8260]]) 0.4419881999492645\n",
      "1357 tensor([[0.3637],\n",
      "        [0.5365],\n",
      "        [0.7010],\n",
      "        [0.8261]]) 0.44185882806777954\n",
      "1358 tensor([[0.3635],\n",
      "        [0.5365],\n",
      "        [0.7010],\n",
      "        [0.8261]]) 0.44172951579093933\n",
      "1359 tensor([[0.3634],\n",
      "        [0.5364],\n",
      "        [0.7011],\n",
      "        [0.8262]]) 0.4416002929210663\n",
      "1360 tensor([[0.3632],\n",
      "        [0.5363],\n",
      "        [0.7011],\n",
      "        [0.8263]]) 0.4414711594581604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1361 tensor([[0.3631],\n",
      "        [0.5363],\n",
      "        [0.7011],\n",
      "        [0.8263]]) 0.4413420855998993\n",
      "1362 tensor([[0.3629],\n",
      "        [0.5362],\n",
      "        [0.7011],\n",
      "        [0.8264]]) 0.44121310114860535\n",
      "1363 tensor([[0.3628],\n",
      "        [0.5361],\n",
      "        [0.7011],\n",
      "        [0.8265]]) 0.44108420610427856\n",
      "1364 tensor([[0.3626],\n",
      "        [0.5360],\n",
      "        [0.7012],\n",
      "        [0.8265]]) 0.4409554898738861\n",
      "1365 tensor([[0.3624],\n",
      "        [0.5360],\n",
      "        [0.7012],\n",
      "        [0.8266]]) 0.4408266544342041\n",
      "1366 tensor([[0.3623],\n",
      "        [0.5359],\n",
      "        [0.7012],\n",
      "        [0.8267]]) 0.4406980574131012\n",
      "1367 tensor([[0.3621],\n",
      "        [0.5358],\n",
      "        [0.7012],\n",
      "        [0.8268]]) 0.4405694603919983\n",
      "1368 tensor([[0.3620],\n",
      "        [0.5358],\n",
      "        [0.7013],\n",
      "        [0.8268]]) 0.44044098258018494\n",
      "1369 tensor([[0.3618],\n",
      "        [0.5357],\n",
      "        [0.7013],\n",
      "        [0.8269]]) 0.44031256437301636\n",
      "1370 tensor([[0.3617],\n",
      "        [0.5356],\n",
      "        [0.7013],\n",
      "        [0.8270]]) 0.44018426537513733\n",
      "1371 tensor([[0.3615],\n",
      "        [0.5355],\n",
      "        [0.7013],\n",
      "        [0.8270]]) 0.4400560259819031\n",
      "1372 tensor([[0.3614],\n",
      "        [0.5355],\n",
      "        [0.7013],\n",
      "        [0.8271]]) 0.439927875995636\n",
      "1373 tensor([[0.3612],\n",
      "        [0.5354],\n",
      "        [0.7014],\n",
      "        [0.8272]]) 0.4397997558116913\n",
      "1374 tensor([[0.3610],\n",
      "        [0.5353],\n",
      "        [0.7014],\n",
      "        [0.8272]]) 0.43967175483703613\n",
      "1375 tensor([[0.3609],\n",
      "        [0.5353],\n",
      "        [0.7014],\n",
      "        [0.8273]]) 0.43954384326934814\n",
      "1376 tensor([[0.3607],\n",
      "        [0.5352],\n",
      "        [0.7014],\n",
      "        [0.8274]]) 0.4394160211086273\n",
      "1377 tensor([[0.3606],\n",
      "        [0.5351],\n",
      "        [0.7014],\n",
      "        [0.8275]]) 0.4392881989479065\n",
      "1378 tensor([[0.3604],\n",
      "        [0.5350],\n",
      "        [0.7015],\n",
      "        [0.8275]]) 0.4391605854034424\n",
      "1379 tensor([[0.3603],\n",
      "        [0.5350],\n",
      "        [0.7015],\n",
      "        [0.8276]]) 0.43903306126594543\n",
      "1380 tensor([[0.3601],\n",
      "        [0.5349],\n",
      "        [0.7015],\n",
      "        [0.8277]]) 0.4389054477214813\n",
      "1381 tensor([[0.3600],\n",
      "        [0.5348],\n",
      "        [0.7015],\n",
      "        [0.8277]]) 0.43877801299095154\n",
      "1382 tensor([[0.3598],\n",
      "        [0.5348],\n",
      "        [0.7016],\n",
      "        [0.8278]]) 0.4386506974697113\n",
      "1383 tensor([[0.3596],\n",
      "        [0.5347],\n",
      "        [0.7016],\n",
      "        [0.8279]]) 0.43852344155311584\n",
      "1384 tensor([[0.3595],\n",
      "        [0.5346],\n",
      "        [0.7016],\n",
      "        [0.8279]]) 0.43839624524116516\n",
      "1385 tensor([[0.3593],\n",
      "        [0.5345],\n",
      "        [0.7016],\n",
      "        [0.8280]]) 0.43826913833618164\n",
      "1386 tensor([[0.3592],\n",
      "        [0.5345],\n",
      "        [0.7016],\n",
      "        [0.8281]]) 0.4381420910358429\n",
      "1387 tensor([[0.3590],\n",
      "        [0.5344],\n",
      "        [0.7017],\n",
      "        [0.8282]]) 0.4380151629447937\n",
      "1388 tensor([[0.3589],\n",
      "        [0.5343],\n",
      "        [0.7017],\n",
      "        [0.8282]]) 0.4378882348537445\n",
      "1389 tensor([[0.3587],\n",
      "        [0.5343],\n",
      "        [0.7017],\n",
      "        [0.8283]]) 0.43776148557662964\n",
      "1390 tensor([[0.3586],\n",
      "        [0.5342],\n",
      "        [0.7017],\n",
      "        [0.8284]]) 0.43763476610183716\n",
      "1391 tensor([[0.3584],\n",
      "        [0.5341],\n",
      "        [0.7017],\n",
      "        [0.8284]]) 0.43750813603401184\n",
      "1392 tensor([[0.3583],\n",
      "        [0.5340],\n",
      "        [0.7018],\n",
      "        [0.8285]]) 0.4373815655708313\n",
      "1393 tensor([[0.3581],\n",
      "        [0.5340],\n",
      "        [0.7018],\n",
      "        [0.8286]]) 0.43725505471229553\n",
      "1394 tensor([[0.3579],\n",
      "        [0.5339],\n",
      "        [0.7018],\n",
      "        [0.8286]]) 0.4371287226676941\n",
      "1395 tensor([[0.3578],\n",
      "        [0.5338],\n",
      "        [0.7018],\n",
      "        [0.8287]]) 0.43700236082077026\n",
      "1396 tensor([[0.3576],\n",
      "        [0.5338],\n",
      "        [0.7018],\n",
      "        [0.8288]]) 0.4368761479854584\n",
      "1397 tensor([[0.3575],\n",
      "        [0.5337],\n",
      "        [0.7019],\n",
      "        [0.8288]]) 0.43674996495246887\n",
      "1398 tensor([[0.3573],\n",
      "        [0.5336],\n",
      "        [0.7019],\n",
      "        [0.8289]]) 0.4366239011287689\n",
      "1399 tensor([[0.3572],\n",
      "        [0.5335],\n",
      "        [0.7019],\n",
      "        [0.8290]]) 0.43649792671203613\n",
      "1400 tensor([[0.3570],\n",
      "        [0.5335],\n",
      "        [0.7019],\n",
      "        [0.8291]]) 0.4363720118999481\n",
      "1401 tensor([[0.3569],\n",
      "        [0.5334],\n",
      "        [0.7020],\n",
      "        [0.8291]]) 0.4362461268901825\n",
      "1402 tensor([[0.3567],\n",
      "        [0.5333],\n",
      "        [0.7020],\n",
      "        [0.8292]]) 0.4361203908920288\n",
      "1403 tensor([[0.3566],\n",
      "        [0.5333],\n",
      "        [0.7020],\n",
      "        [0.8293]]) 0.4359947443008423\n",
      "1404 tensor([[0.3564],\n",
      "        [0.5332],\n",
      "        [0.7020],\n",
      "        [0.8293]]) 0.43586915731430054\n",
      "1405 tensor([[0.3563],\n",
      "        [0.5331],\n",
      "        [0.7020],\n",
      "        [0.8294]]) 0.43574362993240356\n",
      "1406 tensor([[0.3561],\n",
      "        [0.5331],\n",
      "        [0.7021],\n",
      "        [0.8295]]) 0.435618132352829\n",
      "1407 tensor([[0.3560],\n",
      "        [0.5330],\n",
      "        [0.7021],\n",
      "        [0.8295]]) 0.4354928135871887\n",
      "1408 tensor([[0.3558],\n",
      "        [0.5329],\n",
      "        [0.7021],\n",
      "        [0.8296]]) 0.4353674650192261\n",
      "1409 tensor([[0.3556],\n",
      "        [0.5328],\n",
      "        [0.7021],\n",
      "        [0.8297]]) 0.43524235486984253\n",
      "1410 tensor([[0.3555],\n",
      "        [0.5328],\n",
      "        [0.7021],\n",
      "        [0.8297]]) 0.4351171851158142\n",
      "1411 tensor([[0.3553],\n",
      "        [0.5327],\n",
      "        [0.7022],\n",
      "        [0.8298]]) 0.43499210476875305\n",
      "1412 tensor([[0.3552],\n",
      "        [0.5326],\n",
      "        [0.7022],\n",
      "        [0.8299]]) 0.43486711382865906\n",
      "1413 tensor([[0.3550],\n",
      "        [0.5326],\n",
      "        [0.7022],\n",
      "        [0.8299]]) 0.4347422420978546\n",
      "1414 tensor([[0.3549],\n",
      "        [0.5325],\n",
      "        [0.7022],\n",
      "        [0.8300]]) 0.4346174895763397\n",
      "1415 tensor([[0.3547],\n",
      "        [0.5324],\n",
      "        [0.7023],\n",
      "        [0.8301]]) 0.43449270725250244\n",
      "1416 tensor([[0.3546],\n",
      "        [0.5324],\n",
      "        [0.7023],\n",
      "        [0.8302]]) 0.4343681037425995\n",
      "1417 tensor([[0.3544],\n",
      "        [0.5323],\n",
      "        [0.7023],\n",
      "        [0.8302]]) 0.4342435300350189\n",
      "1418 tensor([[0.3543],\n",
      "        [0.5322],\n",
      "        [0.7023],\n",
      "        [0.8303]]) 0.43411898612976074\n",
      "1419 tensor([[0.3541],\n",
      "        [0.5321],\n",
      "        [0.7023],\n",
      "        [0.8304]]) 0.4339946210384369\n",
      "1420 tensor([[0.3540],\n",
      "        [0.5321],\n",
      "        [0.7024],\n",
      "        [0.8304]]) 0.43387025594711304\n",
      "1421 tensor([[0.3538],\n",
      "        [0.5320],\n",
      "        [0.7024],\n",
      "        [0.8305]]) 0.43374598026275635\n",
      "1422 tensor([[0.3537],\n",
      "        [0.5319],\n",
      "        [0.7024],\n",
      "        [0.8306]]) 0.43362176418304443\n",
      "1423 tensor([[0.3535],\n",
      "        [0.5319],\n",
      "        [0.7024],\n",
      "        [0.8306]]) 0.43349769711494446\n",
      "1424 tensor([[0.3534],\n",
      "        [0.5318],\n",
      "        [0.7024],\n",
      "        [0.8307]]) 0.4333736300468445\n",
      "1425 tensor([[0.3532],\n",
      "        [0.5317],\n",
      "        [0.7025],\n",
      "        [0.8308]]) 0.43324965238571167\n",
      "1426 tensor([[0.3531],\n",
      "        [0.5317],\n",
      "        [0.7025],\n",
      "        [0.8308]]) 0.4331257939338684\n",
      "1427 tensor([[0.3529],\n",
      "        [0.5316],\n",
      "        [0.7025],\n",
      "        [0.8309]]) 0.4330019950866699\n",
      "1428 tensor([[0.3528],\n",
      "        [0.5315],\n",
      "        [0.7025],\n",
      "        [0.8310]]) 0.4328782558441162\n",
      "1429 tensor([[0.3526],\n",
      "        [0.5314],\n",
      "        [0.7025],\n",
      "        [0.8310]]) 0.43275463581085205\n",
      "1430 tensor([[0.3525],\n",
      "        [0.5314],\n",
      "        [0.7026],\n",
      "        [0.8311]]) 0.4326310455799103\n",
      "1431 tensor([[0.3523],\n",
      "        [0.5313],\n",
      "        [0.7026],\n",
      "        [0.8312]]) 0.4325075149536133\n",
      "1432 tensor([[0.3522],\n",
      "        [0.5312],\n",
      "        [0.7026],\n",
      "        [0.8312]]) 0.4323841333389282\n",
      "1433 tensor([[0.3520],\n",
      "        [0.5312],\n",
      "        [0.7026],\n",
      "        [0.8313]]) 0.4322608709335327\n",
      "1434 tensor([[0.3519],\n",
      "        [0.5311],\n",
      "        [0.7027],\n",
      "        [0.8314]]) 0.43213751912117004\n",
      "1435 tensor([[0.3517],\n",
      "        [0.5310],\n",
      "        [0.7027],\n",
      "        [0.8314]]) 0.4320143759250641\n",
      "1436 tensor([[0.3516],\n",
      "        [0.5310],\n",
      "        [0.7027],\n",
      "        [0.8315]]) 0.4318912625312805\n",
      "1437 tensor([[0.3514],\n",
      "        [0.5309],\n",
      "        [0.7027],\n",
      "        [0.8316]]) 0.4317682385444641\n",
      "1438 tensor([[0.3512],\n",
      "        [0.5308],\n",
      "        [0.7027],\n",
      "        [0.8316]]) 0.43164530396461487\n",
      "1439 tensor([[0.3511],\n",
      "        [0.5307],\n",
      "        [0.7028],\n",
      "        [0.8317]]) 0.4315224289894104\n",
      "1440 tensor([[0.3509],\n",
      "        [0.5307],\n",
      "        [0.7028],\n",
      "        [0.8318]]) 0.4313996136188507\n",
      "1441 tensor([[0.3508],\n",
      "        [0.5306],\n",
      "        [0.7028],\n",
      "        [0.8318]]) 0.4312768876552582\n",
      "1442 tensor([[0.3506],\n",
      "        [0.5305],\n",
      "        [0.7028],\n",
      "        [0.8319]]) 0.4311542510986328\n",
      "1443 tensor([[0.3505],\n",
      "        [0.5305],\n",
      "        [0.7028],\n",
      "        [0.8320]]) 0.43103164434432983\n",
      "1444 tensor([[0.3503],\n",
      "        [0.5304],\n",
      "        [0.7029],\n",
      "        [0.8320]]) 0.430909126996994\n",
      "1445 tensor([[0.3502],\n",
      "        [0.5303],\n",
      "        [0.7029],\n",
      "        [0.8321]]) 0.43078672885894775\n",
      "1446 tensor([[0.3500],\n",
      "        [0.5303],\n",
      "        [0.7029],\n",
      "        [0.8322]]) 0.43066442012786865\n",
      "1447 tensor([[0.3499],\n",
      "        [0.5302],\n",
      "        [0.7029],\n",
      "        [0.8323]]) 0.4305421710014343\n",
      "1448 tensor([[0.3497],\n",
      "        [0.5301],\n",
      "        [0.7029],\n",
      "        [0.8323]]) 0.4304199814796448\n",
      "1449 tensor([[0.3496],\n",
      "        [0.5300],\n",
      "        [0.7030],\n",
      "        [0.8324]]) 0.4302978217601776\n",
      "1450 tensor([[0.3494],\n",
      "        [0.5300],\n",
      "        [0.7030],\n",
      "        [0.8325]]) 0.43017578125\n",
      "1451 tensor([[0.3493],\n",
      "        [0.5299],\n",
      "        [0.7030],\n",
      "        [0.8325]]) 0.4300538897514343\n",
      "1452 tensor([[0.3492],\n",
      "        [0.5298],\n",
      "        [0.7030],\n",
      "        [0.8326]]) 0.4299319386482239\n",
      "1453 tensor([[0.3490],\n",
      "        [0.5298],\n",
      "        [0.7031],\n",
      "        [0.8327]]) 0.42981016635894775\n",
      "1454 tensor([[0.3489],\n",
      "        [0.5297],\n",
      "        [0.7031],\n",
      "        [0.8327]]) 0.42968839406967163\n",
      "1455 tensor([[0.3487],\n",
      "        [0.5296],\n",
      "        [0.7031],\n",
      "        [0.8328]]) 0.42956680059432983\n",
      "1456 tensor([[0.3486],\n",
      "        [0.5296],\n",
      "        [0.7031],\n",
      "        [0.8329]]) 0.42944517731666565\n",
      "1457 tensor([[0.3484],\n",
      "        [0.5295],\n",
      "        [0.7031],\n",
      "        [0.8329]]) 0.429323673248291\n",
      "1458 tensor([[0.3483],\n",
      "        [0.5294],\n",
      "        [0.7032],\n",
      "        [0.8330]]) 0.42920222878456116\n",
      "1459 tensor([[0.3481],\n",
      "        [0.5294],\n",
      "        [0.7032],\n",
      "        [0.8331]]) 0.42908090353012085\n",
      "1460 tensor([[0.3480],\n",
      "        [0.5293],\n",
      "        [0.7032],\n",
      "        [0.8331]]) 0.4289596378803253\n",
      "1461 tensor([[0.3478],\n",
      "        [0.5292],\n",
      "        [0.7032],\n",
      "        [0.8332]]) 0.4288384020328522\n",
      "1462 tensor([[0.3477],\n",
      "        [0.5291],\n",
      "        [0.7032],\n",
      "        [0.8333]]) 0.42871734499931335\n",
      "1463 tensor([[0.3475],\n",
      "        [0.5291],\n",
      "        [0.7033],\n",
      "        [0.8333]]) 0.42859622836112976\n",
      "1464 tensor([[0.3474],\n",
      "        [0.5290],\n",
      "        [0.7033],\n",
      "        [0.8334]]) 0.4284753203392029\n",
      "1465 tensor([[0.3472],\n",
      "        [0.5289],\n",
      "        [0.7033],\n",
      "        [0.8335]]) 0.428354412317276\n",
      "1466 tensor([[0.3471],\n",
      "        [0.5289],\n",
      "        [0.7033],\n",
      "        [0.8335]]) 0.4282335937023163\n",
      "1467 tensor([[0.3469],\n",
      "        [0.5288],\n",
      "        [0.7034],\n",
      "        [0.8336]]) 0.42811280488967896\n",
      "1468 tensor([[0.3468],\n",
      "        [0.5287],\n",
      "        [0.7034],\n",
      "        [0.8337]]) 0.4279921352863312\n",
      "1469 tensor([[0.3466],\n",
      "        [0.5287],\n",
      "        [0.7034],\n",
      "        [0.8337]]) 0.4278714954853058\n",
      "1470 tensor([[0.3465],\n",
      "        [0.5286],\n",
      "        [0.7034],\n",
      "        [0.8338]]) 0.4277510344982147\n",
      "1471 tensor([[0.3463],\n",
      "        [0.5285],\n",
      "        [0.7034],\n",
      "        [0.8339]]) 0.42763054370880127\n",
      "1472 tensor([[0.3462],\n",
      "        [0.5285],\n",
      "        [0.7035],\n",
      "        [0.8339]]) 0.42751017212867737\n",
      "1473 tensor([[0.3460],\n",
      "        [0.5284],\n",
      "        [0.7035],\n",
      "        [0.8340]]) 0.42738988995552063\n",
      "1474 tensor([[0.3459],\n",
      "        [0.5283],\n",
      "        [0.7035],\n",
      "        [0.8341]]) 0.42726966738700867\n",
      "1475 tensor([[0.3457],\n",
      "        [0.5283],\n",
      "        [0.7035],\n",
      "        [0.8341]]) 0.4271494746208191\n",
      "1476 tensor([[0.3456],\n",
      "        [0.5282],\n",
      "        [0.7035],\n",
      "        [0.8342]]) 0.42702940106391907\n",
      "1477 tensor([[0.3454],\n",
      "        [0.5281],\n",
      "        [0.7036],\n",
      "        [0.8343]]) 0.4269094169139862\n",
      "1478 tensor([[0.3453],\n",
      "        [0.5280],\n",
      "        [0.7036],\n",
      "        [0.8343]]) 0.42678943276405334\n",
      "1479 tensor([[0.3451],\n",
      "        [0.5280],\n",
      "        [0.7036],\n",
      "        [0.8344]]) 0.4266696572303772\n",
      "1480 tensor([[0.3450],\n",
      "        [0.5279],\n",
      "        [0.7036],\n",
      "        [0.8344]]) 0.42654985189437866\n",
      "1481 tensor([[0.3449],\n",
      "        [0.5278],\n",
      "        [0.7036],\n",
      "        [0.8345]]) 0.4264300763607025\n",
      "1482 tensor([[0.3447],\n",
      "        [0.5278],\n",
      "        [0.7037],\n",
      "        [0.8346]]) 0.42631053924560547\n",
      "1483 tensor([[0.3446],\n",
      "        [0.5277],\n",
      "        [0.7037],\n",
      "        [0.8346]]) 0.42619091272354126\n",
      "1484 tensor([[0.3444],\n",
      "        [0.5276],\n",
      "        [0.7037],\n",
      "        [0.8347]]) 0.4260714650154114\n",
      "1485 tensor([[0.3443],\n",
      "        [0.5276],\n",
      "        [0.7037],\n",
      "        [0.8348]]) 0.42595210671424866\n",
      "1486 tensor([[0.3441],\n",
      "        [0.5275],\n",
      "        [0.7038],\n",
      "        [0.8348]]) 0.42583274841308594\n",
      "1487 tensor([[0.3440],\n",
      "        [0.5274],\n",
      "        [0.7038],\n",
      "        [0.8349]]) 0.425713449716568\n",
      "1488 tensor([[0.3438],\n",
      "        [0.5274],\n",
      "        [0.7038],\n",
      "        [0.8350]]) 0.4255942702293396\n",
      "1489 tensor([[0.3437],\n",
      "        [0.5273],\n",
      "        [0.7038],\n",
      "        [0.8350]]) 0.4254751205444336\n",
      "1490 tensor([[0.3435],\n",
      "        [0.5272],\n",
      "        [0.7038],\n",
      "        [0.8351]]) 0.4253561496734619\n",
      "1491 tensor([[0.3434],\n",
      "        [0.5272],\n",
      "        [0.7039],\n",
      "        [0.8352]]) 0.42523708939552307\n",
      "1492 tensor([[0.3432],\n",
      "        [0.5271],\n",
      "        [0.7039],\n",
      "        [0.8352]]) 0.42511823773384094\n",
      "1493 tensor([[0.3431],\n",
      "        [0.5270],\n",
      "        [0.7039],\n",
      "        [0.8353]]) 0.4249994158744812\n",
      "1494 tensor([[0.3429],\n",
      "        [0.5270],\n",
      "        [0.7039],\n",
      "        [0.8354]]) 0.42488065361976624\n",
      "1495 tensor([[0.3428],\n",
      "        [0.5269],\n",
      "        [0.7039],\n",
      "        [0.8354]]) 0.4247620105743408\n",
      "1496 tensor([[0.3427],\n",
      "        [0.5268],\n",
      "        [0.7040],\n",
      "        [0.8355]]) 0.4246433675289154\n",
      "1497 tensor([[0.3425],\n",
      "        [0.5268],\n",
      "        [0.7040],\n",
      "        [0.8356]]) 0.42452487349510193\n",
      "1498 tensor([[0.3424],\n",
      "        [0.5267],\n",
      "        [0.7040],\n",
      "        [0.8356]]) 0.42440640926361084\n",
      "1499 tensor([[0.3422],\n",
      "        [0.5266],\n",
      "        [0.7040],\n",
      "        [0.8357]]) 0.4242880344390869\n",
      "1500 tensor([[0.3421],\n",
      "        [0.5265],\n",
      "        [0.7040],\n",
      "        [0.8358]]) 0.42416974902153015\n",
      "1501 tensor([[0.3419],\n",
      "        [0.5265],\n",
      "        [0.7041],\n",
      "        [0.8358]]) 0.4240514636039734\n",
      "1502 tensor([[0.3418],\n",
      "        [0.5264],\n",
      "        [0.7041],\n",
      "        [0.8359]]) 0.42393332719802856\n",
      "1503 tensor([[0.3416],\n",
      "        [0.5263],\n",
      "        [0.7041],\n",
      "        [0.8360]]) 0.42381522059440613\n",
      "1504 tensor([[0.3415],\n",
      "        [0.5263],\n",
      "        [0.7041],\n",
      "        [0.8360]]) 0.42369720339775085\n",
      "1505 tensor([[0.3413],\n",
      "        [0.5262],\n",
      "        [0.7042],\n",
      "        [0.8361]]) 0.42357924580574036\n",
      "1506 tensor([[0.3412],\n",
      "        [0.5261],\n",
      "        [0.7042],\n",
      "        [0.8362]]) 0.423461377620697\n",
      "1507 tensor([[0.3411],\n",
      "        [0.5261],\n",
      "        [0.7042],\n",
      "        [0.8362]]) 0.42334359884262085\n",
      "1508 tensor([[0.3409],\n",
      "        [0.5260],\n",
      "        [0.7042],\n",
      "        [0.8363]]) 0.42322590947151184\n",
      "1509 tensor([[0.3408],\n",
      "        [0.5259],\n",
      "        [0.7042],\n",
      "        [0.8363]]) 0.42310816049575806\n",
      "1510 tensor([[0.3406],\n",
      "        [0.5259],\n",
      "        [0.7043],\n",
      "        [0.8364]]) 0.4229906499385834\n",
      "1511 tensor([[0.3405],\n",
      "        [0.5258],\n",
      "        [0.7043],\n",
      "        [0.8365]]) 0.4228730797767639\n",
      "1512 tensor([[0.3403],\n",
      "        [0.5257],\n",
      "        [0.7043],\n",
      "        [0.8365]]) 0.4227556586265564\n",
      "1513 tensor([[0.3402],\n",
      "        [0.5257],\n",
      "        [0.7043],\n",
      "        [0.8366]]) 0.42263829708099365\n",
      "1514 tensor([[0.3400],\n",
      "        [0.5256],\n",
      "        [0.7043],\n",
      "        [0.8367]]) 0.42252108454704285\n",
      "1515 tensor([[0.3399],\n",
      "        [0.5255],\n",
      "        [0.7044],\n",
      "        [0.8367]]) 0.42240387201309204\n",
      "1516 tensor([[0.3398],\n",
      "        [0.5255],\n",
      "        [0.7044],\n",
      "        [0.8368]]) 0.4222866892814636\n",
      "1517 tensor([[0.3396],\n",
      "        [0.5254],\n",
      "        [0.7044],\n",
      "        [0.8369]]) 0.4221695363521576\n",
      "1518 tensor([[0.3395],\n",
      "        [0.5253],\n",
      "        [0.7044],\n",
      "        [0.8369]]) 0.42205262184143066\n",
      "1519 tensor([[0.3393],\n",
      "        [0.5253],\n",
      "        [0.7044],\n",
      "        [0.8370]]) 0.42193564772605896\n",
      "1520 tensor([[0.3392],\n",
      "        [0.5252],\n",
      "        [0.7045],\n",
      "        [0.8371]]) 0.4218188524246216\n",
      "1521 tensor([[0.3390],\n",
      "        [0.5251],\n",
      "        [0.7045],\n",
      "        [0.8371]]) 0.4217020571231842\n",
      "1522 tensor([[0.3389],\n",
      "        [0.5251],\n",
      "        [0.7045],\n",
      "        [0.8372]]) 0.4215852916240692\n",
      "1523 tensor([[0.3387],\n",
      "        [0.5250],\n",
      "        [0.7045],\n",
      "        [0.8373]]) 0.4214686453342438\n",
      "1524 tensor([[0.3386],\n",
      "        [0.5249],\n",
      "        [0.7046],\n",
      "        [0.8373]]) 0.4213520884513855\n",
      "1525 tensor([[0.3385],\n",
      "        [0.5249],\n",
      "        [0.7046],\n",
      "        [0.8374]]) 0.421235591173172\n",
      "1526 tensor([[0.3383],\n",
      "        [0.5248],\n",
      "        [0.7046],\n",
      "        [0.8374]]) 0.42111915349960327\n",
      "1527 tensor([[0.3382],\n",
      "        [0.5247],\n",
      "        [0.7046],\n",
      "        [0.8375]]) 0.4210027754306793\n",
      "1528 tensor([[0.3380],\n",
      "        [0.5247],\n",
      "        [0.7046],\n",
      "        [0.8376]]) 0.4208865165710449\n",
      "1529 tensor([[0.3379],\n",
      "        [0.5246],\n",
      "        [0.7047],\n",
      "        [0.8376]]) 0.4207702875137329\n",
      "1530 tensor([[0.3377],\n",
      "        [0.5245],\n",
      "        [0.7047],\n",
      "        [0.8377]]) 0.42065414786338806\n",
      "1531 tensor([[0.3376],\n",
      "        [0.5244],\n",
      "        [0.7047],\n",
      "        [0.8378]]) 0.4205380380153656\n",
      "1532 tensor([[0.3374],\n",
      "        [0.5244],\n",
      "        [0.7047],\n",
      "        [0.8378]]) 0.4204220771789551\n",
      "1533 tensor([[0.3373],\n",
      "        [0.5243],\n",
      "        [0.7047],\n",
      "        [0.8379]]) 0.42030614614486694\n",
      "1534 tensor([[0.3372],\n",
      "        [0.5242],\n",
      "        [0.7048],\n",
      "        [0.8380]]) 0.42019030451774597\n",
      "1535 tensor([[0.3370],\n",
      "        [0.5242],\n",
      "        [0.7048],\n",
      "        [0.8380]]) 0.4200744330883026\n",
      "1536 tensor([[0.3369],\n",
      "        [0.5241],\n",
      "        [0.7048],\n",
      "        [0.8381]]) 0.41995877027511597\n",
      "1537 tensor([[0.3367],\n",
      "        [0.5240],\n",
      "        [0.7048],\n",
      "        [0.8382]]) 0.4198431372642517\n",
      "1538 tensor([[0.3366],\n",
      "        [0.5240],\n",
      "        [0.7048],\n",
      "        [0.8382]]) 0.4197275638580322\n",
      "1539 tensor([[0.3364],\n",
      "        [0.5239],\n",
      "        [0.7049],\n",
      "        [0.8383]]) 0.4196120500564575\n",
      "1540 tensor([[0.3363],\n",
      "        [0.5238],\n",
      "        [0.7049],\n",
      "        [0.8383]]) 0.41949665546417236\n",
      "1541 tensor([[0.3362],\n",
      "        [0.5238],\n",
      "        [0.7049],\n",
      "        [0.8384]]) 0.41938120126724243\n",
      "1542 tensor([[0.3360],\n",
      "        [0.5237],\n",
      "        [0.7049],\n",
      "        [0.8385]]) 0.4192659258842468\n",
      "1543 tensor([[0.3359],\n",
      "        [0.5236],\n",
      "        [0.7050],\n",
      "        [0.8385]]) 0.4191507399082184\n",
      "1544 tensor([[0.3357],\n",
      "        [0.5236],\n",
      "        [0.7050],\n",
      "        [0.8386]]) 0.41903558373451233\n",
      "1545 tensor([[0.3356],\n",
      "        [0.5235],\n",
      "        [0.7050],\n",
      "        [0.8387]]) 0.41892045736312866\n",
      "1546 tensor([[0.3355],\n",
      "        [0.5234],\n",
      "        [0.7050],\n",
      "        [0.8387]]) 0.41880548000335693\n",
      "1547 tensor([[0.3353],\n",
      "        [0.5234],\n",
      "        [0.7050],\n",
      "        [0.8388]]) 0.41869059205055237\n",
      "1548 tensor([[0.3352],\n",
      "        [0.5233],\n",
      "        [0.7051],\n",
      "        [0.8389]]) 0.4185756742954254\n",
      "1549 tensor([[0.3350],\n",
      "        [0.5232],\n",
      "        [0.7051],\n",
      "        [0.8389]]) 0.4184608459472656\n",
      "1550 tensor([[0.3349],\n",
      "        [0.5232],\n",
      "        [0.7051],\n",
      "        [0.8390]]) 0.418346107006073\n",
      "1551 tensor([[0.3347],\n",
      "        [0.5231],\n",
      "        [0.7051],\n",
      "        [0.8390]]) 0.4182314872741699\n",
      "1552 tensor([[0.3346],\n",
      "        [0.5230],\n",
      "        [0.7051],\n",
      "        [0.8391]]) 0.41811686754226685\n",
      "1553 tensor([[0.3345],\n",
      "        [0.5230],\n",
      "        [0.7052],\n",
      "        [0.8392]]) 0.4180023670196533\n",
      "1554 tensor([[0.3343],\n",
      "        [0.5229],\n",
      "        [0.7052],\n",
      "        [0.8392]]) 0.4178878962993622\n",
      "1555 tensor([[0.3342],\n",
      "        [0.5228],\n",
      "        [0.7052],\n",
      "        [0.8393]]) 0.4177735447883606\n",
      "1556 tensor([[0.3340],\n",
      "        [0.5228],\n",
      "        [0.7052],\n",
      "        [0.8394]]) 0.4176592230796814\n",
      "1557 tensor([[0.3339],\n",
      "        [0.5227],\n",
      "        [0.7052],\n",
      "        [0.8394]]) 0.41754499077796936\n",
      "1558 tensor([[0.3338],\n",
      "        [0.5226],\n",
      "        [0.7053],\n",
      "        [0.8395]]) 0.4174308180809021\n",
      "1559 tensor([[0.3336],\n",
      "        [0.5226],\n",
      "        [0.7053],\n",
      "        [0.8396]]) 0.4173166751861572\n",
      "1560 tensor([[0.3335],\n",
      "        [0.5225],\n",
      "        [0.7053],\n",
      "        [0.8396]]) 0.4172027111053467\n",
      "1561 tensor([[0.3333],\n",
      "        [0.5224],\n",
      "        [0.7053],\n",
      "        [0.8397]]) 0.41708865761756897\n",
      "1562 tensor([[0.3332],\n",
      "        [0.5224],\n",
      "        [0.7054],\n",
      "        [0.8397]]) 0.416974812746048\n",
      "1563 tensor([[0.3330],\n",
      "        [0.5223],\n",
      "        [0.7054],\n",
      "        [0.8398]]) 0.4168609380722046\n",
      "1564 tensor([[0.3329],\n",
      "        [0.5222],\n",
      "        [0.7054],\n",
      "        [0.8399]]) 0.41674721240997314\n",
      "1565 tensor([[0.3328],\n",
      "        [0.5222],\n",
      "        [0.7054],\n",
      "        [0.8399]]) 0.41663357615470886\n",
      "1566 tensor([[0.3326],\n",
      "        [0.5221],\n",
      "        [0.7054],\n",
      "        [0.8400]]) 0.4165198802947998\n",
      "1567 tensor([[0.3325],\n",
      "        [0.5220],\n",
      "        [0.7055],\n",
      "        [0.8401]]) 0.4164063334465027\n",
      "1568 tensor([[0.3323],\n",
      "        [0.5220],\n",
      "        [0.7055],\n",
      "        [0.8401]]) 0.4162929058074951\n",
      "1569 tensor([[0.3322],\n",
      "        [0.5219],\n",
      "        [0.7055],\n",
      "        [0.8402]]) 0.41617950797080994\n",
      "1570 tensor([[0.3321],\n",
      "        [0.5218],\n",
      "        [0.7055],\n",
      "        [0.8402]]) 0.41606613993644714\n",
      "1571 tensor([[0.3319],\n",
      "        [0.5218],\n",
      "        [0.7055],\n",
      "        [0.8403]]) 0.4159528613090515\n",
      "1572 tensor([[0.3318],\n",
      "        [0.5217],\n",
      "        [0.7056],\n",
      "        [0.8404]]) 0.41583967208862305\n",
      "1573 tensor([[0.3316],\n",
      "        [0.5216],\n",
      "        [0.7056],\n",
      "        [0.8404]]) 0.41572651267051697\n",
      "1574 tensor([[0.3315],\n",
      "        [0.5216],\n",
      "        [0.7056],\n",
      "        [0.8405]]) 0.41561347246170044\n",
      "1575 tensor([[0.3314],\n",
      "        [0.5215],\n",
      "        [0.7056],\n",
      "        [0.8406]]) 0.4155004620552063\n",
      "1576 tensor([[0.3312],\n",
      "        [0.5214],\n",
      "        [0.7056],\n",
      "        [0.8406]]) 0.4153875410556793\n",
      "1577 tensor([[0.3311],\n",
      "        [0.5214],\n",
      "        [0.7057],\n",
      "        [0.8407]]) 0.41527462005615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578 tensor([[0.3309],\n",
      "        [0.5213],\n",
      "        [0.7057],\n",
      "        [0.8407]]) 0.4151618480682373\n",
      "1579 tensor([[0.3308],\n",
      "        [0.5212],\n",
      "        [0.7057],\n",
      "        [0.8408]]) 0.41504913568496704\n",
      "1580 tensor([[0.3307],\n",
      "        [0.5212],\n",
      "        [0.7057],\n",
      "        [0.8409]]) 0.41493651270866394\n",
      "1581 tensor([[0.3305],\n",
      "        [0.5211],\n",
      "        [0.7058],\n",
      "        [0.8409]]) 0.4148239493370056\n",
      "1582 tensor([[0.3304],\n",
      "        [0.5211],\n",
      "        [0.7058],\n",
      "        [0.8410]]) 0.4147113859653473\n",
      "1583 tensor([[0.3302],\n",
      "        [0.5210],\n",
      "        [0.7058],\n",
      "        [0.8411]]) 0.4145989418029785\n",
      "1584 tensor([[0.3301],\n",
      "        [0.5209],\n",
      "        [0.7058],\n",
      "        [0.8411]]) 0.41448652744293213\n",
      "1585 tensor([[0.3300],\n",
      "        [0.5209],\n",
      "        [0.7058],\n",
      "        [0.8412]]) 0.4143742620944977\n",
      "1586 tensor([[0.3298],\n",
      "        [0.5208],\n",
      "        [0.7059],\n",
      "        [0.8412]]) 0.414262056350708\n",
      "1587 tensor([[0.3297],\n",
      "        [0.5207],\n",
      "        [0.7059],\n",
      "        [0.8413]]) 0.41414985060691833\n",
      "1588 tensor([[0.3296],\n",
      "        [0.5207],\n",
      "        [0.7059],\n",
      "        [0.8414]]) 0.41403770446777344\n",
      "1589 tensor([[0.3294],\n",
      "        [0.5206],\n",
      "        [0.7059],\n",
      "        [0.8414]]) 0.4139256775379181\n",
      "1590 tensor([[0.3293],\n",
      "        [0.5205],\n",
      "        [0.7059],\n",
      "        [0.8415]]) 0.4138137102127075\n",
      "1591 tensor([[0.3291],\n",
      "        [0.5205],\n",
      "        [0.7060],\n",
      "        [0.8416]]) 0.4137018024921417\n",
      "1592 tensor([[0.3290],\n",
      "        [0.5204],\n",
      "        [0.7060],\n",
      "        [0.8416]]) 0.4135900139808655\n",
      "1593 tensor([[0.3289],\n",
      "        [0.5203],\n",
      "        [0.7060],\n",
      "        [0.8417]]) 0.41347816586494446\n",
      "1594 tensor([[0.3287],\n",
      "        [0.5203],\n",
      "        [0.7060],\n",
      "        [0.8417]]) 0.41336649656295776\n",
      "1595 tensor([[0.3286],\n",
      "        [0.5202],\n",
      "        [0.7060],\n",
      "        [0.8418]]) 0.41325488686561584\n",
      "1596 tensor([[0.3284],\n",
      "        [0.5201],\n",
      "        [0.7061],\n",
      "        [0.8419]]) 0.4131433069705963\n",
      "1597 tensor([[0.3283],\n",
      "        [0.5201],\n",
      "        [0.7061],\n",
      "        [0.8419]]) 0.41303181648254395\n",
      "1598 tensor([[0.3282],\n",
      "        [0.5200],\n",
      "        [0.7061],\n",
      "        [0.8420]]) 0.4129203259944916\n",
      "1599 tensor([[0.3280],\n",
      "        [0.5199],\n",
      "        [0.7061],\n",
      "        [0.8421]]) 0.41280898451805115\n",
      "1600 tensor([[0.3279],\n",
      "        [0.5199],\n",
      "        [0.7062],\n",
      "        [0.8421]]) 0.4126976728439331\n",
      "1601 tensor([[0.3278],\n",
      "        [0.5198],\n",
      "        [0.7062],\n",
      "        [0.8422]]) 0.412586510181427\n",
      "1602 tensor([[0.3276],\n",
      "        [0.5197],\n",
      "        [0.7062],\n",
      "        [0.8422]]) 0.4124752879142761\n",
      "1603 tensor([[0.3275],\n",
      "        [0.5197],\n",
      "        [0.7062],\n",
      "        [0.8423]]) 0.41236427426338196\n",
      "1604 tensor([[0.3273],\n",
      "        [0.5196],\n",
      "        [0.7062],\n",
      "        [0.8424]]) 0.412253201007843\n",
      "1605 tensor([[0.3272],\n",
      "        [0.5195],\n",
      "        [0.7063],\n",
      "        [0.8424]]) 0.41214221715927124\n",
      "1606 tensor([[0.3271],\n",
      "        [0.5195],\n",
      "        [0.7063],\n",
      "        [0.8425]]) 0.4120313227176666\n",
      "1607 tensor([[0.3269],\n",
      "        [0.5194],\n",
      "        [0.7063],\n",
      "        [0.8425]]) 0.4119204878807068\n",
      "1608 tensor([[0.3268],\n",
      "        [0.5193],\n",
      "        [0.7063],\n",
      "        [0.8426]]) 0.4118097424507141\n",
      "1609 tensor([[0.3266],\n",
      "        [0.5193],\n",
      "        [0.7063],\n",
      "        [0.8427]]) 0.4116990566253662\n",
      "1610 tensor([[0.3265],\n",
      "        [0.5192],\n",
      "        [0.7064],\n",
      "        [0.8427]]) 0.4115884304046631\n",
      "1611 tensor([[0.3264],\n",
      "        [0.5191],\n",
      "        [0.7064],\n",
      "        [0.8428]]) 0.41147786378860474\n",
      "1612 tensor([[0.3262],\n",
      "        [0.5191],\n",
      "        [0.7064],\n",
      "        [0.8429]]) 0.41136738657951355\n",
      "1613 tensor([[0.3261],\n",
      "        [0.5190],\n",
      "        [0.7064],\n",
      "        [0.8429]]) 0.4112569987773895\n",
      "1614 tensor([[0.3260],\n",
      "        [0.5190],\n",
      "        [0.7064],\n",
      "        [0.8430]]) 0.4111466109752655\n",
      "1615 tensor([[0.3258],\n",
      "        [0.5189],\n",
      "        [0.7065],\n",
      "        [0.8430]]) 0.41103628277778625\n",
      "1616 tensor([[0.3257],\n",
      "        [0.5188],\n",
      "        [0.7065],\n",
      "        [0.8431]]) 0.41092604398727417\n",
      "1617 tensor([[0.3256],\n",
      "        [0.5188],\n",
      "        [0.7065],\n",
      "        [0.8432]]) 0.41081592440605164\n",
      "1618 tensor([[0.3254],\n",
      "        [0.5187],\n",
      "        [0.7065],\n",
      "        [0.8432]]) 0.4107057750225067\n",
      "1619 tensor([[0.3253],\n",
      "        [0.5186],\n",
      "        [0.7066],\n",
      "        [0.8433]]) 0.41059577465057373\n",
      "1620 tensor([[0.3251],\n",
      "        [0.5186],\n",
      "        [0.7066],\n",
      "        [0.8433]]) 0.4104858338832855\n",
      "1621 tensor([[0.3250],\n",
      "        [0.5185],\n",
      "        [0.7066],\n",
      "        [0.8434]]) 0.4103759229183197\n",
      "1622 tensor([[0.3249],\n",
      "        [0.5184],\n",
      "        [0.7066],\n",
      "        [0.8435]]) 0.41026610136032104\n",
      "1623 tensor([[0.3247],\n",
      "        [0.5184],\n",
      "        [0.7066],\n",
      "        [0.8435]]) 0.4101563096046448\n",
      "1624 tensor([[0.3246],\n",
      "        [0.5183],\n",
      "        [0.7067],\n",
      "        [0.8436]]) 0.41004663705825806\n",
      "1625 tensor([[0.3245],\n",
      "        [0.5182],\n",
      "        [0.7067],\n",
      "        [0.8436]]) 0.4099370241165161\n",
      "1626 tensor([[0.3243],\n",
      "        [0.5182],\n",
      "        [0.7067],\n",
      "        [0.8437]]) 0.40982744097709656\n",
      "1627 tensor([[0.3242],\n",
      "        [0.5181],\n",
      "        [0.7067],\n",
      "        [0.8438]]) 0.40971794724464417\n",
      "1628 tensor([[0.3241],\n",
      "        [0.5180],\n",
      "        [0.7067],\n",
      "        [0.8438]]) 0.40960854291915894\n",
      "1629 tensor([[0.3239],\n",
      "        [0.5180],\n",
      "        [0.7068],\n",
      "        [0.8439]]) 0.4094991683959961\n",
      "1630 tensor([[0.3238],\n",
      "        [0.5179],\n",
      "        [0.7068],\n",
      "        [0.8440]]) 0.4093898832798004\n",
      "1631 tensor([[0.3236],\n",
      "        [0.5178],\n",
      "        [0.7068],\n",
      "        [0.8440]]) 0.40928053855895996\n",
      "1632 tensor([[0.3235],\n",
      "        [0.5178],\n",
      "        [0.7068],\n",
      "        [0.8441]]) 0.409171462059021\n",
      "1633 tensor([[0.3234],\n",
      "        [0.5177],\n",
      "        [0.7068],\n",
      "        [0.8441]]) 0.40906229615211487\n",
      "1634 tensor([[0.3232],\n",
      "        [0.5177],\n",
      "        [0.7069],\n",
      "        [0.8442]]) 0.40895333886146545\n",
      "1635 tensor([[0.3231],\n",
      "        [0.5176],\n",
      "        [0.7069],\n",
      "        [0.8443]]) 0.40884432196617126\n",
      "1636 tensor([[0.3230],\n",
      "        [0.5175],\n",
      "        [0.7069],\n",
      "        [0.8443]]) 0.40873539447784424\n",
      "1637 tensor([[0.3228],\n",
      "        [0.5175],\n",
      "        [0.7069],\n",
      "        [0.8444]]) 0.4086265563964844\n",
      "1638 tensor([[0.3227],\n",
      "        [0.5174],\n",
      "        [0.7069],\n",
      "        [0.8444]]) 0.4085177779197693\n",
      "1639 tensor([[0.3226],\n",
      "        [0.5173],\n",
      "        [0.7070],\n",
      "        [0.8445]]) 0.408409059047699\n",
      "1640 tensor([[0.3224],\n",
      "        [0.5173],\n",
      "        [0.7070],\n",
      "        [0.8446]]) 0.4083004891872406\n",
      "1641 tensor([[0.3223],\n",
      "        [0.5172],\n",
      "        [0.7070],\n",
      "        [0.8446]]) 0.4081918001174927\n",
      "1642 tensor([[0.3222],\n",
      "        [0.5171],\n",
      "        [0.7070],\n",
      "        [0.8447]]) 0.4080832898616791\n",
      "1643 tensor([[0.3220],\n",
      "        [0.5171],\n",
      "        [0.7071],\n",
      "        [0.8447]]) 0.40797486901283264\n",
      "1644 tensor([[0.3219],\n",
      "        [0.5170],\n",
      "        [0.7071],\n",
      "        [0.8448]]) 0.407866507768631\n",
      "1645 tensor([[0.3218],\n",
      "        [0.5169],\n",
      "        [0.7071],\n",
      "        [0.8449]]) 0.4077581465244293\n",
      "1646 tensor([[0.3216],\n",
      "        [0.5169],\n",
      "        [0.7071],\n",
      "        [0.8449]]) 0.4076498746871948\n",
      "1647 tensor([[0.3215],\n",
      "        [0.5168],\n",
      "        [0.7071],\n",
      "        [0.8450]]) 0.40754175186157227\n",
      "1648 tensor([[0.3213],\n",
      "        [0.5167],\n",
      "        [0.7072],\n",
      "        [0.8450]]) 0.4074336290359497\n",
      "1649 tensor([[0.3212],\n",
      "        [0.5167],\n",
      "        [0.7072],\n",
      "        [0.8451]]) 0.40732550621032715\n",
      "1650 tensor([[0.3211],\n",
      "        [0.5166],\n",
      "        [0.7072],\n",
      "        [0.8452]]) 0.40721750259399414\n",
      "1651 tensor([[0.3209],\n",
      "        [0.5166],\n",
      "        [0.7072],\n",
      "        [0.8452]]) 0.4071095287799835\n",
      "1652 tensor([[0.3208],\n",
      "        [0.5165],\n",
      "        [0.7072],\n",
      "        [0.8453]]) 0.4070017337799072\n",
      "1653 tensor([[0.3207],\n",
      "        [0.5164],\n",
      "        [0.7073],\n",
      "        [0.8453]]) 0.40689387917518616\n",
      "1654 tensor([[0.3205],\n",
      "        [0.5164],\n",
      "        [0.7073],\n",
      "        [0.8454]]) 0.40678614377975464\n",
      "1655 tensor([[0.3204],\n",
      "        [0.5163],\n",
      "        [0.7073],\n",
      "        [0.8455]]) 0.4066784679889679\n",
      "1656 tensor([[0.3203],\n",
      "        [0.5162],\n",
      "        [0.7073],\n",
      "        [0.8455]]) 0.4065708518028259\n",
      "1657 tensor([[0.3201],\n",
      "        [0.5162],\n",
      "        [0.7073],\n",
      "        [0.8456]]) 0.4064633250236511\n",
      "1658 tensor([[0.3200],\n",
      "        [0.5161],\n",
      "        [0.7074],\n",
      "        [0.8456]]) 0.4063558578491211\n",
      "1659 tensor([[0.3199],\n",
      "        [0.5160],\n",
      "        [0.7074],\n",
      "        [0.8457]]) 0.40624845027923584\n",
      "1660 tensor([[0.3197],\n",
      "        [0.5160],\n",
      "        [0.7074],\n",
      "        [0.8458]]) 0.406141072511673\n",
      "1661 tensor([[0.3196],\n",
      "        [0.5159],\n",
      "        [0.7074],\n",
      "        [0.8458]]) 0.40603378415107727\n",
      "1662 tensor([[0.3195],\n",
      "        [0.5158],\n",
      "        [0.7074],\n",
      "        [0.8459]]) 0.40592655539512634\n",
      "1663 tensor([[0.3193],\n",
      "        [0.5158],\n",
      "        [0.7075],\n",
      "        [0.8459]]) 0.4058193862438202\n",
      "1664 tensor([[0.3192],\n",
      "        [0.5157],\n",
      "        [0.7075],\n",
      "        [0.8460]]) 0.4057123064994812\n",
      "1665 tensor([[0.3191],\n",
      "        [0.5157],\n",
      "        [0.7075],\n",
      "        [0.8461]]) 0.405605286359787\n",
      "1666 tensor([[0.3189],\n",
      "        [0.5156],\n",
      "        [0.7075],\n",
      "        [0.8461]]) 0.40549832582473755\n",
      "1667 tensor([[0.3188],\n",
      "        [0.5155],\n",
      "        [0.7076],\n",
      "        [0.8462]]) 0.4053913950920105\n",
      "1668 tensor([[0.3187],\n",
      "        [0.5155],\n",
      "        [0.7076],\n",
      "        [0.8462]]) 0.4052845239639282\n",
      "1669 tensor([[0.3185],\n",
      "        [0.5154],\n",
      "        [0.7076],\n",
      "        [0.8463]]) 0.4051777124404907\n",
      "1670 tensor([[0.3184],\n",
      "        [0.5153],\n",
      "        [0.7076],\n",
      "        [0.8464]]) 0.4050709903240204\n",
      "1671 tensor([[0.3183],\n",
      "        [0.5153],\n",
      "        [0.7076],\n",
      "        [0.8464]]) 0.4049643874168396\n",
      "1672 tensor([[0.3181],\n",
      "        [0.5152],\n",
      "        [0.7077],\n",
      "        [0.8465]]) 0.4048578143119812\n",
      "1673 tensor([[0.3180],\n",
      "        [0.5151],\n",
      "        [0.7077],\n",
      "        [0.8465]]) 0.4047513008117676\n",
      "1674 tensor([[0.3179],\n",
      "        [0.5151],\n",
      "        [0.7077],\n",
      "        [0.8466]]) 0.40464478731155396\n",
      "1675 tensor([[0.3177],\n",
      "        [0.5150],\n",
      "        [0.7077],\n",
      "        [0.8467]]) 0.4045383930206299\n",
      "1676 tensor([[0.3176],\n",
      "        [0.5150],\n",
      "        [0.7077],\n",
      "        [0.8467]]) 0.4044320583343506\n",
      "1677 tensor([[0.3175],\n",
      "        [0.5149],\n",
      "        [0.7078],\n",
      "        [0.8468]]) 0.40432578325271606\n",
      "1678 tensor([[0.3173],\n",
      "        [0.5148],\n",
      "        [0.7078],\n",
      "        [0.8468]]) 0.4042195677757263\n",
      "1679 tensor([[0.3172],\n",
      "        [0.5148],\n",
      "        [0.7078],\n",
      "        [0.8469]]) 0.4041134715080261\n",
      "1680 tensor([[0.3171],\n",
      "        [0.5147],\n",
      "        [0.7078],\n",
      "        [0.8469]]) 0.4040073752403259\n",
      "1681 tensor([[0.3169],\n",
      "        [0.5146],\n",
      "        [0.7078],\n",
      "        [0.8470]]) 0.4039013385772705\n",
      "1682 tensor([[0.3168],\n",
      "        [0.5146],\n",
      "        [0.7079],\n",
      "        [0.8471]]) 0.40379542112350464\n",
      "1683 tensor([[0.3167],\n",
      "        [0.5145],\n",
      "        [0.7079],\n",
      "        [0.8471]]) 0.4036894738674164\n",
      "1684 tensor([[0.3165],\n",
      "        [0.5144],\n",
      "        [0.7079],\n",
      "        [0.8472]]) 0.4035836458206177\n",
      "1685 tensor([[0.3164],\n",
      "        [0.5144],\n",
      "        [0.7079],\n",
      "        [0.8472]]) 0.40347790718078613\n",
      "1686 tensor([[0.3163],\n",
      "        [0.5143],\n",
      "        [0.7079],\n",
      "        [0.8473]]) 0.4033721685409546\n",
      "1687 tensor([[0.3162],\n",
      "        [0.5143],\n",
      "        [0.7080],\n",
      "        [0.8474]]) 0.4032665193080902\n",
      "1688 tensor([[0.3160],\n",
      "        [0.5142],\n",
      "        [0.7080],\n",
      "        [0.8474]]) 0.403160959482193\n",
      "1689 tensor([[0.3159],\n",
      "        [0.5141],\n",
      "        [0.7080],\n",
      "        [0.8475]]) 0.4030553996562958\n",
      "1690 tensor([[0.3158],\n",
      "        [0.5141],\n",
      "        [0.7080],\n",
      "        [0.8475]]) 0.4029499590396881\n",
      "1691 tensor([[0.3156],\n",
      "        [0.5140],\n",
      "        [0.7081],\n",
      "        [0.8476]]) 0.4028445780277252\n",
      "1692 tensor([[0.3155],\n",
      "        [0.5139],\n",
      "        [0.7081],\n",
      "        [0.8477]]) 0.4027392268180847\n",
      "1693 tensor([[0.3154],\n",
      "        [0.5139],\n",
      "        [0.7081],\n",
      "        [0.8477]]) 0.40263399481773376\n",
      "1694 tensor([[0.3152],\n",
      "        [0.5138],\n",
      "        [0.7081],\n",
      "        [0.8478]]) 0.40252885222435\n",
      "1695 tensor([[0.3151],\n",
      "        [0.5137],\n",
      "        [0.7081],\n",
      "        [0.8478]]) 0.4024237096309662\n",
      "1696 tensor([[0.3150],\n",
      "        [0.5137],\n",
      "        [0.7082],\n",
      "        [0.8479]]) 0.4023186266422272\n",
      "1697 tensor([[0.3148],\n",
      "        [0.5136],\n",
      "        [0.7082],\n",
      "        [0.8479]]) 0.40221357345581055\n",
      "1698 tensor([[0.3147],\n",
      "        [0.5136],\n",
      "        [0.7082],\n",
      "        [0.8480]]) 0.4021086096763611\n",
      "1699 tensor([[0.3146],\n",
      "        [0.5135],\n",
      "        [0.7082],\n",
      "        [0.8481]]) 0.4020037353038788\n",
      "1700 tensor([[0.3144],\n",
      "        [0.5134],\n",
      "        [0.7082],\n",
      "        [0.8481]]) 0.4018988609313965\n",
      "1701 tensor([[0.3143],\n",
      "        [0.5134],\n",
      "        [0.7083],\n",
      "        [0.8482]]) 0.4017941355705261\n",
      "1702 tensor([[0.3142],\n",
      "        [0.5133],\n",
      "        [0.7083],\n",
      "        [0.8482]]) 0.40168941020965576\n",
      "1703 tensor([[0.3141],\n",
      "        [0.5132],\n",
      "        [0.7083],\n",
      "        [0.8483]]) 0.40158477425575256\n",
      "1704 tensor([[0.3139],\n",
      "        [0.5132],\n",
      "        [0.7083],\n",
      "        [0.8484]]) 0.40148016810417175\n",
      "1705 tensor([[0.3138],\n",
      "        [0.5131],\n",
      "        [0.7083],\n",
      "        [0.8484]]) 0.4013756513595581\n",
      "1706 tensor([[0.3137],\n",
      "        [0.5130],\n",
      "        [0.7084],\n",
      "        [0.8485]]) 0.40127116441726685\n",
      "1707 tensor([[0.3135],\n",
      "        [0.5130],\n",
      "        [0.7084],\n",
      "        [0.8485]]) 0.40116679668426514\n",
      "1708 tensor([[0.3134],\n",
      "        [0.5129],\n",
      "        [0.7084],\n",
      "        [0.8486]]) 0.4010624289512634\n",
      "1709 tensor([[0.3133],\n",
      "        [0.5129],\n",
      "        [0.7084],\n",
      "        [0.8487]]) 0.40095818042755127\n",
      "1710 tensor([[0.3131],\n",
      "        [0.5128],\n",
      "        [0.7084],\n",
      "        [0.8487]]) 0.4008539915084839\n",
      "1711 tensor([[0.3130],\n",
      "        [0.5127],\n",
      "        [0.7085],\n",
      "        [0.8488]]) 0.4007498621940613\n",
      "1712 tensor([[0.3129],\n",
      "        [0.5127],\n",
      "        [0.7085],\n",
      "        [0.8488]]) 0.40064573287963867\n",
      "1713 tensor([[0.3128],\n",
      "        [0.5126],\n",
      "        [0.7085],\n",
      "        [0.8489]]) 0.4005417227745056\n",
      "1714 tensor([[0.3126],\n",
      "        [0.5125],\n",
      "        [0.7085],\n",
      "        [0.8489]]) 0.40043774247169495\n",
      "1715 tensor([[0.3125],\n",
      "        [0.5125],\n",
      "        [0.7086],\n",
      "        [0.8490]]) 0.40033382177352905\n",
      "1716 tensor([[0.3124],\n",
      "        [0.5124],\n",
      "        [0.7086],\n",
      "        [0.8491]]) 0.4002299904823303\n",
      "1717 tensor([[0.3122],\n",
      "        [0.5124],\n",
      "        [0.7086],\n",
      "        [0.8491]]) 0.4001261591911316\n",
      "1718 tensor([[0.3121],\n",
      "        [0.5123],\n",
      "        [0.7086],\n",
      "        [0.8492]]) 0.4000225067138672\n",
      "1719 tensor([[0.3120],\n",
      "        [0.5122],\n",
      "        [0.7086],\n",
      "        [0.8492]]) 0.3999188542366028\n",
      "1720 tensor([[0.3118],\n",
      "        [0.5122],\n",
      "        [0.7087],\n",
      "        [0.8493]]) 0.3998152017593384\n",
      "1721 tensor([[0.3117],\n",
      "        [0.5121],\n",
      "        [0.7087],\n",
      "        [0.8493]]) 0.3997116982936859\n",
      "1722 tensor([[0.3116],\n",
      "        [0.5120],\n",
      "        [0.7087],\n",
      "        [0.8494]]) 0.39960819482803345\n",
      "1723 tensor([[0.3115],\n",
      "        [0.5120],\n",
      "        [0.7087],\n",
      "        [0.8495]]) 0.39950481057167053\n",
      "1724 tensor([[0.3113],\n",
      "        [0.5119],\n",
      "        [0.7087],\n",
      "        [0.8495]]) 0.39940139651298523\n",
      "1725 tensor([[0.3112],\n",
      "        [0.5119],\n",
      "        [0.7088],\n",
      "        [0.8496]]) 0.39929819107055664\n",
      "1726 tensor([[0.3111],\n",
      "        [0.5118],\n",
      "        [0.7088],\n",
      "        [0.8496]]) 0.3991948962211609\n",
      "1727 tensor([[0.3109],\n",
      "        [0.5117],\n",
      "        [0.7088],\n",
      "        [0.8497]]) 0.3990917205810547\n",
      "1728 tensor([[0.3108],\n",
      "        [0.5117],\n",
      "        [0.7088],\n",
      "        [0.8498]]) 0.39898860454559326\n",
      "1729 tensor([[0.3107],\n",
      "        [0.5116],\n",
      "        [0.7088],\n",
      "        [0.8498]]) 0.3988855481147766\n",
      "1730 tensor([[0.3106],\n",
      "        [0.5115],\n",
      "        [0.7089],\n",
      "        [0.8499]]) 0.3987825810909271\n",
      "1731 tensor([[0.3104],\n",
      "        [0.5115],\n",
      "        [0.7089],\n",
      "        [0.8499]]) 0.3986796438694\n",
      "1732 tensor([[0.3103],\n",
      "        [0.5114],\n",
      "        [0.7089],\n",
      "        [0.8500]]) 0.3985767960548401\n",
      "1733 tensor([[0.3102],\n",
      "        [0.5114],\n",
      "        [0.7089],\n",
      "        [0.8500]]) 0.39847397804260254\n",
      "1734 tensor([[0.3100],\n",
      "        [0.5113],\n",
      "        [0.7089],\n",
      "        [0.8501]]) 0.39837121963500977\n",
      "1735 tensor([[0.3099],\n",
      "        [0.5112],\n",
      "        [0.7090],\n",
      "        [0.8502]]) 0.39826852083206177\n",
      "1736 tensor([[0.3098],\n",
      "        [0.5112],\n",
      "        [0.7090],\n",
      "        [0.8502]]) 0.3981659412384033\n",
      "1737 tensor([[0.3097],\n",
      "        [0.5111],\n",
      "        [0.7090],\n",
      "        [0.8503]]) 0.3980633020401001\n",
      "1738 tensor([[0.3095],\n",
      "        [0.5110],\n",
      "        [0.7090],\n",
      "        [0.8503]]) 0.3979608714580536\n",
      "1739 tensor([[0.3094],\n",
      "        [0.5110],\n",
      "        [0.7090],\n",
      "        [0.8504]]) 0.3978583812713623\n",
      "1740 tensor([[0.3093],\n",
      "        [0.5109],\n",
      "        [0.7091],\n",
      "        [0.8504]]) 0.39775601029396057\n",
      "1741 tensor([[0.3091],\n",
      "        [0.5109],\n",
      "        [0.7091],\n",
      "        [0.8505]]) 0.3976536989212036\n",
      "1742 tensor([[0.3090],\n",
      "        [0.5108],\n",
      "        [0.7091],\n",
      "        [0.8506]]) 0.39755141735076904\n",
      "1743 tensor([[0.3089],\n",
      "        [0.5107],\n",
      "        [0.7091],\n",
      "        [0.8506]]) 0.39744922518730164\n",
      "1744 tensor([[0.3088],\n",
      "        [0.5107],\n",
      "        [0.7092],\n",
      "        [0.8507]]) 0.3973470628261566\n",
      "1745 tensor([[0.3086],\n",
      "        [0.5106],\n",
      "        [0.7092],\n",
      "        [0.8507]]) 0.39724496006965637\n",
      "1746 tensor([[0.3085],\n",
      "        [0.5105],\n",
      "        [0.7092],\n",
      "        [0.8508]]) 0.3971429467201233\n",
      "1747 tensor([[0.3084],\n",
      "        [0.5105],\n",
      "        [0.7092],\n",
      "        [0.8508]]) 0.3970409631729126\n",
      "1748 tensor([[0.3082],\n",
      "        [0.5104],\n",
      "        [0.7092],\n",
      "        [0.8509]]) 0.39693906903266907\n",
      "1749 tensor([[0.3081],\n",
      "        [0.5104],\n",
      "        [0.7093],\n",
      "        [0.8510]]) 0.3968372046947479\n",
      "1750 tensor([[0.3080],\n",
      "        [0.5103],\n",
      "        [0.7093],\n",
      "        [0.8510]]) 0.39673539996147156\n",
      "1751 tensor([[0.3079],\n",
      "        [0.5102],\n",
      "        [0.7093],\n",
      "        [0.8511]]) 0.39663365483283997\n",
      "1752 tensor([[0.3077],\n",
      "        [0.5102],\n",
      "        [0.7093],\n",
      "        [0.8511]]) 0.39653196930885315\n",
      "1753 tensor([[0.3076],\n",
      "        [0.5101],\n",
      "        [0.7093],\n",
      "        [0.8512]]) 0.39643043279647827\n",
      "1754 tensor([[0.3075],\n",
      "        [0.5100],\n",
      "        [0.7094],\n",
      "        [0.8512]]) 0.3963288366794586\n",
      "1755 tensor([[0.3074],\n",
      "        [0.5100],\n",
      "        [0.7094],\n",
      "        [0.8513]]) 0.3962273597717285\n",
      "1756 tensor([[0.3072],\n",
      "        [0.5099],\n",
      "        [0.7094],\n",
      "        [0.8514]]) 0.3961259424686432\n",
      "1757 tensor([[0.3071],\n",
      "        [0.5099],\n",
      "        [0.7094],\n",
      "        [0.8514]]) 0.39602458477020264\n",
      "1758 tensor([[0.3070],\n",
      "        [0.5098],\n",
      "        [0.7094],\n",
      "        [0.8515]]) 0.39592331647872925\n",
      "1759 tensor([[0.3068],\n",
      "        [0.5097],\n",
      "        [0.7095],\n",
      "        [0.8515]]) 0.39582201838493347\n",
      "1760 tensor([[0.3067],\n",
      "        [0.5097],\n",
      "        [0.7095],\n",
      "        [0.8516]]) 0.39572077989578247\n",
      "1761 tensor([[0.3066],\n",
      "        [0.5096],\n",
      "        [0.7095],\n",
      "        [0.8516]]) 0.39561963081359863\n",
      "1762 tensor([[0.3065],\n",
      "        [0.5095],\n",
      "        [0.7095],\n",
      "        [0.8517]]) 0.39551863074302673\n",
      "1763 tensor([[0.3063],\n",
      "        [0.5095],\n",
      "        [0.7095],\n",
      "        [0.8517]]) 0.39541757106781006\n",
      "1764 tensor([[0.3062],\n",
      "        [0.5094],\n",
      "        [0.7096],\n",
      "        [0.8518]]) 0.39531663060188293\n",
      "1765 tensor([[0.3061],\n",
      "        [0.5094],\n",
      "        [0.7096],\n",
      "        [0.8519]]) 0.3952156901359558\n",
      "1766 tensor([[0.3060],\n",
      "        [0.5093],\n",
      "        [0.7096],\n",
      "        [0.8519]]) 0.3951148986816406\n",
      "1767 tensor([[0.3058],\n",
      "        [0.5092],\n",
      "        [0.7096],\n",
      "        [0.8520]]) 0.39501410722732544\n",
      "1768 tensor([[0.3057],\n",
      "        [0.5092],\n",
      "        [0.7096],\n",
      "        [0.8520]]) 0.39491337537765503\n",
      "1769 tensor([[0.3056],\n",
      "        [0.5091],\n",
      "        [0.7097],\n",
      "        [0.8521]]) 0.3948127031326294\n",
      "1770 tensor([[0.3055],\n",
      "        [0.5091],\n",
      "        [0.7097],\n",
      "        [0.8521]]) 0.3947121500968933\n",
      "1771 tensor([[0.3053],\n",
      "        [0.5090],\n",
      "        [0.7097],\n",
      "        [0.8522]]) 0.39461156725883484\n",
      "1772 tensor([[0.3052],\n",
      "        [0.5089],\n",
      "        [0.7097],\n",
      "        [0.8523]]) 0.39451107382774353\n",
      "1773 tensor([[0.3051],\n",
      "        [0.5089],\n",
      "        [0.7097],\n",
      "        [0.8523]]) 0.394410640001297\n",
      "1774 tensor([[0.3050],\n",
      "        [0.5088],\n",
      "        [0.7098],\n",
      "        [0.8524]]) 0.3943102955818176\n",
      "1775 tensor([[0.3048],\n",
      "        [0.5087],\n",
      "        [0.7098],\n",
      "        [0.8524]]) 0.39420995116233826\n",
      "1776 tensor([[0.3047],\n",
      "        [0.5087],\n",
      "        [0.7098],\n",
      "        [0.8525]]) 0.39410969614982605\n",
      "1777 tensor([[0.3046],\n",
      "        [0.5086],\n",
      "        [0.7098],\n",
      "        [0.8525]]) 0.394009530544281\n",
      "1778 tensor([[0.3045],\n",
      "        [0.5086],\n",
      "        [0.7099],\n",
      "        [0.8526]]) 0.39390936493873596\n",
      "1779 tensor([[0.3043],\n",
      "        [0.5085],\n",
      "        [0.7099],\n",
      "        [0.8527]]) 0.39380931854248047\n",
      "1780 tensor([[0.3042],\n",
      "        [0.5084],\n",
      "        [0.7099],\n",
      "        [0.8527]]) 0.39370930194854736\n",
      "1781 tensor([[0.3041],\n",
      "        [0.5084],\n",
      "        [0.7099],\n",
      "        [0.8528]]) 0.39360928535461426\n",
      "1782 tensor([[0.3040],\n",
      "        [0.5083],\n",
      "        [0.7099],\n",
      "        [0.8528]]) 0.3935094475746155\n",
      "1783 tensor([[0.3038],\n",
      "        [0.5083],\n",
      "        [0.7100],\n",
      "        [0.8529]]) 0.3934096097946167\n",
      "1784 tensor([[0.3037],\n",
      "        [0.5082],\n",
      "        [0.7100],\n",
      "        [0.8529]]) 0.3933097720146179\n",
      "1785 tensor([[0.3036],\n",
      "        [0.5081],\n",
      "        [0.7100],\n",
      "        [0.8530]]) 0.3932100534439087\n",
      "1786 tensor([[0.3035],\n",
      "        [0.5081],\n",
      "        [0.7100],\n",
      "        [0.8530]]) 0.39311036467552185\n",
      "1787 tensor([[0.3033],\n",
      "        [0.5080],\n",
      "        [0.7100],\n",
      "        [0.8531]]) 0.3930107653141022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788 tensor([[0.3032],\n",
      "        [0.5079],\n",
      "        [0.7101],\n",
      "        [0.8532]]) 0.3929111957550049\n",
      "1789 tensor([[0.3031],\n",
      "        [0.5079],\n",
      "        [0.7101],\n",
      "        [0.8532]]) 0.39281174540519714\n",
      "1790 tensor([[0.3030],\n",
      "        [0.5078],\n",
      "        [0.7101],\n",
      "        [0.8533]]) 0.392712265253067\n",
      "1791 tensor([[0.3028],\n",
      "        [0.5078],\n",
      "        [0.7101],\n",
      "        [0.8533]]) 0.39261290431022644\n",
      "1792 tensor([[0.3027],\n",
      "        [0.5077],\n",
      "        [0.7101],\n",
      "        [0.8534]]) 0.39251354336738586\n",
      "1793 tensor([[0.3026],\n",
      "        [0.5076],\n",
      "        [0.7102],\n",
      "        [0.8534]]) 0.39241430163383484\n",
      "1794 tensor([[0.3025],\n",
      "        [0.5076],\n",
      "        [0.7102],\n",
      "        [0.8535]]) 0.3923150897026062\n",
      "1795 tensor([[0.3023],\n",
      "        [0.5075],\n",
      "        [0.7102],\n",
      "        [0.8535]]) 0.39221593737602234\n",
      "1796 tensor([[0.3022],\n",
      "        [0.5075],\n",
      "        [0.7102],\n",
      "        [0.8536]]) 0.39211681485176086\n",
      "1797 tensor([[0.3021],\n",
      "        [0.5074],\n",
      "        [0.7102],\n",
      "        [0.8537]]) 0.39201778173446655\n",
      "1798 tensor([[0.3020],\n",
      "        [0.5073],\n",
      "        [0.7103],\n",
      "        [0.8537]]) 0.3919188678264618\n",
      "1799 tensor([[0.3018],\n",
      "        [0.5073],\n",
      "        [0.7103],\n",
      "        [0.8538]]) 0.39181992411613464\n",
      "1800 tensor([[0.3017],\n",
      "        [0.5072],\n",
      "        [0.7103],\n",
      "        [0.8538]]) 0.39172104001045227\n",
      "1801 tensor([[0.3016],\n",
      "        [0.5071],\n",
      "        [0.7103],\n",
      "        [0.8539]]) 0.39162224531173706\n",
      "1802 tensor([[0.3015],\n",
      "        [0.5071],\n",
      "        [0.7103],\n",
      "        [0.8539]]) 0.39152348041534424\n",
      "1803 tensor([[0.3013],\n",
      "        [0.5070],\n",
      "        [0.7104],\n",
      "        [0.8540]]) 0.3914247751235962\n",
      "1804 tensor([[0.3012],\n",
      "        [0.5070],\n",
      "        [0.7104],\n",
      "        [0.8540]]) 0.3913261294364929\n",
      "1805 tensor([[0.3011],\n",
      "        [0.5069],\n",
      "        [0.7104],\n",
      "        [0.8541]]) 0.3912275731563568\n",
      "1806 tensor([[0.3010],\n",
      "        [0.5068],\n",
      "        [0.7104],\n",
      "        [0.8542]]) 0.3911290466785431\n",
      "1807 tensor([[0.3008],\n",
      "        [0.5068],\n",
      "        [0.7104],\n",
      "        [0.8542]]) 0.39103060960769653\n",
      "1808 tensor([[0.3007],\n",
      "        [0.5067],\n",
      "        [0.7105],\n",
      "        [0.8543]]) 0.3909321427345276\n",
      "1809 tensor([[0.3006],\n",
      "        [0.5067],\n",
      "        [0.7105],\n",
      "        [0.8543]]) 0.39083385467529297\n",
      "1810 tensor([[0.3005],\n",
      "        [0.5066],\n",
      "        [0.7105],\n",
      "        [0.8544]]) 0.39073556661605835\n",
      "1811 tensor([[0.3003],\n",
      "        [0.5065],\n",
      "        [0.7105],\n",
      "        [0.8544]]) 0.3906373083591461\n",
      "1812 tensor([[0.3002],\n",
      "        [0.5065],\n",
      "        [0.7106],\n",
      "        [0.8545]]) 0.39053910970687866\n",
      "1813 tensor([[0.3001],\n",
      "        [0.5064],\n",
      "        [0.7106],\n",
      "        [0.8545]]) 0.390440970659256\n",
      "1814 tensor([[0.3000],\n",
      "        [0.5064],\n",
      "        [0.7106],\n",
      "        [0.8546]]) 0.39034295082092285\n",
      "1815 tensor([[0.2999],\n",
      "        [0.5063],\n",
      "        [0.7106],\n",
      "        [0.8546]]) 0.3902449309825897\n",
      "1816 tensor([[0.2997],\n",
      "        [0.5062],\n",
      "        [0.7106],\n",
      "        [0.8547]]) 0.3901469111442566\n",
      "1817 tensor([[0.2996],\n",
      "        [0.5062],\n",
      "        [0.7107],\n",
      "        [0.8548]]) 0.390049010515213\n",
      "1818 tensor([[0.2995],\n",
      "        [0.5061],\n",
      "        [0.7107],\n",
      "        [0.8548]]) 0.389951229095459\n",
      "1819 tensor([[0.2994],\n",
      "        [0.5061],\n",
      "        [0.7107],\n",
      "        [0.8549]]) 0.38985341787338257\n",
      "1820 tensor([[0.2992],\n",
      "        [0.5060],\n",
      "        [0.7107],\n",
      "        [0.8549]]) 0.3897557258605957\n",
      "1821 tensor([[0.2991],\n",
      "        [0.5059],\n",
      "        [0.7107],\n",
      "        [0.8550]]) 0.3896580636501312\n",
      "1822 tensor([[0.2990],\n",
      "        [0.5059],\n",
      "        [0.7108],\n",
      "        [0.8550]]) 0.38956043124198914\n",
      "1823 tensor([[0.2989],\n",
      "        [0.5058],\n",
      "        [0.7108],\n",
      "        [0.8551]]) 0.38946282863616943\n",
      "1824 tensor([[0.2988],\n",
      "        [0.5058],\n",
      "        [0.7108],\n",
      "        [0.8551]]) 0.3893653154373169\n",
      "1825 tensor([[0.2986],\n",
      "        [0.5057],\n",
      "        [0.7108],\n",
      "        [0.8552]]) 0.3892679214477539\n",
      "1826 tensor([[0.2985],\n",
      "        [0.5056],\n",
      "        [0.7108],\n",
      "        [0.8553]]) 0.3891705274581909\n",
      "1827 tensor([[0.2984],\n",
      "        [0.5056],\n",
      "        [0.7109],\n",
      "        [0.8553]]) 0.38907313346862793\n",
      "1828 tensor([[0.2983],\n",
      "        [0.5055],\n",
      "        [0.7109],\n",
      "        [0.8554]]) 0.38897591829299927\n",
      "1829 tensor([[0.2981],\n",
      "        [0.5054],\n",
      "        [0.7109],\n",
      "        [0.8554]]) 0.38887864351272583\n",
      "1830 tensor([[0.2980],\n",
      "        [0.5054],\n",
      "        [0.7109],\n",
      "        [0.8555]]) 0.38878148794174194\n",
      "1831 tensor([[0.2979],\n",
      "        [0.5053],\n",
      "        [0.7109],\n",
      "        [0.8555]]) 0.38868436217308044\n",
      "1832 tensor([[0.2978],\n",
      "        [0.5053],\n",
      "        [0.7110],\n",
      "        [0.8556]]) 0.3885873556137085\n",
      "1833 tensor([[0.2977],\n",
      "        [0.5052],\n",
      "        [0.7110],\n",
      "        [0.8556]]) 0.38849031925201416\n",
      "1834 tensor([[0.2975],\n",
      "        [0.5051],\n",
      "        [0.7110],\n",
      "        [0.8557]]) 0.3883934020996094\n",
      "1835 tensor([[0.2974],\n",
      "        [0.5051],\n",
      "        [0.7110],\n",
      "        [0.8557]]) 0.388296514749527\n",
      "1836 tensor([[0.2973],\n",
      "        [0.5050],\n",
      "        [0.7110],\n",
      "        [0.8558]]) 0.38819968700408936\n",
      "1837 tensor([[0.2972],\n",
      "        [0.5050],\n",
      "        [0.7111],\n",
      "        [0.8559]]) 0.3881029188632965\n",
      "1838 tensor([[0.2970],\n",
      "        [0.5049],\n",
      "        [0.7111],\n",
      "        [0.8559]]) 0.38800621032714844\n",
      "1839 tensor([[0.2969],\n",
      "        [0.5048],\n",
      "        [0.7111],\n",
      "        [0.8560]]) 0.38790953159332275\n",
      "1840 tensor([[0.2968],\n",
      "        [0.5048],\n",
      "        [0.7111],\n",
      "        [0.8560]]) 0.38781294226646423\n",
      "1841 tensor([[0.2967],\n",
      "        [0.5047],\n",
      "        [0.7111],\n",
      "        [0.8561]]) 0.3877164125442505\n",
      "1842 tensor([[0.2966],\n",
      "        [0.5047],\n",
      "        [0.7112],\n",
      "        [0.8561]]) 0.38761988282203674\n",
      "1843 tensor([[0.2964],\n",
      "        [0.5046],\n",
      "        [0.7112],\n",
      "        [0.8562]]) 0.38752347230911255\n",
      "1844 tensor([[0.2963],\n",
      "        [0.5045],\n",
      "        [0.7112],\n",
      "        [0.8562]]) 0.38742709159851074\n",
      "1845 tensor([[0.2962],\n",
      "        [0.5045],\n",
      "        [0.7112],\n",
      "        [0.8563]]) 0.38733071088790894\n",
      "1846 tensor([[0.2961],\n",
      "        [0.5044],\n",
      "        [0.7112],\n",
      "        [0.8563]]) 0.3872344493865967\n",
      "1847 tensor([[0.2960],\n",
      "        [0.5044],\n",
      "        [0.7113],\n",
      "        [0.8564]]) 0.3871382474899292\n",
      "1848 tensor([[0.2958],\n",
      "        [0.5043],\n",
      "        [0.7113],\n",
      "        [0.8564]]) 0.3870420753955841\n",
      "1849 tensor([[0.2957],\n",
      "        [0.5042],\n",
      "        [0.7113],\n",
      "        [0.8565]]) 0.3869459331035614\n",
      "1850 tensor([[0.2956],\n",
      "        [0.5042],\n",
      "        [0.7113],\n",
      "        [0.8566]]) 0.38684988021850586\n",
      "1851 tensor([[0.2955],\n",
      "        [0.5041],\n",
      "        [0.7114],\n",
      "        [0.8566]]) 0.3867538869380951\n",
      "1852 tensor([[0.2953],\n",
      "        [0.5041],\n",
      "        [0.7114],\n",
      "        [0.8567]]) 0.3866579234600067\n",
      "1853 tensor([[0.2952],\n",
      "        [0.5040],\n",
      "        [0.7114],\n",
      "        [0.8567]]) 0.3865620493888855\n",
      "1854 tensor([[0.2951],\n",
      "        [0.5039],\n",
      "        [0.7114],\n",
      "        [0.8568]]) 0.38646620512008667\n",
      "1855 tensor([[0.2950],\n",
      "        [0.5039],\n",
      "        [0.7114],\n",
      "        [0.8568]]) 0.3863704800605774\n",
      "1856 tensor([[0.2949],\n",
      "        [0.5038],\n",
      "        [0.7115],\n",
      "        [0.8569]]) 0.3862747251987457\n",
      "1857 tensor([[0.2947],\n",
      "        [0.5038],\n",
      "        [0.7115],\n",
      "        [0.8569]]) 0.38617902994155884\n",
      "1858 tensor([[0.2946],\n",
      "        [0.5037],\n",
      "        [0.7115],\n",
      "        [0.8570]]) 0.3860834538936615\n",
      "1859 tensor([[0.2945],\n",
      "        [0.5036],\n",
      "        [0.7115],\n",
      "        [0.8570]]) 0.38598787784576416\n",
      "1860 tensor([[0.2944],\n",
      "        [0.5036],\n",
      "        [0.7115],\n",
      "        [0.8571]]) 0.3858923316001892\n",
      "1861 tensor([[0.2943],\n",
      "        [0.5035],\n",
      "        [0.7116],\n",
      "        [0.8571]]) 0.3857969343662262\n",
      "1862 tensor([[0.2941],\n",
      "        [0.5035],\n",
      "        [0.7116],\n",
      "        [0.8572]]) 0.38570156693458557\n",
      "1863 tensor([[0.2940],\n",
      "        [0.5034],\n",
      "        [0.7116],\n",
      "        [0.8573]]) 0.38560616970062256\n",
      "1864 tensor([[0.2939],\n",
      "        [0.5033],\n",
      "        [0.7116],\n",
      "        [0.8573]]) 0.3855108916759491\n",
      "1865 tensor([[0.2938],\n",
      "        [0.5033],\n",
      "        [0.7116],\n",
      "        [0.8574]]) 0.38541561365127563\n",
      "1866 tensor([[0.2937],\n",
      "        [0.5032],\n",
      "        [0.7117],\n",
      "        [0.8574]]) 0.3853204548358917\n",
      "1867 tensor([[0.2935],\n",
      "        [0.5032],\n",
      "        [0.7117],\n",
      "        [0.8575]]) 0.3852253258228302\n",
      "1868 tensor([[0.2934],\n",
      "        [0.5031],\n",
      "        [0.7117],\n",
      "        [0.8575]]) 0.38513022661209106\n",
      "1869 tensor([[0.2933],\n",
      "        [0.5030],\n",
      "        [0.7117],\n",
      "        [0.8576]]) 0.3850352466106415\n",
      "1870 tensor([[0.2932],\n",
      "        [0.5030],\n",
      "        [0.7117],\n",
      "        [0.8576]]) 0.3849402666091919\n",
      "1871 tensor([[0.2931],\n",
      "        [0.5029],\n",
      "        [0.7118],\n",
      "        [0.8577]]) 0.3848453760147095\n",
      "1872 tensor([[0.2930],\n",
      "        [0.5029],\n",
      "        [0.7118],\n",
      "        [0.8577]]) 0.38475048542022705\n",
      "1873 tensor([[0.2928],\n",
      "        [0.5028],\n",
      "        [0.7118],\n",
      "        [0.8578]]) 0.3846556544303894\n",
      "1874 tensor([[0.2927],\n",
      "        [0.5027],\n",
      "        [0.7118],\n",
      "        [0.8578]]) 0.3845609724521637\n",
      "1875 tensor([[0.2926],\n",
      "        [0.5027],\n",
      "        [0.7118],\n",
      "        [0.8579]]) 0.384466290473938\n",
      "1876 tensor([[0.2925],\n",
      "        [0.5026],\n",
      "        [0.7119],\n",
      "        [0.8579]]) 0.38437163829803467\n",
      "1877 tensor([[0.2924],\n",
      "        [0.5026],\n",
      "        [0.7119],\n",
      "        [0.8580]]) 0.3842770755290985\n",
      "1878 tensor([[0.2922],\n",
      "        [0.5025],\n",
      "        [0.7119],\n",
      "        [0.8581]]) 0.38418251276016235\n",
      "1879 tensor([[0.2921],\n",
      "        [0.5025],\n",
      "        [0.7119],\n",
      "        [0.8581]]) 0.38408803939819336\n",
      "1880 tensor([[0.2920],\n",
      "        [0.5024],\n",
      "        [0.7119],\n",
      "        [0.8582]]) 0.38399362564086914\n",
      "1881 tensor([[0.2919],\n",
      "        [0.5023],\n",
      "        [0.7120],\n",
      "        [0.8582]]) 0.3838992714881897\n",
      "1882 tensor([[0.2918],\n",
      "        [0.5023],\n",
      "        [0.7120],\n",
      "        [0.8583]]) 0.38380491733551025\n",
      "1883 tensor([[0.2916],\n",
      "        [0.5022],\n",
      "        [0.7120],\n",
      "        [0.8583]]) 0.38371068239212036\n",
      "1884 tensor([[0.2915],\n",
      "        [0.5022],\n",
      "        [0.7120],\n",
      "        [0.8584]]) 0.38361647725105286\n",
      "1885 tensor([[0.2914],\n",
      "        [0.5021],\n",
      "        [0.7120],\n",
      "        [0.8584]]) 0.38352230191230774\n",
      "1886 tensor([[0.2913],\n",
      "        [0.5020],\n",
      "        [0.7121],\n",
      "        [0.8585]]) 0.3834282159805298\n",
      "1887 tensor([[0.2912],\n",
      "        [0.5020],\n",
      "        [0.7121],\n",
      "        [0.8585]]) 0.3833341598510742\n",
      "1888 tensor([[0.2911],\n",
      "        [0.5019],\n",
      "        [0.7121],\n",
      "        [0.8586]]) 0.38324010372161865\n",
      "1889 tensor([[0.2909],\n",
      "        [0.5019],\n",
      "        [0.7121],\n",
      "        [0.8586]]) 0.3831462264060974\n",
      "1890 tensor([[0.2908],\n",
      "        [0.5018],\n",
      "        [0.7121],\n",
      "        [0.8587]]) 0.3830523192882538\n",
      "1891 tensor([[0.2907],\n",
      "        [0.5017],\n",
      "        [0.7122],\n",
      "        [0.8587]]) 0.3829585313796997\n",
      "1892 tensor([[0.2906],\n",
      "        [0.5017],\n",
      "        [0.7122],\n",
      "        [0.8588]]) 0.382864773273468\n",
      "1893 tensor([[0.2905],\n",
      "        [0.5016],\n",
      "        [0.7122],\n",
      "        [0.8588]]) 0.38277101516723633\n",
      "1894 tensor([[0.2903],\n",
      "        [0.5016],\n",
      "        [0.7122],\n",
      "        [0.8589]]) 0.3826773762702942\n",
      "1895 tensor([[0.2902],\n",
      "        [0.5015],\n",
      "        [0.7122],\n",
      "        [0.8590]]) 0.38258370757102966\n",
      "1896 tensor([[0.2901],\n",
      "        [0.5014],\n",
      "        [0.7123],\n",
      "        [0.8590]]) 0.3824900984764099\n",
      "1897 tensor([[0.2900],\n",
      "        [0.5014],\n",
      "        [0.7123],\n",
      "        [0.8591]]) 0.3823966085910797\n",
      "1898 tensor([[0.2899],\n",
      "        [0.5013],\n",
      "        [0.7123],\n",
      "        [0.8591]]) 0.3823031485080719\n",
      "1899 tensor([[0.2898],\n",
      "        [0.5013],\n",
      "        [0.7123],\n",
      "        [0.8592]]) 0.3822097182273865\n",
      "1900 tensor([[0.2896],\n",
      "        [0.5012],\n",
      "        [0.7123],\n",
      "        [0.8592]]) 0.3821163773536682\n",
      "1901 tensor([[0.2895],\n",
      "        [0.5011],\n",
      "        [0.7124],\n",
      "        [0.8593]]) 0.38202306628227234\n",
      "1902 tensor([[0.2894],\n",
      "        [0.5011],\n",
      "        [0.7124],\n",
      "        [0.8593]]) 0.38192981481552124\n",
      "1903 tensor([[0.2893],\n",
      "        [0.5010],\n",
      "        [0.7124],\n",
      "        [0.8594]]) 0.3818366527557373\n",
      "1904 tensor([[0.2892],\n",
      "        [0.5010],\n",
      "        [0.7124],\n",
      "        [0.8594]]) 0.381743460893631\n",
      "1905 tensor([[0.2890],\n",
      "        [0.5009],\n",
      "        [0.7125],\n",
      "        [0.8595]]) 0.3816503882408142\n",
      "1906 tensor([[0.2889],\n",
      "        [0.5009],\n",
      "        [0.7125],\n",
      "        [0.8595]]) 0.3815573453903198\n",
      "1907 tensor([[0.2888],\n",
      "        [0.5008],\n",
      "        [0.7125],\n",
      "        [0.8596]]) 0.3814643919467926\n",
      "1908 tensor([[0.2887],\n",
      "        [0.5007],\n",
      "        [0.7125],\n",
      "        [0.8596]]) 0.38137146830558777\n",
      "1909 tensor([[0.2886],\n",
      "        [0.5007],\n",
      "        [0.7125],\n",
      "        [0.8597]]) 0.38127854466438293\n",
      "1910 tensor([[0.2885],\n",
      "        [0.5006],\n",
      "        [0.7126],\n",
      "        [0.8597]]) 0.38118574023246765\n",
      "1911 tensor([[0.2883],\n",
      "        [0.5006],\n",
      "        [0.7126],\n",
      "        [0.8598]]) 0.38109296560287476\n",
      "1912 tensor([[0.2882],\n",
      "        [0.5005],\n",
      "        [0.7126],\n",
      "        [0.8598]]) 0.38100019097328186\n",
      "1913 tensor([[0.2881],\n",
      "        [0.5004],\n",
      "        [0.7126],\n",
      "        [0.8599]]) 0.3809075653553009\n",
      "1914 tensor([[0.2880],\n",
      "        [0.5004],\n",
      "        [0.7126],\n",
      "        [0.8600]]) 0.38081496953964233\n",
      "1915 tensor([[0.2879],\n",
      "        [0.5003],\n",
      "        [0.7127],\n",
      "        [0.8600]]) 0.38072240352630615\n",
      "1916 tensor([[0.2878],\n",
      "        [0.5003],\n",
      "        [0.7127],\n",
      "        [0.8601]]) 0.38062989711761475\n",
      "1917 tensor([[0.2876],\n",
      "        [0.5002],\n",
      "        [0.7127],\n",
      "        [0.8601]]) 0.3805374205112457\n",
      "1918 tensor([[0.2875],\n",
      "        [0.5002],\n",
      "        [0.7127],\n",
      "        [0.8602]]) 0.3804450035095215\n",
      "1919 tensor([[0.2874],\n",
      "        [0.5001],\n",
      "        [0.7127],\n",
      "        [0.8602]]) 0.380352646112442\n",
      "1920 tensor([[0.2873],\n",
      "        [0.5000],\n",
      "        [0.7128],\n",
      "        [0.8603]]) 0.38026031851768494\n",
      "1921 tensor([[0.2872],\n",
      "        [0.5000],\n",
      "        [0.7128],\n",
      "        [0.8603]]) 0.380168080329895\n",
      "1922 tensor([[0.2871],\n",
      "        [0.4999],\n",
      "        [0.7128],\n",
      "        [0.8604]]) 0.3800758421421051\n",
      "1923 tensor([[0.2870],\n",
      "        [0.4999],\n",
      "        [0.7128],\n",
      "        [0.8604]]) 0.37998369336128235\n",
      "1924 tensor([[0.2868],\n",
      "        [0.4998],\n",
      "        [0.7128],\n",
      "        [0.8605]]) 0.37989163398742676\n",
      "1925 tensor([[0.2867],\n",
      "        [0.4997],\n",
      "        [0.7129],\n",
      "        [0.8605]]) 0.37979957461357117\n",
      "1926 tensor([[0.2866],\n",
      "        [0.4997],\n",
      "        [0.7129],\n",
      "        [0.8606]]) 0.37970757484436035\n",
      "1927 tensor([[0.2865],\n",
      "        [0.4996],\n",
      "        [0.7129],\n",
      "        [0.8606]]) 0.3796156644821167\n",
      "1928 tensor([[0.2864],\n",
      "        [0.4996],\n",
      "        [0.7129],\n",
      "        [0.8607]]) 0.37952375411987305\n",
      "1929 tensor([[0.2863],\n",
      "        [0.4995],\n",
      "        [0.7129],\n",
      "        [0.8607]]) 0.37943193316459656\n",
      "1930 tensor([[0.2861],\n",
      "        [0.4994],\n",
      "        [0.7130],\n",
      "        [0.8608]]) 0.37934017181396484\n",
      "1931 tensor([[0.2860],\n",
      "        [0.4994],\n",
      "        [0.7130],\n",
      "        [0.8608]]) 0.37924838066101074\n",
      "1932 tensor([[0.2859],\n",
      "        [0.4993],\n",
      "        [0.7130],\n",
      "        [0.8609]]) 0.3791567087173462\n",
      "1933 tensor([[0.2858],\n",
      "        [0.4993],\n",
      "        [0.7130],\n",
      "        [0.8609]]) 0.37906503677368164\n",
      "1934 tensor([[0.2857],\n",
      "        [0.4992],\n",
      "        [0.7130],\n",
      "        [0.8610]]) 0.37897351384162903\n",
      "1935 tensor([[0.2856],\n",
      "        [0.4992],\n",
      "        [0.7131],\n",
      "        [0.8610]]) 0.37888196110725403\n",
      "1936 tensor([[0.2854],\n",
      "        [0.4991],\n",
      "        [0.7131],\n",
      "        [0.8611]]) 0.3787904977798462\n",
      "1937 tensor([[0.2853],\n",
      "        [0.4990],\n",
      "        [0.7131],\n",
      "        [0.8611]]) 0.37869909405708313\n",
      "1938 tensor([[0.2852],\n",
      "        [0.4990],\n",
      "        [0.7131],\n",
      "        [0.8612]]) 0.37860772013664246\n",
      "1939 tensor([[0.2851],\n",
      "        [0.4989],\n",
      "        [0.7131],\n",
      "        [0.8612]]) 0.3785163462162018\n",
      "1940 tensor([[0.2850],\n",
      "        [0.4989],\n",
      "        [0.7132],\n",
      "        [0.8613]]) 0.37842512130737305\n",
      "1941 tensor([[0.2849],\n",
      "        [0.4988],\n",
      "        [0.7132],\n",
      "        [0.8613]]) 0.3783338665962219\n",
      "1942 tensor([[0.2848],\n",
      "        [0.4987],\n",
      "        [0.7132],\n",
      "        [0.8614]]) 0.37824270129203796\n",
      "1943 tensor([[0.2846],\n",
      "        [0.4987],\n",
      "        [0.7132],\n",
      "        [0.8615]]) 0.3781515657901764\n",
      "1944 tensor([[0.2845],\n",
      "        [0.4986],\n",
      "        [0.7132],\n",
      "        [0.8615]]) 0.378060519695282\n",
      "1945 tensor([[0.2844],\n",
      "        [0.4986],\n",
      "        [0.7133],\n",
      "        [0.8616]]) 0.37796953320503235\n",
      "1946 tensor([[0.2843],\n",
      "        [0.4985],\n",
      "        [0.7133],\n",
      "        [0.8616]]) 0.3778786063194275\n",
      "1947 tensor([[0.2842],\n",
      "        [0.4985],\n",
      "        [0.7133],\n",
      "        [0.8617]]) 0.37778767943382263\n",
      "1948 tensor([[0.2841],\n",
      "        [0.4984],\n",
      "        [0.7133],\n",
      "        [0.8617]]) 0.3776967525482178\n",
      "1949 tensor([[0.2840],\n",
      "        [0.4983],\n",
      "        [0.7133],\n",
      "        [0.8618]]) 0.37760597467422485\n",
      "1950 tensor([[0.2838],\n",
      "        [0.4983],\n",
      "        [0.7134],\n",
      "        [0.8618]]) 0.37751513719558716\n",
      "1951 tensor([[0.2837],\n",
      "        [0.4982],\n",
      "        [0.7134],\n",
      "        [0.8619]]) 0.3774245083332062\n",
      "1952 tensor([[0.2836],\n",
      "        [0.4982],\n",
      "        [0.7134],\n",
      "        [0.8619]]) 0.3773338198661804\n",
      "1953 tensor([[0.2835],\n",
      "        [0.4981],\n",
      "        [0.7134],\n",
      "        [0.8620]]) 0.3772432208061218\n",
      "1954 tensor([[0.2834],\n",
      "        [0.4981],\n",
      "        [0.7134],\n",
      "        [0.8620]]) 0.37715262174606323\n",
      "1955 tensor([[0.2833],\n",
      "        [0.4980],\n",
      "        [0.7135],\n",
      "        [0.8621]]) 0.3770621716976166\n",
      "1956 tensor([[0.2832],\n",
      "        [0.4979],\n",
      "        [0.7135],\n",
      "        [0.8621]]) 0.37697166204452515\n",
      "1957 tensor([[0.2830],\n",
      "        [0.4979],\n",
      "        [0.7135],\n",
      "        [0.8622]]) 0.37688127160072327\n",
      "1958 tensor([[0.2829],\n",
      "        [0.4978],\n",
      "        [0.7135],\n",
      "        [0.8622]]) 0.37679094076156616\n",
      "1959 tensor([[0.2828],\n",
      "        [0.4978],\n",
      "        [0.7135],\n",
      "        [0.8623]]) 0.37670060992240906\n",
      "1960 tensor([[0.2827],\n",
      "        [0.4977],\n",
      "        [0.7136],\n",
      "        [0.8623]]) 0.3766104280948639\n",
      "1961 tensor([[0.2826],\n",
      "        [0.4976],\n",
      "        [0.7136],\n",
      "        [0.8624]]) 0.37652018666267395\n",
      "1962 tensor([[0.2825],\n",
      "        [0.4976],\n",
      "        [0.7136],\n",
      "        [0.8624]]) 0.37643003463745117\n",
      "1963 tensor([[0.2824],\n",
      "        [0.4975],\n",
      "        [0.7136],\n",
      "        [0.8625]]) 0.37633997201919556\n",
      "1964 tensor([[0.2822],\n",
      "        [0.4975],\n",
      "        [0.7136],\n",
      "        [0.8625]]) 0.37624984979629517\n",
      "1965 tensor([[0.2821],\n",
      "        [0.4974],\n",
      "        [0.7137],\n",
      "        [0.8626]]) 0.3761598765850067\n",
      "1966 tensor([[0.2820],\n",
      "        [0.4974],\n",
      "        [0.7137],\n",
      "        [0.8626]]) 0.37606990337371826\n",
      "1967 tensor([[0.2819],\n",
      "        [0.4973],\n",
      "        [0.7137],\n",
      "        [0.8627]]) 0.375980019569397\n",
      "1968 tensor([[0.2818],\n",
      "        [0.4972],\n",
      "        [0.7137],\n",
      "        [0.8627]]) 0.37589025497436523\n",
      "1969 tensor([[0.2817],\n",
      "        [0.4972],\n",
      "        [0.7137],\n",
      "        [0.8628]]) 0.3758004605770111\n",
      "1970 tensor([[0.2816],\n",
      "        [0.4971],\n",
      "        [0.7138],\n",
      "        [0.8628]]) 0.3757106065750122\n",
      "1971 tensor([[0.2815],\n",
      "        [0.4971],\n",
      "        [0.7138],\n",
      "        [0.8629]]) 0.37562093138694763\n",
      "1972 tensor([[0.2813],\n",
      "        [0.4970],\n",
      "        [0.7138],\n",
      "        [0.8629]]) 0.37553131580352783\n",
      "1973 tensor([[0.2812],\n",
      "        [0.4970],\n",
      "        [0.7138],\n",
      "        [0.8630]]) 0.37544170022010803\n",
      "1974 tensor([[0.2811],\n",
      "        [0.4969],\n",
      "        [0.7138],\n",
      "        [0.8630]]) 0.375352144241333\n",
      "1975 tensor([[0.2810],\n",
      "        [0.4968],\n",
      "        [0.7139],\n",
      "        [0.8631]]) 0.37526264786720276\n",
      "1976 tensor([[0.2809],\n",
      "        [0.4968],\n",
      "        [0.7139],\n",
      "        [0.8631]]) 0.3751731812953949\n",
      "1977 tensor([[0.2808],\n",
      "        [0.4967],\n",
      "        [0.7139],\n",
      "        [0.8632]]) 0.3750837743282318\n",
      "1978 tensor([[0.2807],\n",
      "        [0.4967],\n",
      "        [0.7139],\n",
      "        [0.8632]]) 0.3749944865703583\n",
      "1979 tensor([[0.2805],\n",
      "        [0.4966],\n",
      "        [0.7139],\n",
      "        [0.8633]]) 0.3749051094055176\n",
      "1980 tensor([[0.2804],\n",
      "        [0.4966],\n",
      "        [0.7140],\n",
      "        [0.8633]]) 0.3748159408569336\n",
      "1981 tensor([[0.2803],\n",
      "        [0.4965],\n",
      "        [0.7140],\n",
      "        [0.8634]]) 0.37472671270370483\n",
      "1982 tensor([[0.2802],\n",
      "        [0.4964],\n",
      "        [0.7140],\n",
      "        [0.8634]]) 0.37463754415512085\n",
      "1983 tensor([[0.2801],\n",
      "        [0.4964],\n",
      "        [0.7140],\n",
      "        [0.8635]]) 0.37454843521118164\n",
      "1984 tensor([[0.2800],\n",
      "        [0.4963],\n",
      "        [0.7140],\n",
      "        [0.8635]]) 0.3744593858718872\n",
      "1985 tensor([[0.2799],\n",
      "        [0.4963],\n",
      "        [0.7141],\n",
      "        [0.8636]]) 0.37437036633491516\n",
      "1986 tensor([[0.2798],\n",
      "        [0.4962],\n",
      "        [0.7141],\n",
      "        [0.8636]]) 0.3742814064025879\n",
      "1987 tensor([[0.2796],\n",
      "        [0.4962],\n",
      "        [0.7141],\n",
      "        [0.8637]]) 0.37419241666793823\n",
      "1988 tensor([[0.2795],\n",
      "        [0.4961],\n",
      "        [0.7141],\n",
      "        [0.8637]]) 0.3741036653518677\n",
      "1989 tensor([[0.2794],\n",
      "        [0.4960],\n",
      "        [0.7141],\n",
      "        [0.8638]]) 0.3740149140357971\n",
      "1990 tensor([[0.2793],\n",
      "        [0.4960],\n",
      "        [0.7142],\n",
      "        [0.8638]]) 0.3739261031150818\n",
      "1991 tensor([[0.2792],\n",
      "        [0.4959],\n",
      "        [0.7142],\n",
      "        [0.8639]]) 0.3738374412059784\n",
      "1992 tensor([[0.2791],\n",
      "        [0.4959],\n",
      "        [0.7142],\n",
      "        [0.8639]]) 0.373748779296875\n",
      "1993 tensor([[0.2790],\n",
      "        [0.4958],\n",
      "        [0.7142],\n",
      "        [0.8640]]) 0.3736601769924164\n",
      "1994 tensor([[0.2789],\n",
      "        [0.4958],\n",
      "        [0.7142],\n",
      "        [0.8640]]) 0.37357157468795776\n",
      "1995 tensor([[0.2788],\n",
      "        [0.4957],\n",
      "        [0.7143],\n",
      "        [0.8641]]) 0.3734830617904663\n",
      "1996 tensor([[0.2786],\n",
      "        [0.4956],\n",
      "        [0.7143],\n",
      "        [0.8641]]) 0.373394638299942\n",
      "1997 tensor([[0.2785],\n",
      "        [0.4956],\n",
      "        [0.7143],\n",
      "        [0.8642]]) 0.3733062148094177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 tensor([[0.2784],\n",
      "        [0.4955],\n",
      "        [0.7143],\n",
      "        [0.8642]]) 0.3732178509235382\n",
      "1999 tensor([[0.2783],\n",
      "        [0.4955],\n",
      "        [0.7143],\n",
      "        [0.8643]]) 0.3731295168399811\n",
      "2000 tensor([[0.2782],\n",
      "        [0.4954],\n",
      "        [0.7144],\n",
      "        [0.8643]]) 0.3730412423610687\n",
      "2001 tensor([[0.2781],\n",
      "        [0.4954],\n",
      "        [0.7144],\n",
      "        [0.8644]]) 0.37295302748680115\n",
      "2002 tensor([[0.2780],\n",
      "        [0.4953],\n",
      "        [0.7144],\n",
      "        [0.8644]]) 0.37286487221717834\n",
      "2003 tensor([[0.2779],\n",
      "        [0.4952],\n",
      "        [0.7144],\n",
      "        [0.8645]]) 0.3727767765522003\n",
      "2004 tensor([[0.2778],\n",
      "        [0.4952],\n",
      "        [0.7144],\n",
      "        [0.8645]]) 0.3726886808872223\n",
      "2005 tensor([[0.2776],\n",
      "        [0.4951],\n",
      "        [0.7145],\n",
      "        [0.8646]]) 0.3726006746292114\n",
      "2006 tensor([[0.2775],\n",
      "        [0.4951],\n",
      "        [0.7145],\n",
      "        [0.8646]]) 0.3725127875804901\n",
      "2007 tensor([[0.2774],\n",
      "        [0.4950],\n",
      "        [0.7145],\n",
      "        [0.8647]]) 0.37242478132247925\n",
      "2008 tensor([[0.2773],\n",
      "        [0.4950],\n",
      "        [0.7145],\n",
      "        [0.8647]]) 0.3723369240760803\n",
      "2009 tensor([[0.2772],\n",
      "        [0.4949],\n",
      "        [0.7145],\n",
      "        [0.8648]]) 0.3722490668296814\n",
      "2010 tensor([[0.2771],\n",
      "        [0.4948],\n",
      "        [0.7146],\n",
      "        [0.8648]]) 0.37216126918792725\n",
      "2011 tensor([[0.2770],\n",
      "        [0.4948],\n",
      "        [0.7146],\n",
      "        [0.8649]]) 0.37207362055778503\n",
      "2012 tensor([[0.2769],\n",
      "        [0.4947],\n",
      "        [0.7146],\n",
      "        [0.8649]]) 0.37198591232299805\n",
      "2013 tensor([[0.2768],\n",
      "        [0.4947],\n",
      "        [0.7146],\n",
      "        [0.8650]]) 0.37189826369285583\n",
      "2014 tensor([[0.2766],\n",
      "        [0.4946],\n",
      "        [0.7146],\n",
      "        [0.8650]]) 0.3718107044696808\n",
      "2015 tensor([[0.2765],\n",
      "        [0.4946],\n",
      "        [0.7147],\n",
      "        [0.8651]]) 0.37172311544418335\n",
      "2016 tensor([[0.2764],\n",
      "        [0.4945],\n",
      "        [0.7147],\n",
      "        [0.8651]]) 0.37163564562797546\n",
      "2017 tensor([[0.2763],\n",
      "        [0.4944],\n",
      "        [0.7147],\n",
      "        [0.8652]]) 0.37154823541641235\n",
      "2018 tensor([[0.2762],\n",
      "        [0.4944],\n",
      "        [0.7147],\n",
      "        [0.8652]]) 0.37146085500717163\n",
      "2019 tensor([[0.2761],\n",
      "        [0.4943],\n",
      "        [0.7147],\n",
      "        [0.8653]]) 0.3713735044002533\n",
      "2020 tensor([[0.2760],\n",
      "        [0.4943],\n",
      "        [0.7148],\n",
      "        [0.8653]]) 0.37128618359565735\n",
      "2021 tensor([[0.2759],\n",
      "        [0.4942],\n",
      "        [0.7148],\n",
      "        [0.8654]]) 0.37119895219802856\n",
      "2022 tensor([[0.2758],\n",
      "        [0.4942],\n",
      "        [0.7148],\n",
      "        [0.8654]]) 0.37111181020736694\n",
      "2023 tensor([[0.2757],\n",
      "        [0.4941],\n",
      "        [0.7148],\n",
      "        [0.8655]]) 0.3710246682167053\n",
      "2024 tensor([[0.2755],\n",
      "        [0.4940],\n",
      "        [0.7148],\n",
      "        [0.8655]]) 0.3709375560283661\n",
      "2025 tensor([[0.2754],\n",
      "        [0.4940],\n",
      "        [0.7149],\n",
      "        [0.8656]]) 0.37085044384002686\n",
      "2026 tensor([[0.2753],\n",
      "        [0.4939],\n",
      "        [0.7149],\n",
      "        [0.8656]]) 0.3707634508609772\n",
      "2027 tensor([[0.2752],\n",
      "        [0.4939],\n",
      "        [0.7149],\n",
      "        [0.8657]]) 0.37067651748657227\n",
      "2028 tensor([[0.2751],\n",
      "        [0.4938],\n",
      "        [0.7149],\n",
      "        [0.8657]]) 0.37058961391448975\n",
      "2029 tensor([[0.2750],\n",
      "        [0.4938],\n",
      "        [0.7149],\n",
      "        [0.8658]]) 0.3705027401447296\n",
      "2030 tensor([[0.2749],\n",
      "        [0.4937],\n",
      "        [0.7150],\n",
      "        [0.8658]]) 0.37041595578193665\n",
      "2031 tensor([[0.2748],\n",
      "        [0.4937],\n",
      "        [0.7150],\n",
      "        [0.8659]]) 0.37032923102378845\n",
      "2032 tensor([[0.2747],\n",
      "        [0.4936],\n",
      "        [0.7150],\n",
      "        [0.8659]]) 0.3702424168586731\n",
      "2033 tensor([[0.2746],\n",
      "        [0.4935],\n",
      "        [0.7150],\n",
      "        [0.8660]]) 0.37015581130981445\n",
      "2034 tensor([[0.2744],\n",
      "        [0.4935],\n",
      "        [0.7150],\n",
      "        [0.8660]]) 0.3700692057609558\n",
      "2035 tensor([[0.2743],\n",
      "        [0.4934],\n",
      "        [0.7151],\n",
      "        [0.8661]]) 0.36998260021209717\n",
      "2036 tensor([[0.2742],\n",
      "        [0.4934],\n",
      "        [0.7151],\n",
      "        [0.8661]]) 0.3698960840702057\n",
      "2037 tensor([[0.2741],\n",
      "        [0.4933],\n",
      "        [0.7151],\n",
      "        [0.8662]]) 0.3698095679283142\n",
      "2038 tensor([[0.2740],\n",
      "        [0.4933],\n",
      "        [0.7151],\n",
      "        [0.8662]]) 0.3697231411933899\n",
      "2039 tensor([[0.2739],\n",
      "        [0.4932],\n",
      "        [0.7151],\n",
      "        [0.8663]]) 0.3696367144584656\n",
      "2040 tensor([[0.2738],\n",
      "        [0.4931],\n",
      "        [0.7152],\n",
      "        [0.8663]]) 0.3695504367351532\n",
      "2041 tensor([[0.2737],\n",
      "        [0.4931],\n",
      "        [0.7152],\n",
      "        [0.8664]]) 0.36946409940719604\n",
      "2042 tensor([[0.2736],\n",
      "        [0.4930],\n",
      "        [0.7152],\n",
      "        [0.8664]]) 0.36937788128852844\n",
      "2043 tensor([[0.2735],\n",
      "        [0.4930],\n",
      "        [0.7152],\n",
      "        [0.8665]]) 0.36929166316986084\n",
      "2044 tensor([[0.2734],\n",
      "        [0.4929],\n",
      "        [0.7152],\n",
      "        [0.8665]]) 0.3692055642604828\n",
      "2045 tensor([[0.2732],\n",
      "        [0.4929],\n",
      "        [0.7153],\n",
      "        [0.8665]]) 0.36911946535110474\n",
      "2046 tensor([[0.2731],\n",
      "        [0.4928],\n",
      "        [0.7153],\n",
      "        [0.8666]]) 0.3690333664417267\n",
      "2047 tensor([[0.2730],\n",
      "        [0.4928],\n",
      "        [0.7153],\n",
      "        [0.8666]]) 0.3689473867416382\n",
      "2048 tensor([[0.2729],\n",
      "        [0.4927],\n",
      "        [0.7153],\n",
      "        [0.8667]]) 0.3688614070415497\n",
      "2049 tensor([[0.2728],\n",
      "        [0.4926],\n",
      "        [0.7153],\n",
      "        [0.8667]]) 0.36877554655075073\n",
      "2050 tensor([[0.2727],\n",
      "        [0.4926],\n",
      "        [0.7154],\n",
      "        [0.8668]]) 0.3686896562576294\n",
      "2051 tensor([[0.2726],\n",
      "        [0.4925],\n",
      "        [0.7154],\n",
      "        [0.8668]]) 0.36860382556915283\n",
      "2052 tensor([[0.2725],\n",
      "        [0.4925],\n",
      "        [0.7154],\n",
      "        [0.8669]]) 0.36851808428764343\n",
      "2053 tensor([[0.2724],\n",
      "        [0.4924],\n",
      "        [0.7154],\n",
      "        [0.8669]]) 0.36843234300613403\n",
      "2054 tensor([[0.2723],\n",
      "        [0.4924],\n",
      "        [0.7154],\n",
      "        [0.8670]]) 0.3683466911315918\n",
      "2055 tensor([[0.2722],\n",
      "        [0.4923],\n",
      "        [0.7155],\n",
      "        [0.8670]]) 0.36826109886169434\n",
      "2056 tensor([[0.2721],\n",
      "        [0.4922],\n",
      "        [0.7155],\n",
      "        [0.8671]]) 0.3681755065917969\n",
      "2057 tensor([[0.2719],\n",
      "        [0.4922],\n",
      "        [0.7155],\n",
      "        [0.8671]]) 0.3680899441242218\n",
      "2058 tensor([[0.2718],\n",
      "        [0.4921],\n",
      "        [0.7155],\n",
      "        [0.8672]]) 0.3680044710636139\n",
      "2059 tensor([[0.2717],\n",
      "        [0.4921],\n",
      "        [0.7155],\n",
      "        [0.8672]]) 0.36791908740997314\n",
      "2060 tensor([[0.2716],\n",
      "        [0.4920],\n",
      "        [0.7156],\n",
      "        [0.8673]]) 0.36783361434936523\n",
      "2061 tensor([[0.2715],\n",
      "        [0.4920],\n",
      "        [0.7156],\n",
      "        [0.8673]]) 0.36774832010269165\n",
      "2062 tensor([[0.2714],\n",
      "        [0.4919],\n",
      "        [0.7156],\n",
      "        [0.8674]]) 0.36766305565834045\n",
      "2063 tensor([[0.2713],\n",
      "        [0.4919],\n",
      "        [0.7156],\n",
      "        [0.8674]]) 0.36757779121398926\n",
      "2064 tensor([[0.2712],\n",
      "        [0.4918],\n",
      "        [0.7156],\n",
      "        [0.8675]]) 0.36749252676963806\n",
      "2065 tensor([[0.2711],\n",
      "        [0.4917],\n",
      "        [0.7157],\n",
      "        [0.8675]]) 0.3674074113368988\n",
      "2066 tensor([[0.2710],\n",
      "        [0.4917],\n",
      "        [0.7157],\n",
      "        [0.8676]]) 0.36732226610183716\n",
      "2067 tensor([[0.2709],\n",
      "        [0.4916],\n",
      "        [0.7157],\n",
      "        [0.8676]]) 0.3672372102737427\n",
      "2068 tensor([[0.2708],\n",
      "        [0.4916],\n",
      "        [0.7157],\n",
      "        [0.8677]]) 0.36715221405029297\n",
      "2069 tensor([[0.2707],\n",
      "        [0.4915],\n",
      "        [0.7157],\n",
      "        [0.8677]]) 0.36706721782684326\n",
      "2070 tensor([[0.2705],\n",
      "        [0.4915],\n",
      "        [0.7158],\n",
      "        [0.8678]]) 0.3669823110103607\n",
      "2071 tensor([[0.2704],\n",
      "        [0.4914],\n",
      "        [0.7158],\n",
      "        [0.8678]]) 0.36689743399620056\n",
      "2072 tensor([[0.2703],\n",
      "        [0.4914],\n",
      "        [0.7158],\n",
      "        [0.8679]]) 0.3668126165866852\n",
      "2073 tensor([[0.2702],\n",
      "        [0.4913],\n",
      "        [0.7158],\n",
      "        [0.8679]]) 0.3667278587818146\n",
      "2074 tensor([[0.2701],\n",
      "        [0.4912],\n",
      "        [0.7158],\n",
      "        [0.8679]]) 0.36664310097694397\n",
      "2075 tensor([[0.2700],\n",
      "        [0.4912],\n",
      "        [0.7159],\n",
      "        [0.8680]]) 0.3665584325790405\n",
      "2076 tensor([[0.2699],\n",
      "        [0.4911],\n",
      "        [0.7159],\n",
      "        [0.8680]]) 0.3664737343788147\n",
      "2077 tensor([[0.2698],\n",
      "        [0.4911],\n",
      "        [0.7159],\n",
      "        [0.8681]]) 0.36638909578323364\n",
      "2078 tensor([[0.2697],\n",
      "        [0.4910],\n",
      "        [0.7159],\n",
      "        [0.8681]]) 0.3663046061992645\n",
      "2079 tensor([[0.2696],\n",
      "        [0.4910],\n",
      "        [0.7159],\n",
      "        [0.8682]]) 0.366220086812973\n",
      "2080 tensor([[0.2695],\n",
      "        [0.4909],\n",
      "        [0.7160],\n",
      "        [0.8682]]) 0.3661355972290039\n",
      "2081 tensor([[0.2694],\n",
      "        [0.4909],\n",
      "        [0.7160],\n",
      "        [0.8683]]) 0.36605116724967957\n",
      "2082 tensor([[0.2693],\n",
      "        [0.4908],\n",
      "        [0.7160],\n",
      "        [0.8683]]) 0.3659668266773224\n",
      "2083 tensor([[0.2692],\n",
      "        [0.4907],\n",
      "        [0.7160],\n",
      "        [0.8684]]) 0.3658824563026428\n",
      "2084 tensor([[0.2691],\n",
      "        [0.4907],\n",
      "        [0.7160],\n",
      "        [0.8684]]) 0.3657982051372528\n",
      "2085 tensor([[0.2689],\n",
      "        [0.4906],\n",
      "        [0.7161],\n",
      "        [0.8685]]) 0.3657139241695404\n",
      "2086 tensor([[0.2688],\n",
      "        [0.4906],\n",
      "        [0.7161],\n",
      "        [0.8685]]) 0.3656297028064728\n",
      "2087 tensor([[0.2687],\n",
      "        [0.4905],\n",
      "        [0.7161],\n",
      "        [0.8686]]) 0.3655456006526947\n",
      "2088 tensor([[0.2686],\n",
      "        [0.4905],\n",
      "        [0.7161],\n",
      "        [0.8686]]) 0.3654614984989166\n",
      "2089 tensor([[0.2685],\n",
      "        [0.4904],\n",
      "        [0.7161],\n",
      "        [0.8687]]) 0.3653774559497833\n",
      "2090 tensor([[0.2684],\n",
      "        [0.4904],\n",
      "        [0.7162],\n",
      "        [0.8687]]) 0.3652934432029724\n",
      "2091 tensor([[0.2683],\n",
      "        [0.4903],\n",
      "        [0.7162],\n",
      "        [0.8688]]) 0.3652094900608063\n",
      "2092 tensor([[0.2682],\n",
      "        [0.4902],\n",
      "        [0.7162],\n",
      "        [0.8688]]) 0.3651255667209625\n",
      "2093 tensor([[0.2681],\n",
      "        [0.4902],\n",
      "        [0.7162],\n",
      "        [0.8689]]) 0.36504167318344116\n",
      "2094 tensor([[0.2680],\n",
      "        [0.4901],\n",
      "        [0.7162],\n",
      "        [0.8689]]) 0.36495786905288696\n",
      "2095 tensor([[0.2679],\n",
      "        [0.4901],\n",
      "        [0.7163],\n",
      "        [0.8689]]) 0.36487406492233276\n",
      "2096 tensor([[0.2678],\n",
      "        [0.4900],\n",
      "        [0.7163],\n",
      "        [0.8690]]) 0.36479029059410095\n",
      "2097 tensor([[0.2677],\n",
      "        [0.4900],\n",
      "        [0.7163],\n",
      "        [0.8690]]) 0.3647066354751587\n",
      "2098 tensor([[0.2676],\n",
      "        [0.4899],\n",
      "        [0.7163],\n",
      "        [0.8691]]) 0.36462295055389404\n",
      "2099 tensor([[0.2675],\n",
      "        [0.4899],\n",
      "        [0.7163],\n",
      "        [0.8691]]) 0.36453938484191895\n",
      "2100 tensor([[0.2674],\n",
      "        [0.4898],\n",
      "        [0.7164],\n",
      "        [0.8692]]) 0.36445578932762146\n",
      "2101 tensor([[0.2673],\n",
      "        [0.4897],\n",
      "        [0.7164],\n",
      "        [0.8692]]) 0.3643723130226135\n",
      "2102 tensor([[0.2671],\n",
      "        [0.4897],\n",
      "        [0.7164],\n",
      "        [0.8693]]) 0.364288866519928\n",
      "2103 tensor([[0.2670],\n",
      "        [0.4896],\n",
      "        [0.7164],\n",
      "        [0.8693]]) 0.3642054498195648\n",
      "2104 tensor([[0.2669],\n",
      "        [0.4896],\n",
      "        [0.7164],\n",
      "        [0.8694]]) 0.36412206292152405\n",
      "2105 tensor([[0.2668],\n",
      "        [0.4895],\n",
      "        [0.7165],\n",
      "        [0.8694]]) 0.36403873562812805\n",
      "2106 tensor([[0.2667],\n",
      "        [0.4895],\n",
      "        [0.7165],\n",
      "        [0.8695]]) 0.36395546793937683\n",
      "2107 tensor([[0.2666],\n",
      "        [0.4894],\n",
      "        [0.7165],\n",
      "        [0.8695]]) 0.363872230052948\n",
      "2108 tensor([[0.2665],\n",
      "        [0.4894],\n",
      "        [0.7165],\n",
      "        [0.8696]]) 0.36378905177116394\n",
      "2109 tensor([[0.2664],\n",
      "        [0.4893],\n",
      "        [0.7165],\n",
      "        [0.8696]]) 0.36370593309402466\n",
      "2110 tensor([[0.2663],\n",
      "        [0.4893],\n",
      "        [0.7166],\n",
      "        [0.8697]]) 0.36362284421920776\n",
      "2111 tensor([[0.2662],\n",
      "        [0.4892],\n",
      "        [0.7166],\n",
      "        [0.8697]]) 0.36353978514671326\n",
      "2112 tensor([[0.2661],\n",
      "        [0.4891],\n",
      "        [0.7166],\n",
      "        [0.8697]]) 0.36345675587654114\n",
      "2113 tensor([[0.2660],\n",
      "        [0.4891],\n",
      "        [0.7166],\n",
      "        [0.8698]]) 0.3633737862110138\n",
      "2114 tensor([[0.2659],\n",
      "        [0.4890],\n",
      "        [0.7166],\n",
      "        [0.8698]]) 0.36329084634780884\n",
      "2115 tensor([[0.2658],\n",
      "        [0.4890],\n",
      "        [0.7167],\n",
      "        [0.8699]]) 0.36320793628692627\n",
      "2116 tensor([[0.2657],\n",
      "        [0.4889],\n",
      "        [0.7167],\n",
      "        [0.8699]]) 0.3631250858306885\n",
      "2117 tensor([[0.2656],\n",
      "        [0.4889],\n",
      "        [0.7167],\n",
      "        [0.8700]]) 0.3630423843860626\n",
      "2118 tensor([[0.2655],\n",
      "        [0.4888],\n",
      "        [0.7167],\n",
      "        [0.8700]]) 0.362959623336792\n",
      "2119 tensor([[0.2654],\n",
      "        [0.4888],\n",
      "        [0.7167],\n",
      "        [0.8701]]) 0.362876832485199\n",
      "2120 tensor([[0.2653],\n",
      "        [0.4887],\n",
      "        [0.7168],\n",
      "        [0.8701]]) 0.36279428005218506\n",
      "2121 tensor([[0.2652],\n",
      "        [0.4886],\n",
      "        [0.7168],\n",
      "        [0.8702]]) 0.3627116084098816\n",
      "2122 tensor([[0.2650],\n",
      "        [0.4886],\n",
      "        [0.7168],\n",
      "        [0.8702]]) 0.3626290559768677\n",
      "2123 tensor([[0.2649],\n",
      "        [0.4885],\n",
      "        [0.7168],\n",
      "        [0.8703]]) 0.36254656314849854\n",
      "2124 tensor([[0.2648],\n",
      "        [0.4885],\n",
      "        [0.7168],\n",
      "        [0.8703]]) 0.362464040517807\n",
      "2125 tensor([[0.2647],\n",
      "        [0.4884],\n",
      "        [0.7169],\n",
      "        [0.8704]]) 0.36238163709640503\n",
      "2126 tensor([[0.2646],\n",
      "        [0.4884],\n",
      "        [0.7169],\n",
      "        [0.8704]]) 0.36229923367500305\n",
      "2127 tensor([[0.2645],\n",
      "        [0.4883],\n",
      "        [0.7169],\n",
      "        [0.8705]]) 0.362216979265213\n",
      "2128 tensor([[0.2644],\n",
      "        [0.4883],\n",
      "        [0.7169],\n",
      "        [0.8705]]) 0.3621346950531006\n",
      "2129 tensor([[0.2643],\n",
      "        [0.4882],\n",
      "        [0.7169],\n",
      "        [0.8705]]) 0.3620523512363434\n",
      "2130 tensor([[0.2642],\n",
      "        [0.4882],\n",
      "        [0.7170],\n",
      "        [0.8706]]) 0.3619701862335205\n",
      "2131 tensor([[0.2641],\n",
      "        [0.4881],\n",
      "        [0.7170],\n",
      "        [0.8706]]) 0.36188799142837524\n",
      "2132 tensor([[0.2640],\n",
      "        [0.4880],\n",
      "        [0.7170],\n",
      "        [0.8707]]) 0.36180591583251953\n",
      "2133 tensor([[0.2639],\n",
      "        [0.4880],\n",
      "        [0.7170],\n",
      "        [0.8707]]) 0.3617238402366638\n",
      "2134 tensor([[0.2638],\n",
      "        [0.4879],\n",
      "        [0.7170],\n",
      "        [0.8708]]) 0.3616417944431305\n",
      "2135 tensor([[0.2637],\n",
      "        [0.4879],\n",
      "        [0.7171],\n",
      "        [0.8708]]) 0.36155980825424194\n",
      "2136 tensor([[0.2636],\n",
      "        [0.4878],\n",
      "        [0.7171],\n",
      "        [0.8709]]) 0.36147791147232056\n",
      "2137 tensor([[0.2635],\n",
      "        [0.4878],\n",
      "        [0.7171],\n",
      "        [0.8709]]) 0.3613959550857544\n",
      "2138 tensor([[0.2634],\n",
      "        [0.4877],\n",
      "        [0.7171],\n",
      "        [0.8710]]) 0.36131414771080017\n",
      "2139 tensor([[0.2633],\n",
      "        [0.4877],\n",
      "        [0.7171],\n",
      "        [0.8710]]) 0.36123231053352356\n",
      "2140 tensor([[0.2632],\n",
      "        [0.4876],\n",
      "        [0.7172],\n",
      "        [0.8711]]) 0.3611505925655365\n",
      "2141 tensor([[0.2631],\n",
      "        [0.4876],\n",
      "        [0.7172],\n",
      "        [0.8711]]) 0.36106881499290466\n",
      "2142 tensor([[0.2630],\n",
      "        [0.4875],\n",
      "        [0.7172],\n",
      "        [0.8711]]) 0.36098712682724\n",
      "2143 tensor([[0.2629],\n",
      "        [0.4874],\n",
      "        [0.7172],\n",
      "        [0.8712]]) 0.3609054684638977\n",
      "2144 tensor([[0.2628],\n",
      "        [0.4874],\n",
      "        [0.7172],\n",
      "        [0.8712]]) 0.3608238995075226\n",
      "2145 tensor([[0.2627],\n",
      "        [0.4873],\n",
      "        [0.7172],\n",
      "        [0.8713]]) 0.3607423007488251\n",
      "2146 tensor([[0.2626],\n",
      "        [0.4873],\n",
      "        [0.7173],\n",
      "        [0.8713]]) 0.3606608211994171\n",
      "2147 tensor([[0.2625],\n",
      "        [0.4872],\n",
      "        [0.7173],\n",
      "        [0.8714]]) 0.36057937145233154\n",
      "2148 tensor([[0.2624],\n",
      "        [0.4872],\n",
      "        [0.7173],\n",
      "        [0.8714]]) 0.36049798130989075\n",
      "2149 tensor([[0.2623],\n",
      "        [0.4871],\n",
      "        [0.7173],\n",
      "        [0.8715]]) 0.3604165315628052\n",
      "2150 tensor([[0.2621],\n",
      "        [0.4871],\n",
      "        [0.7173],\n",
      "        [0.8715]]) 0.36033523082733154\n",
      "2151 tensor([[0.2620],\n",
      "        [0.4870],\n",
      "        [0.7174],\n",
      "        [0.8716]]) 0.3602539300918579\n",
      "2152 tensor([[0.2619],\n",
      "        [0.4870],\n",
      "        [0.7174],\n",
      "        [0.8716]]) 0.36017268896102905\n",
      "2153 tensor([[0.2618],\n",
      "        [0.4869],\n",
      "        [0.7174],\n",
      "        [0.8717]]) 0.36009150743484497\n",
      "2154 tensor([[0.2617],\n",
      "        [0.4869],\n",
      "        [0.7174],\n",
      "        [0.8717]]) 0.3600102961063385\n",
      "2155 tensor([[0.2616],\n",
      "        [0.4868],\n",
      "        [0.7174],\n",
      "        [0.8717]]) 0.3599292039871216\n",
      "2156 tensor([[0.2615],\n",
      "        [0.4867],\n",
      "        [0.7175],\n",
      "        [0.8718]]) 0.3598482012748718\n",
      "2157 tensor([[0.2614],\n",
      "        [0.4867],\n",
      "        [0.7175],\n",
      "        [0.8718]]) 0.3597671389579773\n",
      "2158 tensor([[0.2613],\n",
      "        [0.4866],\n",
      "        [0.7175],\n",
      "        [0.8719]]) 0.3596862256526947\n",
      "2159 tensor([[0.2612],\n",
      "        [0.4866],\n",
      "        [0.7175],\n",
      "        [0.8719]]) 0.35960525274276733\n",
      "2160 tensor([[0.2611],\n",
      "        [0.4865],\n",
      "        [0.7175],\n",
      "        [0.8720]]) 0.35952436923980713\n",
      "2161 tensor([[0.2610],\n",
      "        [0.4865],\n",
      "        [0.7176],\n",
      "        [0.8720]]) 0.3594435453414917\n",
      "2162 tensor([[0.2609],\n",
      "        [0.4864],\n",
      "        [0.7176],\n",
      "        [0.8721]]) 0.35936272144317627\n",
      "2163 tensor([[0.2608],\n",
      "        [0.4864],\n",
      "        [0.7176],\n",
      "        [0.8721]]) 0.35928189754486084\n",
      "2164 tensor([[0.2607],\n",
      "        [0.4863],\n",
      "        [0.7176],\n",
      "        [0.8722]]) 0.35920122265815735\n",
      "2165 tensor([[0.2606],\n",
      "        [0.4863],\n",
      "        [0.7176],\n",
      "        [0.8722]]) 0.3591204583644867\n",
      "2166 tensor([[0.2605],\n",
      "        [0.4862],\n",
      "        [0.7177],\n",
      "        [0.8722]]) 0.359039843082428\n",
      "2167 tensor([[0.2604],\n",
      "        [0.4861],\n",
      "        [0.7177],\n",
      "        [0.8723]]) 0.3589591979980469\n",
      "2168 tensor([[0.2603],\n",
      "        [0.4861],\n",
      "        [0.7177],\n",
      "        [0.8723]]) 0.3588787317276001\n",
      "2169 tensor([[0.2602],\n",
      "        [0.4860],\n",
      "        [0.7177],\n",
      "        [0.8724]]) 0.35879823565483093\n",
      "2170 tensor([[0.2601],\n",
      "        [0.4860],\n",
      "        [0.7177],\n",
      "        [0.8724]]) 0.35871776938438416\n",
      "2171 tensor([[0.2600],\n",
      "        [0.4859],\n",
      "        [0.7178],\n",
      "        [0.8725]]) 0.3586373031139374\n",
      "2172 tensor([[0.2599],\n",
      "        [0.4859],\n",
      "        [0.7178],\n",
      "        [0.8725]]) 0.35855692625045776\n",
      "2173 tensor([[0.2598],\n",
      "        [0.4858],\n",
      "        [0.7178],\n",
      "        [0.8726]]) 0.35847657918930054\n",
      "2174 tensor([[0.2597],\n",
      "        [0.4858],\n",
      "        [0.7178],\n",
      "        [0.8726]]) 0.35839635133743286\n",
      "2175 tensor([[0.2596],\n",
      "        [0.4857],\n",
      "        [0.7178],\n",
      "        [0.8727]]) 0.358316034078598\n",
      "2176 tensor([[0.2595],\n",
      "        [0.4857],\n",
      "        [0.7179],\n",
      "        [0.8727]]) 0.3582358658313751\n",
      "2177 tensor([[0.2594],\n",
      "        [0.4856],\n",
      "        [0.7179],\n",
      "        [0.8727]]) 0.3581557273864746\n",
      "2178 tensor([[0.2593],\n",
      "        [0.4856],\n",
      "        [0.7179],\n",
      "        [0.8728]]) 0.3580756187438965\n",
      "2179 tensor([[0.2592],\n",
      "        [0.4855],\n",
      "        [0.7179],\n",
      "        [0.8728]]) 0.35799551010131836\n",
      "2180 tensor([[0.2591],\n",
      "        [0.4854],\n",
      "        [0.7179],\n",
      "        [0.8729]]) 0.3579155206680298\n",
      "2181 tensor([[0.2590],\n",
      "        [0.4854],\n",
      "        [0.7180],\n",
      "        [0.8729]]) 0.3578355312347412\n",
      "2182 tensor([[0.2589],\n",
      "        [0.4853],\n",
      "        [0.7180],\n",
      "        [0.8730]]) 0.35775554180145264\n",
      "2183 tensor([[0.2588],\n",
      "        [0.4853],\n",
      "        [0.7180],\n",
      "        [0.8730]]) 0.3576756417751312\n",
      "2184 tensor([[0.2587],\n",
      "        [0.4852],\n",
      "        [0.7180],\n",
      "        [0.8731]]) 0.3575957417488098\n",
      "2185 tensor([[0.2586],\n",
      "        [0.4852],\n",
      "        [0.7180],\n",
      "        [0.8731]]) 0.3575159013271332\n",
      "2186 tensor([[0.2585],\n",
      "        [0.4851],\n",
      "        [0.7181],\n",
      "        [0.8732]]) 0.3574361205101013\n",
      "2187 tensor([[0.2584],\n",
      "        [0.4851],\n",
      "        [0.7181],\n",
      "        [0.8732]]) 0.35735636949539185\n",
      "2188 tensor([[0.2583],\n",
      "        [0.4850],\n",
      "        [0.7181],\n",
      "        [0.8732]]) 0.35727667808532715\n",
      "2189 tensor([[0.2582],\n",
      "        [0.4850],\n",
      "        [0.7181],\n",
      "        [0.8733]]) 0.3571970462799072\n",
      "2190 tensor([[0.2581],\n",
      "        [0.4849],\n",
      "        [0.7181],\n",
      "        [0.8733]]) 0.3571174144744873\n",
      "2191 tensor([[0.2580],\n",
      "        [0.4849],\n",
      "        [0.7182],\n",
      "        [0.8734]]) 0.35703787207603455\n",
      "2192 tensor([[0.2579],\n",
      "        [0.4848],\n",
      "        [0.7182],\n",
      "        [0.8734]]) 0.35695838928222656\n",
      "2193 tensor([[0.2578],\n",
      "        [0.4848],\n",
      "        [0.7182],\n",
      "        [0.8735]]) 0.3568788468837738\n",
      "2194 tensor([[0.2577],\n",
      "        [0.4847],\n",
      "        [0.7182],\n",
      "        [0.8735]]) 0.3567993938922882\n",
      "2195 tensor([[0.2576],\n",
      "        [0.4846],\n",
      "        [0.7182],\n",
      "        [0.8736]]) 0.3567200303077698\n",
      "2196 tensor([[0.2575],\n",
      "        [0.4846],\n",
      "        [0.7182],\n",
      "        [0.8736]]) 0.35664069652557373\n",
      "2197 tensor([[0.2574],\n",
      "        [0.4845],\n",
      "        [0.7183],\n",
      "        [0.8737]]) 0.3565613329410553\n",
      "2198 tensor([[0.2573],\n",
      "        [0.4845],\n",
      "        [0.7183],\n",
      "        [0.8737]]) 0.35648205876350403\n",
      "2199 tensor([[0.2572],\n",
      "        [0.4844],\n",
      "        [0.7183],\n",
      "        [0.8737]]) 0.3564028739929199\n",
      "2200 tensor([[0.2571],\n",
      "        [0.4844],\n",
      "        [0.7183],\n",
      "        [0.8738]]) 0.35632362961769104\n",
      "2201 tensor([[0.2570],\n",
      "        [0.4843],\n",
      "        [0.7183],\n",
      "        [0.8738]]) 0.3562445044517517\n",
      "2202 tensor([[0.2569],\n",
      "        [0.4843],\n",
      "        [0.7184],\n",
      "        [0.8739]]) 0.3561653792858124\n",
      "2203 tensor([[0.2568],\n",
      "        [0.4842],\n",
      "        [0.7184],\n",
      "        [0.8739]]) 0.3560863137245178\n",
      "2204 tensor([[0.2567],\n",
      "        [0.4842],\n",
      "        [0.7184],\n",
      "        [0.8740]]) 0.35600727796554565\n",
      "2205 tensor([[0.2566],\n",
      "        [0.4841],\n",
      "        [0.7184],\n",
      "        [0.8740]]) 0.35592833161354065\n",
      "2206 tensor([[0.2565],\n",
      "        [0.4841],\n",
      "        [0.7184],\n",
      "        [0.8741]]) 0.35584938526153564\n",
      "2207 tensor([[0.2564],\n",
      "        [0.4840],\n",
      "        [0.7185],\n",
      "        [0.8741]]) 0.355770468711853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208 tensor([[0.2563],\n",
      "        [0.4839],\n",
      "        [0.7185],\n",
      "        [0.8741]]) 0.3556915819644928\n",
      "2209 tensor([[0.2562],\n",
      "        [0.4839],\n",
      "        [0.7185],\n",
      "        [0.8742]]) 0.3556128144264221\n",
      "2210 tensor([[0.2561],\n",
      "        [0.4838],\n",
      "        [0.7185],\n",
      "        [0.8742]]) 0.35553407669067383\n",
      "2211 tensor([[0.2560],\n",
      "        [0.4838],\n",
      "        [0.7185],\n",
      "        [0.8743]]) 0.35545530915260315\n",
      "2212 tensor([[0.2559],\n",
      "        [0.4837],\n",
      "        [0.7186],\n",
      "        [0.8743]]) 0.35537663102149963\n",
      "2213 tensor([[0.2558],\n",
      "        [0.4837],\n",
      "        [0.7186],\n",
      "        [0.8744]]) 0.3552979528903961\n",
      "2214 tensor([[0.2557],\n",
      "        [0.4836],\n",
      "        [0.7186],\n",
      "        [0.8744]]) 0.35521939396858215\n",
      "2215 tensor([[0.2556],\n",
      "        [0.4836],\n",
      "        [0.7186],\n",
      "        [0.8745]]) 0.3551408052444458\n",
      "2216 tensor([[0.2555],\n",
      "        [0.4835],\n",
      "        [0.7186],\n",
      "        [0.8745]]) 0.3550622761249542\n",
      "2217 tensor([[0.2554],\n",
      "        [0.4835],\n",
      "        [0.7187],\n",
      "        [0.8745]]) 0.35498374700546265\n",
      "2218 tensor([[0.2553],\n",
      "        [0.4834],\n",
      "        [0.7187],\n",
      "        [0.8746]]) 0.3549053370952606\n",
      "2219 tensor([[0.2552],\n",
      "        [0.4834],\n",
      "        [0.7187],\n",
      "        [0.8746]]) 0.3548269271850586\n",
      "2220 tensor([[0.2551],\n",
      "        [0.4833],\n",
      "        [0.7187],\n",
      "        [0.8747]]) 0.35474860668182373\n",
      "2221 tensor([[0.2550],\n",
      "        [0.4833],\n",
      "        [0.7187],\n",
      "        [0.8747]]) 0.3546702563762665\n",
      "2222 tensor([[0.2549],\n",
      "        [0.4832],\n",
      "        [0.7188],\n",
      "        [0.8748]]) 0.354591965675354\n",
      "2223 tensor([[0.2548],\n",
      "        [0.4832],\n",
      "        [0.7188],\n",
      "        [0.8748]]) 0.3545137643814087\n",
      "2224 tensor([[0.2547],\n",
      "        [0.4831],\n",
      "        [0.7188],\n",
      "        [0.8749]]) 0.35443562269210815\n",
      "2225 tensor([[0.2546],\n",
      "        [0.4830],\n",
      "        [0.7188],\n",
      "        [0.8749]]) 0.35435742139816284\n",
      "2226 tensor([[0.2545],\n",
      "        [0.4830],\n",
      "        [0.7188],\n",
      "        [0.8749]]) 0.3542793393135071\n",
      "2227 tensor([[0.2544],\n",
      "        [0.4829],\n",
      "        [0.7189],\n",
      "        [0.8750]]) 0.35420122742652893\n",
      "2228 tensor([[0.2543],\n",
      "        [0.4829],\n",
      "        [0.7189],\n",
      "        [0.8750]]) 0.35412320494651794\n",
      "2229 tensor([[0.2542],\n",
      "        [0.4828],\n",
      "        [0.7189],\n",
      "        [0.8751]]) 0.35404521226882935\n",
      "2230 tensor([[0.2541],\n",
      "        [0.4828],\n",
      "        [0.7189],\n",
      "        [0.8751]]) 0.3539672791957855\n",
      "2231 tensor([[0.2540],\n",
      "        [0.4827],\n",
      "        [0.7189],\n",
      "        [0.8752]]) 0.3538893461227417\n",
      "2232 tensor([[0.2539],\n",
      "        [0.4827],\n",
      "        [0.7189],\n",
      "        [0.8752]]) 0.3538115620613098\n",
      "2233 tensor([[0.2538],\n",
      "        [0.4826],\n",
      "        [0.7190],\n",
      "        [0.8753]]) 0.35373368859291077\n",
      "2234 tensor([[0.2537],\n",
      "        [0.4826],\n",
      "        [0.7190],\n",
      "        [0.8753]]) 0.3536559045314789\n",
      "2235 tensor([[0.2536],\n",
      "        [0.4825],\n",
      "        [0.7190],\n",
      "        [0.8753]]) 0.3535781800746918\n",
      "2236 tensor([[0.2535],\n",
      "        [0.4825],\n",
      "        [0.7190],\n",
      "        [0.8754]]) 0.3535004258155823\n",
      "2237 tensor([[0.2534],\n",
      "        [0.4824],\n",
      "        [0.7190],\n",
      "        [0.8754]]) 0.3534228801727295\n",
      "2238 tensor([[0.2533],\n",
      "        [0.4824],\n",
      "        [0.7191],\n",
      "        [0.8755]]) 0.35334527492523193\n",
      "2239 tensor([[0.2532],\n",
      "        [0.4823],\n",
      "        [0.7191],\n",
      "        [0.8755]]) 0.3532676100730896\n",
      "2240 tensor([[0.2531],\n",
      "        [0.4823],\n",
      "        [0.7191],\n",
      "        [0.8756]]) 0.3531900644302368\n",
      "2241 tensor([[0.2530],\n",
      "        [0.4822],\n",
      "        [0.7191],\n",
      "        [0.8756]]) 0.3531126081943512\n",
      "2242 tensor([[0.2529],\n",
      "        [0.4821],\n",
      "        [0.7191],\n",
      "        [0.8756]]) 0.3530351519584656\n",
      "2243 tensor([[0.2528],\n",
      "        [0.4821],\n",
      "        [0.7192],\n",
      "        [0.8757]]) 0.35295769572257996\n",
      "2244 tensor([[0.2527],\n",
      "        [0.4820],\n",
      "        [0.7192],\n",
      "        [0.8757]]) 0.3528803288936615\n",
      "2245 tensor([[0.2526],\n",
      "        [0.4820],\n",
      "        [0.7192],\n",
      "        [0.8758]]) 0.35280299186706543\n",
      "2246 tensor([[0.2525],\n",
      "        [0.4819],\n",
      "        [0.7192],\n",
      "        [0.8758]]) 0.3527257442474365\n",
      "2247 tensor([[0.2524],\n",
      "        [0.4819],\n",
      "        [0.7192],\n",
      "        [0.8759]]) 0.3526484966278076\n",
      "2248 tensor([[0.2523],\n",
      "        [0.4818],\n",
      "        [0.7193],\n",
      "        [0.8759]]) 0.3525712788105011\n",
      "2249 tensor([[0.2522],\n",
      "        [0.4818],\n",
      "        [0.7193],\n",
      "        [0.8760]]) 0.35249409079551697\n",
      "2250 tensor([[0.2521],\n",
      "        [0.4817],\n",
      "        [0.7193],\n",
      "        [0.8760]]) 0.3524169921875\n",
      "2251 tensor([[0.2520],\n",
      "        [0.4817],\n",
      "        [0.7193],\n",
      "        [0.8760]]) 0.35233989357948303\n",
      "2252 tensor([[0.2519],\n",
      "        [0.4816],\n",
      "        [0.7193],\n",
      "        [0.8761]]) 0.35226282477378845\n",
      "2253 tensor([[0.2519],\n",
      "        [0.4816],\n",
      "        [0.7194],\n",
      "        [0.8761]]) 0.35218581557273865\n",
      "2254 tensor([[0.2518],\n",
      "        [0.4815],\n",
      "        [0.7194],\n",
      "        [0.8762]]) 0.35210883617401123\n",
      "2255 tensor([[0.2517],\n",
      "        [0.4815],\n",
      "        [0.7194],\n",
      "        [0.8762]]) 0.3520318865776062\n",
      "2256 tensor([[0.2516],\n",
      "        [0.4814],\n",
      "        [0.7194],\n",
      "        [0.8763]]) 0.35195502638816833\n",
      "2257 tensor([[0.2515],\n",
      "        [0.4814],\n",
      "        [0.7194],\n",
      "        [0.8763]]) 0.3518781363964081\n",
      "2258 tensor([[0.2514],\n",
      "        [0.4813],\n",
      "        [0.7195],\n",
      "        [0.8763]]) 0.3518013656139374\n",
      "2259 tensor([[0.2513],\n",
      "        [0.4813],\n",
      "        [0.7195],\n",
      "        [0.8764]]) 0.35172462463378906\n",
      "2260 tensor([[0.2512],\n",
      "        [0.4812],\n",
      "        [0.7195],\n",
      "        [0.8764]]) 0.35164791345596313\n",
      "2261 tensor([[0.2511],\n",
      "        [0.4812],\n",
      "        [0.7195],\n",
      "        [0.8765]]) 0.3515712320804596\n",
      "2262 tensor([[0.2510],\n",
      "        [0.4811],\n",
      "        [0.7195],\n",
      "        [0.8765]]) 0.35149455070495605\n",
      "2263 tensor([[0.2509],\n",
      "        [0.4810],\n",
      "        [0.7195],\n",
      "        [0.8766]]) 0.3514179289340973\n",
      "2264 tensor([[0.2508],\n",
      "        [0.4810],\n",
      "        [0.7196],\n",
      "        [0.8766]]) 0.3513414263725281\n",
      "2265 tensor([[0.2507],\n",
      "        [0.4809],\n",
      "        [0.7196],\n",
      "        [0.8767]]) 0.3512648940086365\n",
      "2266 tensor([[0.2506],\n",
      "        [0.4809],\n",
      "        [0.7196],\n",
      "        [0.8767]]) 0.3511883616447449\n",
      "2267 tensor([[0.2505],\n",
      "        [0.4808],\n",
      "        [0.7196],\n",
      "        [0.8767]]) 0.3511119484901428\n",
      "2268 tensor([[0.2504],\n",
      "        [0.4808],\n",
      "        [0.7196],\n",
      "        [0.8768]]) 0.35103553533554077\n",
      "2269 tensor([[0.2503],\n",
      "        [0.4807],\n",
      "        [0.7197],\n",
      "        [0.8768]]) 0.3509591817855835\n",
      "2270 tensor([[0.2502],\n",
      "        [0.4807],\n",
      "        [0.7197],\n",
      "        [0.8769]]) 0.350882887840271\n",
      "2271 tensor([[0.2501],\n",
      "        [0.4806],\n",
      "        [0.7197],\n",
      "        [0.8769]]) 0.35080650448799133\n",
      "2272 tensor([[0.2500],\n",
      "        [0.4806],\n",
      "        [0.7197],\n",
      "        [0.8770]]) 0.3507302403450012\n",
      "2273 tensor([[0.2499],\n",
      "        [0.4805],\n",
      "        [0.7197],\n",
      "        [0.8770]]) 0.3506540060043335\n",
      "2274 tensor([[0.2498],\n",
      "        [0.4805],\n",
      "        [0.7198],\n",
      "        [0.8770]]) 0.3505779206752777\n",
      "2275 tensor([[0.2497],\n",
      "        [0.4804],\n",
      "        [0.7198],\n",
      "        [0.8771]]) 0.35050174593925476\n",
      "2276 tensor([[0.2496],\n",
      "        [0.4804],\n",
      "        [0.7198],\n",
      "        [0.8771]]) 0.35042572021484375\n",
      "2277 tensor([[0.2495],\n",
      "        [0.4803],\n",
      "        [0.7198],\n",
      "        [0.8772]]) 0.3503496050834656\n",
      "2278 tensor([[0.2494],\n",
      "        [0.4803],\n",
      "        [0.7198],\n",
      "        [0.8772]]) 0.35027360916137695\n",
      "2279 tensor([[0.2493],\n",
      "        [0.4802],\n",
      "        [0.7199],\n",
      "        [0.8773]]) 0.35019761323928833\n",
      "2280 tensor([[0.2492],\n",
      "        [0.4802],\n",
      "        [0.7199],\n",
      "        [0.8773]]) 0.35012173652648926\n",
      "2281 tensor([[0.2491],\n",
      "        [0.4801],\n",
      "        [0.7199],\n",
      "        [0.8773]]) 0.3500458300113678\n",
      "2282 tensor([[0.2491],\n",
      "        [0.4801],\n",
      "        [0.7199],\n",
      "        [0.8774]]) 0.3499700129032135\n",
      "2283 tensor([[0.2490],\n",
      "        [0.4800],\n",
      "        [0.7199],\n",
      "        [0.8774]]) 0.34989413619041443\n",
      "2284 tensor([[0.2489],\n",
      "        [0.4800],\n",
      "        [0.7200],\n",
      "        [0.8775]]) 0.3498184084892273\n",
      "2285 tensor([[0.2488],\n",
      "        [0.4799],\n",
      "        [0.7200],\n",
      "        [0.8775]]) 0.3497426509857178\n",
      "2286 tensor([[0.2487],\n",
      "        [0.4798],\n",
      "        [0.7200],\n",
      "        [0.8776]]) 0.34966692328453064\n",
      "2287 tensor([[0.2486],\n",
      "        [0.4798],\n",
      "        [0.7200],\n",
      "        [0.8776]]) 0.3495912551879883\n",
      "2288 tensor([[0.2485],\n",
      "        [0.4797],\n",
      "        [0.7200],\n",
      "        [0.8776]]) 0.3495156764984131\n",
      "2289 tensor([[0.2484],\n",
      "        [0.4797],\n",
      "        [0.7201],\n",
      "        [0.8777]]) 0.3494400978088379\n",
      "2290 tensor([[0.2483],\n",
      "        [0.4796],\n",
      "        [0.7201],\n",
      "        [0.8777]]) 0.34936457872390747\n",
      "2291 tensor([[0.2482],\n",
      "        [0.4796],\n",
      "        [0.7201],\n",
      "        [0.8778]]) 0.3492891192436218\n",
      "2292 tensor([[0.2481],\n",
      "        [0.4795],\n",
      "        [0.7201],\n",
      "        [0.8778]]) 0.3492136597633362\n",
      "2293 tensor([[0.2480],\n",
      "        [0.4795],\n",
      "        [0.7201],\n",
      "        [0.8779]]) 0.34913820028305054\n",
      "2294 tensor([[0.2479],\n",
      "        [0.4794],\n",
      "        [0.7201],\n",
      "        [0.8779]]) 0.34906280040740967\n",
      "2295 tensor([[0.2478],\n",
      "        [0.4794],\n",
      "        [0.7202],\n",
      "        [0.8779]]) 0.3489874601364136\n",
      "2296 tensor([[0.2477],\n",
      "        [0.4793],\n",
      "        [0.7202],\n",
      "        [0.8780]]) 0.34891217947006226\n",
      "2297 tensor([[0.2476],\n",
      "        [0.4793],\n",
      "        [0.7202],\n",
      "        [0.8780]]) 0.34883689880371094\n",
      "2298 tensor([[0.2475],\n",
      "        [0.4792],\n",
      "        [0.7202],\n",
      "        [0.8781]]) 0.34876173734664917\n",
      "2299 tensor([[0.2474],\n",
      "        [0.4792],\n",
      "        [0.7202],\n",
      "        [0.8781]]) 0.348686546087265\n",
      "2300 tensor([[0.2473],\n",
      "        [0.4791],\n",
      "        [0.7203],\n",
      "        [0.8782]]) 0.34861138463020325\n",
      "2301 tensor([[0.2472],\n",
      "        [0.4791],\n",
      "        [0.7203],\n",
      "        [0.8782]]) 0.34853628277778625\n",
      "2302 tensor([[0.2471],\n",
      "        [0.4790],\n",
      "        [0.7203],\n",
      "        [0.8782]]) 0.34846124053001404\n",
      "2303 tensor([[0.2470],\n",
      "        [0.4790],\n",
      "        [0.7203],\n",
      "        [0.8783]]) 0.34838616847991943\n",
      "2304 tensor([[0.2470],\n",
      "        [0.4789],\n",
      "        [0.7203],\n",
      "        [0.8783]]) 0.3483112156391144\n",
      "2305 tensor([[0.2469],\n",
      "        [0.4789],\n",
      "        [0.7204],\n",
      "        [0.8784]]) 0.3482362627983093\n",
      "2306 tensor([[0.2468],\n",
      "        [0.4788],\n",
      "        [0.7204],\n",
      "        [0.8784]]) 0.3481612801551819\n",
      "2307 tensor([[0.2467],\n",
      "        [0.4788],\n",
      "        [0.7204],\n",
      "        [0.8785]]) 0.3480864465236664\n",
      "2308 tensor([[0.2466],\n",
      "        [0.4787],\n",
      "        [0.7204],\n",
      "        [0.8785]]) 0.3480115830898285\n",
      "2309 tensor([[0.2465],\n",
      "        [0.4787],\n",
      "        [0.7204],\n",
      "        [0.8785]]) 0.34793686866760254\n",
      "2310 tensor([[0.2464],\n",
      "        [0.4786],\n",
      "        [0.7205],\n",
      "        [0.8786]]) 0.34786203503608704\n",
      "2311 tensor([[0.2463],\n",
      "        [0.4786],\n",
      "        [0.7205],\n",
      "        [0.8786]]) 0.3477873206138611\n",
      "2312 tensor([[0.2462],\n",
      "        [0.4785],\n",
      "        [0.7205],\n",
      "        [0.8787]]) 0.3477126359939575\n",
      "2313 tensor([[0.2461],\n",
      "        [0.4785],\n",
      "        [0.7205],\n",
      "        [0.8787]]) 0.3476380407810211\n",
      "2314 tensor([[0.2460],\n",
      "        [0.4784],\n",
      "        [0.7205],\n",
      "        [0.8788]]) 0.34756338596343994\n",
      "2315 tensor([[0.2459],\n",
      "        [0.4783],\n",
      "        [0.7206],\n",
      "        [0.8788]]) 0.3474888503551483\n",
      "2316 tensor([[0.2458],\n",
      "        [0.4783],\n",
      "        [0.7206],\n",
      "        [0.8788]]) 0.34741437435150146\n",
      "2317 tensor([[0.2457],\n",
      "        [0.4782],\n",
      "        [0.7206],\n",
      "        [0.8789]]) 0.34733980894088745\n",
      "2318 tensor([[0.2456],\n",
      "        [0.4782],\n",
      "        [0.7206],\n",
      "        [0.8789]]) 0.34726542234420776\n",
      "2319 tensor([[0.2455],\n",
      "        [0.4781],\n",
      "        [0.7206],\n",
      "        [0.8790]]) 0.3471909463405609\n",
      "2320 tensor([[0.2454],\n",
      "        [0.4781],\n",
      "        [0.7206],\n",
      "        [0.8790]]) 0.3471166491508484\n",
      "2321 tensor([[0.2454],\n",
      "        [0.4780],\n",
      "        [0.7207],\n",
      "        [0.8790]]) 0.3470422625541687\n",
      "2322 tensor([[0.2453],\n",
      "        [0.4780],\n",
      "        [0.7207],\n",
      "        [0.8791]]) 0.3469679653644562\n",
      "2323 tensor([[0.2452],\n",
      "        [0.4779],\n",
      "        [0.7207],\n",
      "        [0.8791]]) 0.3468937277793884\n",
      "2324 tensor([[0.2451],\n",
      "        [0.4779],\n",
      "        [0.7207],\n",
      "        [0.8792]]) 0.34681951999664307\n",
      "2325 tensor([[0.2450],\n",
      "        [0.4778],\n",
      "        [0.7207],\n",
      "        [0.8792]]) 0.3467453420162201\n",
      "2326 tensor([[0.2449],\n",
      "        [0.4778],\n",
      "        [0.7208],\n",
      "        [0.8793]]) 0.3466711640357971\n",
      "2327 tensor([[0.2448],\n",
      "        [0.4777],\n",
      "        [0.7208],\n",
      "        [0.8793]]) 0.3465970456600189\n",
      "2328 tensor([[0.2447],\n",
      "        [0.4777],\n",
      "        [0.7208],\n",
      "        [0.8793]]) 0.3465229868888855\n",
      "2329 tensor([[0.2446],\n",
      "        [0.4776],\n",
      "        [0.7208],\n",
      "        [0.8794]]) 0.34644895792007446\n",
      "2330 tensor([[0.2445],\n",
      "        [0.4776],\n",
      "        [0.7208],\n",
      "        [0.8794]]) 0.3463749289512634\n",
      "2331 tensor([[0.2444],\n",
      "        [0.4775],\n",
      "        [0.7209],\n",
      "        [0.8795]]) 0.34630095958709717\n",
      "2332 tensor([[0.2443],\n",
      "        [0.4775],\n",
      "        [0.7209],\n",
      "        [0.8795]]) 0.34622710943222046\n",
      "2333 tensor([[0.2442],\n",
      "        [0.4774],\n",
      "        [0.7209],\n",
      "        [0.8795]]) 0.346153199672699\n",
      "2334 tensor([[0.2441],\n",
      "        [0.4774],\n",
      "        [0.7209],\n",
      "        [0.8796]]) 0.34607934951782227\n",
      "2335 tensor([[0.2440],\n",
      "        [0.4773],\n",
      "        [0.7209],\n",
      "        [0.8796]]) 0.3460055887699127\n",
      "2336 tensor([[0.2440],\n",
      "        [0.4773],\n",
      "        [0.7210],\n",
      "        [0.8797]]) 0.3459317982196808\n",
      "2337 tensor([[0.2439],\n",
      "        [0.4772],\n",
      "        [0.7210],\n",
      "        [0.8797]]) 0.34585803747177124\n",
      "2338 tensor([[0.2438],\n",
      "        [0.4772],\n",
      "        [0.7210],\n",
      "        [0.8798]]) 0.34578442573547363\n",
      "2339 tensor([[0.2437],\n",
      "        [0.4771],\n",
      "        [0.7210],\n",
      "        [0.8798]]) 0.34571072459220886\n",
      "2340 tensor([[0.2436],\n",
      "        [0.4771],\n",
      "        [0.7210],\n",
      "        [0.8798]]) 0.3456372022628784\n",
      "2341 tensor([[0.2435],\n",
      "        [0.4770],\n",
      "        [0.7210],\n",
      "        [0.8799]]) 0.3455636203289032\n",
      "2342 tensor([[0.2434],\n",
      "        [0.4770],\n",
      "        [0.7211],\n",
      "        [0.8799]]) 0.345490038394928\n",
      "2343 tensor([[0.2433],\n",
      "        [0.4769],\n",
      "        [0.7211],\n",
      "        [0.8800]]) 0.3454165756702423\n",
      "2344 tensor([[0.2432],\n",
      "        [0.4769],\n",
      "        [0.7211],\n",
      "        [0.8800]]) 0.34534308314323425\n",
      "2345 tensor([[0.2431],\n",
      "        [0.4768],\n",
      "        [0.7211],\n",
      "        [0.8801]]) 0.3452696204185486\n",
      "2346 tensor([[0.2430],\n",
      "        [0.4768],\n",
      "        [0.7211],\n",
      "        [0.8801]]) 0.34519636631011963\n",
      "2347 tensor([[0.2429],\n",
      "        [0.4767],\n",
      "        [0.7212],\n",
      "        [0.8801]]) 0.34512293338775635\n",
      "2348 tensor([[0.2428],\n",
      "        [0.4767],\n",
      "        [0.7212],\n",
      "        [0.8802]]) 0.3450496196746826\n",
      "2349 tensor([[0.2427],\n",
      "        [0.4766],\n",
      "        [0.7212],\n",
      "        [0.8802]]) 0.34497636556625366\n",
      "2350 tensor([[0.2427],\n",
      "        [0.4766],\n",
      "        [0.7212],\n",
      "        [0.8803]]) 0.3449031114578247\n",
      "2351 tensor([[0.2426],\n",
      "        [0.4765],\n",
      "        [0.7212],\n",
      "        [0.8803]]) 0.3448299169540405\n",
      "2352 tensor([[0.2425],\n",
      "        [0.4765],\n",
      "        [0.7213],\n",
      "        [0.8803]]) 0.34475672245025635\n",
      "2353 tensor([[0.2424],\n",
      "        [0.4764],\n",
      "        [0.7213],\n",
      "        [0.8804]]) 0.34468361735343933\n",
      "2354 tensor([[0.2423],\n",
      "        [0.4764],\n",
      "        [0.7213],\n",
      "        [0.8804]]) 0.3446105718612671\n",
      "2355 tensor([[0.2422],\n",
      "        [0.4763],\n",
      "        [0.7213],\n",
      "        [0.8805]]) 0.34453749656677246\n",
      "2356 tensor([[0.2421],\n",
      "        [0.4763],\n",
      "        [0.7213],\n",
      "        [0.8805]]) 0.344464510679245\n",
      "2357 tensor([[0.2420],\n",
      "        [0.4762],\n",
      "        [0.7214],\n",
      "        [0.8805]]) 0.3443915545940399\n",
      "2358 tensor([[0.2419],\n",
      "        [0.4762],\n",
      "        [0.7214],\n",
      "        [0.8806]]) 0.34431859850883484\n",
      "2359 tensor([[0.2418],\n",
      "        [0.4761],\n",
      "        [0.7214],\n",
      "        [0.8806]]) 0.34424564242362976\n",
      "2360 tensor([[0.2417],\n",
      "        [0.4760],\n",
      "        [0.7214],\n",
      "        [0.8807]]) 0.3441728353500366\n",
      "2361 tensor([[0.2416],\n",
      "        [0.4760],\n",
      "        [0.7214],\n",
      "        [0.8807]]) 0.3441000282764435\n",
      "2362 tensor([[0.2415],\n",
      "        [0.4759],\n",
      "        [0.7214],\n",
      "        [0.8808]]) 0.34402722120285034\n",
      "2363 tensor([[0.2415],\n",
      "        [0.4759],\n",
      "        [0.7215],\n",
      "        [0.8808]]) 0.343954473733902\n",
      "2364 tensor([[0.2414],\n",
      "        [0.4758],\n",
      "        [0.7215],\n",
      "        [0.8808]]) 0.343881756067276\n",
      "2365 tensor([[0.2413],\n",
      "        [0.4758],\n",
      "        [0.7215],\n",
      "        [0.8809]]) 0.3438090682029724\n",
      "2366 tensor([[0.2412],\n",
      "        [0.4757],\n",
      "        [0.7215],\n",
      "        [0.8809]]) 0.3437364101409912\n",
      "2367 tensor([[0.2411],\n",
      "        [0.4757],\n",
      "        [0.7215],\n",
      "        [0.8810]]) 0.3436638414859772\n",
      "2368 tensor([[0.2410],\n",
      "        [0.4756],\n",
      "        [0.7216],\n",
      "        [0.8810]]) 0.34359124302864075\n",
      "2369 tensor([[0.2409],\n",
      "        [0.4756],\n",
      "        [0.7216],\n",
      "        [0.8810]]) 0.34351876378059387\n",
      "2370 tensor([[0.2408],\n",
      "        [0.4755],\n",
      "        [0.7216],\n",
      "        [0.8811]]) 0.3434462249279022\n",
      "2371 tensor([[0.2407],\n",
      "        [0.4755],\n",
      "        [0.7216],\n",
      "        [0.8811]]) 0.34337377548217773\n",
      "2372 tensor([[0.2406],\n",
      "        [0.4754],\n",
      "        [0.7216],\n",
      "        [0.8812]]) 0.34330132603645325\n",
      "2373 tensor([[0.2405],\n",
      "        [0.4754],\n",
      "        [0.7217],\n",
      "        [0.8812]]) 0.34322893619537354\n",
      "2374 tensor([[0.2404],\n",
      "        [0.4753],\n",
      "        [0.7217],\n",
      "        [0.8812]]) 0.3431566059589386\n",
      "2375 tensor([[0.2404],\n",
      "        [0.4753],\n",
      "        [0.7217],\n",
      "        [0.8813]]) 0.34308433532714844\n",
      "2376 tensor([[0.2403],\n",
      "        [0.4752],\n",
      "        [0.7217],\n",
      "        [0.8813]]) 0.34301209449768066\n",
      "2377 tensor([[0.2402],\n",
      "        [0.4752],\n",
      "        [0.7217],\n",
      "        [0.8814]]) 0.3429398536682129\n",
      "2378 tensor([[0.2401],\n",
      "        [0.4751],\n",
      "        [0.7218],\n",
      "        [0.8814]]) 0.3428676426410675\n",
      "2379 tensor([[0.2400],\n",
      "        [0.4751],\n",
      "        [0.7218],\n",
      "        [0.8815]]) 0.3427954912185669\n",
      "2380 tensor([[0.2399],\n",
      "        [0.4750],\n",
      "        [0.7218],\n",
      "        [0.8815]]) 0.3427233397960663\n",
      "2381 tensor([[0.2398],\n",
      "        [0.4750],\n",
      "        [0.7218],\n",
      "        [0.8815]]) 0.3426513075828552\n",
      "2382 tensor([[0.2397],\n",
      "        [0.4749],\n",
      "        [0.7218],\n",
      "        [0.8816]]) 0.3425792455673218\n",
      "2383 tensor([[0.2396],\n",
      "        [0.4749],\n",
      "        [0.7218],\n",
      "        [0.8816]]) 0.3425072729587555\n",
      "2384 tensor([[0.2395],\n",
      "        [0.4748],\n",
      "        [0.7219],\n",
      "        [0.8817]]) 0.3424352705478668\n",
      "2385 tensor([[0.2394],\n",
      "        [0.4748],\n",
      "        [0.7219],\n",
      "        [0.8817]]) 0.3423633277416229\n",
      "2386 tensor([[0.2394],\n",
      "        [0.4747],\n",
      "        [0.7219],\n",
      "        [0.8817]]) 0.34229138493537903\n",
      "2387 tensor([[0.2393],\n",
      "        [0.4747],\n",
      "        [0.7219],\n",
      "        [0.8818]]) 0.3422195613384247\n",
      "2388 tensor([[0.2392],\n",
      "        [0.4746],\n",
      "        [0.7219],\n",
      "        [0.8818]]) 0.34214773774147034\n",
      "2389 tensor([[0.2391],\n",
      "        [0.4746],\n",
      "        [0.7220],\n",
      "        [0.8819]]) 0.3420759439468384\n",
      "2390 tensor([[0.2390],\n",
      "        [0.4745],\n",
      "        [0.7220],\n",
      "        [0.8819]]) 0.3420041799545288\n",
      "2391 tensor([[0.2389],\n",
      "        [0.4745],\n",
      "        [0.7220],\n",
      "        [0.8819]]) 0.3419324457645416\n",
      "2392 tensor([[0.2388],\n",
      "        [0.4744],\n",
      "        [0.7220],\n",
      "        [0.8820]]) 0.3418607711791992\n",
      "2393 tensor([[0.2387],\n",
      "        [0.4744],\n",
      "        [0.7220],\n",
      "        [0.8820]]) 0.3417891263961792\n",
      "2394 tensor([[0.2386],\n",
      "        [0.4743],\n",
      "        [0.7221],\n",
      "        [0.8821]]) 0.3417174816131592\n",
      "2395 tensor([[0.2385],\n",
      "        [0.4743],\n",
      "        [0.7221],\n",
      "        [0.8821]]) 0.3416459560394287\n",
      "2396 tensor([[0.2385],\n",
      "        [0.4742],\n",
      "        [0.7221],\n",
      "        [0.8821]]) 0.34157437086105347\n",
      "2397 tensor([[0.2384],\n",
      "        [0.4742],\n",
      "        [0.7221],\n",
      "        [0.8822]]) 0.3415028750896454\n",
      "2398 tensor([[0.2383],\n",
      "        [0.4741],\n",
      "        [0.7221],\n",
      "        [0.8822]]) 0.3414314389228821\n",
      "2399 tensor([[0.2382],\n",
      "        [0.4741],\n",
      "        [0.7222],\n",
      "        [0.8823]]) 0.3413600027561188\n",
      "2400 tensor([[0.2381],\n",
      "        [0.4740],\n",
      "        [0.7222],\n",
      "        [0.8823]]) 0.34128859639167786\n",
      "2401 tensor([[0.2380],\n",
      "        [0.4740],\n",
      "        [0.7222],\n",
      "        [0.8823]]) 0.3412172496318817\n",
      "2402 tensor([[0.2379],\n",
      "        [0.4739],\n",
      "        [0.7222],\n",
      "        [0.8824]]) 0.34114593267440796\n",
      "2403 tensor([[0.2378],\n",
      "        [0.4739],\n",
      "        [0.7222],\n",
      "        [0.8824]]) 0.341074675321579\n",
      "2404 tensor([[0.2377],\n",
      "        [0.4738],\n",
      "        [0.7222],\n",
      "        [0.8825]]) 0.3410033881664276\n",
      "2405 tensor([[0.2376],\n",
      "        [0.4738],\n",
      "        [0.7223],\n",
      "        [0.8825]]) 0.3409321904182434\n",
      "2406 tensor([[0.2376],\n",
      "        [0.4737],\n",
      "        [0.7223],\n",
      "        [0.8825]]) 0.3408609926700592\n",
      "2407 tensor([[0.2375],\n",
      "        [0.4737],\n",
      "        [0.7223],\n",
      "        [0.8826]]) 0.34078988432884216\n",
      "2408 tensor([[0.2374],\n",
      "        [0.4736],\n",
      "        [0.7223],\n",
      "        [0.8826]]) 0.3407188057899475\n",
      "2409 tensor([[0.2373],\n",
      "        [0.4736],\n",
      "        [0.7223],\n",
      "        [0.8827]]) 0.34064772725105286\n",
      "2410 tensor([[0.2372],\n",
      "        [0.4735],\n",
      "        [0.7224],\n",
      "        [0.8827]]) 0.3405766785144806\n",
      "2411 tensor([[0.2371],\n",
      "        [0.4735],\n",
      "        [0.7224],\n",
      "        [0.8828]]) 0.3405056893825531\n",
      "2412 tensor([[0.2370],\n",
      "        [0.4734],\n",
      "        [0.7224],\n",
      "        [0.8828]]) 0.3404347598552704\n",
      "2413 tensor([[0.2369],\n",
      "        [0.4734],\n",
      "        [0.7224],\n",
      "        [0.8828]]) 0.34036383032798767\n",
      "2414 tensor([[0.2368],\n",
      "        [0.4733],\n",
      "        [0.7224],\n",
      "        [0.8829]]) 0.34029293060302734\n",
      "2415 tensor([[0.2367],\n",
      "        [0.4733],\n",
      "        [0.7225],\n",
      "        [0.8829]]) 0.340222030878067\n",
      "2416 tensor([[0.2367],\n",
      "        [0.4732],\n",
      "        [0.7225],\n",
      "        [0.8830]]) 0.34015122056007385\n",
      "2417 tensor([[0.2366],\n",
      "        [0.4732],\n",
      "        [0.7225],\n",
      "        [0.8830]]) 0.34008046984672546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418 tensor([[0.2365],\n",
      "        [0.4731],\n",
      "        [0.7225],\n",
      "        [0.8830]]) 0.3400096893310547\n",
      "2419 tensor([[0.2364],\n",
      "        [0.4731],\n",
      "        [0.7225],\n",
      "        [0.8831]]) 0.3399389982223511\n",
      "2420 tensor([[0.2363],\n",
      "        [0.4730],\n",
      "        [0.7225],\n",
      "        [0.8831]]) 0.33986830711364746\n",
      "2421 tensor([[0.2362],\n",
      "        [0.4730],\n",
      "        [0.7226],\n",
      "        [0.8832]]) 0.3397976756095886\n",
      "2422 tensor([[0.2361],\n",
      "        [0.4729],\n",
      "        [0.7226],\n",
      "        [0.8832]]) 0.3397270739078522\n",
      "2423 tensor([[0.2360],\n",
      "        [0.4729],\n",
      "        [0.7226],\n",
      "        [0.8832]]) 0.3396565020084381\n",
      "2424 tensor([[0.2359],\n",
      "        [0.4728],\n",
      "        [0.7226],\n",
      "        [0.8833]]) 0.33958595991134644\n",
      "2425 tensor([[0.2359],\n",
      "        [0.4728],\n",
      "        [0.7226],\n",
      "        [0.8833]]) 0.3395155072212219\n",
      "2426 tensor([[0.2358],\n",
      "        [0.4727],\n",
      "        [0.7227],\n",
      "        [0.8834]]) 0.339445024728775\n",
      "2427 tensor([[0.2357],\n",
      "        [0.4727],\n",
      "        [0.7227],\n",
      "        [0.8834]]) 0.3393746018409729\n",
      "2428 tensor([[0.2356],\n",
      "        [0.4726],\n",
      "        [0.7227],\n",
      "        [0.8834]]) 0.33930420875549316\n",
      "2429 tensor([[0.2355],\n",
      "        [0.4726],\n",
      "        [0.7227],\n",
      "        [0.8835]]) 0.3392338156700134\n",
      "2430 tensor([[0.2354],\n",
      "        [0.4725],\n",
      "        [0.7227],\n",
      "        [0.8835]]) 0.33916357159614563\n",
      "2431 tensor([[0.2353],\n",
      "        [0.4725],\n",
      "        [0.7228],\n",
      "        [0.8836]]) 0.33909323811531067\n",
      "2432 tensor([[0.2352],\n",
      "        [0.4724],\n",
      "        [0.7228],\n",
      "        [0.8836]]) 0.33902302384376526\n",
      "2433 tensor([[0.2351],\n",
      "        [0.4724],\n",
      "        [0.7228],\n",
      "        [0.8836]]) 0.33895277976989746\n",
      "2434 tensor([[0.2351],\n",
      "        [0.4723],\n",
      "        [0.7228],\n",
      "        [0.8837]]) 0.3388826549053192\n",
      "2435 tensor([[0.2350],\n",
      "        [0.4723],\n",
      "        [0.7228],\n",
      "        [0.8837]]) 0.3388124704360962\n",
      "2436 tensor([[0.2349],\n",
      "        [0.4722],\n",
      "        [0.7228],\n",
      "        [0.8838]]) 0.3387424051761627\n",
      "2437 tensor([[0.2348],\n",
      "        [0.4722],\n",
      "        [0.7229],\n",
      "        [0.8838]]) 0.33867231011390686\n",
      "2438 tensor([[0.2347],\n",
      "        [0.4721],\n",
      "        [0.7229],\n",
      "        [0.8838]]) 0.3386022448539734\n",
      "2439 tensor([[0.2346],\n",
      "        [0.4721],\n",
      "        [0.7229],\n",
      "        [0.8839]]) 0.3385322391986847\n",
      "2440 tensor([[0.2345],\n",
      "        [0.4720],\n",
      "        [0.7229],\n",
      "        [0.8839]]) 0.338462233543396\n",
      "2441 tensor([[0.2344],\n",
      "        [0.4720],\n",
      "        [0.7229],\n",
      "        [0.8839]]) 0.33839231729507446\n",
      "2442 tensor([[0.2344],\n",
      "        [0.4719],\n",
      "        [0.7230],\n",
      "        [0.8840]]) 0.3383224606513977\n",
      "2443 tensor([[0.2343],\n",
      "        [0.4719],\n",
      "        [0.7230],\n",
      "        [0.8840]]) 0.33825260400772095\n",
      "2444 tensor([[0.2342],\n",
      "        [0.4718],\n",
      "        [0.7230],\n",
      "        [0.8841]]) 0.3381827771663666\n",
      "2445 tensor([[0.2341],\n",
      "        [0.4718],\n",
      "        [0.7230],\n",
      "        [0.8841]]) 0.3381129801273346\n",
      "2446 tensor([[0.2340],\n",
      "        [0.4717],\n",
      "        [0.7230],\n",
      "        [0.8841]]) 0.338043212890625\n",
      "2447 tensor([[0.2339],\n",
      "        [0.4717],\n",
      "        [0.7231],\n",
      "        [0.8842]]) 0.3379734754562378\n",
      "2448 tensor([[0.2338],\n",
      "        [0.4716],\n",
      "        [0.7231],\n",
      "        [0.8842]]) 0.33790382742881775\n",
      "2449 tensor([[0.2337],\n",
      "        [0.4716],\n",
      "        [0.7231],\n",
      "        [0.8843]]) 0.3378341794013977\n",
      "2450 tensor([[0.2336],\n",
      "        [0.4715],\n",
      "        [0.7231],\n",
      "        [0.8843]]) 0.33776456117630005\n",
      "2451 tensor([[0.2336],\n",
      "        [0.4715],\n",
      "        [0.7231],\n",
      "        [0.8843]]) 0.33769491314888\n",
      "2452 tensor([[0.2335],\n",
      "        [0.4714],\n",
      "        [0.7231],\n",
      "        [0.8844]]) 0.3376254141330719\n",
      "2453 tensor([[0.2334],\n",
      "        [0.4714],\n",
      "        [0.7232],\n",
      "        [0.8844]]) 0.3375558853149414\n",
      "2454 tensor([[0.2333],\n",
      "        [0.4713],\n",
      "        [0.7232],\n",
      "        [0.8845]]) 0.3374863862991333\n",
      "2455 tensor([[0.2332],\n",
      "        [0.4713],\n",
      "        [0.7232],\n",
      "        [0.8845]]) 0.33741700649261475\n",
      "2456 tensor([[0.2331],\n",
      "        [0.4713],\n",
      "        [0.7232],\n",
      "        [0.8845]]) 0.3373475968837738\n",
      "2457 tensor([[0.2330],\n",
      "        [0.4712],\n",
      "        [0.7232],\n",
      "        [0.8846]]) 0.33727821707725525\n",
      "2458 tensor([[0.2329],\n",
      "        [0.4712],\n",
      "        [0.7233],\n",
      "        [0.8846]]) 0.3372088670730591\n",
      "2459 tensor([[0.2329],\n",
      "        [0.4711],\n",
      "        [0.7233],\n",
      "        [0.8847]]) 0.3371395766735077\n",
      "2460 tensor([[0.2328],\n",
      "        [0.4711],\n",
      "        [0.7233],\n",
      "        [0.8847]]) 0.3370703160762787\n",
      "2461 tensor([[0.2327],\n",
      "        [0.4710],\n",
      "        [0.7233],\n",
      "        [0.8847]]) 0.3370010256767273\n",
      "2462 tensor([[0.2326],\n",
      "        [0.4710],\n",
      "        [0.7233],\n",
      "        [0.8848]]) 0.3369317948818207\n",
      "2463 tensor([[0.2325],\n",
      "        [0.4709],\n",
      "        [0.7234],\n",
      "        [0.8848]]) 0.336862713098526\n",
      "2464 tensor([[0.2324],\n",
      "        [0.4709],\n",
      "        [0.7234],\n",
      "        [0.8849]]) 0.33679354190826416\n",
      "2465 tensor([[0.2323],\n",
      "        [0.4708],\n",
      "        [0.7234],\n",
      "        [0.8849]]) 0.3367244601249695\n",
      "2466 tensor([[0.2323],\n",
      "        [0.4708],\n",
      "        [0.7234],\n",
      "        [0.8849]]) 0.3366553783416748\n",
      "2467 tensor([[0.2322],\n",
      "        [0.4707],\n",
      "        [0.7234],\n",
      "        [0.8850]]) 0.3365863859653473\n",
      "2468 tensor([[0.2321],\n",
      "        [0.4707],\n",
      "        [0.7234],\n",
      "        [0.8850]]) 0.336517333984375\n",
      "2469 tensor([[0.2320],\n",
      "        [0.4706],\n",
      "        [0.7235],\n",
      "        [0.8851]]) 0.33644843101501465\n",
      "2470 tensor([[0.2319],\n",
      "        [0.4706],\n",
      "        [0.7235],\n",
      "        [0.8851]]) 0.3363794982433319\n",
      "2471 tensor([[0.2318],\n",
      "        [0.4705],\n",
      "        [0.7235],\n",
      "        [0.8851]]) 0.33631059527397156\n",
      "2472 tensor([[0.2317],\n",
      "        [0.4705],\n",
      "        [0.7235],\n",
      "        [0.8852]]) 0.3362417221069336\n",
      "2473 tensor([[0.2316],\n",
      "        [0.4704],\n",
      "        [0.7235],\n",
      "        [0.8852]]) 0.336172878742218\n",
      "2474 tensor([[0.2316],\n",
      "        [0.4704],\n",
      "        [0.7236],\n",
      "        [0.8852]]) 0.33610406517982483\n",
      "2475 tensor([[0.2315],\n",
      "        [0.4703],\n",
      "        [0.7236],\n",
      "        [0.8853]]) 0.3360353410243988\n",
      "2476 tensor([[0.2314],\n",
      "        [0.4703],\n",
      "        [0.7236],\n",
      "        [0.8853]]) 0.3359666168689728\n",
      "2477 tensor([[0.2313],\n",
      "        [0.4702],\n",
      "        [0.7236],\n",
      "        [0.8854]]) 0.3358979821205139\n",
      "2478 tensor([[0.2312],\n",
      "        [0.4702],\n",
      "        [0.7236],\n",
      "        [0.8854]]) 0.33582931756973267\n",
      "2479 tensor([[0.2311],\n",
      "        [0.4701],\n",
      "        [0.7237],\n",
      "        [0.8854]]) 0.3357607126235962\n",
      "2480 tensor([[0.2310],\n",
      "        [0.4701],\n",
      "        [0.7237],\n",
      "        [0.8855]]) 0.33569207787513733\n",
      "2481 tensor([[0.2310],\n",
      "        [0.4700],\n",
      "        [0.7237],\n",
      "        [0.8855]]) 0.335623562335968\n",
      "2482 tensor([[0.2309],\n",
      "        [0.4700],\n",
      "        [0.7237],\n",
      "        [0.8856]]) 0.3355550169944763\n",
      "2483 tensor([[0.2308],\n",
      "        [0.4699],\n",
      "        [0.7237],\n",
      "        [0.8856]]) 0.3354865610599518\n",
      "2484 tensor([[0.2307],\n",
      "        [0.4699],\n",
      "        [0.7237],\n",
      "        [0.8856]]) 0.33541810512542725\n",
      "2485 tensor([[0.2306],\n",
      "        [0.4698],\n",
      "        [0.7238],\n",
      "        [0.8857]]) 0.3353497087955475\n",
      "2486 tensor([[0.2305],\n",
      "        [0.4698],\n",
      "        [0.7238],\n",
      "        [0.8857]]) 0.3352813124656677\n",
      "2487 tensor([[0.2304],\n",
      "        [0.4697],\n",
      "        [0.7238],\n",
      "        [0.8858]]) 0.3352130055427551\n",
      "2488 tensor([[0.2303],\n",
      "        [0.4697],\n",
      "        [0.7238],\n",
      "        [0.8858]]) 0.33514469861984253\n",
      "2489 tensor([[0.2303],\n",
      "        [0.4696],\n",
      "        [0.7238],\n",
      "        [0.8858]]) 0.3350764214992523\n",
      "2490 tensor([[0.2302],\n",
      "        [0.4696],\n",
      "        [0.7239],\n",
      "        [0.8859]]) 0.3350081443786621\n",
      "2491 tensor([[0.2301],\n",
      "        [0.4695],\n",
      "        [0.7239],\n",
      "        [0.8859]]) 0.33493995666503906\n",
      "2492 tensor([[0.2300],\n",
      "        [0.4695],\n",
      "        [0.7239],\n",
      "        [0.8859]]) 0.334871768951416\n",
      "2493 tensor([[0.2299],\n",
      "        [0.4694],\n",
      "        [0.7239],\n",
      "        [0.8860]]) 0.33480361104011536\n",
      "2494 tensor([[0.2298],\n",
      "        [0.4694],\n",
      "        [0.7239],\n",
      "        [0.8860]]) 0.33473554253578186\n",
      "2495 tensor([[0.2297],\n",
      "        [0.4693],\n",
      "        [0.7240],\n",
      "        [0.8861]]) 0.334667444229126\n",
      "2496 tensor([[0.2297],\n",
      "        [0.4693],\n",
      "        [0.7240],\n",
      "        [0.8861]]) 0.33459946513175964\n",
      "2497 tensor([[0.2296],\n",
      "        [0.4692],\n",
      "        [0.7240],\n",
      "        [0.8861]]) 0.33453142642974854\n",
      "2498 tensor([[0.2295],\n",
      "        [0.4692],\n",
      "        [0.7240],\n",
      "        [0.8862]]) 0.3344634473323822\n",
      "2499 tensor([[0.2294],\n",
      "        [0.4691],\n",
      "        [0.7240],\n",
      "        [0.8862]]) 0.33439552783966064\n",
      "2500 tensor([[0.2293],\n",
      "        [0.4691],\n",
      "        [0.7240],\n",
      "        [0.8863]]) 0.3343275487422943\n",
      "2501 tensor([[0.2292],\n",
      "        [0.4690],\n",
      "        [0.7241],\n",
      "        [0.8863]]) 0.3342597186565399\n",
      "2502 tensor([[0.2291],\n",
      "        [0.4690],\n",
      "        [0.7241],\n",
      "        [0.8863]]) 0.33419185876846313\n",
      "2503 tensor([[0.2291],\n",
      "        [0.4690],\n",
      "        [0.7241],\n",
      "        [0.8864]]) 0.33412405848503113\n",
      "2504 tensor([[0.2290],\n",
      "        [0.4689],\n",
      "        [0.7241],\n",
      "        [0.8864]]) 0.3340562880039215\n",
      "2505 tensor([[0.2289],\n",
      "        [0.4689],\n",
      "        [0.7241],\n",
      "        [0.8864]]) 0.33398860692977905\n",
      "2506 tensor([[0.2288],\n",
      "        [0.4688],\n",
      "        [0.7242],\n",
      "        [0.8865]]) 0.3339208662509918\n",
      "2507 tensor([[0.2287],\n",
      "        [0.4688],\n",
      "        [0.7242],\n",
      "        [0.8865]]) 0.33385321497917175\n",
      "2508 tensor([[0.2286],\n",
      "        [0.4687],\n",
      "        [0.7242],\n",
      "        [0.8866]]) 0.3337855637073517\n",
      "2509 tensor([[0.2286],\n",
      "        [0.4687],\n",
      "        [0.7242],\n",
      "        [0.8866]]) 0.333717942237854\n",
      "2510 tensor([[0.2285],\n",
      "        [0.4686],\n",
      "        [0.7242],\n",
      "        [0.8866]]) 0.3336503505706787\n",
      "2511 tensor([[0.2284],\n",
      "        [0.4686],\n",
      "        [0.7243],\n",
      "        [0.8867]]) 0.3335827887058258\n",
      "2512 tensor([[0.2283],\n",
      "        [0.4685],\n",
      "        [0.7243],\n",
      "        [0.8867]]) 0.33351537585258484\n",
      "2513 tensor([[0.2282],\n",
      "        [0.4685],\n",
      "        [0.7243],\n",
      "        [0.8868]]) 0.3334479033946991\n",
      "2514 tensor([[0.2281],\n",
      "        [0.4684],\n",
      "        [0.7243],\n",
      "        [0.8868]]) 0.33338046073913574\n",
      "2515 tensor([[0.2280],\n",
      "        [0.4684],\n",
      "        [0.7243],\n",
      "        [0.8868]]) 0.3333130180835724\n",
      "2516 tensor([[0.2280],\n",
      "        [0.4683],\n",
      "        [0.7243],\n",
      "        [0.8869]]) 0.3332456350326538\n",
      "2517 tensor([[0.2279],\n",
      "        [0.4683],\n",
      "        [0.7244],\n",
      "        [0.8869]]) 0.3331782817840576\n",
      "2518 tensor([[0.2278],\n",
      "        [0.4682],\n",
      "        [0.7244],\n",
      "        [0.8869]]) 0.333111047744751\n",
      "2519 tensor([[0.2277],\n",
      "        [0.4682],\n",
      "        [0.7244],\n",
      "        [0.8870]]) 0.3330437242984772\n",
      "2520 tensor([[0.2276],\n",
      "        [0.4681],\n",
      "        [0.7244],\n",
      "        [0.8870]]) 0.33297649025917053\n",
      "2521 tensor([[0.2275],\n",
      "        [0.4681],\n",
      "        [0.7244],\n",
      "        [0.8871]]) 0.33290931582450867\n",
      "2522 tensor([[0.2274],\n",
      "        [0.4680],\n",
      "        [0.7245],\n",
      "        [0.8871]]) 0.3328421711921692\n",
      "2523 tensor([[0.2274],\n",
      "        [0.4680],\n",
      "        [0.7245],\n",
      "        [0.8871]]) 0.3327749967575073\n",
      "2524 tensor([[0.2273],\n",
      "        [0.4679],\n",
      "        [0.7245],\n",
      "        [0.8872]]) 0.33270785212516785\n",
      "2525 tensor([[0.2272],\n",
      "        [0.4679],\n",
      "        [0.7245],\n",
      "        [0.8872]]) 0.3326408565044403\n",
      "2526 tensor([[0.2271],\n",
      "        [0.4678],\n",
      "        [0.7245],\n",
      "        [0.8872]]) 0.3325737714767456\n",
      "2527 tensor([[0.2270],\n",
      "        [0.4678],\n",
      "        [0.7245],\n",
      "        [0.8873]]) 0.33250680565834045\n",
      "2528 tensor([[0.2269],\n",
      "        [0.4677],\n",
      "        [0.7246],\n",
      "        [0.8873]]) 0.3324398398399353\n",
      "2529 tensor([[0.2269],\n",
      "        [0.4677],\n",
      "        [0.7246],\n",
      "        [0.8874]]) 0.33237284421920776\n",
      "2530 tensor([[0.2268],\n",
      "        [0.4676],\n",
      "        [0.7246],\n",
      "        [0.8874]]) 0.3323059678077698\n",
      "2531 tensor([[0.2267],\n",
      "        [0.4676],\n",
      "        [0.7246],\n",
      "        [0.8874]]) 0.3322390913963318\n",
      "2532 tensor([[0.2266],\n",
      "        [0.4675],\n",
      "        [0.7246],\n",
      "        [0.8875]]) 0.3321722447872162\n",
      "2533 tensor([[0.2265],\n",
      "        [0.4675],\n",
      "        [0.7247],\n",
      "        [0.8875]]) 0.33210545778274536\n",
      "2534 tensor([[0.2264],\n",
      "        [0.4675],\n",
      "        [0.7247],\n",
      "        [0.8875]]) 0.33203867077827454\n",
      "2535 tensor([[0.2264],\n",
      "        [0.4674],\n",
      "        [0.7247],\n",
      "        [0.8876]]) 0.3319719135761261\n",
      "2536 tensor([[0.2263],\n",
      "        [0.4674],\n",
      "        [0.7247],\n",
      "        [0.8876]]) 0.33190521597862244\n",
      "2537 tensor([[0.2262],\n",
      "        [0.4673],\n",
      "        [0.7247],\n",
      "        [0.8877]]) 0.3318385183811188\n",
      "2538 tensor([[0.2261],\n",
      "        [0.4673],\n",
      "        [0.7248],\n",
      "        [0.8877]]) 0.3317718803882599\n",
      "2539 tensor([[0.2260],\n",
      "        [0.4672],\n",
      "        [0.7248],\n",
      "        [0.8877]]) 0.3317053020000458\n",
      "2540 tensor([[0.2259],\n",
      "        [0.4672],\n",
      "        [0.7248],\n",
      "        [0.8878]]) 0.3316386938095093\n",
      "2541 tensor([[0.2259],\n",
      "        [0.4671],\n",
      "        [0.7248],\n",
      "        [0.8878]]) 0.33157217502593994\n",
      "2542 tensor([[0.2258],\n",
      "        [0.4671],\n",
      "        [0.7248],\n",
      "        [0.8879]]) 0.3315056562423706\n",
      "2543 tensor([[0.2257],\n",
      "        [0.4670],\n",
      "        [0.7248],\n",
      "        [0.8879]]) 0.33143919706344604\n",
      "2544 tensor([[0.2256],\n",
      "        [0.4670],\n",
      "        [0.7249],\n",
      "        [0.8879]]) 0.3313727378845215\n",
      "2545 tensor([[0.2255],\n",
      "        [0.4669],\n",
      "        [0.7249],\n",
      "        [0.8880]]) 0.3313062787055969\n",
      "2546 tensor([[0.2254],\n",
      "        [0.4669],\n",
      "        [0.7249],\n",
      "        [0.8880]]) 0.3312399089336395\n",
      "2547 tensor([[0.2254],\n",
      "        [0.4668],\n",
      "        [0.7249],\n",
      "        [0.8880]]) 0.3311735689640045\n",
      "2548 tensor([[0.2253],\n",
      "        [0.4668],\n",
      "        [0.7249],\n",
      "        [0.8881]]) 0.3311072885990143\n",
      "2549 tensor([[0.2252],\n",
      "        [0.4667],\n",
      "        [0.7250],\n",
      "        [0.8881]]) 0.33104097843170166\n",
      "2550 tensor([[0.2251],\n",
      "        [0.4667],\n",
      "        [0.7250],\n",
      "        [0.8882]]) 0.3309747278690338\n",
      "2551 tensor([[0.2250],\n",
      "        [0.4666],\n",
      "        [0.7250],\n",
      "        [0.8882]]) 0.3309084475040436\n",
      "2552 tensor([[0.2249],\n",
      "        [0.4666],\n",
      "        [0.7250],\n",
      "        [0.8882]]) 0.3308423161506653\n",
      "2553 tensor([[0.2249],\n",
      "        [0.4665],\n",
      "        [0.7250],\n",
      "        [0.8883]]) 0.3307760953903198\n",
      "2554 tensor([[0.2248],\n",
      "        [0.4665],\n",
      "        [0.7250],\n",
      "        [0.8883]]) 0.3307100236415863\n",
      "2555 tensor([[0.2247],\n",
      "        [0.4664],\n",
      "        [0.7251],\n",
      "        [0.8883]]) 0.3306439518928528\n",
      "2556 tensor([[0.2246],\n",
      "        [0.4664],\n",
      "        [0.7251],\n",
      "        [0.8884]]) 0.33057788014411926\n",
      "2557 tensor([[0.2245],\n",
      "        [0.4664],\n",
      "        [0.7251],\n",
      "        [0.8884]]) 0.33051183819770813\n",
      "2558 tensor([[0.2244],\n",
      "        [0.4663],\n",
      "        [0.7251],\n",
      "        [0.8885]]) 0.3304458260536194\n",
      "2559 tensor([[0.2244],\n",
      "        [0.4663],\n",
      "        [0.7251],\n",
      "        [0.8885]]) 0.3303799033164978\n",
      "2560 tensor([[0.2243],\n",
      "        [0.4662],\n",
      "        [0.7252],\n",
      "        [0.8885]]) 0.3303139805793762\n",
      "2561 tensor([[0.2242],\n",
      "        [0.4662],\n",
      "        [0.7252],\n",
      "        [0.8886]]) 0.33024802803993225\n",
      "2562 tensor([[0.2241],\n",
      "        [0.4661],\n",
      "        [0.7252],\n",
      "        [0.8886]]) 0.33018216490745544\n",
      "2563 tensor([[0.2240],\n",
      "        [0.4661],\n",
      "        [0.7252],\n",
      "        [0.8886]]) 0.330116331577301\n",
      "2564 tensor([[0.2239],\n",
      "        [0.4660],\n",
      "        [0.7252],\n",
      "        [0.8887]]) 0.33005058765411377\n",
      "2565 tensor([[0.2239],\n",
      "        [0.4660],\n",
      "        [0.7253],\n",
      "        [0.8887]]) 0.32998475432395935\n",
      "2566 tensor([[0.2238],\n",
      "        [0.4659],\n",
      "        [0.7253],\n",
      "        [0.8887]]) 0.32991909980773926\n",
      "2567 tensor([[0.2237],\n",
      "        [0.4659],\n",
      "        [0.7253],\n",
      "        [0.8888]]) 0.329853355884552\n",
      "2568 tensor([[0.2236],\n",
      "        [0.4658],\n",
      "        [0.7253],\n",
      "        [0.8888]]) 0.3297876715660095\n",
      "2569 tensor([[0.2235],\n",
      "        [0.4658],\n",
      "        [0.7253],\n",
      "        [0.8889]]) 0.3297220468521118\n",
      "2570 tensor([[0.2234],\n",
      "        [0.4657],\n",
      "        [0.7253],\n",
      "        [0.8889]]) 0.3296564519405365\n",
      "2571 tensor([[0.2234],\n",
      "        [0.4657],\n",
      "        [0.7254],\n",
      "        [0.8889]]) 0.3295908570289612\n",
      "2572 tensor([[0.2233],\n",
      "        [0.4656],\n",
      "        [0.7254],\n",
      "        [0.8890]]) 0.32952529191970825\n",
      "2573 tensor([[0.2232],\n",
      "        [0.4656],\n",
      "        [0.7254],\n",
      "        [0.8890]]) 0.3294598162174225\n",
      "2574 tensor([[0.2231],\n",
      "        [0.4655],\n",
      "        [0.7254],\n",
      "        [0.8890]]) 0.32939428091049194\n",
      "2575 tensor([[0.2230],\n",
      "        [0.4655],\n",
      "        [0.7254],\n",
      "        [0.8891]]) 0.3293288052082062\n",
      "2576 tensor([[0.2230],\n",
      "        [0.4654],\n",
      "        [0.7255],\n",
      "        [0.8891]]) 0.3292634189128876\n",
      "2577 tensor([[0.2229],\n",
      "        [0.4654],\n",
      "        [0.7255],\n",
      "        [0.8892]]) 0.3291980028152466\n",
      "2578 tensor([[0.2228],\n",
      "        [0.4654],\n",
      "        [0.7255],\n",
      "        [0.8892]]) 0.32913270592689514\n",
      "2579 tensor([[0.2227],\n",
      "        [0.4653],\n",
      "        [0.7255],\n",
      "        [0.8892]]) 0.3290673494338989\n",
      "2580 tensor([[0.2226],\n",
      "        [0.4653],\n",
      "        [0.7255],\n",
      "        [0.8893]]) 0.3290020823478699\n",
      "2581 tensor([[0.2225],\n",
      "        [0.4652],\n",
      "        [0.7255],\n",
      "        [0.8893]]) 0.3289368152618408\n",
      "2582 tensor([[0.2225],\n",
      "        [0.4652],\n",
      "        [0.7256],\n",
      "        [0.8893]]) 0.32887154817581177\n",
      "2583 tensor([[0.2224],\n",
      "        [0.4651],\n",
      "        [0.7256],\n",
      "        [0.8894]]) 0.3288063406944275\n",
      "2584 tensor([[0.2223],\n",
      "        [0.4651],\n",
      "        [0.7256],\n",
      "        [0.8894]]) 0.3287412226200104\n",
      "2585 tensor([[0.2222],\n",
      "        [0.4650],\n",
      "        [0.7256],\n",
      "        [0.8895]]) 0.32867610454559326\n",
      "2586 tensor([[0.2221],\n",
      "        [0.4650],\n",
      "        [0.7256],\n",
      "        [0.8895]]) 0.32861095666885376\n",
      "2587 tensor([[0.2220],\n",
      "        [0.4649],\n",
      "        [0.7257],\n",
      "        [0.8895]]) 0.3285459280014038\n",
      "2588 tensor([[0.2220],\n",
      "        [0.4649],\n",
      "        [0.7257],\n",
      "        [0.8896]]) 0.32848086953163147\n",
      "2589 tensor([[0.2219],\n",
      "        [0.4648],\n",
      "        [0.7257],\n",
      "        [0.8896]]) 0.3284158706665039\n",
      "2590 tensor([[0.2218],\n",
      "        [0.4648],\n",
      "        [0.7257],\n",
      "        [0.8896]]) 0.32835090160369873\n",
      "2591 tensor([[0.2217],\n",
      "        [0.4647],\n",
      "        [0.7257],\n",
      "        [0.8897]]) 0.32828596234321594\n",
      "2592 tensor([[0.2216],\n",
      "        [0.4647],\n",
      "        [0.7257],\n",
      "        [0.8897]]) 0.32822102308273315\n",
      "2593 tensor([[0.2216],\n",
      "        [0.4646],\n",
      "        [0.7258],\n",
      "        [0.8897]]) 0.32815614342689514\n",
      "2594 tensor([[0.2215],\n",
      "        [0.4646],\n",
      "        [0.7258],\n",
      "        [0.8898]]) 0.3280912935733795\n",
      "2595 tensor([[0.2214],\n",
      "        [0.4645],\n",
      "        [0.7258],\n",
      "        [0.8898]]) 0.32802650332450867\n",
      "2596 tensor([[0.2213],\n",
      "        [0.4645],\n",
      "        [0.7258],\n",
      "        [0.8899]]) 0.3279617428779602\n",
      "2597 tensor([[0.2212],\n",
      "        [0.4645],\n",
      "        [0.7258],\n",
      "        [0.8899]]) 0.32789695262908936\n",
      "2598 tensor([[0.2212],\n",
      "        [0.4644],\n",
      "        [0.7259],\n",
      "        [0.8899]]) 0.3278322219848633\n",
      "2599 tensor([[0.2211],\n",
      "        [0.4644],\n",
      "        [0.7259],\n",
      "        [0.8900]]) 0.32776758074760437\n",
      "2600 tensor([[0.2210],\n",
      "        [0.4643],\n",
      "        [0.7259],\n",
      "        [0.8900]]) 0.3277028799057007\n",
      "2601 tensor([[0.2209],\n",
      "        [0.4643],\n",
      "        [0.7259],\n",
      "        [0.8900]]) 0.32763826847076416\n",
      "2602 tensor([[0.2208],\n",
      "        [0.4642],\n",
      "        [0.7259],\n",
      "        [0.8901]]) 0.32757362723350525\n",
      "2603 tensor([[0.2207],\n",
      "        [0.4642],\n",
      "        [0.7260],\n",
      "        [0.8901]]) 0.3275090754032135\n",
      "2604 tensor([[0.2207],\n",
      "        [0.4641],\n",
      "        [0.7260],\n",
      "        [0.8902]]) 0.32744455337524414\n",
      "2605 tensor([[0.2206],\n",
      "        [0.4641],\n",
      "        [0.7260],\n",
      "        [0.8902]]) 0.32738006114959717\n",
      "2606 tensor([[0.2205],\n",
      "        [0.4640],\n",
      "        [0.7260],\n",
      "        [0.8902]]) 0.3273155689239502\n",
      "2607 tensor([[0.2204],\n",
      "        [0.4640],\n",
      "        [0.7260],\n",
      "        [0.8903]]) 0.327251136302948\n",
      "2608 tensor([[0.2203],\n",
      "        [0.4639],\n",
      "        [0.7260],\n",
      "        [0.8903]]) 0.3271867334842682\n",
      "2609 tensor([[0.2203],\n",
      "        [0.4639],\n",
      "        [0.7261],\n",
      "        [0.8903]]) 0.32712236046791077\n",
      "2610 tensor([[0.2202],\n",
      "        [0.4638],\n",
      "        [0.7261],\n",
      "        [0.8904]]) 0.32705798745155334\n",
      "2611 tensor([[0.2201],\n",
      "        [0.4638],\n",
      "        [0.7261],\n",
      "        [0.8904]]) 0.3269937038421631\n",
      "2612 tensor([[0.2200],\n",
      "        [0.4637],\n",
      "        [0.7261],\n",
      "        [0.8904]]) 0.32692939043045044\n",
      "2613 tensor([[0.2199],\n",
      "        [0.4637],\n",
      "        [0.7261],\n",
      "        [0.8905]]) 0.32686513662338257\n",
      "2614 tensor([[0.2199],\n",
      "        [0.4637],\n",
      "        [0.7262],\n",
      "        [0.8905]]) 0.3268009126186371\n",
      "2615 tensor([[0.2198],\n",
      "        [0.4636],\n",
      "        [0.7262],\n",
      "        [0.8906]]) 0.3267366886138916\n",
      "2616 tensor([[0.2197],\n",
      "        [0.4636],\n",
      "        [0.7262],\n",
      "        [0.8906]]) 0.3266725540161133\n",
      "2617 tensor([[0.2196],\n",
      "        [0.4635],\n",
      "        [0.7262],\n",
      "        [0.8906]]) 0.3266083896160126\n",
      "2618 tensor([[0.2195],\n",
      "        [0.4635],\n",
      "        [0.7262],\n",
      "        [0.8907]]) 0.3265443444252014\n",
      "2619 tensor([[0.2195],\n",
      "        [0.4634],\n",
      "        [0.7262],\n",
      "        [0.8907]]) 0.3264802098274231\n",
      "2620 tensor([[0.2194],\n",
      "        [0.4634],\n",
      "        [0.7263],\n",
      "        [0.8907]]) 0.3264161944389343\n",
      "2621 tensor([[0.2193],\n",
      "        [0.4633],\n",
      "        [0.7263],\n",
      "        [0.8908]]) 0.32635217905044556\n",
      "2622 tensor([[0.2192],\n",
      "        [0.4633],\n",
      "        [0.7263],\n",
      "        [0.8908]]) 0.32628822326660156\n",
      "2623 tensor([[0.2191],\n",
      "        [0.4632],\n",
      "        [0.7263],\n",
      "        [0.8908]]) 0.32622429728507996\n",
      "2624 tensor([[0.2191],\n",
      "        [0.4632],\n",
      "        [0.7263],\n",
      "        [0.8909]]) 0.32616037130355835\n",
      "2625 tensor([[0.2190],\n",
      "        [0.4631],\n",
      "        [0.7264],\n",
      "        [0.8909]]) 0.32609647512435913\n",
      "2626 tensor([[0.2189],\n",
      "        [0.4631],\n",
      "        [0.7264],\n",
      "        [0.8910]]) 0.3260326385498047\n",
      "2627 tensor([[0.2188],\n",
      "        [0.4630],\n",
      "        [0.7264],\n",
      "        [0.8910]]) 0.32596877217292786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2628 tensor([[0.2187],\n",
      "        [0.4630],\n",
      "        [0.7264],\n",
      "        [0.8910]]) 0.3259049952030182\n",
      "2629 tensor([[0.2187],\n",
      "        [0.4629],\n",
      "        [0.7264],\n",
      "        [0.8911]]) 0.3258412480354309\n",
      "2630 tensor([[0.2186],\n",
      "        [0.4629],\n",
      "        [0.7264],\n",
      "        [0.8911]]) 0.32577750086784363\n",
      "2631 tensor([[0.2185],\n",
      "        [0.4629],\n",
      "        [0.7265],\n",
      "        [0.8911]]) 0.3257138133049011\n",
      "2632 tensor([[0.2184],\n",
      "        [0.4628],\n",
      "        [0.7265],\n",
      "        [0.8912]]) 0.325650155544281\n",
      "2633 tensor([[0.2183],\n",
      "        [0.4628],\n",
      "        [0.7265],\n",
      "        [0.8912]]) 0.3255864977836609\n",
      "2634 tensor([[0.2183],\n",
      "        [0.4627],\n",
      "        [0.7265],\n",
      "        [0.8912]]) 0.32552286982536316\n",
      "2635 tensor([[0.2182],\n",
      "        [0.4627],\n",
      "        [0.7265],\n",
      "        [0.8913]]) 0.3254593312740326\n",
      "2636 tensor([[0.2181],\n",
      "        [0.4626],\n",
      "        [0.7266],\n",
      "        [0.8913]]) 0.32539576292037964\n",
      "2637 tensor([[0.2180],\n",
      "        [0.4626],\n",
      "        [0.7266],\n",
      "        [0.8913]]) 0.32533225417137146\n",
      "2638 tensor([[0.2179],\n",
      "        [0.4625],\n",
      "        [0.7266],\n",
      "        [0.8914]]) 0.32526877522468567\n",
      "2639 tensor([[0.2179],\n",
      "        [0.4625],\n",
      "        [0.7266],\n",
      "        [0.8914]]) 0.3252052962779999\n",
      "2640 tensor([[0.2178],\n",
      "        [0.4624],\n",
      "        [0.7266],\n",
      "        [0.8915]]) 0.32514187693595886\n",
      "2641 tensor([[0.2177],\n",
      "        [0.4624],\n",
      "        [0.7266],\n",
      "        [0.8915]]) 0.32507845759391785\n",
      "2642 tensor([[0.2176],\n",
      "        [0.4623],\n",
      "        [0.7267],\n",
      "        [0.8915]]) 0.3250150680541992\n",
      "2643 tensor([[0.2175],\n",
      "        [0.4623],\n",
      "        [0.7267],\n",
      "        [0.8916]]) 0.32495179772377014\n",
      "2644 tensor([[0.2175],\n",
      "        [0.4622],\n",
      "        [0.7267],\n",
      "        [0.8916]]) 0.3248884975910187\n",
      "2645 tensor([[0.2174],\n",
      "        [0.4622],\n",
      "        [0.7267],\n",
      "        [0.8916]]) 0.3248251676559448\n",
      "2646 tensor([[0.2173],\n",
      "        [0.4622],\n",
      "        [0.7267],\n",
      "        [0.8917]]) 0.3247619569301605\n",
      "2647 tensor([[0.2172],\n",
      "        [0.4621],\n",
      "        [0.7268],\n",
      "        [0.8917]]) 0.32469871640205383\n",
      "2648 tensor([[0.2171],\n",
      "        [0.4621],\n",
      "        [0.7268],\n",
      "        [0.8917]]) 0.3246355652809143\n",
      "2649 tensor([[0.2171],\n",
      "        [0.4620],\n",
      "        [0.7268],\n",
      "        [0.8918]]) 0.3245723843574524\n",
      "2650 tensor([[0.2170],\n",
      "        [0.4620],\n",
      "        [0.7268],\n",
      "        [0.8918]]) 0.32450929284095764\n",
      "2651 tensor([[0.2169],\n",
      "        [0.4619],\n",
      "        [0.7268],\n",
      "        [0.8918]]) 0.3244462013244629\n",
      "2652 tensor([[0.2168],\n",
      "        [0.4619],\n",
      "        [0.7268],\n",
      "        [0.8919]]) 0.3243831396102905\n",
      "2653 tensor([[0.2167],\n",
      "        [0.4618],\n",
      "        [0.7269],\n",
      "        [0.8919]]) 0.32432007789611816\n",
      "2654 tensor([[0.2167],\n",
      "        [0.4618],\n",
      "        [0.7269],\n",
      "        [0.8920]]) 0.32425710558891296\n",
      "2655 tensor([[0.2166],\n",
      "        [0.4617],\n",
      "        [0.7269],\n",
      "        [0.8920]]) 0.32419413328170776\n",
      "2656 tensor([[0.2165],\n",
      "        [0.4617],\n",
      "        [0.7269],\n",
      "        [0.8920]]) 0.3241311311721802\n",
      "2657 tensor([[0.2164],\n",
      "        [0.4616],\n",
      "        [0.7269],\n",
      "        [0.8921]]) 0.32406821846961975\n",
      "2658 tensor([[0.2164],\n",
      "        [0.4616],\n",
      "        [0.7270],\n",
      "        [0.8921]]) 0.3240053951740265\n",
      "2659 tensor([[0.2163],\n",
      "        [0.4616],\n",
      "        [0.7270],\n",
      "        [0.8921]]) 0.32394254207611084\n",
      "2660 tensor([[0.2162],\n",
      "        [0.4615],\n",
      "        [0.7270],\n",
      "        [0.8922]]) 0.3238796591758728\n",
      "2661 tensor([[0.2161],\n",
      "        [0.4615],\n",
      "        [0.7270],\n",
      "        [0.8922]]) 0.32381686568260193\n",
      "2662 tensor([[0.2160],\n",
      "        [0.4614],\n",
      "        [0.7270],\n",
      "        [0.8922]]) 0.32375413179397583\n",
      "2663 tensor([[0.2160],\n",
      "        [0.4614],\n",
      "        [0.7270],\n",
      "        [0.8923]]) 0.32369136810302734\n",
      "2664 tensor([[0.2159],\n",
      "        [0.4613],\n",
      "        [0.7271],\n",
      "        [0.8923]]) 0.323628693819046\n",
      "2665 tensor([[0.2158],\n",
      "        [0.4613],\n",
      "        [0.7271],\n",
      "        [0.8923]]) 0.3235659599304199\n",
      "2666 tensor([[0.2157],\n",
      "        [0.4612],\n",
      "        [0.7271],\n",
      "        [0.8924]]) 0.32350337505340576\n",
      "2667 tensor([[0.2156],\n",
      "        [0.4612],\n",
      "        [0.7271],\n",
      "        [0.8924]]) 0.323440819978714\n",
      "2668 tensor([[0.2156],\n",
      "        [0.4611],\n",
      "        [0.7271],\n",
      "        [0.8925]]) 0.32337817549705505\n",
      "2669 tensor([[0.2155],\n",
      "        [0.4611],\n",
      "        [0.7272],\n",
      "        [0.8925]]) 0.3233155608177185\n",
      "2670 tensor([[0.2154],\n",
      "        [0.4610],\n",
      "        [0.7272],\n",
      "        [0.8925]]) 0.3232530951499939\n",
      "2671 tensor([[0.2153],\n",
      "        [0.4610],\n",
      "        [0.7272],\n",
      "        [0.8926]]) 0.3231906294822693\n",
      "2672 tensor([[0.2153],\n",
      "        [0.4610],\n",
      "        [0.7272],\n",
      "        [0.8926]]) 0.3231281042098999\n",
      "2673 tensor([[0.2152],\n",
      "        [0.4609],\n",
      "        [0.7272],\n",
      "        [0.8926]]) 0.32306569814682007\n",
      "2674 tensor([[0.2151],\n",
      "        [0.4609],\n",
      "        [0.7272],\n",
      "        [0.8927]]) 0.3230033218860626\n",
      "2675 tensor([[0.2150],\n",
      "        [0.4608],\n",
      "        [0.7273],\n",
      "        [0.8927]]) 0.3229408860206604\n",
      "2676 tensor([[0.2149],\n",
      "        [0.4608],\n",
      "        [0.7273],\n",
      "        [0.8927]]) 0.32287856936454773\n",
      "2677 tensor([[0.2149],\n",
      "        [0.4607],\n",
      "        [0.7273],\n",
      "        [0.8928]]) 0.32281622290611267\n",
      "2678 tensor([[0.2148],\n",
      "        [0.4607],\n",
      "        [0.7273],\n",
      "        [0.8928]]) 0.32275399565696716\n",
      "2679 tensor([[0.2147],\n",
      "        [0.4606],\n",
      "        [0.7273],\n",
      "        [0.8928]]) 0.32269173860549927\n",
      "2680 tensor([[0.2146],\n",
      "        [0.4606],\n",
      "        [0.7274],\n",
      "        [0.8929]]) 0.32262948155403137\n",
      "2681 tensor([[0.2146],\n",
      "        [0.4605],\n",
      "        [0.7274],\n",
      "        [0.8929]]) 0.32256731390953064\n",
      "2682 tensor([[0.2145],\n",
      "        [0.4605],\n",
      "        [0.7274],\n",
      "        [0.8929]]) 0.32250508666038513\n",
      "2683 tensor([[0.2144],\n",
      "        [0.4604],\n",
      "        [0.7274],\n",
      "        [0.8930]]) 0.32244300842285156\n",
      "2684 tensor([[0.2143],\n",
      "        [0.4604],\n",
      "        [0.7274],\n",
      "        [0.8930]]) 0.322380930185318\n",
      "2685 tensor([[0.2142],\n",
      "        [0.4604],\n",
      "        [0.7274],\n",
      "        [0.8931]]) 0.32231879234313965\n",
      "2686 tensor([[0.2142],\n",
      "        [0.4603],\n",
      "        [0.7275],\n",
      "        [0.8931]]) 0.32225674390792847\n",
      "2687 tensor([[0.2141],\n",
      "        [0.4603],\n",
      "        [0.7275],\n",
      "        [0.8931]]) 0.32219481468200684\n",
      "2688 tensor([[0.2140],\n",
      "        [0.4602],\n",
      "        [0.7275],\n",
      "        [0.8932]]) 0.3221327066421509\n",
      "2689 tensor([[0.2139],\n",
      "        [0.4602],\n",
      "        [0.7275],\n",
      "        [0.8932]]) 0.32207077741622925\n",
      "2690 tensor([[0.2139],\n",
      "        [0.4601],\n",
      "        [0.7275],\n",
      "        [0.8932]]) 0.32200887799263\n",
      "2691 tensor([[0.2138],\n",
      "        [0.4601],\n",
      "        [0.7276],\n",
      "        [0.8933]]) 0.321946918964386\n",
      "2692 tensor([[0.2137],\n",
      "        [0.4600],\n",
      "        [0.7276],\n",
      "        [0.8933]]) 0.3218850791454315\n",
      "2693 tensor([[0.2136],\n",
      "        [0.4600],\n",
      "        [0.7276],\n",
      "        [0.8933]]) 0.32182323932647705\n",
      "2694 tensor([[0.2135],\n",
      "        [0.4599],\n",
      "        [0.7276],\n",
      "        [0.8934]]) 0.3217613697052002\n",
      "2695 tensor([[0.2135],\n",
      "        [0.4599],\n",
      "        [0.7276],\n",
      "        [0.8934]]) 0.3216996192932129\n",
      "2696 tensor([[0.2134],\n",
      "        [0.4598],\n",
      "        [0.7276],\n",
      "        [0.8934]]) 0.3216378390789032\n",
      "2697 tensor([[0.2133],\n",
      "        [0.4598],\n",
      "        [0.7277],\n",
      "        [0.8935]]) 0.3215760886669159\n",
      "2698 tensor([[0.2132],\n",
      "        [0.4598],\n",
      "        [0.7277],\n",
      "        [0.8935]]) 0.32151445746421814\n",
      "2699 tensor([[0.2132],\n",
      "        [0.4597],\n",
      "        [0.7277],\n",
      "        [0.8935]]) 0.321452796459198\n",
      "2700 tensor([[0.2131],\n",
      "        [0.4597],\n",
      "        [0.7277],\n",
      "        [0.8936]]) 0.32139110565185547\n",
      "2701 tensor([[0.2130],\n",
      "        [0.4596],\n",
      "        [0.7277],\n",
      "        [0.8936]]) 0.3213295340538025\n",
      "2702 tensor([[0.2129],\n",
      "        [0.4596],\n",
      "        [0.7277],\n",
      "        [0.8936]]) 0.3212679326534271\n",
      "2703 tensor([[0.2129],\n",
      "        [0.4595],\n",
      "        [0.7278],\n",
      "        [0.8937]]) 0.32120633125305176\n",
      "2704 tensor([[0.2128],\n",
      "        [0.4595],\n",
      "        [0.7278],\n",
      "        [0.8937]]) 0.32114481925964355\n",
      "2705 tensor([[0.2127],\n",
      "        [0.4594],\n",
      "        [0.7278],\n",
      "        [0.8938]]) 0.3210833966732025\n",
      "2706 tensor([[0.2126],\n",
      "        [0.4594],\n",
      "        [0.7278],\n",
      "        [0.8938]]) 0.3210218846797943\n",
      "2707 tensor([[0.2125],\n",
      "        [0.4593],\n",
      "        [0.7278],\n",
      "        [0.8938]]) 0.32096049189567566\n",
      "2708 tensor([[0.2125],\n",
      "        [0.4593],\n",
      "        [0.7279],\n",
      "        [0.8939]]) 0.32089903950691223\n",
      "2709 tensor([[0.2124],\n",
      "        [0.4593],\n",
      "        [0.7279],\n",
      "        [0.8939]]) 0.32083773612976074\n",
      "2710 tensor([[0.2123],\n",
      "        [0.4592],\n",
      "        [0.7279],\n",
      "        [0.8939]]) 0.3207763135433197\n",
      "2711 tensor([[0.2122],\n",
      "        [0.4592],\n",
      "        [0.7279],\n",
      "        [0.8940]]) 0.3207150101661682\n",
      "2712 tensor([[0.2122],\n",
      "        [0.4591],\n",
      "        [0.7279],\n",
      "        [0.8940]]) 0.32065367698669434\n",
      "2713 tensor([[0.2121],\n",
      "        [0.4591],\n",
      "        [0.7279],\n",
      "        [0.8940]]) 0.3205924332141876\n",
      "2714 tensor([[0.2120],\n",
      "        [0.4590],\n",
      "        [0.7280],\n",
      "        [0.8941]]) 0.3205311894416809\n",
      "2715 tensor([[0.2119],\n",
      "        [0.4590],\n",
      "        [0.7280],\n",
      "        [0.8941]]) 0.32047000527381897\n",
      "2716 tensor([[0.2119],\n",
      "        [0.4589],\n",
      "        [0.7280],\n",
      "        [0.8941]]) 0.32040879130363464\n",
      "2717 tensor([[0.2118],\n",
      "        [0.4589],\n",
      "        [0.7280],\n",
      "        [0.8942]]) 0.32034769654273987\n",
      "2718 tensor([[0.2117],\n",
      "        [0.4588],\n",
      "        [0.7280],\n",
      "        [0.8942]]) 0.3202865421772003\n",
      "2719 tensor([[0.2116],\n",
      "        [0.4588],\n",
      "        [0.7281],\n",
      "        [0.8942]]) 0.3202255070209503\n",
      "2720 tensor([[0.2115],\n",
      "        [0.4587],\n",
      "        [0.7281],\n",
      "        [0.8943]]) 0.32016444206237793\n",
      "2721 tensor([[0.2115],\n",
      "        [0.4587],\n",
      "        [0.7281],\n",
      "        [0.8943]]) 0.32010334730148315\n",
      "2722 tensor([[0.2114],\n",
      "        [0.4587],\n",
      "        [0.7281],\n",
      "        [0.8943]]) 0.32004237174987793\n",
      "2723 tensor([[0.2113],\n",
      "        [0.4586],\n",
      "        [0.7281],\n",
      "        [0.8944]]) 0.3199813961982727\n",
      "2724 tensor([[0.2112],\n",
      "        [0.4586],\n",
      "        [0.7281],\n",
      "        [0.8944]]) 0.31992045044898987\n",
      "2725 tensor([[0.2112],\n",
      "        [0.4585],\n",
      "        [0.7282],\n",
      "        [0.8944]]) 0.3198595643043518\n",
      "2726 tensor([[0.2111],\n",
      "        [0.4585],\n",
      "        [0.7282],\n",
      "        [0.8945]]) 0.31979867815971375\n",
      "2727 tensor([[0.2110],\n",
      "        [0.4584],\n",
      "        [0.7282],\n",
      "        [0.8945]]) 0.3197377622127533\n",
      "2728 tensor([[0.2109],\n",
      "        [0.4584],\n",
      "        [0.7282],\n",
      "        [0.8945]]) 0.3196769952774048\n",
      "2729 tensor([[0.2109],\n",
      "        [0.4583],\n",
      "        [0.7282],\n",
      "        [0.8946]]) 0.3196161985397339\n",
      "2730 tensor([[0.2108],\n",
      "        [0.4583],\n",
      "        [0.7283],\n",
      "        [0.8946]]) 0.3195554316043854\n",
      "2731 tensor([[0.2107],\n",
      "        [0.4582],\n",
      "        [0.7283],\n",
      "        [0.8946]]) 0.31949466466903687\n",
      "2732 tensor([[0.2106],\n",
      "        [0.4582],\n",
      "        [0.7283],\n",
      "        [0.8947]]) 0.31943389773368835\n",
      "2733 tensor([[0.2106],\n",
      "        [0.4582],\n",
      "        [0.7283],\n",
      "        [0.8947]]) 0.3193732500076294\n",
      "2734 tensor([[0.2105],\n",
      "        [0.4581],\n",
      "        [0.7283],\n",
      "        [0.8948]]) 0.31931257247924805\n",
      "2735 tensor([[0.2104],\n",
      "        [0.4581],\n",
      "        [0.7283],\n",
      "        [0.8948]]) 0.31925198435783386\n",
      "2736 tensor([[0.2103],\n",
      "        [0.4580],\n",
      "        [0.7284],\n",
      "        [0.8948]]) 0.3191913664340973\n",
      "2737 tensor([[0.2103],\n",
      "        [0.4580],\n",
      "        [0.7284],\n",
      "        [0.8949]]) 0.3191308081150055\n",
      "2738 tensor([[0.2102],\n",
      "        [0.4579],\n",
      "        [0.7284],\n",
      "        [0.8949]]) 0.3190702795982361\n",
      "2739 tensor([[0.2101],\n",
      "        [0.4579],\n",
      "        [0.7284],\n",
      "        [0.8949]]) 0.3190096914768219\n",
      "2740 tensor([[0.2100],\n",
      "        [0.4578],\n",
      "        [0.7284],\n",
      "        [0.8950]]) 0.31894922256469727\n",
      "2741 tensor([[0.2100],\n",
      "        [0.4578],\n",
      "        [0.7285],\n",
      "        [0.8950]]) 0.3188888132572174\n",
      "2742 tensor([[0.2099],\n",
      "        [0.4578],\n",
      "        [0.7285],\n",
      "        [0.8950]]) 0.31882837414741516\n",
      "2743 tensor([[0.2098],\n",
      "        [0.4577],\n",
      "        [0.7285],\n",
      "        [0.8951]]) 0.3187679350376129\n",
      "2744 tensor([[0.2097],\n",
      "        [0.4577],\n",
      "        [0.7285],\n",
      "        [0.8951]]) 0.31870758533477783\n",
      "2745 tensor([[0.2097],\n",
      "        [0.4576],\n",
      "        [0.7285],\n",
      "        [0.8951]]) 0.31864723563194275\n",
      "2746 tensor([[0.2096],\n",
      "        [0.4576],\n",
      "        [0.7285],\n",
      "        [0.8952]]) 0.31858688592910767\n",
      "2747 tensor([[0.2095],\n",
      "        [0.4575],\n",
      "        [0.7286],\n",
      "        [0.8952]]) 0.31852656602859497\n",
      "2748 tensor([[0.2094],\n",
      "        [0.4575],\n",
      "        [0.7286],\n",
      "        [0.8952]]) 0.31846633553504944\n",
      "2749 tensor([[0.2094],\n",
      "        [0.4574],\n",
      "        [0.7286],\n",
      "        [0.8953]]) 0.3184061050415039\n",
      "2750 tensor([[0.2093],\n",
      "        [0.4574],\n",
      "        [0.7286],\n",
      "        [0.8953]]) 0.31834590435028076\n",
      "2751 tensor([[0.2092],\n",
      "        [0.4573],\n",
      "        [0.7286],\n",
      "        [0.8953]]) 0.3182857036590576\n",
      "2752 tensor([[0.2091],\n",
      "        [0.4573],\n",
      "        [0.7286],\n",
      "        [0.8954]]) 0.31822553277015686\n",
      "2753 tensor([[0.2091],\n",
      "        [0.4573],\n",
      "        [0.7287],\n",
      "        [0.8954]]) 0.31816545128822327\n",
      "2754 tensor([[0.2090],\n",
      "        [0.4572],\n",
      "        [0.7287],\n",
      "        [0.8954]]) 0.3181053400039673\n",
      "2755 tensor([[0.2089],\n",
      "        [0.4572],\n",
      "        [0.7287],\n",
      "        [0.8955]]) 0.31804531812667847\n",
      "2756 tensor([[0.2088],\n",
      "        [0.4571],\n",
      "        [0.7287],\n",
      "        [0.8955]]) 0.31798526644706726\n",
      "2757 tensor([[0.2088],\n",
      "        [0.4571],\n",
      "        [0.7287],\n",
      "        [0.8955]]) 0.31792521476745605\n",
      "2758 tensor([[0.2087],\n",
      "        [0.4570],\n",
      "        [0.7288],\n",
      "        [0.8956]]) 0.3178652822971344\n",
      "2759 tensor([[0.2086],\n",
      "        [0.4570],\n",
      "        [0.7288],\n",
      "        [0.8956]]) 0.31780532002449036\n",
      "2760 tensor([[0.2085],\n",
      "        [0.4569],\n",
      "        [0.7288],\n",
      "        [0.8956]]) 0.3177453279495239\n",
      "2761 tensor([[0.2085],\n",
      "        [0.4569],\n",
      "        [0.7288],\n",
      "        [0.8957]]) 0.31768545508384705\n",
      "2762 tensor([[0.2084],\n",
      "        [0.4568],\n",
      "        [0.7288],\n",
      "        [0.8957]]) 0.31762558221817017\n",
      "2763 tensor([[0.2083],\n",
      "        [0.4568],\n",
      "        [0.7288],\n",
      "        [0.8957]]) 0.31756576895713806\n",
      "2764 tensor([[0.2082],\n",
      "        [0.4568],\n",
      "        [0.7289],\n",
      "        [0.8958]]) 0.31750595569610596\n",
      "2765 tensor([[0.2082],\n",
      "        [0.4567],\n",
      "        [0.7289],\n",
      "        [0.8958]]) 0.317446231842041\n",
      "2766 tensor([[0.2081],\n",
      "        [0.4567],\n",
      "        [0.7289],\n",
      "        [0.8958]]) 0.3173863887786865\n",
      "2767 tensor([[0.2080],\n",
      "        [0.4566],\n",
      "        [0.7289],\n",
      "        [0.8959]]) 0.3173266649246216\n",
      "2768 tensor([[0.2079],\n",
      "        [0.4566],\n",
      "        [0.7289],\n",
      "        [0.8959]]) 0.31726697087287903\n",
      "2769 tensor([[0.2079],\n",
      "        [0.4565],\n",
      "        [0.7290],\n",
      "        [0.8959]]) 0.31720733642578125\n",
      "2770 tensor([[0.2078],\n",
      "        [0.4565],\n",
      "        [0.7290],\n",
      "        [0.8960]]) 0.3171476423740387\n",
      "2771 tensor([[0.2077],\n",
      "        [0.4564],\n",
      "        [0.7290],\n",
      "        [0.8960]]) 0.3170880377292633\n",
      "2772 tensor([[0.2076],\n",
      "        [0.4564],\n",
      "        [0.7290],\n",
      "        [0.8960]]) 0.3170284032821655\n",
      "2773 tensor([[0.2076],\n",
      "        [0.4564],\n",
      "        [0.7290],\n",
      "        [0.8961]]) 0.3169688880443573\n",
      "2774 tensor([[0.2075],\n",
      "        [0.4563],\n",
      "        [0.7290],\n",
      "        [0.8961]]) 0.3169093430042267\n",
      "2775 tensor([[0.2074],\n",
      "        [0.4563],\n",
      "        [0.7291],\n",
      "        [0.8961]]) 0.31684985756874084\n",
      "2776 tensor([[0.2073],\n",
      "        [0.4562],\n",
      "        [0.7291],\n",
      "        [0.8962]]) 0.3167904019355774\n",
      "2777 tensor([[0.2073],\n",
      "        [0.4562],\n",
      "        [0.7291],\n",
      "        [0.8962]]) 0.31673094630241394\n",
      "2778 tensor([[0.2072],\n",
      "        [0.4561],\n",
      "        [0.7291],\n",
      "        [0.8962]]) 0.3166714906692505\n",
      "2779 tensor([[0.2071],\n",
      "        [0.4561],\n",
      "        [0.7291],\n",
      "        [0.8963]]) 0.3166120946407318\n",
      "2780 tensor([[0.2070],\n",
      "        [0.4560],\n",
      "        [0.7291],\n",
      "        [0.8963]]) 0.3165527284145355\n",
      "2781 tensor([[0.2070],\n",
      "        [0.4560],\n",
      "        [0.7292],\n",
      "        [0.8963]]) 0.31649336218833923\n",
      "2782 tensor([[0.2069],\n",
      "        [0.4560],\n",
      "        [0.7292],\n",
      "        [0.8964]]) 0.3164340853691101\n",
      "2783 tensor([[0.2068],\n",
      "        [0.4559],\n",
      "        [0.7292],\n",
      "        [0.8964]]) 0.3163747787475586\n",
      "2784 tensor([[0.2067],\n",
      "        [0.4559],\n",
      "        [0.7292],\n",
      "        [0.8964]]) 0.31631550192832947\n",
      "2785 tensor([[0.2067],\n",
      "        [0.4558],\n",
      "        [0.7292],\n",
      "        [0.8965]]) 0.31625622510910034\n",
      "2786 tensor([[0.2066],\n",
      "        [0.4558],\n",
      "        [0.7293],\n",
      "        [0.8965]]) 0.316197007894516\n",
      "2787 tensor([[0.2065],\n",
      "        [0.4557],\n",
      "        [0.7293],\n",
      "        [0.8965]]) 0.3161378502845764\n",
      "2788 tensor([[0.2064],\n",
      "        [0.4557],\n",
      "        [0.7293],\n",
      "        [0.8966]]) 0.31607872247695923\n",
      "2789 tensor([[0.2064],\n",
      "        [0.4556],\n",
      "        [0.7293],\n",
      "        [0.8966]]) 0.31601959466934204\n",
      "2790 tensor([[0.2063],\n",
      "        [0.4556],\n",
      "        [0.7293],\n",
      "        [0.8966]]) 0.31596052646636963\n",
      "2791 tensor([[0.2062],\n",
      "        [0.4556],\n",
      "        [0.7293],\n",
      "        [0.8967]]) 0.3159014582633972\n",
      "2792 tensor([[0.2062],\n",
      "        [0.4555],\n",
      "        [0.7294],\n",
      "        [0.8967]]) 0.3158423900604248\n",
      "2793 tensor([[0.2061],\n",
      "        [0.4555],\n",
      "        [0.7294],\n",
      "        [0.8967]]) 0.31578338146209717\n",
      "2794 tensor([[0.2060],\n",
      "        [0.4554],\n",
      "        [0.7294],\n",
      "        [0.8968]]) 0.3157244026660919\n",
      "2795 tensor([[0.2059],\n",
      "        [0.4554],\n",
      "        [0.7294],\n",
      "        [0.8968]]) 0.31566548347473145\n",
      "2796 tensor([[0.2059],\n",
      "        [0.4553],\n",
      "        [0.7294],\n",
      "        [0.8968]]) 0.3156065344810486\n",
      "2797 tensor([[0.2058],\n",
      "        [0.4553],\n",
      "        [0.7294],\n",
      "        [0.8969]]) 0.3155476152896881\n",
      "2798 tensor([[0.2057],\n",
      "        [0.4552],\n",
      "        [0.7295],\n",
      "        [0.8969]]) 0.31548869609832764\n",
      "2799 tensor([[0.2056],\n",
      "        [0.4552],\n",
      "        [0.7295],\n",
      "        [0.8969]]) 0.3154298663139343\n",
      "2800 tensor([[0.2056],\n",
      "        [0.4551],\n",
      "        [0.7295],\n",
      "        [0.8970]]) 0.3153710663318634\n",
      "2801 tensor([[0.2055],\n",
      "        [0.4551],\n",
      "        [0.7295],\n",
      "        [0.8970]]) 0.3153122663497925\n",
      "2802 tensor([[0.2054],\n",
      "        [0.4551],\n",
      "        [0.7295],\n",
      "        [0.8970]]) 0.31525346636772156\n",
      "2803 tensor([[0.2053],\n",
      "        [0.4550],\n",
      "        [0.7296],\n",
      "        [0.8971]]) 0.3151947855949402\n",
      "2804 tensor([[0.2053],\n",
      "        [0.4550],\n",
      "        [0.7296],\n",
      "        [0.8971]]) 0.31513604521751404\n",
      "2805 tensor([[0.2052],\n",
      "        [0.4549],\n",
      "        [0.7296],\n",
      "        [0.8971]]) 0.3150773048400879\n",
      "2806 tensor([[0.2051],\n",
      "        [0.4549],\n",
      "        [0.7296],\n",
      "        [0.8972]]) 0.3150187134742737\n",
      "2807 tensor([[0.2051],\n",
      "        [0.4548],\n",
      "        [0.7296],\n",
      "        [0.8972]]) 0.3149600327014923\n",
      "2808 tensor([[0.2050],\n",
      "        [0.4548],\n",
      "        [0.7296],\n",
      "        [0.8972]]) 0.3149014413356781\n",
      "2809 tensor([[0.2049],\n",
      "        [0.4547],\n",
      "        [0.7297],\n",
      "        [0.8973]]) 0.3148428201675415\n",
      "2810 tensor([[0.2048],\n",
      "        [0.4547],\n",
      "        [0.7297],\n",
      "        [0.8973]]) 0.31478428840637207\n",
      "2811 tensor([[0.2048],\n",
      "        [0.4547],\n",
      "        [0.7297],\n",
      "        [0.8973]]) 0.3147258460521698\n",
      "2812 tensor([[0.2047],\n",
      "        [0.4546],\n",
      "        [0.7297],\n",
      "        [0.8974]]) 0.31466731429100037\n",
      "2813 tensor([[0.2046],\n",
      "        [0.4546],\n",
      "        [0.7297],\n",
      "        [0.8974]]) 0.3146088123321533\n",
      "2814 tensor([[0.2045],\n",
      "        [0.4545],\n",
      "        [0.7298],\n",
      "        [0.8974]]) 0.31455039978027344\n",
      "2815 tensor([[0.2045],\n",
      "        [0.4545],\n",
      "        [0.7298],\n",
      "        [0.8975]]) 0.31449198722839355\n",
      "2816 tensor([[0.2044],\n",
      "        [0.4544],\n",
      "        [0.7298],\n",
      "        [0.8975]]) 0.31443357467651367\n",
      "2817 tensor([[0.2043],\n",
      "        [0.4544],\n",
      "        [0.7298],\n",
      "        [0.8975]]) 0.3143751919269562\n",
      "2818 tensor([[0.2043],\n",
      "        [0.4544],\n",
      "        [0.7298],\n",
      "        [0.8976]]) 0.31431689858436584\n",
      "2819 tensor([[0.2042],\n",
      "        [0.4543],\n",
      "        [0.7298],\n",
      "        [0.8976]]) 0.3142585754394531\n",
      "2820 tensor([[0.2041],\n",
      "        [0.4543],\n",
      "        [0.7299],\n",
      "        [0.8976]]) 0.3142002820968628\n",
      "2821 tensor([[0.2040],\n",
      "        [0.4542],\n",
      "        [0.7299],\n",
      "        [0.8977]]) 0.31414198875427246\n",
      "2822 tensor([[0.2040],\n",
      "        [0.4542],\n",
      "        [0.7299],\n",
      "        [0.8977]]) 0.3140838146209717\n",
      "2823 tensor([[0.2039],\n",
      "        [0.4541],\n",
      "        [0.7299],\n",
      "        [0.8977]]) 0.31402555108070374\n",
      "2824 tensor([[0.2038],\n",
      "        [0.4541],\n",
      "        [0.7299],\n",
      "        [0.8978]]) 0.3139674663543701\n",
      "2825 tensor([[0.2037],\n",
      "        [0.4540],\n",
      "        [0.7299],\n",
      "        [0.8978]]) 0.31390926241874695\n",
      "2826 tensor([[0.2037],\n",
      "        [0.4540],\n",
      "        [0.7300],\n",
      "        [0.8978]]) 0.31385108828544617\n",
      "2827 tensor([[0.2036],\n",
      "        [0.4540],\n",
      "        [0.7300],\n",
      "        [0.8979]]) 0.31379303336143494\n",
      "2828 tensor([[0.2035],\n",
      "        [0.4539],\n",
      "        [0.7300],\n",
      "        [0.8979]]) 0.3137349486351013\n",
      "2829 tensor([[0.2035],\n",
      "        [0.4539],\n",
      "        [0.7300],\n",
      "        [0.8979]]) 0.31367695331573486\n",
      "2830 tensor([[0.2034],\n",
      "        [0.4538],\n",
      "        [0.7300],\n",
      "        [0.8980]]) 0.31361886858940125\n",
      "2831 tensor([[0.2033],\n",
      "        [0.4538],\n",
      "        [0.7301],\n",
      "        [0.8980]]) 0.3135609030723572\n",
      "2832 tensor([[0.2032],\n",
      "        [0.4537],\n",
      "        [0.7301],\n",
      "        [0.8980]]) 0.3135029673576355\n",
      "2833 tensor([[0.2032],\n",
      "        [0.4537],\n",
      "        [0.7301],\n",
      "        [0.8981]]) 0.3134450912475586\n",
      "2834 tensor([[0.2031],\n",
      "        [0.4536],\n",
      "        [0.7301],\n",
      "        [0.8981]]) 0.31338709592819214\n",
      "2835 tensor([[0.2030],\n",
      "        [0.4536],\n",
      "        [0.7301],\n",
      "        [0.8981]]) 0.31332921981811523\n",
      "2836 tensor([[0.2030],\n",
      "        [0.4536],\n",
      "        [0.7301],\n",
      "        [0.8982]]) 0.3132713735103607\n",
      "2837 tensor([[0.2029],\n",
      "        [0.4535],\n",
      "        [0.7302],\n",
      "        [0.8982]]) 0.3132135272026062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838 tensor([[0.2028],\n",
      "        [0.4535],\n",
      "        [0.7302],\n",
      "        [0.8982]]) 0.31315577030181885\n",
      "2839 tensor([[0.2027],\n",
      "        [0.4534],\n",
      "        [0.7302],\n",
      "        [0.8983]]) 0.3130979537963867\n",
      "2840 tensor([[0.2027],\n",
      "        [0.4534],\n",
      "        [0.7302],\n",
      "        [0.8983]]) 0.31304019689559937\n",
      "2841 tensor([[0.2026],\n",
      "        [0.4533],\n",
      "        [0.7302],\n",
      "        [0.8983]]) 0.3129824697971344\n",
      "2842 tensor([[0.2025],\n",
      "        [0.4533],\n",
      "        [0.7302],\n",
      "        [0.8984]]) 0.3129248023033142\n",
      "2843 tensor([[0.2024],\n",
      "        [0.4532],\n",
      "        [0.7303],\n",
      "        [0.8984]]) 0.312867134809494\n",
      "2844 tensor([[0.2024],\n",
      "        [0.4532],\n",
      "        [0.7303],\n",
      "        [0.8984]]) 0.3128095269203186\n",
      "2845 tensor([[0.2023],\n",
      "        [0.4532],\n",
      "        [0.7303],\n",
      "        [0.8985]]) 0.3127518594264984\n",
      "2846 tensor([[0.2022],\n",
      "        [0.4531],\n",
      "        [0.7303],\n",
      "        [0.8985]]) 0.3126942813396454\n",
      "2847 tensor([[0.2022],\n",
      "        [0.4531],\n",
      "        [0.7303],\n",
      "        [0.8985]]) 0.31263673305511475\n",
      "2848 tensor([[0.2021],\n",
      "        [0.4530],\n",
      "        [0.7304],\n",
      "        [0.8986]]) 0.3125791549682617\n",
      "2849 tensor([[0.2020],\n",
      "        [0.4530],\n",
      "        [0.7304],\n",
      "        [0.8986]]) 0.31252169609069824\n",
      "2850 tensor([[0.2019],\n",
      "        [0.4529],\n",
      "        [0.7304],\n",
      "        [0.8986]]) 0.31246417760849\n",
      "2851 tensor([[0.2019],\n",
      "        [0.4529],\n",
      "        [0.7304],\n",
      "        [0.8987]]) 0.3124067187309265\n",
      "2852 tensor([[0.2018],\n",
      "        [0.4529],\n",
      "        [0.7304],\n",
      "        [0.8987]]) 0.3123492896556854\n",
      "2853 tensor([[0.2017],\n",
      "        [0.4528],\n",
      "        [0.7304],\n",
      "        [0.8987]]) 0.3122919201850891\n",
      "2854 tensor([[0.2017],\n",
      "        [0.4528],\n",
      "        [0.7305],\n",
      "        [0.8987]]) 0.3122345507144928\n",
      "2855 tensor([[0.2016],\n",
      "        [0.4527],\n",
      "        [0.7305],\n",
      "        [0.8988]]) 0.3121771514415741\n",
      "2856 tensor([[0.2015],\n",
      "        [0.4527],\n",
      "        [0.7305],\n",
      "        [0.8988]]) 0.31211984157562256\n",
      "2857 tensor([[0.2014],\n",
      "        [0.4526],\n",
      "        [0.7305],\n",
      "        [0.8988]]) 0.31206250190734863\n",
      "2858 tensor([[0.2014],\n",
      "        [0.4526],\n",
      "        [0.7305],\n",
      "        [0.8989]]) 0.31200525164604187\n",
      "2859 tensor([[0.2013],\n",
      "        [0.4525],\n",
      "        [0.7305],\n",
      "        [0.8989]]) 0.3119480609893799\n",
      "2860 tensor([[0.2012],\n",
      "        [0.4525],\n",
      "        [0.7306],\n",
      "        [0.8989]]) 0.31189075112342834\n",
      "2861 tensor([[0.2012],\n",
      "        [0.4525],\n",
      "        [0.7306],\n",
      "        [0.8990]]) 0.31183362007141113\n",
      "2862 tensor([[0.2011],\n",
      "        [0.4524],\n",
      "        [0.7306],\n",
      "        [0.8990]]) 0.31177642941474915\n",
      "2863 tensor([[0.2010],\n",
      "        [0.4524],\n",
      "        [0.7306],\n",
      "        [0.8990]]) 0.31171923875808716\n",
      "2864 tensor([[0.2009],\n",
      "        [0.4523],\n",
      "        [0.7306],\n",
      "        [0.8991]]) 0.31166213750839233\n",
      "2865 tensor([[0.2009],\n",
      "        [0.4523],\n",
      "        [0.7306],\n",
      "        [0.8991]]) 0.3116050660610199\n",
      "2866 tensor([[0.2008],\n",
      "        [0.4522],\n",
      "        [0.7307],\n",
      "        [0.8991]]) 0.31154799461364746\n",
      "2867 tensor([[0.2007],\n",
      "        [0.4522],\n",
      "        [0.7307],\n",
      "        [0.8992]]) 0.31149089336395264\n",
      "2868 tensor([[0.2007],\n",
      "        [0.4522],\n",
      "        [0.7307],\n",
      "        [0.8992]]) 0.311433881521225\n",
      "2869 tensor([[0.2006],\n",
      "        [0.4521],\n",
      "        [0.7307],\n",
      "        [0.8992]]) 0.3113769590854645\n",
      "2870 tensor([[0.2005],\n",
      "        [0.4521],\n",
      "        [0.7307],\n",
      "        [0.8993]]) 0.3113199770450592\n",
      "2871 tensor([[0.2005],\n",
      "        [0.4520],\n",
      "        [0.7308],\n",
      "        [0.8993]]) 0.3112630546092987\n",
      "2872 tensor([[0.2004],\n",
      "        [0.4520],\n",
      "        [0.7308],\n",
      "        [0.8993]]) 0.3112061023712158\n",
      "2873 tensor([[0.2003],\n",
      "        [0.4519],\n",
      "        [0.7308],\n",
      "        [0.8994]]) 0.3111492395401001\n",
      "2874 tensor([[0.2002],\n",
      "        [0.4519],\n",
      "        [0.7308],\n",
      "        [0.8994]]) 0.31109243631362915\n",
      "2875 tensor([[0.2002],\n",
      "        [0.4518],\n",
      "        [0.7308],\n",
      "        [0.8994]]) 0.31103554368019104\n",
      "2876 tensor([[0.2001],\n",
      "        [0.4518],\n",
      "        [0.7308],\n",
      "        [0.8995]]) 0.3109787702560425\n",
      "2877 tensor([[0.2000],\n",
      "        [0.4518],\n",
      "        [0.7309],\n",
      "        [0.8995]]) 0.31092193722724915\n",
      "2878 tensor([[0.2000],\n",
      "        [0.4517],\n",
      "        [0.7309],\n",
      "        [0.8995]]) 0.31086522340774536\n",
      "2879 tensor([[0.1999],\n",
      "        [0.4517],\n",
      "        [0.7309],\n",
      "        [0.8996]]) 0.3108084797859192\n",
      "2880 tensor([[0.1998],\n",
      "        [0.4516],\n",
      "        [0.7309],\n",
      "        [0.8996]]) 0.3107517957687378\n",
      "2881 tensor([[0.1997],\n",
      "        [0.4516],\n",
      "        [0.7309],\n",
      "        [0.8996]]) 0.310695081949234\n",
      "2882 tensor([[0.1997],\n",
      "        [0.4515],\n",
      "        [0.7309],\n",
      "        [0.8996]]) 0.310638427734375\n",
      "2883 tensor([[0.1996],\n",
      "        [0.4515],\n",
      "        [0.7310],\n",
      "        [0.8997]]) 0.3105818033218384\n",
      "2884 tensor([[0.1995],\n",
      "        [0.4515],\n",
      "        [0.7310],\n",
      "        [0.8997]]) 0.31052517890930176\n",
      "2885 tensor([[0.1995],\n",
      "        [0.4514],\n",
      "        [0.7310],\n",
      "        [0.8997]]) 0.3104686737060547\n",
      "2886 tensor([[0.1994],\n",
      "        [0.4514],\n",
      "        [0.7310],\n",
      "        [0.8998]]) 0.31041207909584045\n",
      "2887 tensor([[0.1993],\n",
      "        [0.4513],\n",
      "        [0.7310],\n",
      "        [0.8998]]) 0.31035560369491577\n",
      "2888 tensor([[0.1993],\n",
      "        [0.4513],\n",
      "        [0.7311],\n",
      "        [0.8998]]) 0.3102990686893463\n",
      "2889 tensor([[0.1992],\n",
      "        [0.4512],\n",
      "        [0.7311],\n",
      "        [0.8999]]) 0.31024256348609924\n",
      "2890 tensor([[0.1991],\n",
      "        [0.4512],\n",
      "        [0.7311],\n",
      "        [0.8999]]) 0.31018614768981934\n",
      "2891 tensor([[0.1990],\n",
      "        [0.4512],\n",
      "        [0.7311],\n",
      "        [0.8999]]) 0.31012973189353943\n",
      "2892 tensor([[0.1990],\n",
      "        [0.4511],\n",
      "        [0.7311],\n",
      "        [0.9000]]) 0.3100733458995819\n",
      "2893 tensor([[0.1989],\n",
      "        [0.4511],\n",
      "        [0.7311],\n",
      "        [0.9000]]) 0.3100169599056244\n",
      "2894 tensor([[0.1988],\n",
      "        [0.4510],\n",
      "        [0.7312],\n",
      "        [0.9000]]) 0.30996066331863403\n",
      "2895 tensor([[0.1988],\n",
      "        [0.4510],\n",
      "        [0.7312],\n",
      "        [0.9001]]) 0.3099043071269989\n",
      "2896 tensor([[0.1987],\n",
      "        [0.4509],\n",
      "        [0.7312],\n",
      "        [0.9001]]) 0.30984801054000854\n",
      "2897 tensor([[0.1986],\n",
      "        [0.4509],\n",
      "        [0.7312],\n",
      "        [0.9001]]) 0.3097917437553406\n",
      "2898 tensor([[0.1986],\n",
      "        [0.4508],\n",
      "        [0.7312],\n",
      "        [0.9002]]) 0.3097354769706726\n",
      "2899 tensor([[0.1985],\n",
      "        [0.4508],\n",
      "        [0.7312],\n",
      "        [0.9002]]) 0.3096792995929718\n",
      "2900 tensor([[0.1984],\n",
      "        [0.4508],\n",
      "        [0.7313],\n",
      "        [0.9002]]) 0.3096230626106262\n",
      "2901 tensor([[0.1983],\n",
      "        [0.4507],\n",
      "        [0.7313],\n",
      "        [0.9003]]) 0.3095668852329254\n",
      "2902 tensor([[0.1983],\n",
      "        [0.4507],\n",
      "        [0.7313],\n",
      "        [0.9003]]) 0.309510737657547\n",
      "2903 tensor([[0.1982],\n",
      "        [0.4506],\n",
      "        [0.7313],\n",
      "        [0.9003]]) 0.30945464968681335\n",
      "2904 tensor([[0.1981],\n",
      "        [0.4506],\n",
      "        [0.7313],\n",
      "        [0.9003]]) 0.30939850211143494\n",
      "2905 tensor([[0.1981],\n",
      "        [0.4505],\n",
      "        [0.7313],\n",
      "        [0.9004]]) 0.3093424439430237\n",
      "2906 tensor([[0.1980],\n",
      "        [0.4505],\n",
      "        [0.7314],\n",
      "        [0.9004]]) 0.3092864453792572\n",
      "2907 tensor([[0.1979],\n",
      "        [0.4505],\n",
      "        [0.7314],\n",
      "        [0.9004]]) 0.30923041701316833\n",
      "2908 tensor([[0.1979],\n",
      "        [0.4504],\n",
      "        [0.7314],\n",
      "        [0.9005]]) 0.30917438864707947\n",
      "2909 tensor([[0.1978],\n",
      "        [0.4504],\n",
      "        [0.7314],\n",
      "        [0.9005]]) 0.30911844968795776\n",
      "2910 tensor([[0.1977],\n",
      "        [0.4503],\n",
      "        [0.7314],\n",
      "        [0.9005]]) 0.30906254053115845\n",
      "2911 tensor([[0.1977],\n",
      "        [0.4503],\n",
      "        [0.7315],\n",
      "        [0.9006]]) 0.30900660157203674\n",
      "2912 tensor([[0.1976],\n",
      "        [0.4502],\n",
      "        [0.7315],\n",
      "        [0.9006]]) 0.3089506924152374\n",
      "2913 tensor([[0.1975],\n",
      "        [0.4502],\n",
      "        [0.7315],\n",
      "        [0.9006]]) 0.3088948726654053\n",
      "2914 tensor([[0.1974],\n",
      "        [0.4502],\n",
      "        [0.7315],\n",
      "        [0.9007]]) 0.30883899331092834\n",
      "2915 tensor([[0.1974],\n",
      "        [0.4501],\n",
      "        [0.7315],\n",
      "        [0.9007]]) 0.3087831735610962\n",
      "2916 tensor([[0.1973],\n",
      "        [0.4501],\n",
      "        [0.7315],\n",
      "        [0.9007]]) 0.3087274134159088\n",
      "2917 tensor([[0.1972],\n",
      "        [0.4500],\n",
      "        [0.7316],\n",
      "        [0.9008]]) 0.30867165327072144\n",
      "2918 tensor([[0.1972],\n",
      "        [0.4500],\n",
      "        [0.7316],\n",
      "        [0.9008]]) 0.3086158335208893\n",
      "2919 tensor([[0.1971],\n",
      "        [0.4499],\n",
      "        [0.7316],\n",
      "        [0.9008]]) 0.30856016278266907\n",
      "2920 tensor([[0.1970],\n",
      "        [0.4499],\n",
      "        [0.7316],\n",
      "        [0.9008]]) 0.30850452184677124\n",
      "2921 tensor([[0.1970],\n",
      "        [0.4499],\n",
      "        [0.7316],\n",
      "        [0.9009]]) 0.30844882130622864\n",
      "2922 tensor([[0.1969],\n",
      "        [0.4498],\n",
      "        [0.7316],\n",
      "        [0.9009]]) 0.3083931803703308\n",
      "2923 tensor([[0.1968],\n",
      "        [0.4498],\n",
      "        [0.7317],\n",
      "        [0.9009]]) 0.30833759903907776\n",
      "2924 tensor([[0.1968],\n",
      "        [0.4497],\n",
      "        [0.7317],\n",
      "        [0.9010]]) 0.30828192830085754\n",
      "2925 tensor([[0.1967],\n",
      "        [0.4497],\n",
      "        [0.7317],\n",
      "        [0.9010]]) 0.30822640657424927\n",
      "2926 tensor([[0.1966],\n",
      "        [0.4496],\n",
      "        [0.7317],\n",
      "        [0.9010]]) 0.3081708550453186\n",
      "2927 tensor([[0.1965],\n",
      "        [0.4496],\n",
      "        [0.7317],\n",
      "        [0.9011]]) 0.3081153631210327\n",
      "2928 tensor([[0.1965],\n",
      "        [0.4496],\n",
      "        [0.7317],\n",
      "        [0.9011]]) 0.3080598711967468\n",
      "2929 tensor([[0.1964],\n",
      "        [0.4495],\n",
      "        [0.7318],\n",
      "        [0.9011]]) 0.3080044090747833\n",
      "2930 tensor([[0.1963],\n",
      "        [0.4495],\n",
      "        [0.7318],\n",
      "        [0.9012]]) 0.3079490065574646\n",
      "2931 tensor([[0.1963],\n",
      "        [0.4494],\n",
      "        [0.7318],\n",
      "        [0.9012]]) 0.3078935146331787\n",
      "2932 tensor([[0.1962],\n",
      "        [0.4494],\n",
      "        [0.7318],\n",
      "        [0.9012]]) 0.30783817172050476\n",
      "2933 tensor([[0.1961],\n",
      "        [0.4493],\n",
      "        [0.7318],\n",
      "        [0.9013]]) 0.3077828288078308\n",
      "2934 tensor([[0.1961],\n",
      "        [0.4493],\n",
      "        [0.7319],\n",
      "        [0.9013]]) 0.3077274262905121\n",
      "2935 tensor([[0.1960],\n",
      "        [0.4493],\n",
      "        [0.7319],\n",
      "        [0.9013]]) 0.3076721727848053\n",
      "2936 tensor([[0.1959],\n",
      "        [0.4492],\n",
      "        [0.7319],\n",
      "        [0.9013]]) 0.30761685967445374\n",
      "2937 tensor([[0.1959],\n",
      "        [0.4492],\n",
      "        [0.7319],\n",
      "        [0.9014]]) 0.30756163597106934\n",
      "2938 tensor([[0.1958],\n",
      "        [0.4491],\n",
      "        [0.7319],\n",
      "        [0.9014]]) 0.30750638246536255\n",
      "2939 tensor([[0.1957],\n",
      "        [0.4491],\n",
      "        [0.7319],\n",
      "        [0.9014]]) 0.30745112895965576\n",
      "2940 tensor([[0.1957],\n",
      "        [0.4490],\n",
      "        [0.7320],\n",
      "        [0.9015]]) 0.30739596486091614\n",
      "2941 tensor([[0.1956],\n",
      "        [0.4490],\n",
      "        [0.7320],\n",
      "        [0.9015]]) 0.3073408007621765\n",
      "2942 tensor([[0.1955],\n",
      "        [0.4490],\n",
      "        [0.7320],\n",
      "        [0.9015]]) 0.3072856068611145\n",
      "2943 tensor([[0.1955],\n",
      "        [0.4489],\n",
      "        [0.7320],\n",
      "        [0.9016]]) 0.30723053216934204\n",
      "2944 tensor([[0.1954],\n",
      "        [0.4489],\n",
      "        [0.7320],\n",
      "        [0.9016]]) 0.30717548727989197\n",
      "2945 tensor([[0.1953],\n",
      "        [0.4488],\n",
      "        [0.7320],\n",
      "        [0.9016]]) 0.3071204125881195\n",
      "2946 tensor([[0.1952],\n",
      "        [0.4488],\n",
      "        [0.7321],\n",
      "        [0.9017]]) 0.30706536769866943\n",
      "2947 tensor([[0.1952],\n",
      "        [0.4487],\n",
      "        [0.7321],\n",
      "        [0.9017]]) 0.30701035261154175\n",
      "2948 tensor([[0.1951],\n",
      "        [0.4487],\n",
      "        [0.7321],\n",
      "        [0.9017]]) 0.3069553077220917\n",
      "2949 tensor([[0.1950],\n",
      "        [0.4487],\n",
      "        [0.7321],\n",
      "        [0.9018]]) 0.30690038204193115\n",
      "2950 tensor([[0.1950],\n",
      "        [0.4486],\n",
      "        [0.7321],\n",
      "        [0.9018]]) 0.30684539675712585\n",
      "2951 tensor([[0.1949],\n",
      "        [0.4486],\n",
      "        [0.7321],\n",
      "        [0.9018]]) 0.3067905008792877\n",
      "2952 tensor([[0.1948],\n",
      "        [0.4485],\n",
      "        [0.7322],\n",
      "        [0.9018]]) 0.3067355751991272\n",
      "2953 tensor([[0.1948],\n",
      "        [0.4485],\n",
      "        [0.7322],\n",
      "        [0.9019]]) 0.3066807687282562\n",
      "2954 tensor([[0.1947],\n",
      "        [0.4484],\n",
      "        [0.7322],\n",
      "        [0.9019]]) 0.3066258728504181\n",
      "2955 tensor([[0.1946],\n",
      "        [0.4484],\n",
      "        [0.7322],\n",
      "        [0.9019]]) 0.30657103657722473\n",
      "2956 tensor([[0.1946],\n",
      "        [0.4484],\n",
      "        [0.7322],\n",
      "        [0.9020]]) 0.30651623010635376\n",
      "2957 tensor([[0.1945],\n",
      "        [0.4483],\n",
      "        [0.7323],\n",
      "        [0.9020]]) 0.3064614534378052\n",
      "2958 tensor([[0.1944],\n",
      "        [0.4483],\n",
      "        [0.7323],\n",
      "        [0.9020]]) 0.30640676617622375\n",
      "2959 tensor([[0.1944],\n",
      "        [0.4482],\n",
      "        [0.7323],\n",
      "        [0.9021]]) 0.30635201930999756\n",
      "2960 tensor([[0.1943],\n",
      "        [0.4482],\n",
      "        [0.7323],\n",
      "        [0.9021]]) 0.30629730224609375\n",
      "2961 tensor([[0.1942],\n",
      "        [0.4481],\n",
      "        [0.7323],\n",
      "        [0.9021]]) 0.3062426745891571\n",
      "2962 tensor([[0.1942],\n",
      "        [0.4481],\n",
      "        [0.7323],\n",
      "        [0.9022]]) 0.30618801712989807\n",
      "2963 tensor([[0.1941],\n",
      "        [0.4481],\n",
      "        [0.7324],\n",
      "        [0.9022]]) 0.30613332986831665\n",
      "2964 tensor([[0.1940],\n",
      "        [0.4480],\n",
      "        [0.7324],\n",
      "        [0.9022]]) 0.3060787618160248\n",
      "2965 tensor([[0.1940],\n",
      "        [0.4480],\n",
      "        [0.7324],\n",
      "        [0.9022]]) 0.3060241937637329\n",
      "2966 tensor([[0.1939],\n",
      "        [0.4479],\n",
      "        [0.7324],\n",
      "        [0.9023]]) 0.30596959590911865\n",
      "2967 tensor([[0.1938],\n",
      "        [0.4479],\n",
      "        [0.7324],\n",
      "        [0.9023]]) 0.30591511726379395\n",
      "2968 tensor([[0.1938],\n",
      "        [0.4478],\n",
      "        [0.7324],\n",
      "        [0.9023]]) 0.30586057901382446\n",
      "2969 tensor([[0.1937],\n",
      "        [0.4478],\n",
      "        [0.7325],\n",
      "        [0.9024]]) 0.30580615997314453\n",
      "2970 tensor([[0.1936],\n",
      "        [0.4478],\n",
      "        [0.7325],\n",
      "        [0.9024]]) 0.3057516813278198\n",
      "2971 tensor([[0.1936],\n",
      "        [0.4477],\n",
      "        [0.7325],\n",
      "        [0.9024]]) 0.3056972026824951\n",
      "2972 tensor([[0.1935],\n",
      "        [0.4477],\n",
      "        [0.7325],\n",
      "        [0.9025]]) 0.30564287304878235\n",
      "2973 tensor([[0.1934],\n",
      "        [0.4476],\n",
      "        [0.7325],\n",
      "        [0.9025]]) 0.3055884540081024\n",
      "2974 tensor([[0.1934],\n",
      "        [0.4476],\n",
      "        [0.7325],\n",
      "        [0.9025]]) 0.30553409457206726\n",
      "2975 tensor([[0.1933],\n",
      "        [0.4476],\n",
      "        [0.7326],\n",
      "        [0.9026]]) 0.3054797351360321\n",
      "2976 tensor([[0.1932],\n",
      "        [0.4475],\n",
      "        [0.7326],\n",
      "        [0.9026]]) 0.30542540550231934\n",
      "2977 tensor([[0.1932],\n",
      "        [0.4475],\n",
      "        [0.7326],\n",
      "        [0.9026]]) 0.30537116527557373\n",
      "2978 tensor([[0.1931],\n",
      "        [0.4474],\n",
      "        [0.7326],\n",
      "        [0.9026]]) 0.30531683564186096\n",
      "2979 tensor([[0.1930],\n",
      "        [0.4474],\n",
      "        [0.7326],\n",
      "        [0.9027]]) 0.30526259541511536\n",
      "2980 tensor([[0.1930],\n",
      "        [0.4473],\n",
      "        [0.7326],\n",
      "        [0.9027]]) 0.3052084147930145\n",
      "2981 tensor([[0.1929],\n",
      "        [0.4473],\n",
      "        [0.7327],\n",
      "        [0.9027]]) 0.3051542341709137\n",
      "2982 tensor([[0.1928],\n",
      "        [0.4473],\n",
      "        [0.7327],\n",
      "        [0.9028]]) 0.30510011315345764\n",
      "2983 tensor([[0.1928],\n",
      "        [0.4472],\n",
      "        [0.7327],\n",
      "        [0.9028]]) 0.3050459027290344\n",
      "2984 tensor([[0.1927],\n",
      "        [0.4472],\n",
      "        [0.7327],\n",
      "        [0.9028]]) 0.30499184131622314\n",
      "2985 tensor([[0.1926],\n",
      "        [0.4471],\n",
      "        [0.7327],\n",
      "        [0.9029]]) 0.3049376904964447\n",
      "2986 tensor([[0.1925],\n",
      "        [0.4471],\n",
      "        [0.7328],\n",
      "        [0.9029]]) 0.3048836290836334\n",
      "2987 tensor([[0.1925],\n",
      "        [0.4470],\n",
      "        [0.7328],\n",
      "        [0.9029]]) 0.3048296272754669\n",
      "2988 tensor([[0.1924],\n",
      "        [0.4470],\n",
      "        [0.7328],\n",
      "        [0.9029]]) 0.304775595664978\n",
      "2989 tensor([[0.1923],\n",
      "        [0.4470],\n",
      "        [0.7328],\n",
      "        [0.9030]]) 0.3047215938568115\n",
      "2990 tensor([[0.1923],\n",
      "        [0.4469],\n",
      "        [0.7328],\n",
      "        [0.9030]]) 0.3046676218509674\n",
      "2991 tensor([[0.1922],\n",
      "        [0.4469],\n",
      "        [0.7328],\n",
      "        [0.9030]]) 0.3046136796474457\n",
      "2992 tensor([[0.1921],\n",
      "        [0.4468],\n",
      "        [0.7329],\n",
      "        [0.9031]]) 0.30455973744392395\n",
      "2993 tensor([[0.1921],\n",
      "        [0.4468],\n",
      "        [0.7329],\n",
      "        [0.9031]]) 0.304505854845047\n",
      "2994 tensor([[0.1920],\n",
      "        [0.4467],\n",
      "        [0.7329],\n",
      "        [0.9031]]) 0.30445194244384766\n",
      "2995 tensor([[0.1920],\n",
      "        [0.4467],\n",
      "        [0.7329],\n",
      "        [0.9032]]) 0.3043980896472931\n",
      "2996 tensor([[0.1919],\n",
      "        [0.4467],\n",
      "        [0.7329],\n",
      "        [0.9032]]) 0.3043442964553833\n",
      "2997 tensor([[0.1918],\n",
      "        [0.4466],\n",
      "        [0.7329],\n",
      "        [0.9032]]) 0.3042904734611511\n",
      "2998 tensor([[0.1918],\n",
      "        [0.4466],\n",
      "        [0.7330],\n",
      "        [0.9032]]) 0.3042367100715637\n",
      "2999 tensor([[0.1917],\n",
      "        [0.4465],\n",
      "        [0.7330],\n",
      "        [0.9033]]) 0.3041829466819763\n",
      "predict 1 hour 1.0 True\n",
      "predict 7 hours 7.0 True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0],[4.0]]))\n",
    "y_data = Variable(torch.Tensor([[0.],[0.],[1.],[1.]]))\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1) #  1 in  1 out ,  fc1 을 의미\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = F.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion  = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(3000):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, y_pred.data, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # 무슨의미?\n",
    "    \n",
    "hour_var = Variable(torch.Tensor([[1.0]]))\n",
    "print(\"predict 1 hour\", 1.0, model(hour_val).item() > 0.5)\n",
    "hour_var = Variable(torch.Tensor([[7.0]]))\n",
    "print(\"predict 7 hours\", 7.0, model(hour_val).item() > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29560757.526162334\n",
      "1 25203982.51614423\n",
      "2 24984338.47927185\n",
      "3 25139267.089290652\n",
      "4 23235932.1400598\n",
      "5 18717557.85970682\n",
      "6 12984532.778878015\n",
      "7 8030642.541835573\n",
      "8 4700838.418221118\n",
      "9 2785027.10788454\n",
      "10 1751871.7762626251\n",
      "11 1196558.6843283735\n",
      "12 884045.0595939002\n",
      "13 694371.182695887\n",
      "14 568869.3623803745\n",
      "15 478853.15738181584\n",
      "16 410177.83314982103\n",
      "17 355474.77855629893\n",
      "18 310571.05865350185\n",
      "19 272996.32737294544\n",
      "20 241157.30321640294\n",
      "21 213924.66189462773\n",
      "22 190458.8210964006\n",
      "23 170116.78861539013\n",
      "24 152388.51306843225\n",
      "25 136865.40225299486\n",
      "26 123234.92820179772\n",
      "27 111231.47987111873\n",
      "28 100615.30561869932\n",
      "29 91201.74463462822\n",
      "30 82828.1583079018\n",
      "31 75363.21276864831\n",
      "32 68689.86932081093\n",
      "33 62717.046842809796\n",
      "34 57353.19787196291\n",
      "35 52524.072025177884\n",
      "36 48168.15867992394\n",
      "37 44234.91698952689\n",
      "38 40677.78512123893\n",
      "39 37452.513563851666\n",
      "40 34521.84453925093\n",
      "41 31856.395911933145\n",
      "42 29428.79850008386\n",
      "43 27214.696090924845\n",
      "44 25192.492382284567\n",
      "45 23342.683715129373\n",
      "46 21648.636857870002\n",
      "47 20095.118694460925\n",
      "48 18668.807193828095\n",
      "49 17358.270672522573\n",
      "50 16152.418867667122\n",
      "51 15041.955739636063\n",
      "52 14018.103831153596\n",
      "53 13075.305648315356\n",
      "54 12204.584498719989\n",
      "55 11399.317339714107\n",
      "56 10654.00026274778\n",
      "57 9964.758057734995\n",
      "58 9326.952675767501\n",
      "59 8735.16422825013\n",
      "60 8185.679403521223\n",
      "61 7675.107782973047\n",
      "62 7200.2715643256315\n",
      "63 6758.26188736464\n",
      "64 6346.55742513388\n",
      "65 5963.2598436100425\n",
      "66 5605.619640251107\n",
      "67 5271.780162933426\n",
      "68 4960.056124448148\n",
      "69 4668.914140642333\n",
      "70 4397.007687478952\n",
      "71 4142.578628339742\n",
      "72 3904.4148054012717\n",
      "73 3681.425948849619\n",
      "74 3472.4325516265403\n",
      "75 3276.513803642146\n",
      "76 3092.7213314558876\n",
      "77 2920.2495156773903\n",
      "78 2758.268014399933\n",
      "79 2606.0531697109773\n",
      "80 2463.0071222006486\n",
      "81 2328.5180715446977\n",
      "82 2201.964947529917\n",
      "83 2082.875091230394\n",
      "84 1970.804033212293\n",
      "85 1865.2483383411595\n",
      "86 1765.7823122280947\n",
      "87 1672.0454818245828\n",
      "88 1583.665612858208\n",
      "89 1500.2842425889526\n",
      "90 1421.5953330255188\n",
      "91 1347.3512310088415\n",
      "92 1277.2640825946614\n",
      "93 1211.0371392204543\n",
      "94 1148.471722536563\n",
      "95 1089.3614036842919\n",
      "96 1033.4912229227161\n",
      "97 980.6461421323506\n",
      "98 930.6661194168205\n",
      "99 883.3973114886721\n",
      "100 838.6695807889396\n",
      "101 796.3256149581654\n",
      "102 756.2354610057372\n",
      "103 718.2891249709886\n",
      "104 682.3358844483785\n",
      "105 648.2762592671128\n",
      "106 616.0161036038803\n",
      "107 585.4469502506015\n",
      "108 556.4583138348355\n",
      "109 528.9717402953353\n",
      "110 502.91326204456317\n",
      "111 478.1988613837949\n",
      "112 454.75157736299985\n",
      "113 432.49804888217204\n",
      "114 411.3900092545924\n",
      "115 391.3524690932712\n",
      "116 372.32926734032094\n",
      "117 354.2672430293853\n",
      "118 337.12717455342823\n",
      "119 320.83801879988465\n",
      "120 305.36547421815646\n",
      "121 290.6680040365701\n",
      "122 276.7078835455698\n",
      "123 263.4363121672365\n",
      "124 250.8264244388112\n",
      "125 238.84210889496973\n",
      "126 227.45015362053687\n",
      "127 216.61711503201343\n",
      "128 206.3162206687791\n",
      "129 196.524629261768\n",
      "130 187.21060565544374\n",
      "131 178.35056086299375\n",
      "132 169.92145541564497\n",
      "133 161.90744326829775\n",
      "134 154.27863017211445\n",
      "135 147.0188959988107\n",
      "136 140.11142718096082\n",
      "137 133.54137024331706\n",
      "138 127.2833034914486\n",
      "139 121.32645924490089\n",
      "140 115.65684494652709\n",
      "141 110.25979381838427\n",
      "142 105.12886243471793\n",
      "143 100.24406328396788\n",
      "144 95.594497673093\n",
      "145 91.1647049931867\n",
      "146 86.94484219165625\n",
      "147 82.9246725256443\n",
      "148 79.0966256561029\n",
      "149 75.44777423500865\n",
      "150 71.97093961699522\n",
      "151 68.65824310636191\n",
      "152 65.5034287430089\n",
      "153 62.4945451479875\n",
      "154 59.63252795879014\n",
      "155 56.92360231939088\n",
      "156 54.34221869835159\n",
      "157 51.88072668207819\n",
      "158 49.53346765448766\n",
      "159 47.294371761347826\n",
      "160 45.16039730818013\n",
      "161 43.125648773212895\n",
      "162 41.1838583260175\n",
      "163 39.33188439915618\n",
      "164 37.56506471397639\n",
      "165 35.879479272985364\n",
      "166 34.27164510934627\n",
      "167 32.736641117026224\n",
      "168 31.271806244908774\n",
      "169 29.873819584428787\n",
      "170 28.539925986627267\n",
      "171 27.267262710062063\n",
      "172 26.05185808585066\n",
      "173 24.89263772929233\n",
      "174 23.78531461053445\n",
      "175 22.72836229689657\n",
      "176 21.719050875717453\n",
      "177 20.755246703895807\n",
      "178 19.835020052425364\n",
      "179 18.956372118016695\n",
      "180 18.117647910592858\n",
      "181 17.316670222526646\n",
      "182 16.551487086417154\n",
      "183 15.820744788759956\n",
      "184 15.122749226502108\n",
      "185 14.456358385082996\n",
      "186 13.819800058373977\n",
      "187 13.211551997023953\n",
      "188 12.630642598308206\n",
      "189 12.075740953320057\n",
      "190 11.546275282505444\n",
      "191 11.039659311162422\n",
      "192 10.55559910261348\n",
      "193 10.093186422808882\n",
      "194 9.651358051129375\n",
      "195 9.229356562365773\n",
      "196 8.82591413878448\n",
      "197 8.440380343046106\n",
      "198 8.071910239783673\n",
      "199 7.719759780835202\n",
      "200 7.383446384582271\n",
      "201 7.061813021351341\n",
      "202 6.754364651661085\n",
      "203 6.460498351273634\n",
      "204 6.179690751890378\n",
      "205 5.911372702155204\n",
      "206 5.654731233193331\n",
      "207 5.409651655054372\n",
      "208 5.175101201612939\n",
      "209 4.950846738440528\n",
      "210 4.736612878082607\n",
      "211 4.531629802768895\n",
      "212 4.335661272874368\n",
      "213 4.148259455677289\n",
      "214 3.9690807730674122\n",
      "215 3.797850401452821\n",
      "216 3.6339906037919234\n",
      "217 3.4772973315177724\n",
      "218 3.327448534672095\n",
      "219 3.1841535105469223\n",
      "220 3.0472168370097026\n",
      "221 2.916153029098168\n",
      "222 2.7907758069113546\n",
      "223 2.670859968215676\n",
      "224 2.5562500493436193\n",
      "225 2.4466937957084443\n",
      "226 2.3417507948982887\n",
      "227 2.2413858499156403\n",
      "228 2.1453558661366294\n",
      "229 2.053483767275799\n",
      "230 1.9656564164105386\n",
      "231 1.8815971225852623\n",
      "232 1.8011652334973105\n",
      "233 1.7242071192777222\n",
      "234 1.650582285811515\n",
      "235 1.580192663857309\n",
      "236 1.5127840420566638\n",
      "237 1.4482809013531854\n",
      "238 1.3865692771982774\n",
      "239 1.3275154183213322\n",
      "240 1.2710296410929907\n",
      "241 1.2169601720453789\n",
      "242 1.1652786426161703\n",
      "243 1.1157486567236834\n",
      "244 1.0683563350926177\n",
      "245 1.0230258406184563\n",
      "246 0.9796060900015531\n",
      "247 0.9380493531275181\n",
      "248 0.8982745678356227\n",
      "249 0.8602074333241656\n",
      "250 0.8238031138698081\n",
      "251 0.788933100720419\n",
      "252 0.7555492783212637\n",
      "253 0.7235921365959105\n",
      "254 0.6930014205523379\n",
      "255 0.6637313310394746\n",
      "256 0.6357064136940338\n",
      "257 0.6088717726887978\n",
      "258 0.5831782707357522\n",
      "259 0.5585792828932783\n",
      "260 0.5350651320103267\n",
      "261 0.512528654395712\n",
      "262 0.4909427359230473\n",
      "263 0.47027402368584026\n",
      "264 0.45048418443593063\n",
      "265 0.43154599632910207\n",
      "266 0.4134037423832007\n",
      "267 0.39603064085114015\n",
      "268 0.3793925164682578\n",
      "269 0.3634612673816733\n",
      "270 0.34821010097957616\n",
      "271 0.3336070505382329\n",
      "272 0.3196244173072097\n",
      "273 0.3062268707177686\n",
      "274 0.293394293876124\n",
      "275 0.28110769561986776\n",
      "276 0.2693438226310809\n",
      "277 0.2580713157695769\n",
      "278 0.24729174470118004\n",
      "279 0.23695242842701905\n",
      "280 0.22705224115325812\n",
      "281 0.21756946016197404\n",
      "282 0.20848246601970288\n",
      "283 0.19978002087133995\n",
      "284 0.19144251295567608\n",
      "285 0.18345713619946374\n",
      "286 0.17581210784299287\n",
      "287 0.1684846080840993\n",
      "288 0.16146517406993094\n",
      "289 0.15474132857093917\n",
      "290 0.1482984374170359\n",
      "291 0.14213031494963982\n",
      "292 0.1362191533712959\n",
      "293 0.1305550086523042\n",
      "294 0.12512943634361368\n",
      "295 0.11992943598897551\n",
      "296 0.11495424543864524\n",
      "297 0.11018482905878078\n",
      "298 0.10561174397208511\n",
      "299 0.10122978640204366\n",
      "300 0.0970308111971265\n",
      "301 0.0930109371075326\n",
      "302 0.08915597623971433\n",
      "303 0.08546217218492512\n",
      "304 0.08192276363833928\n",
      "305 0.0785308759471298\n",
      "306 0.07528253675453156\n",
      "307 0.07216827735605075\n",
      "308 0.06918423987111003\n",
      "309 0.06632415908531397\n",
      "310 0.06358281493302488\n",
      "311 0.06095655964168006\n",
      "312 0.05843995074944156\n",
      "313 0.056027802591722554\n",
      "314 0.053715664948450176\n",
      "315 0.051502372871049196\n",
      "316 0.04937979912077399\n",
      "317 0.04734416415513419\n",
      "318 0.04539290059751059\n",
      "319 0.04352249178694581\n",
      "320 0.04172966627062989\n",
      "321 0.0400117014709227\n",
      "322 0.038365729102963736\n",
      "323 0.036787361672196865\n",
      "324 0.035273948752145054\n",
      "325 0.03382340109429344\n",
      "326 0.03243298070609791\n",
      "327 0.031100857072233097\n",
      "328 0.02982315549876359\n",
      "329 0.028598407454244468\n",
      "330 0.027424472784007087\n",
      "331 0.026298745363369153\n",
      "332 0.025220332778307708\n",
      "333 0.024186075851489852\n",
      "334 0.02319544724302861\n",
      "335 0.02224480369288121\n",
      "336 0.021333206198285944\n",
      "337 0.02046006490524163\n",
      "338 0.019622082253282914\n",
      "339 0.018818591420890658\n",
      "340 0.01804821371215508\n",
      "341 0.017309697962609696\n",
      "342 0.016601976383259425\n",
      "343 0.015923127293161365\n",
      "344 0.015272199535028615\n",
      "345 0.014647983719788754\n",
      "346 0.014049541570050573\n",
      "347 0.01347575833352452\n",
      "348 0.012925570587434243\n",
      "349 0.012397833481875942\n",
      "350 0.011891899711076393\n",
      "351 0.011406791753616072\n",
      "352 0.0109415332603604\n",
      "353 0.010495672669029156\n",
      "354 0.010068394440062828\n",
      "355 0.009658119669103012\n",
      "356 0.009264573264661551\n",
      "357 0.008887255164451551\n",
      "358 0.008525528715208942\n",
      "359 0.00817843812570912\n",
      "360 0.007845579589500235\n",
      "361 0.007526312595675107\n",
      "362 0.007220137040271502\n",
      "363 0.006926658724030458\n",
      "364 0.0066450432067099545\n",
      "365 0.006374970784951236\n",
      "366 0.006115880091749398\n",
      "367 0.005867396527508748\n",
      "368 0.005629251025407202\n",
      "369 0.005400681827822294\n",
      "370 0.005181420719692475\n",
      "371 0.004971117083164869\n",
      "372 0.004769500704839085\n",
      "373 0.0045760890601487855\n",
      "374 0.004390728243334536\n",
      "375 0.004212820996912859\n",
      "376 0.0040420973408636495\n",
      "377 0.0038782905992924338\n",
      "378 0.0037212305588327655\n",
      "379 0.0035705445953611724\n",
      "380 0.003425945080047273\n",
      "381 0.003287252280319143\n",
      "382 0.0031542032483873146\n",
      "383 0.0030265917080826354\n",
      "384 0.0029041717845199612\n",
      "385 0.0027867241702171476\n",
      "386 0.0026740495224092894\n",
      "387 0.0025659308351586607\n",
      "388 0.0024622306726577742\n",
      "389 0.0023628049194786725\n",
      "390 0.002267339189337898\n",
      "391 0.002175751463030772\n",
      "392 0.0020879020231483287\n",
      "393 0.0020036256760970865\n",
      "394 0.0019227982505948004\n",
      "395 0.0018452928556100107\n",
      "396 0.0017708706397871472\n",
      "397 0.0016994443296178784\n",
      "398 0.001630938033716835\n",
      "399 0.00156521849525154\n",
      "400 0.0015021268155512313\n",
      "401 0.0014415897812420787\n",
      "402 0.0013835045379780525\n",
      "403 0.0013277718750092978\n",
      "404 0.001274322279557456\n",
      "405 0.0012230129173529409\n",
      "406 0.001173787055668102\n",
      "407 0.0011265429933228987\n",
      "408 0.0010812044022018058\n",
      "409 0.001037725678833357\n",
      "410 0.000995999840345358\n",
      "411 0.0009559425174117298\n",
      "412 0.0009175016040126255\n",
      "413 0.000880626232380702\n",
      "414 0.0008452430057050979\n",
      "415 0.0008112874226179445\n",
      "416 0.0007787145780862516\n",
      "417 0.0007474655508148465\n",
      "418 0.000717446812250033\n",
      "419 0.0006886481414442756\n",
      "420 0.0006610195996488192\n",
      "421 0.0006344939251527313\n",
      "422 0.0006090352265542621\n",
      "423 0.0005846004041192827\n",
      "424 0.0005611531854916291\n",
      "425 0.0005386597020836581\n",
      "426 0.0005170612513492574\n",
      "427 0.0004963369451857196\n",
      "428 0.0004764419740236332\n",
      "429 0.00045735357023037835\n",
      "430 0.00043903830077150194\n",
      "431 0.0004214485639770485\n",
      "432 0.00040456708692874533\n",
      "433 0.00038836930247387934\n",
      "434 0.0003728211190065329\n",
      "435 0.00035790405391410325\n",
      "436 0.0003435815819621824\n",
      "437 0.00032983366847769006\n",
      "438 0.0003166382539298847\n",
      "439 0.0003039882746407093\n",
      "440 0.0002918391058309424\n",
      "441 0.0002801717082848963\n",
      "442 0.0002689701324819683\n",
      "443 0.0002582190607671019\n",
      "444 0.00024790214428022816\n",
      "445 0.00023800120555018538\n",
      "446 0.0002284937461057017\n",
      "447 0.00021936760512527673\n",
      "448 0.0002106081385525679\n",
      "449 0.00020219755280737688\n",
      "450 0.00019412641774631297\n",
      "451 0.00018637879460814546\n",
      "452 0.0001789405723463062\n",
      "453 0.000171799276606565\n",
      "454 0.00016494649759200955\n",
      "455 0.00015836707813207223\n",
      "456 0.00015205359147610695\n",
      "457 0.00014598918551685883\n",
      "458 0.0001401680487555201\n",
      "459 0.0001345803887324269\n",
      "460 0.0001292168295560847\n",
      "461 0.00012407067881961082\n",
      "462 0.00011913452946968026\n",
      "463 0.00011438731305215142\n",
      "464 0.00010983029616131137\n",
      "465 0.00010545610114315577\n",
      "466 0.00010125863003459805\n",
      "467 9.722749928747525e-05\n",
      "468 9.3358590522659e-05\n",
      "469 8.964233112127666e-05\n",
      "470 8.60746757387264e-05\n",
      "471 8.265160030459972e-05\n",
      "472 7.936327917791453e-05\n",
      "473 7.620618441363472e-05\n",
      "474 7.317585091913062e-05\n",
      "475 7.026569197035221e-05\n",
      "476 6.747269363014489e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 6.479058059689731e-05\n",
      "478 6.221526319971121e-05\n",
      "479 5.9742248742643784e-05\n",
      "480 5.7367839689913184e-05\n",
      "481 5.5089659120857544e-05\n",
      "482 5.29016083545676e-05\n",
      "483 5.080017447109259e-05\n",
      "484 4.878235353831583e-05\n",
      "485 4.684719268110266e-05\n",
      "486 4.498858694888523e-05\n",
      "487 4.320286365080256e-05\n",
      "488 4.148828238018003e-05\n",
      "489 3.984173376711199e-05\n",
      "490 3.82604611926163e-05\n",
      "491 3.674267448283093e-05\n",
      "492 3.528577650680684e-05\n",
      "493 3.388620106898997e-05\n",
      "494 3.254230122373735e-05\n",
      "495 3.125192953635249e-05\n",
      "496 3.001283711606239e-05\n",
      "497 2.8823356483802172e-05\n",
      "498 2.7680591236186737e-05\n",
      "499 2.658353347097475e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "# N은 배치 크기이며, D_in은 입력의 차원입니다;\n",
    "# H는 은닉 계층의 차원이며, D_out은 출력 차원입니다:\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 무작위의 입력과 출력 데이터를 생성합니다.\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# 무작위로 가중치를 초기화합니다.\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 순전파 단계: 예측값 y를 계산합니다.\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # 손실(loss)을 계산하고 출력합니다.\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # 손실에 따른 w1, w2의 변화도를 계산하고 역전파합니다.\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # 가중치를 갱신합니다.\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(32286998., device='cuda:0')\n",
      "1 tensor(26419928., device='cuda:0')\n",
      "2 tensor(22868584., device='cuda:0')\n",
      "3 tensor(18751144., device='cuda:0')\n",
      "4 tensor(14016036., device='cuda:0')\n",
      "5 tensor(9545731., device='cuda:0')\n",
      "6 tensor(6176968., device='cuda:0')\n",
      "7 tensor(3957021.7500, device='cuda:0')\n",
      "8 tensor(2615198., device='cuda:0')\n",
      "9 tensor(1817381.2500, device='cuda:0')\n",
      "10 tensor(1334801.2500, device='cuda:0')\n",
      "11 tensor(1028522.1250, device='cuda:0')\n",
      "12 tensor(822915.4375, device='cuda:0')\n",
      "13 tensor(676146.3750, device='cuda:0')\n",
      "14 tensor(566002., device='cuda:0')\n",
      "15 tensor(479965.9688, device='cuda:0')\n",
      "16 tensor(410855.6250, device='cuda:0')\n",
      "17 tensor(354274.2500, device='cuda:0')\n",
      "18 tensor(307186.9688, device='cuda:0')\n",
      "19 tensor(267592.9375, device='cuda:0')\n",
      "20 tensor(234040.2656, device='cuda:0')\n",
      "21 tensor(205444.1562, device='cuda:0')\n",
      "22 tensor(180955.1406, device='cuda:0')\n",
      "23 tensor(159909., device='cuda:0')\n",
      "24 tensor(141748.4375, device='cuda:0')\n",
      "25 tensor(126003.8516, device='cuda:0')\n",
      "26 tensor(112278.8828, device='cuda:0')\n",
      "27 tensor(100276.9688, device='cuda:0')\n",
      "28 tensor(89750.0156, device='cuda:0')\n",
      "29 tensor(80478.4219, device='cuda:0')\n",
      "30 tensor(72309.1406, device='cuda:0')\n",
      "31 tensor(65096.8438, device='cuda:0')\n",
      "32 tensor(58727.4141, device='cuda:0')\n",
      "33 tensor(53078.3906, device='cuda:0')\n",
      "34 tensor(48050.7930, device='cuda:0')\n",
      "35 tensor(43569.4141, device='cuda:0')\n",
      "36 tensor(39564.1680, device='cuda:0')\n",
      "37 tensor(35982.8906, device='cuda:0')\n",
      "38 tensor(32771.3672, device='cuda:0')\n",
      "39 tensor(29886.5918, device='cuda:0')\n",
      "40 tensor(27290.1836, device='cuda:0')\n",
      "41 tensor(24948.6875, device='cuda:0')\n",
      "42 tensor(22836.1133, device='cuda:0')\n",
      "43 tensor(20927.2500, device='cuda:0')\n",
      "44 tensor(19197.9453, device='cuda:0')\n",
      "45 tensor(17630.2246, device='cuda:0')\n",
      "46 tensor(16206.9141, device='cuda:0')\n",
      "47 tensor(14913.8359, device='cuda:0')\n",
      "48 tensor(13736.9619, device='cuda:0')\n",
      "49 tensor(12664.3545, device='cuda:0')\n",
      "50 tensor(11685.7949, device='cuda:0')\n",
      "51 tensor(10792.3037, device='cuda:0')\n",
      "52 tensor(9975.6602, device='cuda:0')\n",
      "53 tensor(9228.4834, device='cuda:0')\n",
      "54 tensor(8543.4785, device='cuda:0')\n",
      "55 tensor(7915.2671, device='cuda:0')\n",
      "56 tensor(7338.7280, device='cuda:0')\n",
      "57 tensor(6808.9844, device='cuda:0')\n",
      "58 tensor(6321.9648, device='cuda:0')\n",
      "59 tensor(5873.6240, device='cuda:0')\n",
      "60 tensor(5460.6382, device='cuda:0')\n",
      "61 tensor(5079.9092, device='cuda:0')\n",
      "62 tensor(4728.6841, device='cuda:0')\n",
      "63 tensor(4404.9292, device='cuda:0')\n",
      "64 tensor(4105.6084, device='cuda:0')\n",
      "65 tensor(3828.9233, device='cuda:0')\n",
      "66 tensor(3572.7847, device='cuda:0')\n",
      "67 tensor(3335.5586, device='cuda:0')\n",
      "68 tensor(3115.7986, device='cuda:0')\n",
      "69 tensor(2911.9150, device='cuda:0')\n",
      "70 tensor(2722.7578, device='cuda:0')\n",
      "71 tensor(2547.1025, device='cuda:0')\n",
      "72 tensor(2383.8542, device='cuda:0')\n",
      "73 tensor(2232.1389, device='cuda:0')\n",
      "74 tensor(2091.0825, device='cuda:0')\n",
      "75 tensor(1959.8337, device='cuda:0')\n",
      "76 tensor(1837.5894, device='cuda:0')\n",
      "77 tensor(1723.6772, device='cuda:0')\n",
      "78 tensor(1617.5168, device='cuda:0')\n",
      "79 tensor(1518.4679, device='cuda:0')\n",
      "80 tensor(1426.0652, device='cuda:0')\n",
      "81 tensor(1339.7599, device='cuda:0')\n",
      "82 tensor(1259.1647, device='cuda:0')\n",
      "83 tensor(1183.8665, device='cuda:0')\n",
      "84 tensor(1113.4462, device='cuda:0')\n",
      "85 tensor(1047.5825, device='cuda:0')\n",
      "86 tensor(985.9431, device='cuda:0')\n",
      "87 tensor(928.2361, device='cuda:0')\n",
      "88 tensor(874.2013, device='cuda:0')\n",
      "89 tensor(823.5479, device='cuda:0')\n",
      "90 tensor(776.0900, device='cuda:0')\n",
      "91 tensor(731.5797, device='cuda:0')\n",
      "92 tensor(689.8268, device='cuda:0')\n",
      "93 tensor(650.6447, device='cuda:0')\n",
      "94 tensor(613.8571, device='cuda:0')\n",
      "95 tensor(579.3199, device='cuda:0')\n",
      "96 tensor(546.8665, device='cuda:0')\n",
      "97 tensor(516.3751, device='cuda:0')\n",
      "98 tensor(487.7047, device='cuda:0')\n",
      "99 tensor(460.7395, device='cuda:0')\n",
      "100 tensor(435.3769, device='cuda:0')\n",
      "101 tensor(411.5116, device='cuda:0')\n",
      "102 tensor(389.0426, device='cuda:0')\n",
      "103 tensor(367.8856, device='cuda:0')\n",
      "104 tensor(347.9652, device='cuda:0')\n",
      "105 tensor(329.1946, device='cuda:0')\n",
      "106 tensor(311.5027, device='cuda:0')\n",
      "107 tensor(294.8227, device='cuda:0')\n",
      "108 tensor(279.0951, device='cuda:0')\n",
      "109 tensor(264.2645, device='cuda:0')\n",
      "110 tensor(250.2720, device='cuda:0')\n",
      "111 tensor(237.0641, device='cuda:0')\n",
      "112 tensor(224.5964, device='cuda:0')\n",
      "113 tensor(212.8266, device='cuda:0')\n",
      "114 tensor(201.7094, device='cuda:0')\n",
      "115 tensor(191.2092, device='cuda:0')\n",
      "116 tensor(181.2887, device='cuda:0')\n",
      "117 tensor(171.9095, device='cuda:0')\n",
      "118 tensor(163.0443, device='cuda:0')\n",
      "119 tensor(154.6623, device='cuda:0')\n",
      "120 tensor(146.7354, device='cuda:0')\n",
      "121 tensor(139.2400, device='cuda:0')\n",
      "122 tensor(132.1452, device='cuda:0')\n",
      "123 tensor(125.4326, device='cuda:0')\n",
      "124 tensor(119.0770, device='cuda:0')\n",
      "125 tensor(113.0624, device='cuda:0')\n",
      "126 tensor(107.3666, device='cuda:0')\n",
      "127 tensor(101.9731, device='cuda:0')\n",
      "128 tensor(96.8642, device='cuda:0')\n",
      "129 tensor(92.0213, device='cuda:0')\n",
      "130 tensor(87.4341, device='cuda:0')\n",
      "131 tensor(83.0856, device='cuda:0')\n",
      "132 tensor(78.9647, device='cuda:0')\n",
      "133 tensor(75.0566, device='cuda:0')\n",
      "134 tensor(71.3521, device='cuda:0')\n",
      "135 tensor(67.8377, device='cuda:0')\n",
      "136 tensor(64.5058, device='cuda:0')\n",
      "137 tensor(61.3433, device='cuda:0')\n",
      "138 tensor(58.3437, device='cuda:0')\n",
      "139 tensor(55.4959, device='cuda:0')\n",
      "140 tensor(52.7935, device='cuda:0')\n",
      "141 tensor(50.2281, device='cuda:0')\n",
      "142 tensor(47.7924, device='cuda:0')\n",
      "143 tensor(45.4796, device='cuda:0')\n",
      "144 tensor(43.2835, device='cuda:0')\n",
      "145 tensor(41.1979, device='cuda:0')\n",
      "146 tensor(39.2161, device='cuda:0')\n",
      "147 tensor(37.3332, device='cuda:0')\n",
      "148 tensor(35.5454, device='cuda:0')\n",
      "149 tensor(33.8459, device='cuda:0')\n",
      "150 tensor(32.2300, device='cuda:0')\n",
      "151 tensor(30.6940, device='cuda:0')\n",
      "152 tensor(29.2339, device='cuda:0')\n",
      "153 tensor(27.8462, device='cuda:0')\n",
      "154 tensor(26.5264, device='cuda:0')\n",
      "155 tensor(25.2717, device='cuda:0')\n",
      "156 tensor(24.0780, device='cuda:0')\n",
      "157 tensor(22.9424, device='cuda:0')\n",
      "158 tensor(21.8621, device='cuda:0')\n",
      "159 tensor(20.8350, device='cuda:0')\n",
      "160 tensor(19.8576, device='cuda:0')\n",
      "161 tensor(18.9268, device='cuda:0')\n",
      "162 tensor(18.0411, device='cuda:0')\n",
      "163 tensor(17.1988, device='cuda:0')\n",
      "164 tensor(16.3969, device='cuda:0')\n",
      "165 tensor(15.6329, device='cuda:0')\n",
      "166 tensor(14.9063, device='cuda:0')\n",
      "167 tensor(14.2135, device='cuda:0')\n",
      "168 tensor(13.5547, device='cuda:0')\n",
      "169 tensor(12.9269, device='cuda:0')\n",
      "170 tensor(12.3290, device='cuda:0')\n",
      "171 tensor(11.7597, device='cuda:0')\n",
      "172 tensor(11.2170, device='cuda:0')\n",
      "173 tensor(10.7006, device='cuda:0')\n",
      "174 tensor(10.2085, device='cuda:0')\n",
      "175 tensor(9.7393, device='cuda:0')\n",
      "176 tensor(9.2927, device='cuda:0')\n",
      "177 tensor(8.8666, device='cuda:0')\n",
      "178 tensor(8.4606, device='cuda:0')\n",
      "179 tensor(8.0738, device='cuda:0')\n",
      "180 tensor(7.7054, device='cuda:0')\n",
      "181 tensor(7.3539, device='cuda:0')\n",
      "182 tensor(7.0187, device='cuda:0')\n",
      "183 tensor(6.6993, device='cuda:0')\n",
      "184 tensor(6.3948, device='cuda:0')\n",
      "185 tensor(6.1045, device='cuda:0')\n",
      "186 tensor(5.8276, device='cuda:0')\n",
      "187 tensor(5.5636, device='cuda:0')\n",
      "188 tensor(5.3118, device='cuda:0')\n",
      "189 tensor(5.0717, device='cuda:0')\n",
      "190 tensor(4.8425, device='cuda:0')\n",
      "191 tensor(4.6240, device='cuda:0')\n",
      "192 tensor(4.4155, device='cuda:0')\n",
      "193 tensor(4.2168, device='cuda:0')\n",
      "194 tensor(4.0270, device='cuda:0')\n",
      "195 tensor(3.8460, device='cuda:0')\n",
      "196 tensor(3.6735, device='cuda:0')\n",
      "197 tensor(3.5087, device='cuda:0')\n",
      "198 tensor(3.3514, device='cuda:0')\n",
      "199 tensor(3.2013, device='cuda:0')\n",
      "200 tensor(3.0581, device='cuda:0')\n",
      "201 tensor(2.9214, device='cuda:0')\n",
      "202 tensor(2.7910, device='cuda:0')\n",
      "203 tensor(2.6666, device='cuda:0')\n",
      "204 tensor(2.5476, device='cuda:0')\n",
      "205 tensor(2.4341, device='cuda:0')\n",
      "206 tensor(2.3258, device='cuda:0')\n",
      "207 tensor(2.2225, device='cuda:0')\n",
      "208 tensor(2.1237, device='cuda:0')\n",
      "209 tensor(2.0293, device='cuda:0')\n",
      "210 tensor(1.9394, device='cuda:0')\n",
      "211 tensor(1.8534, device='cuda:0')\n",
      "212 tensor(1.7713, device='cuda:0')\n",
      "213 tensor(1.6930, device='cuda:0')\n",
      "214 tensor(1.6181, device='cuda:0')\n",
      "215 tensor(1.5466, device='cuda:0')\n",
      "216 tensor(1.4783, device='cuda:0')\n",
      "217 tensor(1.4130, device='cuda:0')\n",
      "218 tensor(1.3507, device='cuda:0')\n",
      "219 tensor(1.2912, device='cuda:0')\n",
      "220 tensor(1.2344, device='cuda:0')\n",
      "221 tensor(1.1801, device='cuda:0')\n",
      "222 tensor(1.1283, device='cuda:0')\n",
      "223 tensor(1.0787, device='cuda:0')\n",
      "224 tensor(1.0312, device='cuda:0')\n",
      "225 tensor(0.9860, device='cuda:0')\n",
      "226 tensor(0.9428, device='cuda:0')\n",
      "227 tensor(0.9015, device='cuda:0')\n",
      "228 tensor(0.8620, device='cuda:0')\n",
      "229 tensor(0.8243, device='cuda:0')\n",
      "230 tensor(0.7882, device='cuda:0')\n",
      "231 tensor(0.7537, device='cuda:0')\n",
      "232 tensor(0.7208, device='cuda:0')\n",
      "233 tensor(0.6894, device='cuda:0')\n",
      "234 tensor(0.6593, device='cuda:0')\n",
      "235 tensor(0.6306, device='cuda:0')\n",
      "236 tensor(0.6031, device='cuda:0')\n",
      "237 tensor(0.5768, device='cuda:0')\n",
      "238 tensor(0.5517, device='cuda:0')\n",
      "239 tensor(0.5277, device='cuda:0')\n",
      "240 tensor(0.5048, device='cuda:0')\n",
      "241 tensor(0.4828, device='cuda:0')\n",
      "242 tensor(0.4619, device='cuda:0')\n",
      "243 tensor(0.4418, device='cuda:0')\n",
      "244 tensor(0.4227, device='cuda:0')\n",
      "245 tensor(0.4043, device='cuda:0')\n",
      "246 tensor(0.3868, device='cuda:0')\n",
      "247 tensor(0.3701, device='cuda:0')\n",
      "248 tensor(0.3541, device='cuda:0')\n",
      "249 tensor(0.3387, device='cuda:0')\n",
      "250 tensor(0.3241, device='cuda:0')\n",
      "251 tensor(0.3101, device='cuda:0')\n",
      "252 tensor(0.2967, device='cuda:0')\n",
      "253 tensor(0.2839, device='cuda:0')\n",
      "254 tensor(0.2716, device='cuda:0')\n",
      "255 tensor(0.2599, device='cuda:0')\n",
      "256 tensor(0.2487, device='cuda:0')\n",
      "257 tensor(0.2380, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 tensor(0.2278, device='cuda:0')\n",
      "259 tensor(0.2179, device='cuda:0')\n",
      "260 tensor(0.2086, device='cuda:0')\n",
      "261 tensor(0.1996, device='cuda:0')\n",
      "262 tensor(0.1910, device='cuda:0')\n",
      "263 tensor(0.1828, device='cuda:0')\n",
      "264 tensor(0.1750, device='cuda:0')\n",
      "265 tensor(0.1674, device='cuda:0')\n",
      "266 tensor(0.1602, device='cuda:0')\n",
      "267 tensor(0.1534, device='cuda:0')\n",
      "268 tensor(0.1468, device='cuda:0')\n",
      "269 tensor(0.1405, device='cuda:0')\n",
      "270 tensor(0.1345, device='cuda:0')\n",
      "271 tensor(0.1288, device='cuda:0')\n",
      "272 tensor(0.1233, device='cuda:0')\n",
      "273 tensor(0.1180, device='cuda:0')\n",
      "274 tensor(0.1129, device='cuda:0')\n",
      "275 tensor(0.1081, device='cuda:0')\n",
      "276 tensor(0.1035, device='cuda:0')\n",
      "277 tensor(0.0991, device='cuda:0')\n",
      "278 tensor(0.0948, device='cuda:0')\n",
      "279 tensor(0.0908, device='cuda:0')\n",
      "280 tensor(0.0869, device='cuda:0')\n",
      "281 tensor(0.0832, device='cuda:0')\n",
      "282 tensor(0.0797, device='cuda:0')\n",
      "283 tensor(0.0763, device='cuda:0')\n",
      "284 tensor(0.0731, device='cuda:0')\n",
      "285 tensor(0.0699, device='cuda:0')\n",
      "286 tensor(0.0670, device='cuda:0')\n",
      "287 tensor(0.0641, device='cuda:0')\n",
      "288 tensor(0.0614, device='cuda:0')\n",
      "289 tensor(0.0588, device='cuda:0')\n",
      "290 tensor(0.0563, device='cuda:0')\n",
      "291 tensor(0.0539, device='cuda:0')\n",
      "292 tensor(0.0516, device='cuda:0')\n",
      "293 tensor(0.0494, device='cuda:0')\n",
      "294 tensor(0.0474, device='cuda:0')\n",
      "295 tensor(0.0454, device='cuda:0')\n",
      "296 tensor(0.0434, device='cuda:0')\n",
      "297 tensor(0.0416, device='cuda:0')\n",
      "298 tensor(0.0398, device='cuda:0')\n",
      "299 tensor(0.0381, device='cuda:0')\n",
      "300 tensor(0.0365, device='cuda:0')\n",
      "301 tensor(0.0350, device='cuda:0')\n",
      "302 tensor(0.0335, device='cuda:0')\n",
      "303 tensor(0.0321, device='cuda:0')\n",
      "304 tensor(0.0308, device='cuda:0')\n",
      "305 tensor(0.0295, device='cuda:0')\n",
      "306 tensor(0.0282, device='cuda:0')\n",
      "307 tensor(0.0270, device='cuda:0')\n",
      "308 tensor(0.0259, device='cuda:0')\n",
      "309 tensor(0.0248, device='cuda:0')\n",
      "310 tensor(0.0238, device='cuda:0')\n",
      "311 tensor(0.0228, device='cuda:0')\n",
      "312 tensor(0.0218, device='cuda:0')\n",
      "313 tensor(0.0209, device='cuda:0')\n",
      "314 tensor(0.0200, device='cuda:0')\n",
      "315 tensor(0.0192, device='cuda:0')\n",
      "316 tensor(0.0184, device='cuda:0')\n",
      "317 tensor(0.0176, device='cuda:0')\n",
      "318 tensor(0.0169, device='cuda:0')\n",
      "319 tensor(0.0162, device='cuda:0')\n",
      "320 tensor(0.0155, device='cuda:0')\n",
      "321 tensor(0.0149, device='cuda:0')\n",
      "322 tensor(0.0143, device='cuda:0')\n",
      "323 tensor(0.0137, device='cuda:0')\n",
      "324 tensor(0.0131, device='cuda:0')\n",
      "325 tensor(0.0126, device='cuda:0')\n",
      "326 tensor(0.0121, device='cuda:0')\n",
      "327 tensor(0.0116, device='cuda:0')\n",
      "328 tensor(0.0111, device='cuda:0')\n",
      "329 tensor(0.0106, device='cuda:0')\n",
      "330 tensor(0.0102, device='cuda:0')\n",
      "331 tensor(0.0098, device='cuda:0')\n",
      "332 tensor(0.0094, device='cuda:0')\n",
      "333 tensor(0.0090, device='cuda:0')\n",
      "334 tensor(0.0086, device='cuda:0')\n",
      "335 tensor(0.0083, device='cuda:0')\n",
      "336 tensor(0.0080, device='cuda:0')\n",
      "337 tensor(0.0076, device='cuda:0')\n",
      "338 tensor(0.0073, device='cuda:0')\n",
      "339 tensor(0.0070, device='cuda:0')\n",
      "340 tensor(0.0068, device='cuda:0')\n",
      "341 tensor(0.0065, device='cuda:0')\n",
      "342 tensor(0.0062, device='cuda:0')\n",
      "343 tensor(0.0060, device='cuda:0')\n",
      "344 tensor(0.0057, device='cuda:0')\n",
      "345 tensor(0.0055, device='cuda:0')\n",
      "346 tensor(0.0053, device='cuda:0')\n",
      "347 tensor(0.0051, device='cuda:0')\n",
      "348 tensor(0.0049, device='cuda:0')\n",
      "349 tensor(0.0047, device='cuda:0')\n",
      "350 tensor(0.0045, device='cuda:0')\n",
      "351 tensor(0.0043, device='cuda:0')\n",
      "352 tensor(0.0042, device='cuda:0')\n",
      "353 tensor(0.0040, device='cuda:0')\n",
      "354 tensor(0.0039, device='cuda:0')\n",
      "355 tensor(0.0037, device='cuda:0')\n",
      "356 tensor(0.0036, device='cuda:0')\n",
      "357 tensor(0.0034, device='cuda:0')\n",
      "358 tensor(0.0033, device='cuda:0')\n",
      "359 tensor(0.0032, device='cuda:0')\n",
      "360 tensor(0.0031, device='cuda:0')\n",
      "361 tensor(0.0030, device='cuda:0')\n",
      "362 tensor(0.0028, device='cuda:0')\n",
      "363 tensor(0.0027, device='cuda:0')\n",
      "364 tensor(0.0026, device='cuda:0')\n",
      "365 tensor(0.0025, device='cuda:0')\n",
      "366 tensor(0.0024, device='cuda:0')\n",
      "367 tensor(0.0024, device='cuda:0')\n",
      "368 tensor(0.0023, device='cuda:0')\n",
      "369 tensor(0.0022, device='cuda:0')\n",
      "370 tensor(0.0021, device='cuda:0')\n",
      "371 tensor(0.0020, device='cuda:0')\n",
      "372 tensor(0.0020, device='cuda:0')\n",
      "373 tensor(0.0019, device='cuda:0')\n",
      "374 tensor(0.0018, device='cuda:0')\n",
      "375 tensor(0.0018, device='cuda:0')\n",
      "376 tensor(0.0017, device='cuda:0')\n",
      "377 tensor(0.0016, device='cuda:0')\n",
      "378 tensor(0.0016, device='cuda:0')\n",
      "379 tensor(0.0015, device='cuda:0')\n",
      "380 tensor(0.0015, device='cuda:0')\n",
      "381 tensor(0.0014, device='cuda:0')\n",
      "382 tensor(0.0014, device='cuda:0')\n",
      "383 tensor(0.0013, device='cuda:0')\n",
      "384 tensor(0.0013, device='cuda:0')\n",
      "385 tensor(0.0012, device='cuda:0')\n",
      "386 tensor(0.0012, device='cuda:0')\n",
      "387 tensor(0.0012, device='cuda:0')\n",
      "388 tensor(0.0011, device='cuda:0')\n",
      "389 tensor(0.0011, device='cuda:0')\n",
      "390 tensor(0.0011, device='cuda:0')\n",
      "391 tensor(0.0010, device='cuda:0')\n",
      "392 tensor(0.0010, device='cuda:0')\n",
      "393 tensor(0.0010, device='cuda:0')\n",
      "394 tensor(0.0009, device='cuda:0')\n",
      "395 tensor(0.0009, device='cuda:0')\n",
      "396 tensor(0.0009, device='cuda:0')\n",
      "397 tensor(0.0008, device='cuda:0')\n",
      "398 tensor(0.0008, device='cuda:0')\n",
      "399 tensor(0.0008, device='cuda:0')\n",
      "400 tensor(0.0008, device='cuda:0')\n",
      "401 tensor(0.0007, device='cuda:0')\n",
      "402 tensor(0.0007, device='cuda:0')\n",
      "403 tensor(0.0007, device='cuda:0')\n",
      "404 tensor(0.0007, device='cuda:0')\n",
      "405 tensor(0.0007, device='cuda:0')\n",
      "406 tensor(0.0006, device='cuda:0')\n",
      "407 tensor(0.0006, device='cuda:0')\n",
      "408 tensor(0.0006, device='cuda:0')\n",
      "409 tensor(0.0006, device='cuda:0')\n",
      "410 tensor(0.0006, device='cuda:0')\n",
      "411 tensor(0.0006, device='cuda:0')\n",
      "412 tensor(0.0005, device='cuda:0')\n",
      "413 tensor(0.0005, device='cuda:0')\n",
      "414 tensor(0.0005, device='cuda:0')\n",
      "415 tensor(0.0005, device='cuda:0')\n",
      "416 tensor(0.0005, device='cuda:0')\n",
      "417 tensor(0.0005, device='cuda:0')\n",
      "418 tensor(0.0005, device='cuda:0')\n",
      "419 tensor(0.0004, device='cuda:0')\n",
      "420 tensor(0.0004, device='cuda:0')\n",
      "421 tensor(0.0004, device='cuda:0')\n",
      "422 tensor(0.0004, device='cuda:0')\n",
      "423 tensor(0.0004, device='cuda:0')\n",
      "424 tensor(0.0004, device='cuda:0')\n",
      "425 tensor(0.0004, device='cuda:0')\n",
      "426 tensor(0.0004, device='cuda:0')\n",
      "427 tensor(0.0004, device='cuda:0')\n",
      "428 tensor(0.0004, device='cuda:0')\n",
      "429 tensor(0.0003, device='cuda:0')\n",
      "430 tensor(0.0003, device='cuda:0')\n",
      "431 tensor(0.0003, device='cuda:0')\n",
      "432 tensor(0.0003, device='cuda:0')\n",
      "433 tensor(0.0003, device='cuda:0')\n",
      "434 tensor(0.0003, device='cuda:0')\n",
      "435 tensor(0.0003, device='cuda:0')\n",
      "436 tensor(0.0003, device='cuda:0')\n",
      "437 tensor(0.0003, device='cuda:0')\n",
      "438 tensor(0.0003, device='cuda:0')\n",
      "439 tensor(0.0003, device='cuda:0')\n",
      "440 tensor(0.0003, device='cuda:0')\n",
      "441 tensor(0.0003, device='cuda:0')\n",
      "442 tensor(0.0002, device='cuda:0')\n",
      "443 tensor(0.0002, device='cuda:0')\n",
      "444 tensor(0.0002, device='cuda:0')\n",
      "445 tensor(0.0002, device='cuda:0')\n",
      "446 tensor(0.0002, device='cuda:0')\n",
      "447 tensor(0.0002, device='cuda:0')\n",
      "448 tensor(0.0002, device='cuda:0')\n",
      "449 tensor(0.0002, device='cuda:0')\n",
      "450 tensor(0.0002, device='cuda:0')\n",
      "451 tensor(0.0002, device='cuda:0')\n",
      "452 tensor(0.0002, device='cuda:0')\n",
      "453 tensor(0.0002, device='cuda:0')\n",
      "454 tensor(0.0002, device='cuda:0')\n",
      "455 tensor(0.0002, device='cuda:0')\n",
      "456 tensor(0.0002, device='cuda:0')\n",
      "457 tensor(0.0002, device='cuda:0')\n",
      "458 tensor(0.0002, device='cuda:0')\n",
      "459 tensor(0.0002, device='cuda:0')\n",
      "460 tensor(0.0002, device='cuda:0')\n",
      "461 tensor(0.0002, device='cuda:0')\n",
      "462 tensor(0.0002, device='cuda:0')\n",
      "463 tensor(0.0002, device='cuda:0')\n",
      "464 tensor(0.0002, device='cuda:0')\n",
      "465 tensor(0.0002, device='cuda:0')\n",
      "466 tensor(0.0001, device='cuda:0')\n",
      "467 tensor(0.0001, device='cuda:0')\n",
      "468 tensor(0.0001, device='cuda:0')\n",
      "469 tensor(0.0001, device='cuda:0')\n",
      "470 tensor(0.0001, device='cuda:0')\n",
      "471 tensor(0.0001, device='cuda:0')\n",
      "472 tensor(0.0001, device='cuda:0')\n",
      "473 tensor(0.0001, device='cuda:0')\n",
      "474 tensor(0.0001, device='cuda:0')\n",
      "475 tensor(0.0001, device='cuda:0')\n",
      "476 tensor(0.0001, device='cuda:0')\n",
      "477 tensor(0.0001, device='cuda:0')\n",
      "478 tensor(0.0001, device='cuda:0')\n",
      "479 tensor(0.0001, device='cuda:0')\n",
      "480 tensor(0.0001, device='cuda:0')\n",
      "481 tensor(0.0001, device='cuda:0')\n",
      "482 tensor(0.0001, device='cuda:0')\n",
      "483 tensor(0.0001, device='cuda:0')\n",
      "484 tensor(0.0001, device='cuda:0')\n",
      "485 tensor(0.0001, device='cuda:0')\n",
      "486 tensor(0.0001, device='cuda:0')\n",
      "487 tensor(0.0001, device='cuda:0')\n",
      "488 tensor(9.8586e-05, device='cuda:0')\n",
      "489 tensor(9.6928e-05, device='cuda:0')\n",
      "490 tensor(9.5371e-05, device='cuda:0')\n",
      "491 tensor(9.4031e-05, device='cuda:0')\n",
      "492 tensor(9.2332e-05, device='cuda:0')\n",
      "493 tensor(9.0768e-05, device='cuda:0')\n",
      "494 tensor(8.9320e-05, device='cuda:0')\n",
      "495 tensor(8.7471e-05, device='cuda:0')\n",
      "496 tensor(8.5809e-05, device='cuda:0')\n",
      "497 tensor(8.4473e-05, device='cuda:0')\n",
      "498 tensor(8.3294e-05, device='cuda:0')\n",
      "499 tensor(8.2114e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # GPU에서 실행하려면 이 주석을 제거하세요.\n",
    "\n",
    "# N은 배치 크기이며, D_in은 입력의 차원입니다;\n",
    "# H는 은닉 계층의 차원이며, D_out은 출력 차원입니다:\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 무작위의 입력과 출력 데이터를 생성합니다.\n",
    "x = torch.randn(N, D_in).type(dtype)\n",
    "y = torch.randn(N, D_out).type(dtype)\n",
    "\n",
    "# 무작위로 가중치를 초기화합니다.\n",
    "w1 = torch.randn(D_in, H).type(dtype)\n",
    "w2 = torch.randn(H, D_out).type(dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 순전파 단계: 예측값 y를 계산합니다.\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # 손실(loss)을 계산하고 출력합니다.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # 손실에 따른 w1, w2의 변화도를 계산하고 역전파합니다.\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # 경사하강법(Gradient Descent)를 사용하여 가중치를 갱신합니다.\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n",
      "0 tensor(0.6468)\n",
      "1 tensor(0.6466)\n",
      "2 tensor(0.6465)\n",
      "3 tensor(0.6463)\n",
      "4 tensor(0.6462)\n",
      "5 tensor(0.6461)\n",
      "6 tensor(0.6460)\n",
      "7 tensor(0.6459)\n",
      "8 tensor(0.6458)\n",
      "9 tensor(0.6458)\n",
      "10 tensor(0.6457)\n",
      "11 tensor(0.6456)\n",
      "12 tensor(0.6456)\n",
      "13 tensor(0.6455)\n",
      "14 tensor(0.6455)\n",
      "15 tensor(0.6454)\n",
      "16 tensor(0.6454)\n",
      "17 tensor(0.6454)\n",
      "18 tensor(0.6453)\n",
      "19 tensor(0.6453)\n",
      "20 tensor(0.6453)\n",
      "21 tensor(0.6452)\n",
      "22 tensor(0.6452)\n",
      "23 tensor(0.6452)\n",
      "24 tensor(0.6452)\n",
      "25 tensor(0.6452)\n",
      "26 tensor(0.6451)\n",
      "27 tensor(0.6451)\n",
      "28 tensor(0.6451)\n",
      "29 tensor(0.6451)\n",
      "30 tensor(0.6451)\n",
      "31 tensor(0.6451)\n",
      "32 tensor(0.6451)\n",
      "33 tensor(0.6451)\n",
      "34 tensor(0.6450)\n",
      "35 tensor(0.6450)\n",
      "36 tensor(0.6450)\n",
      "37 tensor(0.6450)\n",
      "38 tensor(0.6450)\n",
      "39 tensor(0.6450)\n",
      "40 tensor(0.6450)\n",
      "41 tensor(0.6450)\n",
      "42 tensor(0.6450)\n",
      "43 tensor(0.6450)\n",
      "44 tensor(0.6450)\n",
      "45 tensor(0.6450)\n",
      "46 tensor(0.6450)\n",
      "47 tensor(0.6450)\n",
      "48 tensor(0.6450)\n",
      "49 tensor(0.6450)\n",
      "50 tensor(0.6450)\n",
      "51 tensor(0.6450)\n",
      "52 tensor(0.6450)\n",
      "53 tensor(0.6450)\n",
      "54 tensor(0.6450)\n",
      "55 tensor(0.6450)\n",
      "56 tensor(0.6450)\n",
      "57 tensor(0.6450)\n",
      "58 tensor(0.6450)\n",
      "59 tensor(0.6450)\n",
      "60 tensor(0.6450)\n",
      "61 tensor(0.6450)\n",
      "62 tensor(0.6450)\n",
      "63 tensor(0.6450)\n",
      "64 tensor(0.6450)\n",
      "65 tensor(0.6450)\n",
      "66 tensor(0.6450)\n",
      "67 tensor(0.6450)\n",
      "68 tensor(0.6450)\n",
      "69 tensor(0.6449)\n",
      "70 tensor(0.6449)\n",
      "71 tensor(0.6449)\n",
      "72 tensor(0.6449)\n",
      "73 tensor(0.6449)\n",
      "74 tensor(0.6449)\n",
      "75 tensor(0.6449)\n",
      "76 tensor(0.6449)\n",
      "77 tensor(0.6449)\n",
      "78 tensor(0.6449)\n",
      "79 tensor(0.6449)\n",
      "80 tensor(0.6449)\n",
      "81 tensor(0.6449)\n",
      "82 tensor(0.6449)\n",
      "83 tensor(0.6449)\n",
      "84 tensor(0.6449)\n",
      "85 tensor(0.6449)\n",
      "86 tensor(0.6449)\n",
      "87 tensor(0.6449)\n",
      "88 tensor(0.6449)\n",
      "89 tensor(0.6449)\n",
      "90 tensor(0.6449)\n",
      "91 tensor(0.6449)\n",
      "92 tensor(0.6449)\n",
      "93 tensor(0.6449)\n",
      "94 tensor(0.6449)\n",
      "95 tensor(0.6449)\n",
      "96 tensor(0.6449)\n",
      "97 tensor(0.6449)\n",
      "98 tensor(0.6449)\n",
      "99 tensor(0.6449)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from urllib.request import urlretrieve\n",
    "#urlretrieve(\"https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/blob/master/data/diabetes.csv.gz\")\n",
    "xy = np.loadtxt('./diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1])) # 1차원은 전부다 선택하고 2차원은 0부터 8까지 [0:9] 랑 같은의미\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "\n",
    "print(x_data.data.shape) #torch.size([759,8])\n",
    "print(y_data.data.shape) #torch.size([759,1])\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8,6)\n",
    "        self.l2 = torch.nn.Linear(6,4)\n",
    "        self.l3 = torch.nn.Linear(4,1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # weight 수정됨\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n",
      "0 tensor(1.6508)\n",
      "1 tensor(0.7925)\n",
      "2 tensor(0.6478)\n",
      "3 tensor(0.6463)\n",
      "4 tensor(0.6457)\n",
      "5 tensor(0.6453)\n",
      "6 tensor(0.6451)\n",
      "7 tensor(0.6448)\n",
      "8 tensor(0.6446)\n",
      "9 tensor(0.6444)\n",
      "10 tensor(0.6442)\n",
      "11 tensor(0.6439)\n",
      "12 tensor(0.6437)\n",
      "13 tensor(0.6435)\n",
      "14 tensor(0.6433)\n",
      "15 tensor(0.6430)\n",
      "16 tensor(0.6428)\n",
      "17 tensor(0.6426)\n",
      "18 tensor(0.6424)\n",
      "19 tensor(0.6421)\n",
      "20 tensor(0.6419)\n",
      "21 tensor(0.6416)\n",
      "22 tensor(0.6414)\n",
      "23 tensor(0.6411)\n",
      "24 tensor(0.6409)\n",
      "25 tensor(0.6406)\n",
      "26 tensor(0.6403)\n",
      "27 tensor(0.6401)\n",
      "28 tensor(0.6398)\n",
      "29 tensor(0.6395)\n",
      "30 tensor(0.6392)\n",
      "31 tensor(0.6389)\n",
      "32 tensor(0.6387)\n",
      "33 tensor(0.6384)\n",
      "34 tensor(0.6381)\n",
      "35 tensor(0.6378)\n",
      "36 tensor(0.6375)\n",
      "37 tensor(0.6371)\n",
      "38 tensor(0.6368)\n",
      "39 tensor(0.6365)\n",
      "40 tensor(0.6361)\n",
      "41 tensor(0.6358)\n",
      "42 tensor(0.6354)\n",
      "43 tensor(0.6351)\n",
      "44 tensor(0.6347)\n",
      "45 tensor(0.6343)\n",
      "46 tensor(0.6339)\n",
      "47 tensor(0.6335)\n",
      "48 tensor(0.6331)\n",
      "49 tensor(0.6326)\n",
      "50 tensor(0.6322)\n",
      "51 tensor(0.6317)\n",
      "52 tensor(0.6313)\n",
      "53 tensor(0.6308)\n",
      "54 tensor(0.6303)\n",
      "55 tensor(0.6298)\n",
      "56 tensor(0.6293)\n",
      "57 tensor(0.6287)\n",
      "58 tensor(0.6282)\n",
      "59 tensor(0.6276)\n",
      "60 tensor(0.6270)\n",
      "61 tensor(0.6264)\n",
      "62 tensor(0.6258)\n",
      "63 tensor(0.6251)\n",
      "64 tensor(0.6245)\n",
      "65 tensor(0.6238)\n",
      "66 tensor(0.6231)\n",
      "67 tensor(0.6223)\n",
      "68 tensor(0.6216)\n",
      "69 tensor(0.6208)\n",
      "70 tensor(0.6200)\n",
      "71 tensor(0.6192)\n",
      "72 tensor(0.6184)\n",
      "73 tensor(0.6175)\n",
      "74 tensor(0.6166)\n",
      "75 tensor(0.6157)\n",
      "76 tensor(0.6147)\n",
      "77 tensor(0.6138)\n",
      "78 tensor(0.6127)\n",
      "79 tensor(0.6117)\n",
      "80 tensor(0.6106)\n",
      "81 tensor(0.6095)\n",
      "82 tensor(0.6084)\n",
      "83 tensor(0.6072)\n",
      "84 tensor(0.6060)\n",
      "85 tensor(0.6048)\n",
      "86 tensor(0.6035)\n",
      "87 tensor(0.6022)\n",
      "88 tensor(0.6009)\n",
      "89 tensor(0.5995)\n",
      "90 tensor(0.5981)\n",
      "91 tensor(0.5967)\n",
      "92 tensor(0.5952)\n",
      "93 tensor(0.5937)\n",
      "94 tensor(0.5921)\n",
      "95 tensor(0.5905)\n",
      "96 tensor(0.5889)\n",
      "97 tensor(0.5873)\n",
      "98 tensor(0.5856)\n",
      "99 tensor(0.5839)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from urllib.request import urlretrieve\n",
    "#urlretrieve(\"https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/blob/master/data/diabetes.csv.gz\")\n",
    "xy = np.loadtxt('./diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1])) # 1차원은 전부다 선택하고 2차원은 0부터 8까지 [0:9] 랑 같은의미\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "\n",
    "print(x_data.data.shape) #torch.size([759,8])\n",
    "print(y_data.data.shape) #torch.size([759,1])\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8,6)\n",
    "        self.l2 = torch.nn.Linear(6,4)\n",
    "        self.l3 = torch.nn.Linear(4,1)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.l1(x))\n",
    "        out2 = self.relu(self.l2(out1))\n",
    "        y_pred = self.relu(self.l3(out2))\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # weight 수정됨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n",
      "0 tensor(0.8370)\n",
      "1 tensor(0.6627)\n",
      "2 tensor(0.6470)\n",
      "3 tensor(0.6454)\n",
      "4 tensor(0.6453)\n",
      "5 tensor(0.6453)\n",
      "6 tensor(0.6453)\n",
      "7 tensor(0.6453)\n",
      "8 tensor(0.6453)\n",
      "9 tensor(0.6453)\n",
      "10 tensor(0.6453)\n",
      "11 tensor(0.6453)\n",
      "12 tensor(0.6453)\n",
      "13 tensor(0.6453)\n",
      "14 tensor(0.6453)\n",
      "15 tensor(0.6453)\n",
      "16 tensor(0.6453)\n",
      "17 tensor(0.6453)\n",
      "18 tensor(0.6453)\n",
      "19 tensor(0.6453)\n",
      "20 tensor(0.6453)\n",
      "21 tensor(0.6453)\n",
      "22 tensor(0.6453)\n",
      "23 tensor(0.6453)\n",
      "24 tensor(0.6453)\n",
      "25 tensor(0.6453)\n",
      "26 tensor(0.6453)\n",
      "27 tensor(0.6453)\n",
      "28 tensor(0.6453)\n",
      "29 tensor(0.6453)\n",
      "30 tensor(0.6453)\n",
      "31 tensor(0.6453)\n",
      "32 tensor(0.6453)\n",
      "33 tensor(0.6453)\n",
      "34 tensor(0.6453)\n",
      "35 tensor(0.6453)\n",
      "36 tensor(0.6453)\n",
      "37 tensor(0.6453)\n",
      "38 tensor(0.6453)\n",
      "39 tensor(0.6453)\n",
      "40 tensor(0.6453)\n",
      "41 tensor(0.6453)\n",
      "42 tensor(0.6453)\n",
      "43 tensor(0.6453)\n",
      "44 tensor(0.6453)\n",
      "45 tensor(0.6453)\n",
      "46 tensor(0.6453)\n",
      "47 tensor(0.6453)\n",
      "48 tensor(0.6453)\n",
      "49 tensor(0.6453)\n",
      "50 tensor(0.6453)\n",
      "51 tensor(0.6453)\n",
      "52 tensor(0.6453)\n",
      "53 tensor(0.6453)\n",
      "54 tensor(0.6453)\n",
      "55 tensor(0.6453)\n",
      "56 tensor(0.6453)\n",
      "57 tensor(0.6453)\n",
      "58 tensor(0.6453)\n",
      "59 tensor(0.6453)\n",
      "60 tensor(0.6453)\n",
      "61 tensor(0.6453)\n",
      "62 tensor(0.6453)\n",
      "63 tensor(0.6453)\n",
      "64 tensor(0.6453)\n",
      "65 tensor(0.6453)\n",
      "66 tensor(0.6453)\n",
      "67 tensor(0.6453)\n",
      "68 tensor(0.6453)\n",
      "69 tensor(0.6453)\n",
      "70 tensor(0.6453)\n",
      "71 tensor(0.6453)\n",
      "72 tensor(0.6453)\n",
      "73 tensor(0.6453)\n",
      "74 tensor(0.6453)\n",
      "75 tensor(0.6453)\n",
      "76 tensor(0.6453)\n",
      "77 tensor(0.6453)\n",
      "78 tensor(0.6453)\n",
      "79 tensor(0.6453)\n",
      "80 tensor(0.6453)\n",
      "81 tensor(0.6453)\n",
      "82 tensor(0.6453)\n",
      "83 tensor(0.6453)\n",
      "84 tensor(0.6453)\n",
      "85 tensor(0.6453)\n",
      "86 tensor(0.6453)\n",
      "87 tensor(0.6453)\n",
      "88 tensor(0.6453)\n",
      "89 tensor(0.6453)\n",
      "90 tensor(0.6453)\n",
      "91 tensor(0.6453)\n",
      "92 tensor(0.6453)\n",
      "93 tensor(0.6453)\n",
      "94 tensor(0.6453)\n",
      "95 tensor(0.6453)\n",
      "96 tensor(0.6453)\n",
      "97 tensor(0.6453)\n",
      "98 tensor(0.6453)\n",
      "99 tensor(0.6453)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xy = np.loadtxt('./diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "\n",
    "print(x_data.data.shape) #torch.size([759,8])\n",
    "print(y_data.data.shape) #torch.size([759,1])\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8,16)\n",
    "        self.l2 = torch.nn.Linear(16,14)\n",
    "        self.l3 = torch.nn.Linear(14,12)\n",
    "        self.l4 = torch.nn.Linear(12,10)\n",
    "        self.l5 = torch.nn.Linear(10,8)\n",
    "        self.l6 = torch.nn.Linear(8,6)\n",
    "        self.l7 = torch.nn.Linear(6,5)\n",
    "        self.l8 = torch.nn.Linear(5,4)\n",
    "        self.l9 = torch.nn.Linear(4,3)\n",
    "        self.l10 = torch.nn.Linear(3,1)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.l1(x))\n",
    "        out2 = self.relu(self.l2(out1))\n",
    "        out3 = self.relu(self.l3(out2))\n",
    "        out4 = self.relu(self.l4(out3))\n",
    "        out5 = self.relu(self.l5(out4))\n",
    "        out6 = self.relu(self.l6(out5))\n",
    "        out7 = self.relu(self.l7(out6))\n",
    "        out8 = self.relu(self.l8(out7))\n",
    "        out9 = self.relu(self.l9(out8))\n",
    "        y_pred = self.relu(self.l10(out9))\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # weight 수정됨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n",
      "0 tensor(0.6653)\n",
      "1 tensor(0.6637)\n",
      "2 tensor(0.6622)\n",
      "3 tensor(0.6608)\n",
      "4 tensor(0.6596)\n",
      "5 tensor(0.6584)\n",
      "6 tensor(0.6573)\n",
      "7 tensor(0.6564)\n",
      "8 tensor(0.6555)\n",
      "9 tensor(0.6547)\n",
      "10 tensor(0.6539)\n",
      "11 tensor(0.6532)\n",
      "12 tensor(0.6526)\n",
      "13 tensor(0.6520)\n",
      "14 tensor(0.6515)\n",
      "15 tensor(0.6510)\n",
      "16 tensor(0.6505)\n",
      "17 tensor(0.6501)\n",
      "18 tensor(0.6497)\n",
      "19 tensor(0.6494)\n",
      "20 tensor(0.6490)\n",
      "21 tensor(0.6487)\n",
      "22 tensor(0.6485)\n",
      "23 tensor(0.6482)\n",
      "24 tensor(0.6480)\n",
      "25 tensor(0.6478)\n",
      "26 tensor(0.6476)\n",
      "27 tensor(0.6474)\n",
      "28 tensor(0.6472)\n",
      "29 tensor(0.6471)\n",
      "30 tensor(0.6469)\n",
      "31 tensor(0.6468)\n",
      "32 tensor(0.6467)\n",
      "33 tensor(0.6466)\n",
      "34 tensor(0.6465)\n",
      "35 tensor(0.6464)\n",
      "36 tensor(0.6463)\n",
      "37 tensor(0.6462)\n",
      "38 tensor(0.6461)\n",
      "39 tensor(0.6461)\n",
      "40 tensor(0.6460)\n",
      "41 tensor(0.6459)\n",
      "42 tensor(0.6459)\n",
      "43 tensor(0.6458)\n",
      "44 tensor(0.6458)\n",
      "45 tensor(0.6458)\n",
      "46 tensor(0.6457)\n",
      "47 tensor(0.6457)\n",
      "48 tensor(0.6456)\n",
      "49 tensor(0.6456)\n",
      "50 tensor(0.6456)\n",
      "51 tensor(0.6456)\n",
      "52 tensor(0.6455)\n",
      "53 tensor(0.6455)\n",
      "54 tensor(0.6455)\n",
      "55 tensor(0.6455)\n",
      "56 tensor(0.6455)\n",
      "57 tensor(0.6455)\n",
      "58 tensor(0.6454)\n",
      "59 tensor(0.6454)\n",
      "60 tensor(0.6454)\n",
      "61 tensor(0.6454)\n",
      "62 tensor(0.6454)\n",
      "63 tensor(0.6454)\n",
      "64 tensor(0.6454)\n",
      "65 tensor(0.6454)\n",
      "66 tensor(0.6454)\n",
      "67 tensor(0.6453)\n",
      "68 tensor(0.6453)\n",
      "69 tensor(0.6453)\n",
      "70 tensor(0.6453)\n",
      "71 tensor(0.6453)\n",
      "72 tensor(0.6453)\n",
      "73 tensor(0.6453)\n",
      "74 tensor(0.6453)\n",
      "75 tensor(0.6453)\n",
      "76 tensor(0.6453)\n",
      "77 tensor(0.6453)\n",
      "78 tensor(0.6453)\n",
      "79 tensor(0.6453)\n",
      "80 tensor(0.6453)\n",
      "81 tensor(0.6453)\n",
      "82 tensor(0.6453)\n",
      "83 tensor(0.6453)\n",
      "84 tensor(0.6453)\n",
      "85 tensor(0.6453)\n",
      "86 tensor(0.6453)\n",
      "87 tensor(0.6453)\n",
      "88 tensor(0.6453)\n",
      "89 tensor(0.6453)\n",
      "90 tensor(0.6453)\n",
      "91 tensor(0.6453)\n",
      "92 tensor(0.6453)\n",
      "93 tensor(0.6453)\n",
      "94 tensor(0.6453)\n",
      "95 tensor(0.6453)\n",
      "96 tensor(0.6453)\n",
      "97 tensor(0.6453)\n",
      "98 tensor(0.6453)\n",
      "99 tensor(0.6453)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xy = np.loadtxt('./diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "\n",
    "print(x_data.data.shape) #torch.size([759,8])\n",
    "print(y_data.data.shape) #torch.size([759,1])\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8,16)\n",
    "        self.l2 = torch.nn.Linear(16,14)\n",
    "        self.l3 = torch.nn.Linear(14,12)\n",
    "        self.l4 = torch.nn.Linear(12,10)\n",
    "        self.l5 = torch.nn.Linear(10,8)\n",
    "        self.l6 = torch.nn.Linear(8,6)\n",
    "        self.l7 = torch.nn.Linear(6,5)\n",
    "        self.l8 = torch.nn.Linear(5,4)\n",
    "        self.l9 = torch.nn.Linear(4,3)\n",
    "        self.l10 = torch.nn.Linear(3,1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        out3 = self.sigmoid(self.l3(out2))\n",
    "        out4 = self.sigmoid(self.l4(out3))\n",
    "        out5 = self.sigmoid(self.l5(out4))\n",
    "        out6 = self.sigmoid(self.l6(out5))\n",
    "        out7 = self.sigmoid(self.l7(out6))\n",
    "        out8 = self.sigmoid(self.l8(out7))\n",
    "        out9 = self.sigmoid(self.l9(out8))\n",
    "        y = self.sigmoid(self.l10(out9))\n",
    "        return y\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # weight 수정됨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(1.1265)\n",
      "0 1 tensor(0.5936)\n",
      "0 2 tensor(0.7592)\n",
      "0 3 tensor(0.6556)\n",
      "0 4 tensor(0.6174)\n",
      "0 5 tensor(0.7550)\n",
      "0 6 tensor(0.6576)\n",
      "0 7 tensor(0.6103)\n",
      "0 8 tensor(0.8521)\n",
      "0 9 tensor(0.6998)\n",
      "0 10 tensor(0.7389)\n",
      "0 11 tensor(0.6585)\n",
      "0 12 tensor(0.6375)\n",
      "0 13 tensor(0.5267)\n",
      "0 14 tensor(0.5785)\n",
      "0 15 tensor(0.8011)\n",
      "0 16 tensor(0.6803)\n",
      "0 17 tensor(0.6093)\n",
      "0 18 tensor(0.6209)\n",
      "0 19 tensor(0.6691)\n",
      "0 20 tensor(0.5869)\n",
      "0 21 tensor(0.8272)\n",
      "0 22 tensor(0.6712)\n",
      "0 23 tensor(0.7101)\n",
      "1 0 tensor(0.6449)\n",
      "1 1 tensor(0.6823)\n",
      "1 2 tensor(0.5886)\n",
      "1 3 tensor(0.5057)\n",
      "1 4 tensor(0.8640)\n",
      "1 5 tensor(0.6768)\n",
      "1 6 tensor(0.6790)\n",
      "1 7 tensor(0.6924)\n",
      "1 8 tensor(0.6656)\n",
      "1 9 tensor(0.7047)\n",
      "1 10 tensor(0.6691)\n",
      "1 11 tensor(0.6321)\n",
      "1 12 tensor(0.6145)\n",
      "1 13 tensor(0.5432)\n",
      "1 14 tensor(0.6542)\n",
      "1 15 tensor(0.6604)\n",
      "1 16 tensor(0.7226)\n",
      "1 17 tensor(0.6854)\n",
      "1 18 tensor(0.6593)\n",
      "1 19 tensor(0.5882)\n",
      "1 20 tensor(0.5766)\n",
      "1 21 tensor(0.6318)\n",
      "1 22 tensor(0.6189)\n",
      "1 23 tensor(0.5196)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class DiabetesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        xy=np.loadtxt('./diabetes.csv.gz',delimiter=',',dtype=np.float32)\n",
    "        self.len = xy.shape[0] # xy의 0번째 차원 길이\n",
    "        self.x_data = torch.from_numpy(xy[:,0:-1])\n",
    "        self.y_data = torch.from_numpy(xy[:,[-1]])\n",
    "        \n",
    "    def __getitem__(self,index): #index를 활용하여 data 활용성 증가\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self): # data size\n",
    "        return self.len\n",
    "    \n",
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True, \n",
    "                          num_workers = 2)\n",
    "#dataset에 우리가 만든 class 입력, batch_size에 데이터 사이즈 개수, 셔플은 셔플, num_workers는 멀티 쓰레딩 지원\n",
    "\n",
    "class Model(torch.nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.l1=torch.nn.Linear(8,4)\n",
    "        self.l2=torch.nn.Linear(4,6)\n",
    "        self.l3=torch.nn.Linear(6,1)\n",
    "         \n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1 = self.relu(self.l1(x))\n",
    "        out2 = self.relu(self.l2(out1))\n",
    "        y_pred = self.relu(self.l3(out2))\n",
    "        return y_pred\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "criterion= torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        y_pred = model(inputs)\n",
    "        \n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # weight 수정됨\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(0.6435)\n",
      "0 1 tensor(0.6837)\n",
      "0 2 tensor(0.6692)\n",
      "0 3 tensor(0.7219)\n",
      "0 4 tensor(0.6386)\n",
      "0 5 tensor(0.6589)\n",
      "0 6 tensor(0.6388)\n",
      "0 7 tensor(0.6645)\n",
      "0 8 tensor(0.6126)\n",
      "0 9 tensor(0.6617)\n",
      "0 10 tensor(0.6631)\n",
      "0 11 tensor(0.6127)\n",
      "0 12 tensor(0.6604)\n",
      "0 13 tensor(0.5925)\n",
      "0 14 tensor(0.6301)\n",
      "0 15 tensor(0.6143)\n",
      "0 16 tensor(0.7086)\n",
      "0 17 tensor(0.6759)\n",
      "0 18 tensor(0.6459)\n",
      "0 19 tensor(0.7231)\n",
      "0 20 tensor(0.6752)\n",
      "0 21 tensor(0.6313)\n",
      "0 22 tensor(0.6613)\n",
      "0 23 tensor(0.6054)\n",
      "1 0 tensor(0.6766)\n",
      "1 1 tensor(0.6606)\n",
      "1 2 tensor(0.6770)\n",
      "1 3 tensor(0.6439)\n",
      "1 4 tensor(0.6449)\n",
      "1 5 tensor(0.5802)\n",
      "1 6 tensor(0.6950)\n",
      "1 7 tensor(0.5108)\n",
      "1 8 tensor(0.5691)\n",
      "1 9 tensor(0.6425)\n",
      "1 10 tensor(0.6822)\n",
      "1 11 tensor(0.7387)\n",
      "1 12 tensor(0.6422)\n",
      "1 13 tensor(0.6063)\n",
      "1 14 tensor(0.6997)\n",
      "1 15 tensor(0.6419)\n",
      "1 16 tensor(0.6245)\n",
      "1 17 tensor(0.6973)\n",
      "1 18 tensor(0.6251)\n",
      "1 19 tensor(0.5876)\n",
      "1 20 tensor(0.6996)\n",
      "1 21 tensor(0.7164)\n",
      "1 22 tensor(0.5726)\n",
      "1 23 tensor(0.6706)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class DiabetesDataset(Dataset):\n",
    "     \n",
    "    def __init__(self):\n",
    "        xy=np.loadtxt('./diabetes.csv.gz',delimiter=',',dtype=np.float32)\n",
    "        self.len=xy.shape[0]\n",
    "        self.x_data=torch.from_numpy(xy[:,0:-1])\n",
    "        self.y_data=torch.from_numpy(xy[:,[-1]])\n",
    "         \n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "     \n",
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=True,\n",
    "                         num_workers=0)\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.l1=torch.nn.Linear(8,4)\n",
    "        self.l2=torch.nn.Linear(4,6)\n",
    "        self.l3=torch.nn.Linear(6,1)\n",
    "         \n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "         \n",
    "    def forward(self,x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "model = MyModel()\n",
    " \n",
    "criterion = torch.nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    " \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(inputs)\n",
    " \n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.data)\n",
    " \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle, gzip, numpy, urllib.request, json\n",
    "\n",
    "# Load the dataset\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " 'root': './',\n",
       " 'target_transform': None,\n",
       " 'targets': tensor([5, 0, 4,  ..., 5, 6, 8]),\n",
       " 'train': True,\n",
       " 'transform': ToTensor()}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from  torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision     # data set 불러오기위해\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(root = './', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_dataset = datasets.MNIST(root = './', train = False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size =32, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size =32, shuffle = False)\n",
    "\n",
    "train_dataset.__dict__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "0 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1 tensor(2.3244)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "2 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "3 tensor(2.3111)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "4 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "5 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "6 tensor(2.3226)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "7 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "8 tensor(2.3264)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "9 tensor(2.3067)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "10 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "11 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "12 tensor(2.2832)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "13 tensor(2.2846)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "14 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "15 tensor(2.3006)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "16 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "17 tensor(2.3082)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "18 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "19 tensor(2.3116)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "20 tensor(2.3168)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "21 tensor(2.3161)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "22 tensor(2.3217)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "23 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "24 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "25 tensor(2.3109)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "26 tensor(2.2920)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "27 tensor(2.3174)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "28 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "29 tensor(2.2954)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "30 tensor(2.2822)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "31 tensor(2.3085)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "32 tensor(2.3321)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "33 tensor(2.3034)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "34 tensor(2.3033)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "35 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "36 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "37 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "38 tensor(2.3262)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "39 tensor(2.3014)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "40 tensor(2.3145)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "41 tensor(2.3091)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "42 tensor(2.3128)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "43 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "44 tensor(2.3276)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "45 tensor(2.3089)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "46 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "47 tensor(2.3167)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "48 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "49 tensor(2.3064)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "50 tensor(2.3204)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "51 tensor(2.3137)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "52 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "53 tensor(2.3008)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "54 tensor(2.2886)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "55 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "56 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "57 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "58 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "59 tensor(2.3213)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "60 tensor(2.3021)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "61 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "62 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "63 tensor(2.3185)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "64 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "65 tensor(2.2874)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "66 tensor(2.3167)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "67 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "68 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "69 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "70 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "71 tensor(2.2929)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "72 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "73 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "74 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "75 tensor(2.3065)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "76 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "77 tensor(2.2809)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "78 tensor(2.3015)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "79 tensor(2.2794)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "80 tensor(2.3159)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "81 tensor(2.2820)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "82 tensor(2.3125)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "83 tensor(2.3204)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "85 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "86 tensor(2.3104)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "87 tensor(2.3140)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "88 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "89 tensor(2.3025)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "90 tensor(2.3116)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "91 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "92 tensor(2.3117)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "93 tensor(2.3140)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "94 tensor(2.2976)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "95 tensor(2.3236)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "96 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "97 tensor(2.3196)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "98 tensor(2.3082)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "99 tensor(2.3288)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "100 tensor(2.3148)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "101 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "102 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "103 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "104 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "105 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "106 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "107 tensor(2.3066)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "108 tensor(2.3065)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "109 tensor(2.3148)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "110 tensor(2.3292)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "111 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "112 tensor(2.2813)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "113 tensor(2.3139)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "114 tensor(2.2926)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "115 tensor(2.3131)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "116 tensor(2.2937)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "117 tensor(2.3236)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "118 tensor(2.3115)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "119 tensor(2.2987)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "120 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "121 tensor(2.2816)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "122 tensor(2.3108)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "123 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "124 tensor(2.3063)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "125 tensor(2.2873)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "126 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "127 tensor(2.3066)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "128 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "129 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "130 tensor(2.3143)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "131 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "132 tensor(2.2722)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "133 tensor(2.2874)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "134 tensor(2.3087)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "135 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "136 tensor(2.2672)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "137 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "138 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "139 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "140 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "141 tensor(2.2985)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "142 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "143 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "144 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "145 tensor(2.2884)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "146 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "147 tensor(2.2875)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "148 tensor(2.3149)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 tensor(2.3076)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "150 tensor(2.3154)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "151 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "152 tensor(2.3278)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "153 tensor(2.3046)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "154 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "155 tensor(2.3128)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "156 tensor(2.2929)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "157 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "158 tensor(2.3008)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "159 tensor(2.3162)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "160 tensor(2.3161)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "161 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "162 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "163 tensor(2.3110)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "164 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "165 tensor(2.3046)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "166 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "167 tensor(2.2803)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "168 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "169 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "170 tensor(2.2929)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "171 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "172 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "173 tensor(2.3152)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "174 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "175 tensor(2.3113)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "176 tensor(2.3018)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "177 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "178 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "179 tensor(2.3063)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "180 tensor(2.2788)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "181 tensor(2.3024)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "182 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "183 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "184 tensor(2.3148)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "185 tensor(2.3195)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "186 tensor(2.2937)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "187 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "188 tensor(2.2774)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "189 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "190 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "191 tensor(2.3146)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "192 tensor(2.2875)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "193 tensor(2.3148)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "194 tensor(2.2922)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "195 tensor(2.3211)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "196 tensor(2.3042)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "197 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "198 tensor(2.2958)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "199 tensor(2.3084)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "200 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "201 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "202 tensor(2.3120)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "203 tensor(2.2940)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "204 tensor(2.3291)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "205 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "206 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "207 tensor(2.2978)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "208 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "209 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "210 tensor(2.2924)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "211 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "212 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "213 tensor(2.3067)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "214 tensor(2.2821)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "215 tensor(2.2907)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "216 tensor(2.2794)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "217 tensor(2.3095)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "218 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "219 tensor(2.2823)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "220 tensor(2.3158)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "221 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "222 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "223 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "224 tensor(2.3072)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "225 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "226 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "227 tensor(2.2859)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "228 tensor(2.3136)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "229 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "230 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "231 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "232 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "233 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "234 tensor(2.2937)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "235 tensor(2.3003)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "236 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "237 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "238 tensor(2.2947)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "239 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "240 tensor(2.3018)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "241 tensor(2.3118)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "242 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "243 tensor(2.3198)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "244 tensor(2.2773)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "245 tensor(2.2777)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "246 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "247 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "248 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "249 tensor(2.3126)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "250 tensor(2.3115)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "251 tensor(2.2919)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "252 tensor(2.2865)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "253 tensor(2.3164)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "254 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "255 tensor(2.2921)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "256 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "257 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "258 tensor(2.3101)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "259 tensor(2.2839)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "260 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "261 tensor(2.3062)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "262 tensor(2.3061)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "263 tensor(2.2948)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "264 tensor(2.2955)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "265 tensor(2.3174)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "266 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "267 tensor(2.2992)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "268 tensor(2.3333)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "269 tensor(2.2929)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "270 tensor(2.3164)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "271 tensor(2.2811)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "272 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "273 tensor(2.3130)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "274 tensor(2.2919)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "275 tensor(2.3064)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "276 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "277 tensor(2.2788)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "278 tensor(2.3162)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "279 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "280 tensor(2.3141)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "281 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "282 tensor(2.3179)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "283 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "284 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "285 tensor(2.2870)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "286 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "287 tensor(2.2842)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "288 tensor(2.3165)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "289 tensor(2.2938)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "290 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "291 tensor(2.3171)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "292 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "293 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "294 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "295 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "296 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "297 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "298 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "299 tensor(2.3141)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "300 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "301 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "302 tensor(2.2625)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "303 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "304 tensor(2.3209)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "305 tensor(2.3086)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "306 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "307 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "308 tensor(2.3061)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "309 tensor(2.2944)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "310 tensor(2.2908)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "311 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "312 tensor(2.2868)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "313 tensor(2.2822)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "314 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "315 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "316 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "317 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "318 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "319 tensor(2.3138)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "320 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "321 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "322 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "323 tensor(2.2853)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "324 tensor(2.3288)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "325 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "326 tensor(2.3159)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "327 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "328 tensor(2.3121)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "329 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "330 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "331 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "332 tensor(2.2889)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "333 tensor(2.2762)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "334 tensor(2.3151)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "335 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "336 tensor(2.3089)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "337 tensor(2.3129)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "338 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "339 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "340 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "341 tensor(2.2764)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "342 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "343 tensor(2.3157)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "344 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "345 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "346 tensor(2.2992)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "347 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "348 tensor(2.2847)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "349 tensor(2.2825)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "350 tensor(2.3108)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "351 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "352 tensor(2.2768)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "353 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "354 tensor(2.3017)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "355 tensor(2.2725)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "356 tensor(2.3136)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "357 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "358 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "359 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "360 tensor(2.3145)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "361 tensor(2.3153)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "362 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "363 tensor(2.3062)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "364 tensor(2.3185)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "365 tensor(2.3103)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "366 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "367 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "368 tensor(2.2889)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "369 tensor(2.3188)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "370 tensor(2.3114)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "371 tensor(2.2971)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "372 tensor(2.3089)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "373 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "374 tensor(2.3103)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "375 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "376 tensor(2.2695)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "377 tensor(2.3080)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "378 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "379 tensor(2.3236)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "380 tensor(2.2912)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "381 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "382 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "383 tensor(2.2948)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "384 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "385 tensor(2.2779)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "386 tensor(2.3010)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "387 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "388 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "389 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "390 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "391 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "392 tensor(2.2852)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "393 tensor(2.2939)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "394 tensor(2.3170)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "395 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "396 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "397 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "398 tensor(2.3132)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "399 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "400 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "401 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "402 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "403 tensor(2.3117)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "404 tensor(2.3113)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "405 tensor(2.3072)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "406 tensor(2.2958)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "407 tensor(2.3017)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "408 tensor(2.3144)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "409 tensor(2.3006)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "410 tensor(2.2729)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "411 tensor(2.3115)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "412 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "413 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "414 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "415 tensor(2.3122)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "416 tensor(2.3123)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "418 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "419 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "420 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "421 tensor(2.3018)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "422 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "423 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "424 tensor(2.2900)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "425 tensor(2.2908)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "426 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "427 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "428 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "429 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "430 tensor(2.3069)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "431 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "432 tensor(2.3177)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "433 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "434 tensor(2.2971)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "435 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "436 tensor(2.2887)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "437 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "438 tensor(2.2810)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "439 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "440 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "441 tensor(2.3142)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "442 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "443 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "444 tensor(2.3136)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "445 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "446 tensor(2.3190)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "447 tensor(2.3133)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "448 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "449 tensor(2.2894)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "450 tensor(2.2872)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "451 tensor(2.2928)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "452 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "453 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "454 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "455 tensor(2.3198)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "456 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "457 tensor(2.3032)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "458 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "459 tensor(2.3109)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "460 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "461 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "462 tensor(2.3048)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "463 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "464 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "465 tensor(2.2820)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "466 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "467 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "468 tensor(2.3107)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "469 tensor(2.2825)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "470 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "471 tensor(2.2853)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "472 tensor(2.3102)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "473 tensor(2.2755)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "474 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "475 tensor(2.3061)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "476 tensor(2.2924)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "477 tensor(2.3133)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "478 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "479 tensor(2.2808)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "480 tensor(2.3135)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "481 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "482 tensor(2.3128)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "483 tensor(2.3068)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "484 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "485 tensor(2.3200)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "486 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "487 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "488 tensor(2.3201)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "489 tensor(2.2871)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "490 tensor(2.3116)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "491 tensor(2.2992)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "492 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "493 tensor(2.2974)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "494 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "495 tensor(2.3025)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "496 tensor(2.3006)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "497 tensor(2.2877)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "498 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "499 tensor(2.3145)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "500 tensor(2.3110)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "501 tensor(2.3239)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "502 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "503 tensor(2.3109)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "504 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "505 tensor(2.2792)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "506 tensor(2.2992)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "507 tensor(2.2830)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "508 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "509 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "510 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "511 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "512 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "513 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "514 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "515 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "516 tensor(2.3166)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "517 tensor(2.3132)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "518 tensor(2.3071)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "519 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "520 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "521 tensor(2.3131)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "522 tensor(2.3046)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "523 tensor(2.2966)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "524 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "525 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "526 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "527 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "528 tensor(2.2793)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "529 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "530 tensor(2.3136)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "531 tensor(2.3104)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "532 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "533 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "534 tensor(2.3075)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "535 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "536 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "537 tensor(2.3091)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "538 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "539 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "540 tensor(2.2953)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "541 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "542 tensor(2.2914)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "543 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "544 tensor(2.2876)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "545 tensor(2.3147)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "546 tensor(2.3195)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "547 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "548 tensor(2.3019)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "549 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "550 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "551 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "552 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "553 tensor(2.3179)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "554 tensor(2.2927)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "555 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "556 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "557 tensor(2.3244)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "558 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "559 tensor(2.3068)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "560 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "561 tensor(2.2890)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "562 tensor(2.3162)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "563 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "564 tensor(2.2894)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "565 tensor(2.3103)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "566 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "567 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "568 tensor(2.2921)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "569 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "570 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "571 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "572 tensor(2.3136)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "573 tensor(2.2768)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "574 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "575 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "576 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "577 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "578 tensor(2.2935)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "579 tensor(2.2826)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "580 tensor(2.3121)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "581 tensor(2.3075)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "582 tensor(2.2895)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "583 tensor(2.3142)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "584 tensor(2.3122)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "585 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "586 tensor(2.2939)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "587 tensor(2.3107)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "588 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "589 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "590 tensor(2.2651)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "591 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "592 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "593 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "594 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "595 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "596 tensor(2.3195)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "597 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "598 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "599 tensor(2.2876)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "600 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "601 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "602 tensor(2.2789)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "603 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "604 tensor(2.3171)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "605 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "606 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "607 tensor(2.3178)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "608 tensor(2.3122)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "609 tensor(2.2813)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "610 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "611 tensor(2.3132)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "612 tensor(2.2925)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "613 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "614 tensor(2.3200)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "615 tensor(2.3248)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "616 tensor(2.2920)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "617 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "618 tensor(2.2966)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "619 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "620 tensor(2.2921)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "621 tensor(2.3032)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "622 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "623 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "624 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "625 tensor(2.3125)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "626 tensor(2.2813)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "627 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "628 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "629 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "630 tensor(2.3034)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "631 tensor(2.3062)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "632 tensor(2.3081)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "633 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "634 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "635 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "636 tensor(2.3129)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "637 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "638 tensor(2.2841)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "639 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "640 tensor(2.3191)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "641 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "642 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "643 tensor(2.3076)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "644 tensor(2.3104)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "645 tensor(2.3030)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "646 tensor(2.3178)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "647 tensor(2.2877)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "648 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "649 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "650 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "651 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "652 tensor(2.2775)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "653 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "654 tensor(2.2873)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "655 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "656 tensor(2.2837)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "657 tensor(2.3103)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "658 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "659 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "660 tensor(2.2852)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "661 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "662 tensor(2.3066)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "663 tensor(2.3171)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "664 tensor(2.2978)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "665 tensor(2.3156)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "666 tensor(2.3033)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "667 tensor(2.3178)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "668 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "669 tensor(2.2890)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "670 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "671 tensor(2.3075)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "672 tensor(2.3263)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "673 tensor(2.2817)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "674 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "675 tensor(2.3140)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "676 tensor(2.3033)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "677 tensor(2.2842)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "678 tensor(2.3144)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "679 tensor(2.3034)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "680 tensor(2.2953)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "681 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "682 tensor(2.2902)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "683 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "684 tensor(2.3055)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "685 tensor(2.2798)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "686 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "687 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "688 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "689 tensor(2.2927)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "690 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "691 tensor(2.2869)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "692 tensor(2.2987)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "693 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "694 tensor(2.3149)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "695 tensor(2.2784)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "696 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "697 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "698 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "699 tensor(2.2777)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "700 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "701 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "702 tensor(2.3147)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "703 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "704 tensor(2.2955)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "705 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "706 tensor(2.2845)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "707 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "708 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "709 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "710 tensor(2.3063)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "711 tensor(2.2775)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "712 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "713 tensor(2.2976)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "714 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "715 tensor(2.3024)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "716 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "717 tensor(2.2808)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "718 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "719 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "720 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "721 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "722 tensor(2.3055)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "723 tensor(2.3087)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "724 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "725 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "726 tensor(2.3121)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "727 tensor(2.3195)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "728 tensor(2.2828)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "729 tensor(2.2886)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "730 tensor(2.2786)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "731 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "732 tensor(2.2842)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "733 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "734 tensor(2.2820)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "735 tensor(2.3167)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "736 tensor(2.2869)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "737 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "738 tensor(2.3032)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "739 tensor(2.2815)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "740 tensor(2.2804)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "741 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "742 tensor(2.3106)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "743 tensor(2.2870)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "744 tensor(2.2824)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "745 tensor(2.3021)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "746 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "747 tensor(2.2859)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "748 tensor(2.2987)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "749 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "750 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "751 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "752 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "753 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "754 tensor(2.2732)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "755 tensor(2.2913)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "756 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "757 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "758 tensor(2.2778)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "759 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "760 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "761 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "762 tensor(2.2809)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "763 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "764 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "765 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "766 tensor(2.2947)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "767 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "768 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "769 tensor(2.2823)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "770 tensor(2.3087)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "771 tensor(2.2836)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "772 tensor(2.2884)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "773 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "774 tensor(2.3080)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "775 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "776 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "777 tensor(2.2895)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "778 tensor(2.2906)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "779 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "780 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "782 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "783 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "784 tensor(2.3205)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "785 tensor(2.3093)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "786 tensor(2.3163)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "787 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "788 tensor(2.3146)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "789 tensor(2.3121)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "790 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "791 tensor(2.3046)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "792 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "793 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "794 tensor(2.2953)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "795 tensor(2.2865)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "796 tensor(2.3109)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "797 tensor(2.3127)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "798 tensor(2.2740)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "799 tensor(2.2800)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "800 tensor(2.3129)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "801 tensor(2.2939)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "802 tensor(2.3216)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "803 tensor(2.3104)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "804 tensor(2.3068)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "805 tensor(2.2943)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "806 tensor(2.2847)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "807 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "808 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "809 tensor(2.3332)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "810 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "811 tensor(2.2812)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "812 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "813 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "814 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "815 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "816 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "817 tensor(2.3014)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "818 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "819 tensor(2.3187)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "820 tensor(2.3196)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "821 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "822 tensor(2.2840)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "823 tensor(2.2895)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "824 tensor(2.2817)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "825 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "826 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "827 tensor(2.2971)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "828 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "829 tensor(2.2800)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "830 tensor(2.2958)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "831 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "832 tensor(2.2852)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "833 tensor(2.3219)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "834 tensor(2.2786)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "835 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "836 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "837 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "838 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "839 tensor(2.3064)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "840 tensor(2.2791)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "841 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "842 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "843 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "844 tensor(2.2817)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "845 tensor(2.3125)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "846 tensor(2.3084)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "847 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "848 tensor(2.2888)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "849 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "850 tensor(2.2919)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "851 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "852 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "853 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "854 tensor(2.2974)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "855 tensor(2.2940)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "856 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "857 tensor(2.3165)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "858 tensor(2.2987)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "859 tensor(2.2838)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "860 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "861 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "862 tensor(2.3055)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "863 tensor(2.3041)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "864 tensor(2.3263)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "865 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "866 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "867 tensor(2.3150)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "868 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "869 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "870 tensor(2.2798)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "871 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "872 tensor(2.3185)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "873 tensor(2.2856)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "874 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "875 tensor(2.2974)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "876 tensor(2.2751)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "877 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "878 tensor(2.3021)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "879 tensor(2.2884)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "880 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "881 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "882 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "883 tensor(2.2860)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "884 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "885 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "886 tensor(2.2840)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "887 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "888 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "889 tensor(2.2890)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "890 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "891 tensor(2.3061)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "892 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "893 tensor(2.3081)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "894 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "895 tensor(2.2900)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "896 tensor(2.2771)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "897 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "898 tensor(2.2801)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "899 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "900 tensor(2.3041)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "901 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "902 tensor(2.2853)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "903 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "904 tensor(2.3017)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "905 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "906 tensor(2.2916)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "907 tensor(2.2938)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "908 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "909 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "910 tensor(2.2739)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "911 tensor(2.3188)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "912 tensor(2.2960)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "913 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "914 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "915 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "916 tensor(2.2850)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "917 tensor(2.3205)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "918 tensor(2.2840)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "919 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "920 tensor(2.2897)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "921 tensor(2.2881)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "922 tensor(2.2872)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "923 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "924 tensor(2.2816)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "925 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "926 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "927 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "928 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "929 tensor(2.3191)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "930 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "931 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "932 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "933 tensor(2.2834)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "934 tensor(2.2966)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "935 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "936 tensor(2.3106)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "937 tensor(2.2810)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "938 tensor(2.2876)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "939 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "940 tensor(2.2966)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "941 tensor(2.2804)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942 tensor(2.3117)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "943 tensor(2.2812)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "944 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "945 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "946 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "947 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "948 tensor(2.3214)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "949 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "950 tensor(2.3003)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "951 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "952 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "953 tensor(2.2899)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "954 tensor(2.2895)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "955 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "956 tensor(2.2762)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "957 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "958 tensor(2.3021)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "959 tensor(2.3211)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "960 tensor(2.3155)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "961 tensor(2.2899)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "962 tensor(2.3126)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "963 tensor(2.2868)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "964 tensor(2.3051)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "965 tensor(2.3269)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "966 tensor(2.3156)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "967 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "968 tensor(2.3159)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "969 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "970 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "971 tensor(2.3105)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "972 tensor(2.2823)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "973 tensor(2.3000)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "974 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "975 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "976 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "977 tensor(2.2862)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "978 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "979 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "980 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "981 tensor(2.2843)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "982 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "983 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "984 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "985 tensor(2.3174)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "986 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "987 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "988 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "989 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "990 tensor(2.2847)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "991 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "992 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "993 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "994 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "995 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "996 tensor(2.2820)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "997 tensor(2.2835)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "998 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "999 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1000 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1001 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1002 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1003 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1004 tensor(2.3143)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1005 tensor(2.3224)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1006 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1007 tensor(2.2820)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1008 tensor(2.2826)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1009 tensor(2.3124)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1010 tensor(2.3169)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1011 tensor(2.3043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1012 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1013 tensor(2.3105)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1014 tensor(2.2906)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1015 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1016 tensor(2.2938)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1017 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1018 tensor(2.3063)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1019 tensor(2.2971)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1020 tensor(2.3109)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1021 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1022 tensor(2.3204)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1023 tensor(2.3153)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1024 tensor(2.2964)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1025 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1026 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1027 tensor(2.2998)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1028 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1029 tensor(2.2960)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1030 tensor(2.2887)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1031 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1032 tensor(2.2765)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1033 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1034 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1035 tensor(2.3071)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1036 tensor(2.3168)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1037 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1038 tensor(2.2777)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1039 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1040 tensor(2.2786)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1041 tensor(2.2899)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1042 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1043 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1044 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1045 tensor(2.2978)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1046 tensor(2.2757)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1047 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1048 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1049 tensor(2.2834)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1050 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1051 tensor(2.3106)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1052 tensor(2.2974)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1053 tensor(2.3086)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1054 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1055 tensor(2.3110)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1056 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1057 tensor(2.3048)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1058 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1059 tensor(2.2825)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1060 tensor(2.3299)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1061 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1062 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1063 tensor(2.2689)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1064 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1065 tensor(2.2992)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1066 tensor(2.3147)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1067 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1068 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1069 tensor(2.2706)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1070 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1071 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1072 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1073 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1074 tensor(2.3048)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1075 tensor(2.3083)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1076 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1077 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1078 tensor(2.3081)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1079 tensor(2.3080)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1080 tensor(2.3075)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1081 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1082 tensor(2.2908)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1083 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1084 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1085 tensor(2.2957)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1086 tensor(2.2744)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1087 tensor(2.3134)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1088 tensor(2.2957)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1089 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1090 tensor(2.2996)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1091 tensor(2.2766)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1092 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1093 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1094 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1095 tensor(2.3116)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1096 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1097 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1098 tensor(2.2899)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1099 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1100 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1101 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1102 tensor(2.2672)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1103 tensor(2.3242)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1104 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1105 tensor(2.3168)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1106 tensor(2.2841)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1107 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1108 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1109 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1110 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1111 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1112 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1113 tensor(2.2921)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1114 tensor(2.2841)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1115 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1116 tensor(2.2824)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1117 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1118 tensor(2.2908)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1119 tensor(2.2957)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1120 tensor(2.2914)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1121 tensor(2.2897)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1122 tensor(2.2877)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1123 tensor(2.2865)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1124 tensor(2.3115)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1125 tensor(2.3071)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1126 tensor(2.3081)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1127 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1128 tensor(2.3162)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1129 tensor(2.2613)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1130 tensor(2.2788)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1131 tensor(2.3093)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1132 tensor(2.2886)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1133 tensor(2.3091)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1134 tensor(2.3095)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1135 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1136 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1137 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1138 tensor(2.2835)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1139 tensor(2.2916)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1140 tensor(2.2889)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1141 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1142 tensor(2.3046)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1143 tensor(2.2863)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1144 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1145 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1146 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1147 tensor(2.2964)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1148 tensor(2.2871)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1149 tensor(2.2747)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1150 tensor(2.2822)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1151 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1152 tensor(2.2839)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1153 tensor(2.2934)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1154 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1155 tensor(2.2985)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1156 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1157 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1158 tensor(2.3029)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1159 tensor(2.2881)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1160 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1161 tensor(2.3071)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1162 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1163 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1164 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1165 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1166 tensor(2.3207)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1167 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1168 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1169 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1170 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1171 tensor(2.2808)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1172 tensor(2.2836)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1173 tensor(2.2597)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1174 tensor(2.3269)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1175 tensor(2.3227)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1176 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1177 tensor(2.2928)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1178 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1179 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1180 tensor(2.2871)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1181 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1182 tensor(2.2727)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1183 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1184 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1185 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1186 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1187 tensor(2.3158)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1188 tensor(2.3218)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1189 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1190 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1191 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1192 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1193 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1194 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1195 tensor(2.3183)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1196 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1197 tensor(2.2670)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1198 tensor(2.2905)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1199 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1200 tensor(2.3085)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1201 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1202 tensor(2.3072)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1203 tensor(2.2827)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1204 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1205 tensor(2.2899)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1206 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1207 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1208 tensor(2.2735)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1209 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1210 tensor(2.3149)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1211 tensor(2.2805)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1212 tensor(2.2865)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1213 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1214 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1215 tensor(2.3050)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1216 tensor(2.3128)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1217 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1218 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1219 tensor(2.3113)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1220 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1221 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1222 tensor(2.3025)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1223 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1224 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1225 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1226 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1227 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1228 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1229 tensor(2.3049)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1230 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1231 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1232 tensor(2.2939)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1233 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1234 tensor(2.3211)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1235 tensor(2.2794)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1236 tensor(2.2814)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1237 tensor(2.3081)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1238 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1239 tensor(2.3020)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1240 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1241 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1242 tensor(2.3071)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1243 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1244 tensor(2.3015)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1245 tensor(2.2964)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1246 tensor(2.3091)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1247 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1248 tensor(2.2888)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1249 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1250 tensor(2.3086)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1251 tensor(2.3008)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1252 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1253 tensor(2.3166)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1254 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1255 tensor(2.3166)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1256 tensor(2.2908)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1257 tensor(2.3102)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1258 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1259 tensor(2.3130)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1260 tensor(2.3086)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1261 tensor(2.3243)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1262 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1263 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1264 tensor(2.2978)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1265 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1266 tensor(2.2816)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1267 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1268 tensor(2.2906)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1269 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1270 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1271 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1272 tensor(2.2912)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1273 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1274 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1275 tensor(2.3034)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1276 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1277 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1278 tensor(2.2916)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1279 tensor(2.3069)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1280 tensor(2.2860)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1281 tensor(2.3070)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1282 tensor(2.2829)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1283 tensor(2.3008)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1284 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1285 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1286 tensor(2.2957)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1287 tensor(2.3064)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1288 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1289 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1290 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1291 tensor(2.2905)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1292 tensor(2.2922)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1293 tensor(2.2914)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1294 tensor(2.3138)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1295 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1296 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1297 tensor(2.2789)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1298 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1299 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1300 tensor(2.2797)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1301 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1302 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1303 tensor(2.2868)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1304 tensor(2.2865)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1305 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1306 tensor(2.2774)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1307 tensor(2.3102)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1308 tensor(2.3105)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1309 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1310 tensor(2.3063)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1311 tensor(2.2771)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1312 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1313 tensor(2.3141)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1314 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1315 tensor(2.3100)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1316 tensor(2.2926)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1317 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1318 tensor(2.3163)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1319 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1320 tensor(2.3052)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1321 tensor(2.3072)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1322 tensor(2.2836)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1323 tensor(2.3265)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1324 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1325 tensor(2.3055)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1326 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1327 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1328 tensor(2.2956)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1329 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1330 tensor(2.3051)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1331 tensor(2.3120)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1332 tensor(2.2847)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1333 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1334 tensor(2.2953)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1335 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1336 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1337 tensor(2.3014)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1338 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1339 tensor(2.2857)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1340 tensor(2.2870)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1341 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1342 tensor(2.2919)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1343 tensor(2.3118)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1344 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1345 tensor(2.2862)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1346 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1347 tensor(2.2898)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1348 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1349 tensor(2.3174)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1350 tensor(2.3086)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1351 tensor(2.2948)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1352 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1353 tensor(2.2895)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1354 tensor(2.3124)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1355 tensor(2.2739)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1356 tensor(2.3085)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1357 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1358 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1359 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1360 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1361 tensor(2.2879)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1362 tensor(2.2912)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1363 tensor(2.2859)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1364 tensor(2.3095)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1365 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1366 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1367 tensor(2.2920)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1368 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1369 tensor(2.2887)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1370 tensor(2.3095)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1371 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1372 tensor(2.2872)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1373 tensor(2.2902)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1374 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1375 tensor(2.3231)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1376 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1377 tensor(2.3101)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1378 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1379 tensor(2.2948)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1380 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1381 tensor(2.2940)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1382 tensor(2.3094)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1383 tensor(2.2960)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1384 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1385 tensor(2.3028)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1386 tensor(2.2922)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1387 tensor(2.2954)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1388 tensor(2.3000)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1389 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1390 tensor(2.3113)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1391 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1392 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1393 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1394 tensor(2.2976)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1395 tensor(2.2787)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1396 tensor(2.3040)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1397 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1398 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1399 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1400 tensor(2.2778)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1401 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1402 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1403 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1404 tensor(2.2777)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1405 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1406 tensor(2.2752)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1407 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1408 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1409 tensor(2.2962)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1410 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1411 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1412 tensor(2.3131)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1413 tensor(2.3034)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1414 tensor(2.2924)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1415 tensor(2.2764)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1416 tensor(2.2835)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1417 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1418 tensor(2.2886)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1419 tensor(2.3151)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1420 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1421 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1422 tensor(2.2879)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1423 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1424 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1425 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1426 tensor(2.2996)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1427 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1428 tensor(2.2964)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1429 tensor(2.3037)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1430 tensor(2.2803)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1431 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1432 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1433 tensor(2.3083)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1434 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1435 tensor(2.2854)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1436 tensor(2.2881)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1437 tensor(2.2772)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1438 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1439 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1440 tensor(2.2616)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1441 tensor(2.3044)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1442 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1443 tensor(2.2816)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1444 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1445 tensor(2.2945)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1446 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1447 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1448 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1449 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1450 tensor(2.2902)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1451 tensor(2.2912)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1452 tensor(2.3176)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1453 tensor(2.2947)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1454 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1455 tensor(2.2876)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1456 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1457 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1458 tensor(2.2880)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1459 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1460 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1461 tensor(2.2916)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1462 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1463 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1464 tensor(2.2765)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1465 tensor(2.3024)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1466 tensor(2.3088)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1467 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1468 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1469 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1470 tensor(2.2854)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1471 tensor(2.2947)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1472 tensor(2.3092)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1473 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1474 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1475 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1476 tensor(2.2890)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1477 tensor(2.2960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1478 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1479 tensor(2.2768)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1480 tensor(2.2943)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1481 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1482 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1483 tensor(2.3051)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1484 tensor(2.3057)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1485 tensor(2.2763)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1486 tensor(2.2822)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1487 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1488 tensor(2.2890)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1489 tensor(2.2902)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1490 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1491 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1492 tensor(2.3051)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1493 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1494 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1495 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1496 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1497 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1498 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1499 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1500 tensor(2.2817)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1501 tensor(2.2837)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1502 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1503 tensor(2.2911)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1504 tensor(2.3015)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1505 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1506 tensor(2.2826)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1507 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1508 tensor(2.2928)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1509 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1510 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1511 tensor(2.2887)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1512 tensor(2.2812)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1513 tensor(2.2834)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1514 tensor(2.2815)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1515 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1516 tensor(2.3076)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1517 tensor(2.2835)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1518 tensor(2.2842)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1519 tensor(2.2941)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1520 tensor(2.2913)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1521 tensor(2.3030)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1522 tensor(2.2823)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1523 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1524 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1525 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1526 tensor(2.2802)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1527 tensor(2.3138)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1528 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1529 tensor(2.2855)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1530 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1531 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1532 tensor(2.3132)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1533 tensor(2.3018)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1534 tensor(2.3038)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1535 tensor(2.3006)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1536 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1537 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1538 tensor(2.3032)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1539 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1540 tensor(2.3098)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1541 tensor(2.3157)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1542 tensor(2.2906)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1543 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1544 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1545 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1546 tensor(2.2867)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1547 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1548 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1549 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1550 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1551 tensor(2.2838)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1552 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1553 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1554 tensor(2.2866)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1555 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1556 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1557 tensor(2.2682)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1558 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1559 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1560 tensor(2.2813)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1561 tensor(2.2799)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1562 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1563 tensor(2.2905)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1564 tensor(2.2804)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1565 tensor(2.2932)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1566 tensor(2.3091)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1567 tensor(2.3024)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1568 tensor(2.2720)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1569 tensor(2.3174)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1570 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1571 tensor(2.2900)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1572 tensor(2.2984)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1573 tensor(2.3118)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1574 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1575 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1576 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1577 tensor(2.2850)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1578 tensor(2.3007)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1579 tensor(2.3033)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1580 tensor(2.2785)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1581 tensor(2.2988)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1582 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1583 tensor(2.2879)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1584 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1585 tensor(2.2692)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1586 tensor(2.2724)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1587 tensor(2.2859)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1588 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1589 tensor(2.2775)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1590 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1591 tensor(2.2949)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1592 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1593 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1594 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1595 tensor(2.2904)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1596 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1597 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1598 tensor(2.3032)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1599 tensor(2.2938)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1600 tensor(2.2894)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1601 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1602 tensor(2.3080)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1603 tensor(2.2875)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1604 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1605 tensor(2.3054)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1606 tensor(2.2886)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1607 tensor(2.2879)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1608 tensor(2.2874)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1609 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1610 tensor(2.3053)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1611 tensor(2.2804)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1612 tensor(2.2829)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1613 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1614 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1615 tensor(2.2955)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1616 tensor(2.2760)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1617 tensor(2.2955)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1618 tensor(2.2999)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1619 tensor(2.2884)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1620 tensor(2.2852)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1621 tensor(2.2875)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1622 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1623 tensor(2.2856)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1624 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1625 tensor(2.2790)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1626 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1627 tensor(2.3095)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1628 tensor(2.3138)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1629 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1630 tensor(2.3029)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1631 tensor(2.3090)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1632 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1633 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1634 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1635 tensor(2.2995)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1636 tensor(2.3108)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1637 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1638 tensor(2.2903)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1639 tensor(2.3119)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1640 tensor(2.3005)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1641 tensor(2.3015)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1642 tensor(2.3060)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1643 tensor(2.2948)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1644 tensor(2.2950)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1645 tensor(2.2943)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1646 tensor(2.2751)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1647 tensor(2.2960)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1648 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1649 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1650 tensor(2.3105)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1651 tensor(2.2875)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1652 tensor(2.3073)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1653 tensor(2.3026)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1654 tensor(2.2745)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1655 tensor(2.3059)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1656 tensor(2.2882)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1657 tensor(2.3132)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1658 tensor(2.2863)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1659 tensor(2.2857)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1660 tensor(2.2822)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1661 tensor(2.2983)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1662 tensor(2.2741)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1663 tensor(2.3043)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1664 tensor(2.2761)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1665 tensor(2.3039)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1666 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1667 tensor(2.2913)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1668 tensor(2.2937)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1669 tensor(2.3145)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1670 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1671 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1672 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1673 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1674 tensor(2.3045)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1675 tensor(2.2934)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1676 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1677 tensor(2.2912)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1678 tensor(2.2976)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1679 tensor(2.2840)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1680 tensor(2.2843)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1681 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1682 tensor(2.2812)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1683 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1684 tensor(2.3014)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1685 tensor(2.2853)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1686 tensor(2.2841)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1687 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1688 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1689 tensor(2.3052)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1690 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1691 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1692 tensor(2.2762)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1693 tensor(2.2786)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1694 tensor(2.2961)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1695 tensor(2.2930)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1696 tensor(2.2783)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1697 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1698 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1699 tensor(2.3027)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1700 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1701 tensor(2.3102)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1702 tensor(2.2955)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1703 tensor(2.2833)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1704 tensor(2.3029)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1705 tensor(2.2964)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1706 tensor(2.3099)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1707 tensor(2.2978)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1708 tensor(2.2994)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1709 tensor(2.2791)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1710 tensor(2.2897)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1711 tensor(2.2744)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1712 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1713 tensor(2.2849)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1714 tensor(2.2830)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1715 tensor(2.2958)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1716 tensor(2.3079)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1717 tensor(2.3074)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1718 tensor(2.2832)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1719 tensor(2.3031)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1720 tensor(2.2656)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1721 tensor(2.3121)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1722 tensor(2.2803)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1723 tensor(2.2731)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1724 tensor(2.2749)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1725 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1726 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1727 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1728 tensor(2.2933)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1729 tensor(2.3035)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1730 tensor(2.2892)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1731 tensor(2.2869)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1732 tensor(2.2942)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1733 tensor(2.3077)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1734 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1735 tensor(2.2891)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1736 tensor(2.3080)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1737 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1738 tensor(2.2788)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1739 tensor(2.2990)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1740 tensor(2.2979)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1741 tensor(2.2969)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1742 tensor(2.2960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1743 tensor(2.3010)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1744 tensor(2.2864)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1745 tensor(2.2882)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1746 tensor(2.2879)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1747 tensor(2.3065)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1748 tensor(2.2851)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1749 tensor(2.2940)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1750 tensor(2.2883)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1751 tensor(2.3004)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1752 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1753 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1754 tensor(2.2873)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1755 tensor(2.3011)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1756 tensor(2.2832)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1757 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1758 tensor(2.3012)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1759 tensor(2.2893)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1760 tensor(2.3048)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1761 tensor(2.2775)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1762 tensor(2.2929)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1763 tensor(2.2699)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1764 tensor(2.2811)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1765 tensor(2.3058)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1766 tensor(2.2972)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1767 tensor(2.2985)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1768 tensor(2.3033)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1769 tensor(2.2975)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1770 tensor(2.2764)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1771 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1772 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1773 tensor(2.2803)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1774 tensor(2.3072)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1775 tensor(2.2952)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1776 tensor(2.3056)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1777 tensor(2.2848)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1778 tensor(2.2931)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1779 tensor(2.3068)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1780 tensor(2.3140)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1781 tensor(2.2885)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1782 tensor(2.3048)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1783 tensor(2.3023)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1784 tensor(2.3019)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1785 tensor(2.2971)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1786 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1787 tensor(2.2951)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1788 tensor(2.3015)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1789 tensor(2.2981)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1790 tensor(2.2959)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1791 tensor(2.3036)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1792 tensor(2.3028)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1793 tensor(2.2917)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1794 tensor(2.2914)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1795 tensor(2.2989)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1796 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1797 tensor(2.2991)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1798 tensor(2.3001)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1799 tensor(2.3066)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1800 tensor(2.3025)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1801 tensor(2.3013)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1802 tensor(2.2837)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1803 tensor(2.2940)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1804 tensor(2.2943)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1805 tensor(2.2817)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1806 tensor(2.2967)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1807 tensor(2.2937)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1808 tensor(2.2815)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1809 tensor(2.2889)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1810 tensor(2.3047)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1811 tensor(2.2915)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1812 tensor(2.2982)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1813 tensor(2.3009)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1814 tensor(2.2907)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1815 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1816 tensor(2.2832)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1817 tensor(2.2928)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1818 tensor(2.2926)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1819 tensor(2.2894)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1820 tensor(2.2846)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1821 tensor(2.2946)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1822 tensor(2.2821)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1823 tensor(2.2970)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1824 tensor(2.2943)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1825 tensor(2.2904)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1826 tensor(2.2985)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1827 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1828 tensor(2.3016)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1829 tensor(2.2889)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1830 tensor(2.2986)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1831 tensor(2.2900)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1832 tensor(2.2993)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1833 tensor(2.2846)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1834 tensor(2.2884)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1835 tensor(2.2861)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1836 tensor(2.2947)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1837 tensor(2.2966)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1838 tensor(2.3068)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1839 tensor(2.2973)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1840 tensor(2.2968)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1841 tensor(2.2918)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1842 tensor(2.2909)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1843 tensor(2.2879)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1844 tensor(2.3003)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1845 tensor(2.2896)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1846 tensor(2.2772)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1847 tensor(2.2965)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1848 tensor(2.2860)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1849 tensor(2.2870)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1850 tensor(2.3002)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1851 tensor(2.2923)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1852 tensor(2.2798)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1853 tensor(2.2985)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1854 tensor(2.2996)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1855 tensor(2.2878)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1856 tensor(2.2871)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1857 tensor(2.2936)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1858 tensor(2.2997)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1859 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1860 tensor(2.2803)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1861 tensor(2.2980)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1862 tensor(2.2719)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1863 tensor(2.2876)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1864 tensor(2.3066)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1865 tensor(2.2987)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1866 tensor(2.3022)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1867 tensor(2.2900)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1868 tensor(2.2813)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1869 tensor(2.2910)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1870 tensor(2.2795)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1871 tensor(2.2977)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1872 tensor(2.2963)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1873 tensor(2.2872)\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 784])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "1874 tensor(2.3056)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.l1=torch.nn.Linear(28*28,28)\n",
    "        self.l2=torch.nn.Linear(28, 14)\n",
    "        self.l3=torch.nn.Linear(14,10)\n",
    "         \n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "         \n",
    "    def forward(self,x):\n",
    "        x = self.sigmoid(self.l1(x))\n",
    "        x = self.sigmoid(self.l2(x))\n",
    "        x = self.sigmoid(self.l3(x))\n",
    "        return x\n",
    "    \n",
    "model = MyModel()\n",
    " \n",
    "criterion = torch.nn.BCELoss(size_average = True) #BCE는 같은 SIZE가 들어가야함\n",
    "loss_function = nn.CrossEntropyLoss() #BATCH X LABELS VS BATCH 로 들어가야함\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "# Training loop\n",
    "\n",
    "for i, (data, target) in enumerate(train_loader):\n",
    "    # get the inputs\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    print(data.shape)\n",
    "    data = data.view(32,28*28) #차원줄여줌 32x1x28x28 -> 32x784\n",
    "    print(data.shape)\n",
    "    x = model(data)\n",
    "    print(x.size()) #model의 size 32X10\n",
    "    #x = x.view(32) # 차원없애기 \n",
    "    print(x.shape)\n",
    "    print(target.shape)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    #loss = criterion(x, target.type('torch.FloatTensor')) #왼쪽 shape 이 뭐로 들어가야는지 알아야한다 # float 로 바꿔줌!!\n",
    "    loss = loss_function(x,target)\n",
    "    print( i, loss.data)\n",
    " \n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 =  0.35667494393873245\n",
      "loss2 =  2.3025850929940455\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4966)\n",
      "tensor(1.1083)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
