{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "learning_rate = 0.0002\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.CenterCrop(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = dset.CIFAR10('./',train =True, download = True, transform = transform)\n",
    "testset = dset.CIFAR10('./',train =False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(testset,batch_size=batch_size,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_dim,mid_dim,out_dim):\n",
    "        super(block,self).__init__()\n",
    "        self.res =  nn.Sequential(\n",
    "            nn.Conv2d(in_dim,mid_dim,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_dim,out_dim,3,1,1)\n",
    "            )\n",
    "               \n",
    "    def forward(self,x):\n",
    "        out = self.res(x)\n",
    "        #print(\"block res :\",out.size())\n",
    "        #out = torch.cat([out,x],dim =1) \n",
    "        out = torch.add(out,x)\n",
    "        #print(\"block res+ x :\",out.size())\n",
    "        out = Variable(out)\n",
    "    \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(model,self).__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,7,2,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2,1),\n",
    "        )\n",
    "        self.block1 = block(32,64,32)\n",
    "        self.block2 = block(32,64,32)\n",
    "        self.fc1 =nn.Linear(100352,1000)\n",
    "        self.fc2 =nn.Linear(1000,10)\n",
    "    def forward(self,y):\n",
    "        y = self.layer_1(y)\n",
    "        #print(y.size())\n",
    "        y = self.block1(y)\n",
    "        #print(y.size())\n",
    "        y = self.block2(y)\n",
    "        #print(y.size())\n",
    "        \n",
    "        y = y.view(y.size(0),-1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.fc2(y)\n",
    "        return y\n",
    "\n",
    "resnet = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(),lr =0.0002 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(2.3755, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(56.1840, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(48.0927, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(49.0618, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(59.7707, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(46.1574, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(53.1658, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(61.5964, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(62.0798, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(40.4856, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(49.0406, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(57.7520, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(36.0196, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(29.0361, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(30.4336, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(27.9937, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(19.9358, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(25.0055, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(22.6653, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(18.8272, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(27.2052, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(26.2307, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(14.0110, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(13.1111, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(13.8614, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(19.8502, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(20.9856, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(16.9879, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(16.9049, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(22.1351, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(15.7447, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(15.7493, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(22.0612, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.3717, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.7296, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.9109, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.2883, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(14.9290, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(15.7241, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.4717, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.5781, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.8657, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.5673, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.7572, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.2616, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.1119, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.6483, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.8382, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.3347, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.9409, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.3442, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.4517, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.9064, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.0543, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.3582, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.1863, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.4234, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.8860, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(17.3600, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(12.1772, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.1203, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.0227, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.5095, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.7679, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.3897, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(12.0882, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(12.8236, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.4178, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(4.3654, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.9902, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(3.3888, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(4.6775, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.6706, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.9736, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.8063, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.3947, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.9775, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.8689, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.2797, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.3212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.3833, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.1656, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.5873, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.5634, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.9905, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.8727, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.7791, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.2571, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.8594, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.3873, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.4396, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.7970, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.6993, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.6008, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.3616, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.4670, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.0815, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.8942, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.3909, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.6627, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(4.9606, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.3296, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9450, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.9031, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.4281, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.1136, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.9740, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.2662, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.3279, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.0762, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.9226, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.6419, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.5284, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.6760, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.5366, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.8570, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.4496, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.8399, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(9.6116, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.9284, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.7525, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.3837, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.2593, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.1026, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.0452, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.1983, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(11.0503, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(10.8744, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.2100, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.6483, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(4.9174, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(4.8663, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.7229, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(5.0887, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(3.9704, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.9464, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(7.0463, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(6.8229, grad_fn=<NllLossBackward>)\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(8.1576, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23c0112cef2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-81cbd95f18cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(y.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(y.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-163cb3602b8a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(\"block res :\",out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#out = torch.cat([out,x],dim =1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    for j,(img, label) in enumerate(train_loader):\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = resnet(img)\n",
    "        print(output.size())\n",
    "        print(label.size())\n",
    "        loss = loss_f(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 43.000000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    data = img, label\n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    output = resnet(img)\n",
    "    _,pridicted = torch.max(output,-1)\n",
    "    total += label.size(0)\n",
    "    correct += (pridicted == label).sum()\n",
    "    \n",
    "print(' accuracy: %f'%(100*correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block1(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_dim,mid_dim,out_dim):\n",
    "        super(block1,self).__init__()\n",
    "        self.res =  nn.Sequential(\n",
    "            nn.Conv2d(in_dim,mid_dim,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_dim,out_dim,3,1,1)\n",
    "            )\n",
    "               \n",
    "    def forward(self,x):\n",
    "        out = self.res(x)\n",
    "        #print(\"block res :\",out.size())\n",
    "        #out = torch.cat([out,x],dim =1) \n",
    "        #out = torch.add(out,x)\n",
    "        #print(\"block res+ x :\",out.size())\n",
    "        #out = Variable(out)\n",
    "    \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(model1,self).__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,7,2,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2,1),\n",
    "        )\n",
    "        self.block1 = block1(32,64,32)\n",
    "        self.block2 = block1(32,64,32)\n",
    "        self.fc1 =nn.Linear(100352,1000)\n",
    "        self.fc2 =nn.Linear(1000,10)\n",
    "    def forward(self,y):\n",
    "        y = self.layer_1(y)\n",
    "        #print(y.size())\n",
    "        y = self.block1(y)\n",
    "        #print(y.size())\n",
    "        y = self.block2(y)\n",
    "        #print(y.size())\n",
    "        \n",
    "        y = y.view(y.size(0),-1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.fc2(y)\n",
    "        return y\n",
    "\n",
    "resnet_noadd = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3066, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3102, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3020, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3063, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2950, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3038, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3055, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3100, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2979, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3083, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2998, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3074, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3139, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3038, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3097, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3081, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3028, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2989, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3087, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2933, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3133, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3119, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2998, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3036, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3044, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2977, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2989, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2988, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3069, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2977, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2992, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2946, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2956, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3044, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3070, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3024, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2983, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3005, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3033, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3056, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3031, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3021, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3053, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3112, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2993, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2975, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3101, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3036, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3070, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3069, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2944, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3080, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3016, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2986, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3021, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2981, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3022, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3035, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3091, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3098, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3013, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3008, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2961, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3060, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2985, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2974, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3037, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2968, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3115, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3109, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3023, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3014, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2988, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2986, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3047, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3125, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2978, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3035, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3087, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2960, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2998, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3079, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3058, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2976, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2934, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3054, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2970, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3049, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2852, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2996, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3034, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3090, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2977, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3035, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3021, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3053, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3013, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3061, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3029, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3028, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3078, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3096, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3098, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2988, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3044, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3044, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3081, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3013, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3054, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3040, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3079, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3065, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3087, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3068, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2919, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2984, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3036, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3012, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2978, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2967, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3077, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3091, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3149, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3103, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3087, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3069, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3005, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3042, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3109, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3007, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2993, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2995, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3075, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3022, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2995, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3077, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3029, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2999, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3112, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2896, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2917, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3048, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3048, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3064, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2974, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3074, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3029, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3003, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3067, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2982, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3075, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3109, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3068, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3066, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3032, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2963, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3102, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2937, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3064, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3061, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3125, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3023, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3034, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2966, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3077, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3060, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2958, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3034, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2999, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3158, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3049, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3016, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2979, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3067, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2963, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2982, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2992, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3154, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3110, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3062, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3135, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3118, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2964, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3107, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3023, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3000, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3070, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3109, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2983, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3014, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3055, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3119, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2969, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3042, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3017, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2996, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3011, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3013, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3084, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2972, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3049, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3060, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3047, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3129, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3036, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3052, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2982, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3056, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3014, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3031, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2947, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2971, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3128, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2946, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2987, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3020, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2888, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2979, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3035, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3045, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "    for j,(img, label) in enumerate(test_loader):\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = resnet_noadd(img)\n",
    "        loss = loss_f(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 18.000000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in train_loader:\n",
    "    data = img,label\n",
    "    img = Variable(img)\n",
    "    label = Variable(label)\n",
    "    \n",
    "    output = resnet_noadd(img)\n",
    "    _,pridicted = torch.max(output,-1)\n",
    "    total += label.size(0)\n",
    "    correct += (pridicted == label).sum()\n",
    "    \n",
    "print(' accuracy: %f'%(100*correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([5, 3]) 5 3 3 5\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-1348198cdd09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# numpy  \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5,3)\n",
    "print(a)\n",
    "print(a.size(),a.size(0), a.size(1), a.size(-1), a.size(-2))\n",
    "print(a.data) # a   \n",
    "print(a.shape) # a.size()  \n",
    "#print(a.shape(0)) - \n",
    "\n",
    "a = a.numpy() # numpy   \n",
    "# print(a.data()) \n",
    "\n",
    "print(a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
